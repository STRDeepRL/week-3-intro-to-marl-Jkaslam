{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6139973357319832, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009211670330842026, "policy_loss": -0.021557879867759765, "vf_loss": 0.022314847795496463, "vf_explained_var": 0.11132643967866898, "kl": 0.015596137434634012, "entropy": 1.9304424783835807, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.7269999999999999, "episode_reward_mean": -0.14007692307692304, "episode_len_mean": 205.6153846153846, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.016}, "policy_reward_max": {"blue_0": 0.895, "red_0": 0.744}, "policy_reward_mean": {"blue_0": -0.05215384615384615, "red_0": -0.08792307692307692}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2384258967636873, "mean_inference_ms": 1.6036950167552217, "mean_action_processing_ms": 0.06914888854313098, "mean_env_wait_ms": 0.11364608265583878, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02536773681640625, "StateBufferConnector_ms": 0.0015937365018404447, "ViewRequirementAgentConnector_ms": 0.03432402243980995}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.7269999999999999, "episode_reward_mean": -0.14007692307692304, "episode_len_mean": 205.6153846153846, "episodes_this_iter": 13, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.016}, "policy_reward_max": {"blue_0": 0.895, "red_0": 0.744}, "policy_reward_mean": {"blue_0": -0.05215384615384615, "red_0": -0.08792307692307692}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2384258967636873, "mean_inference_ms": 1.6036950167552217, "mean_action_processing_ms": 0.06914888854313098, "mean_env_wait_ms": 0.11364608265583878, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02536773681640625, "StateBufferConnector_ms": 0.0015937365018404447, "ViewRequirementAgentConnector_ms": 0.03432402243980995}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 95.69832033956021, "num_env_steps_trained_throughput_per_sec": 95.69832033956021, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 8000, "timers": {"training_iteration_time_ms": 41797.956, "sample_time_ms": 8150.845, "learn_time_ms": 33629.43, "learn_throughput": 118.943, "synch_weights_time_ms": 17.173}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 13, "training_iteration": 1, "trial_id": "bb874_00000", "date": "2023-09-28_21-30-53", "timestamp": 1695951053, "time_this_iter_s": 41.799954891204834, "time_total_s": 41.799954891204834, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac442d70>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4deb90>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dcaf0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 41.799954891204834, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 33.72666666666667, "ram_util_percent": 24.851666666666674}, "win_rate": 0.5384615384615384, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8177963168049852, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0015780701787813693, "policy_loss": -0.01966668720342568, "vf_loss": 0.035602424360695294, "vf_explained_var": 0.18019972319404284, "kl": 0.01099712329635988, "entropy": 1.9120192573716244, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.7269999999999999, "episode_reward_mean": -0.13971875000000003, "episode_len_mean": 206.96875, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.0699999999999998, "red_0": 0.877}, "policy_reward_mean": {"blue_0": -0.06199999999999999, "red_0": -0.07771874999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2371920014681358, "mean_inference_ms": 1.5987782889323081, "mean_action_processing_ms": 0.06874953568486279, "mean_env_wait_ms": 0.1128537800274847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0235825777053833, "StateBufferConnector_ms": 0.0016320496797561646, "ViewRequirementAgentConnector_ms": 0.03403462469577789}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.7269999999999999, "episode_reward_mean": -0.13971875000000003, "episode_len_mean": 206.96875, "episodes_this_iter": 19, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.0699999999999998, "red_0": 0.877}, "policy_reward_mean": {"blue_0": -0.06199999999999999, "red_0": -0.07771874999999998}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2371920014681358, "mean_inference_ms": 1.5987782889323081, "mean_action_processing_ms": 0.06874953568486279, "mean_env_wait_ms": 0.1128537800274847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0235825777053833, "StateBufferConnector_ms": 0.0016320496797561646, "ViewRequirementAgentConnector_ms": 0.03403462469577789}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.59154103603277, "num_env_steps_trained_throughput_per_sec": 100.59154103603277, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 40781.36, "sample_time_ms": 8118.595, "learn_time_ms": 32645.028, "learn_throughput": 122.53, "synch_weights_time_ms": 17.251}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 32, "training_iteration": 2, "trial_id": "bb874_00000", "date": "2023-09-28_21-31-33", "timestamp": 1695951093, "time_this_iter_s": 39.76676082611084, "time_total_s": 81.56671571731567, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab0b6380>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac324ca0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf01480>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 81.56671571731567, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 35.463157894736845, "ram_util_percent": 24.93859649122807}, "win_rate": 0.5625, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9389905198787649, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.01828167272930538, "policy_loss": -0.01647823884365304, "vf_loss": 0.067788824159652, "vf_explained_var": 0.10368988501528899, "kl": 0.013765549334074896, "entropy": 1.8876097151388724, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.15107407407407414, "episode_len_mean": 196.62962962962962, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": -0.009333333333333336, "red_0": -0.1417407407407407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2353131938934556, "mean_inference_ms": 1.5812961379182697, "mean_action_processing_ms": 0.06769689641495032, "mean_env_wait_ms": 0.1114262560187332, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021975349496912072, "StateBufferConnector_ms": 0.0015857043089690032, "ViewRequirementAgentConnector_ms": 0.0328591576328984}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.15107407407407414, "episode_len_mean": 196.62962962962962, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": -0.009333333333333336, "red_0": -0.1417407407407407}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2353131938934556, "mean_inference_ms": 1.5812961379182697, "mean_action_processing_ms": 0.06769689641495032, "mean_env_wait_ms": 0.1114262560187332, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021975349496912072, "StateBufferConnector_ms": 0.0015857043089690032, "ViewRequirementAgentConnector_ms": 0.0328591576328984}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.6092372946315, "num_env_steps_trained_throughput_per_sec": 102.6092372946315, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 24000, "timers": {"training_iteration_time_ms": 40181.852, "sample_time_ms": 7886.939, "learn_time_ms": 32277.123, "learn_throughput": 123.927, "synch_weights_time_ms": 17.309}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 54, "training_iteration": 3, "trial_id": "bb874_00000", "date": "2023-09-28_21-32-12", "timestamp": 1695951132, "time_this_iter_s": 38.984740018844604, "time_total_s": 120.55145573616028, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac442590>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4df1c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4de290>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 120.55145573616028, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 35.090909090909086, "ram_util_percent": 25.012727272727265}, "win_rate": 0.5, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9896719654090702, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.005176820788619807, "policy_loss": -0.02130928292220536, "vf_loss": 0.05034370809250201, "vf_explained_var": 0.18233506189038357, "kl": 0.016004748777753177, "entropy": 1.8867001639058192, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.186171052631579, "episode_len_mean": 193.3421052631579, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": 0.008276315789473694, "red_0": -0.1944473684210526}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23361309689521814, "mean_inference_ms": 1.5672393722135347, "mean_action_processing_ms": 0.06683581866093537, "mean_env_wait_ms": 0.1102295728315114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021088437030189915, "StateBufferConnector_ms": 0.0015501913271452252, "ViewRequirementAgentConnector_ms": 0.03218211625751696}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.186171052631579, "episode_len_mean": 193.3421052631579, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": 0.008276315789473694, "red_0": -0.1944473684210526}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23361309689521814, "mean_inference_ms": 1.5672393722135347, "mean_action_processing_ms": 0.06683581866093537, "mean_env_wait_ms": 0.1102295728315114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021088437030189915, "StateBufferConnector_ms": 0.0015501913271452252, "ViewRequirementAgentConnector_ms": 0.03218211625751696}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.26855644155602, "num_env_steps_trained_throughput_per_sec": 102.26855644155602, "timesteps_total": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 39914.562, "sample_time_ms": 7773.062, "learn_time_ms": 32123.762, "learn_throughput": 124.518, "synch_weights_time_ms": 17.249}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 76, "training_iteration": 4, "trial_id": "bb874_00000", "date": "2023-09-28_21-32-51", "timestamp": 1695951171, "time_this_iter_s": 39.11472487449646, "time_total_s": 159.66618061065674, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac4fec50>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4de320>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dd000>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 159.66618061065674, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 34.99821428571429, "ram_util_percent": 25.099999999999998}, "win_rate": 0.47368421052631576, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9521578603424132, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01124092538811965, "policy_loss": -0.024202274389002316, "vf_loss": 0.022833293402315272, "vf_explained_var": 0.12017724222193162, "kl": 0.017071600708773737, "entropy": 1.8696172986179591, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.17436559139784946, "episode_len_mean": 201.18279569892474, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": -0.021591397849462353, "red_0": -0.1527741935483871}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2324401407971555, "mean_inference_ms": 1.5585476802868912, "mean_action_processing_ms": 0.0663115281194497, "mean_env_wait_ms": 0.10947240814470614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02078343463200395, "StateBufferConnector_ms": 0.0015515153126050068, "ViewRequirementAgentConnector_ms": 0.03183605850383799}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.17436559139784946, "episode_len_mean": 201.18279569892474, "episodes_this_iter": 17, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": -0.021591397849462353, "red_0": -0.1527741935483871}, "hist_stats": {"episode_reward": [0.42199999999999993, -0.7269999999999999, -0.46599999999999997, -0.45500000000000007, -0.2669999999999999, -0.07900000000000007, -0.08300000000000006, -0.5089999999999999, -0.10899999999999999, -0.32499999999999996, 0.42699999999999994, -0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008], "episode_lengths": [300, 217, 143, 140, 82, 300, 300, 158, 34, 99, 300, 300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300], "policy_blue_0_reward": [0.46199999999999997, -1.033, -1.015, 0.5609999999999999, -1.011, -0.04300000000000003, -0.04100000000000003, -1.025, 0.895, 0.691, 0.45699999999999996, -0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2324401407971555, "mean_inference_ms": 1.5585476802868912, "mean_action_processing_ms": 0.0663115281194497, "mean_env_wait_ms": 0.10947240814470614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02078343463200395, "StateBufferConnector_ms": 0.0015515153126050068, "ViewRequirementAgentConnector_ms": 0.03183605850383799}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.41047357113744, "num_env_steps_trained_throughput_per_sec": 102.41047357113744, "timesteps_total": 20000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 40000, "timers": {"training_iteration_time_ms": 39743.349, "sample_time_ms": 7714.482, "learn_time_ms": 32011.24, "learn_throughput": 124.956, "synch_weights_time_ms": 17.133}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 93, "training_iteration": 5, "trial_id": "bb874_00000", "date": "2023-09-28_21-33-31", "timestamp": 1695951211, "time_this_iter_s": 39.06051683425903, "time_total_s": 198.72669744491577, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab0b4b80>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4de680>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dd900>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 198.72669744491577, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 34.80181818181818, "ram_util_percent": 25.074545454545454}, "win_rate": 0.5161290322580645, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0201140133664013, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0009758365022814057, "policy_loss": -0.01625415968640785, "vf_loss": 0.034081607703895615, "vf_explained_var": 0.11973502629746993, "kl": 0.010256163248598495, "entropy": 1.8620403016606966, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "sampler_results": {"episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.15617000000000003, "episode_len_mean": 205.44, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": 0.02012000000000001, "red_0": -0.17629}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999], "episode_lengths": [300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300], "policy_blue_0_reward": [-0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2308848378680079, "mean_inference_ms": 1.54585452594706, "mean_action_processing_ms": 0.06553267621356577, "mean_env_wait_ms": 0.10834548453013541, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02021956443786621, "StateBufferConnector_ms": 0.0015418529510498047, "ViewRequirementAgentConnector_ms": 0.03142356872558594}}, "episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.15617000000000003, "episode_len_mean": 205.44, "episodes_this_iter": 18, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.096, "red_0": 0.961}, "policy_reward_mean": {"blue_0": 0.02012000000000001, "red_0": -0.17629}, "hist_stats": {"episode_reward": [-0.08900000000000007, 0.43899999999999995, -0.6960000000000001, -0.3410000000000001, -0.1309999999999999, 0.4109999999999999, 0.04299999999999993, 0.4049999999999999, 0.128, -0.561, -0.532, -0.30299999999999994, -0.15899999999999992, 0.42599999999999993, -0.08200000000000006, -0.08100000000000007, -0.3629999999999999, -0.684, -0.06800000000000005, -0.08100000000000006, 0.018999999999999906, 0.42899999999999994, 0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999], "episode_lengths": [300, 300, 208, 260, 42, 300, 137, 300, 113, 169, 161, 247, 50, 300, 300, 300, 110, 210, 300, 300, 143, 300, 300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300], "policy_blue_0_reward": [-0.04200000000000003, 0.46599999999999997, 0.346, 0.6719999999999999, -1.008, 0.44999999999999996, 1.0699999999999998, 0.45499999999999996, -0.514, -1.025, 0.49, -0.5289999999999999, -1.0059999999999998, 0.46299999999999997, -0.04300000000000003, -0.046000000000000034, -1.015, -1.028, -0.04000000000000003, -0.04300000000000003, 1.045, 0.45899999999999996, 0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2308848378680079, "mean_inference_ms": 1.54585452594706, "mean_action_processing_ms": 0.06553267621356577, "mean_env_wait_ms": 0.10834548453013541, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02021956443786621, "StateBufferConnector_ms": 0.0015418529510498047, "ViewRequirementAgentConnector_ms": 0.03142356872558594}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.80399489946525, "num_env_steps_trained_throughput_per_sec": 101.80399489946525, "timesteps_total": 24000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 39667.987, "sample_time_ms": 7681.013, "learn_time_ms": 31969.386, "learn_throughput": 125.12, "synch_weights_time_ms": 17.095}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 111, "training_iteration": 6, "trial_id": "bb874_00000", "date": "2023-09-28_21-34-10", "timestamp": 1695951250, "time_this_iter_s": 39.2931866645813, "time_total_s": 238.01988410949707, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab0b5420>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4dd870>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4ddb40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 238.01988410949707, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 34.44285714285714, "ram_util_percent": 25.060714285714287}, "win_rate": 0.5, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0821536605246365, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9913272373960354e-05, "policy_loss": -0.022436007813181884, "vf_loss": 0.04317993151683671, "vf_explained_var": 0.11997618228197098, "kl": 0.013648930382719863, "entropy": 1.8538300710419813, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "sampler_results": {"episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.20002000000000003, "episode_len_mean": 202.16, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.039}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.961}, "policy_reward_mean": {"blue_0": -0.05713000000000001, "red_0": -0.14289}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001], "episode_lengths": [300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190], "policy_blue_0_reward": [0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22850350807371203, "mean_inference_ms": 1.5274929898987153, "mean_action_processing_ms": 0.06441189059292951, "mean_env_wait_ms": 0.10681013146751955, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0193789005279541, "StateBufferConnector_ms": 0.0015053749084472656, "ViewRequirementAgentConnector_ms": 0.03072202205657959}}, "episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.9920000000000002, "episode_reward_mean": -0.20002000000000003, "episode_len_mean": 202.16, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.064, "red_0": -1.039}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.961}, "policy_reward_mean": {"blue_0": -0.05713000000000001, "red_0": -0.14289}, "hist_stats": {"episode_reward": [0.41899999999999993, -0.08100000000000006, -0.4740000000000001, -0.376, -0.30700000000000005, 0.3670000000000001, -0.5800000000000001, -0.14800000000000002, -0.778, -0.9920000000000002, -0.040999999999999814, 0.4179999999999999, 0.08000000000000007, -0.12400000000000011, -0.06900000000000006, 0.3949999999999999, -0.22999999999999998, -0.512, -0.391, -0.29100000000000004, -0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001], "episode_lengths": [300, 300, 145, 118, 248, 42, 179, 46, 238, 291, 13, 300, 129, 192, 300, 300, 71, 155, 119, 89, 120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190], "policy_blue_0_reward": [0.45399999999999996, -0.04500000000000003, 0.5409999999999999, -1.013, -0.528, -0.5019999999999999, 0.43499999999999994, -1.006, 0.257, -1.064, -1.0019999999999998, 0.46299999999999997, 1.096, 0.9029999999999999, -0.04200000000000003, 0.44799999999999995, 0.781, 0.5099999999999999, -1.008, 0.722, 0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22850350807371203, "mean_inference_ms": 1.5274929898987153, "mean_action_processing_ms": 0.06441189059292951, "mean_env_wait_ms": 0.10681013146751955, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0193789005279541, "StateBufferConnector_ms": 0.0015053749084472656, "ViewRequirementAgentConnector_ms": 0.03072202205657959}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.61951757207913, "num_env_steps_trained_throughput_per_sec": 101.61951757207913, "timesteps_total": 28000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 56000, "timers": {"training_iteration_time_ms": 39624.346, "sample_time_ms": 7667.341, "learn_time_ms": 31939.467, "learn_throughput": 125.237, "synch_weights_time_ms": 17.04}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "done": false, "episodes_total": 133, "training_iteration": 7, "trial_id": "bb874_00000", "date": "2023-09-28_21-34-49", "timestamp": 1695951289, "time_this_iter_s": 39.364612102508545, "time_total_s": 277.3844962120056, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab42dd50>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf00af0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf02c20>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 277.3844962120056, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 34.408928571428575, "ram_util_percent": 25.044642857142858}, "win_rate": 0.55, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1931565647944808, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.005600725253952987, "policy_loss": -0.01696579423369258, "vf_loss": 0.044377769577355744, "vf_explained_var": 0.0753919061894218, "kl": 0.011064010665409739, "entropy": 1.835167512545983, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "sampler_results": {"episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.8690000000000001, "episode_reward_mean": -0.20302000000000003, "episode_len_mean": 204.68, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.039}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.07646000000000001, "red_0": -0.12656000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994], "episode_lengths": [120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300], "policy_blue_0_reward": [0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22712806593935803, "mean_inference_ms": 1.5186158997518222, "mean_action_processing_ms": 0.06384371109235132, "mean_env_wait_ms": 0.10603155377212854, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019207358360290527, "StateBufferConnector_ms": 0.0015047788619995117, "ViewRequirementAgentConnector_ms": 0.030588865280151367}}, "episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.8690000000000001, "episode_reward_mean": -0.20302000000000003, "episode_len_mean": 204.68, "episodes_this_iter": 20, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.039}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.07646000000000001, "red_0": -0.12656000000000003}, "hist_stats": {"episode_reward": [-0.401, -0.351, 0.4029999999999999, -0.08600000000000008, -0.5990000000000001, -0.7310000000000001, -0.802, -0.27, -0.16600000000000004, -0.6040000000000001, 0.42499999999999993, -0.503, -0.6949999999999998, -0.09500000000000007, 0.42099999999999993, -0.244, -0.515, -0.32699999999999996, -0.08600000000000006, -0.41500000000000015, -0.19399999999999995, -0.29200000000000004, -0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994], "episode_lengths": [120, 106, 300, 300, 179, 230, 242, 82, 51, 183, 300, 152, 215, 300, 300, 74, 152, 98, 300, 280, 58, 93, 81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300], "policy_blue_0_reward": [0.6209999999999999, -1.0179999999999998, 0.45799999999999996, -0.04000000000000003, 0.43699999999999994, 0.2769999999999999, 0.237, -1.011, 0.841, 0.42999999999999994, 0.45299999999999996, 0.5319999999999999, -1.0259999999999998, -0.046000000000000034, 0.45899999999999996, 0.769, 0.5239999999999999, -1.0159999999999998, -0.03300000000000002, -0.539, -1.013, 0.707, 0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22712806593935803, "mean_inference_ms": 1.5186158997518222, "mean_action_processing_ms": 0.06384371109235132, "mean_env_wait_ms": 0.10603155377212854, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019207358360290527, "StateBufferConnector_ms": 0.0015047788619995117, "ViewRequirementAgentConnector_ms": 0.030588865280151367}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.7149364930354, "num_env_steps_trained_throughput_per_sec": 101.7149364930354, "timesteps_total": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 39587.001, "sample_time_ms": 7653.185, "learn_time_ms": 31916.267, "learn_throughput": 125.328, "synch_weights_time_ms": 17.051}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "episodes_total": 153, "training_iteration": 8, "trial_id": "bb874_00000", "date": "2023-09-28_21-35-29", "timestamp": 1695951329, "time_this_iter_s": 39.327693700790405, "time_total_s": 316.712189912796, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab66d5a0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf008b0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf00e50>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 316.712189912796, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 34.74285714285714, "ram_util_percent": 25.00714285714286}, "win_rate": 0.57, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2998977567379673, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0003057932587883746, "policy_loss": -0.02323838674928993, "vf_loss": 0.04499915645380194, "vf_explained_var": 0.13303773421794177, "kl": 0.014187229433494982, "entropy": 1.7928439442068338, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "sampler_results": {"episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.8690000000000001, "episode_reward_mean": -0.18735, "episode_len_mean": 202.2, "episode_media": {}, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.034}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.18391000000000002, "red_0": -0.003440000000000013}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994, -0.31200000000000006, -0.2479999999999999, -0.17300000000000004, -0.21899999999999986, -0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997], "episode_lengths": [81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300, 248, 81, 55, 68, 161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101], "policy_blue_0_reward": [0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997, 0.717, -1.009, -1.008, -1.008, -0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2261595428164741, "mean_inference_ms": 1.5131809589826297, "mean_action_processing_ms": 0.0634677987174889, "mean_env_wait_ms": 0.10552347805328272, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019202589988708496, "StateBufferConnector_ms": 0.0015000104904174805, "ViewRequirementAgentConnector_ms": 0.030564069747924805}}, "episode_reward_max": 0.44799999999999995, "episode_reward_min": -0.8690000000000001, "episode_reward_mean": -0.18735, "episode_len_mean": 202.2, "episodes_this_iter": 22, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.034}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.18391000000000002, "red_0": -0.003440000000000013}, "hist_stats": {"episode_reward": [-0.265, -0.08100000000000007, 0.42599999999999993, 0.42799999999999994, -0.09500000000000007, -0.5520000000000002, 0.009999999999999787, -0.5529999999999999, -0.10400000000000008, -0.08000000000000006, 0.42199999999999993, -0.18400000000000005, -0.07700000000000005, -0.603, -0.08300000000000007, -0.20599999999999996, -0.628, -0.10700000000000008, -0.08200000000000006, -0.015999999999999903, -0.375, -0.392, -0.09300000000000007, 0.44799999999999995, -0.08000000000000006, -0.02400000000000002, -0.08100000000000007, 0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994, -0.31200000000000006, -0.2479999999999999, -0.17300000000000004, -0.21899999999999986, -0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997], "episode_lengths": [81, 180, 300, 300, 300, 168, 152, 166, 300, 300, 300, 211, 300, 187, 300, 65, 187, 300, 300, 161, 117, 123, 300, 300, 300, 164, 300, 300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300, 248, 81, 55, 68, 161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101], "policy_blue_0_reward": [0.751, -0.521, 0.44399999999999995, 0.45599999999999996, -0.05000000000000004, -1.023, 1.023, -1.025, -0.04400000000000003, -0.04200000000000003, 0.45299999999999996, -0.526, -0.04400000000000003, -1.032, -0.05100000000000004, -1.01, 0.406, -0.05100000000000004, -0.03300000000000002, 0.998, 0.638, 0.612, -0.04300000000000003, 0.469, -0.04100000000000003, -0.518, -0.04300000000000003, 0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997, 0.717, -1.009, -1.008, -1.008, -0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2261595428164741, "mean_inference_ms": 1.5131809589826297, "mean_action_processing_ms": 0.0634677987174889, "mean_env_wait_ms": 0.10552347805328272, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019202589988708496, "StateBufferConnector_ms": 0.0015000104904174805, "ViewRequirementAgentConnector_ms": 0.030564069747924805}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.7122596190644, "num_env_steps_trained_throughput_per_sec": 101.7122596190644, "timesteps_total": 36000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 72000, "timers": {"training_iteration_time_ms": 39558.069, "sample_time_ms": 7642.976, "learn_time_ms": 31897.575, "learn_throughput": 125.401, "synch_weights_time_ms": 17.017}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 175, "training_iteration": 9, "trial_id": "bb874_00000", "date": "2023-09-28_21-36-08", "timestamp": 1695951368, "time_this_iter_s": 39.32873296737671, "time_total_s": 356.04092288017273, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac4fe740>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf03490>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf011b0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 356.04092288017273, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 34.375, "ram_util_percent": 25.098214285714285}, "win_rate": 0.65, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.404101371516784, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.010498955721171417, "policy_loss": -0.019735817934391282, "vf_loss": 0.05941977011971176, "vf_explained_var": 0.06754529941827059, "kl": 0.01132510976167211, "entropy": 1.7401328135281802, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "sampler_results": {"episode_reward_max": 0.44499999999999995, "episode_reward_min": -0.893, "episode_reward_mean": -0.20272, "episode_len_mean": 183.62, "episode_media": {}, "episodes_this_iter": 27, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.034}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.29816, "red_0": 0.09544000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994, -0.31200000000000006, -0.2479999999999999, -0.17300000000000004, -0.21899999999999986, -0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997, 0.43399999999999994, -0.2679999999999999, -0.2509999999999999, -0.124, -0.07600000000000005, 0.41999999999999993, 0.42899999999999994, -0.6819999999999999, -0.7080000000000001, -0.15399999999999991, -0.09699999999999986, -0.17000000000000004, -0.5269999999999999, -0.2569999999999999, 0.43599999999999994, -0.3660000000000001, -0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001], "episode_lengths": [300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300, 248, 81, 55, 68, 161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101, 300, 83, 78, 40, 300, 300, 300, 207, 219, 45, 30, 52, 158, 82, 300, 112, 57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298], "policy_blue_0_reward": [0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997, 0.717, -1.009, -1.008, -1.008, -0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675, 0.45599999999999996, -1.008, -1.018, -1.001, -0.037000000000000026, 0.46799999999999997, 0.46599999999999997, -1.033, 0.31899999999999995, -1.0079999999999998, -1.005, -1.005, 0.498, -1.005, 0.46099999999999997, -1.015, -1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22548555987033922, "mean_inference_ms": 1.509508325115284, "mean_action_processing_ms": 0.06317950718755834, "mean_env_wait_ms": 0.10517520784711497, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018761277198791504, "StateBufferConnector_ms": 0.0014739036560058594, "ViewRequirementAgentConnector_ms": 0.03052043914794922}}, "episode_reward_max": 0.44499999999999995, "episode_reward_min": -0.893, "episode_reward_mean": -0.20272, "episode_len_mean": 183.62, "episodes_this_iter": 27, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.034}, "policy_reward_max": {"blue_0": 1.097, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.29816, "red_0": 0.09544000000000001}, "hist_stats": {"episode_reward": [0.44499999999999995, 0.43999999999999995, -0.137, -0.7440000000000001, -0.5800000000000001, -0.09600000000000007, -0.5020000000000001, -0.11599999999999999, 0.4129999999999999, -0.8690000000000001, -0.359, -0.5810000000000001, -0.664, 0.08499999999999996, -0.7200000000000001, 0.2739999999999999, -0.4, -0.08100000000000006, -0.07700000000000005, -0.5089999999999999, -0.6679999999999999, -0.08200000000000006, -0.30500000000000005, -0.06400000000000004, -0.08400000000000006, -0.15399999999999991, -0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994, -0.31200000000000006, -0.2479999999999999, -0.17300000000000004, -0.21899999999999986, -0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997, 0.43399999999999994, -0.2679999999999999, -0.2509999999999999, -0.124, -0.07600000000000005, 0.41999999999999993, 0.42899999999999994, -0.6819999999999999, -0.7080000000000001, -0.15399999999999991, -0.09699999999999986, -0.17000000000000004, -0.5269999999999999, -0.2569999999999999, 0.43599999999999994, -0.3660000000000001, -0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001], "episode_lengths": [300, 300, 43, 230, 181, 300, 152, 36, 300, 277, 109, 179, 209, 129, 216, 69, 122, 300, 300, 158, 209, 300, 252, 300, 300, 47, 238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300, 248, 81, 55, 68, 161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101, 300, 83, 78, 40, 300, 300, 300, 207, 219, 45, 30, 52, 158, 82, 300, 112, 57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298], "policy_blue_0_reward": [0.46099999999999997, 0.46599999999999997, 0.865, 0.2789999999999999, 0.43399999999999994, -0.04400000000000003, -1.022, -1.005, 0.44499999999999995, 0.1369999999999999, -1.018, -1.029, 0.34299999999999997, 1.097, 0.31399999999999995, -0.512, -1.014, -0.04300000000000003, -0.04900000000000004, -1.0199999999999998, -1.0259999999999998, -0.047000000000000035, -0.53, -0.04200000000000003, -0.04500000000000003, -1.005, -0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997, 0.717, -1.009, -1.008, -1.008, -0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675, 0.45599999999999996, -1.008, -1.018, -1.001, -0.037000000000000026, 0.46799999999999997, 0.46599999999999997, -1.033, 0.31899999999999995, -1.0079999999999998, -1.005, -1.005, 0.498, -1.005, 0.46099999999999997, -1.015, -1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22548555987033922, "mean_inference_ms": 1.509508325115284, "mean_action_processing_ms": 0.06317950718755834, "mean_env_wait_ms": 0.10517520784711497, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018761277198791504, "StateBufferConnector_ms": 0.0014739036560058594, "ViewRequirementAgentConnector_ms": 0.03052043914794922}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.66638063454967, "num_env_steps_trained_throughput_per_sec": 101.66638063454967, "timesteps_total": 40000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 39536.698, "sample_time_ms": 7638.453, "learn_time_ms": 31880.73, "learn_throughput": 125.468, "synch_weights_time_ms": 17.012}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 202, "training_iteration": 10, "trial_id": "bb874_00000", "date": "2023-09-28_21-36-47", "timestamp": 1695951407, "time_this_iter_s": 39.34651207923889, "time_total_s": 395.3874349594116, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac441690>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4dc280>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dec20>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 395.3874349594116, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 34.06071428571428, "ram_util_percent": 25.105357142857144}, "win_rate": 0.66, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4111008611818154, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.00918679662172508, "policy_loss": -0.02339425025032445, "vf_loss": 0.06321129634549531, "vf_explained_var": 0.11210240727911393, "kl": 0.013584506651191283, "entropy": 1.741502234339714, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "sampler_results": {"episode_reward_max": 0.43599999999999994, "episode_reward_min": -0.893, "episode_reward_mean": -0.19473000000000001, "episode_len_mean": 170.03, "episode_media": {}, "episodes_this_iter": 26, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.03}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.3208, "red_0": 0.12607000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994, -0.31200000000000006, -0.2479999999999999, -0.17300000000000004, -0.21899999999999986, -0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997, 0.43399999999999994, -0.2679999999999999, -0.2509999999999999, -0.124, -0.07600000000000005, 0.41999999999999993, 0.42899999999999994, -0.6819999999999999, -0.7080000000000001, -0.15399999999999991, -0.09699999999999986, -0.17000000000000004, -0.5269999999999999, -0.2569999999999999, 0.43599999999999994, -0.3660000000000001, -0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001, -0.751, -0.18700000000000006, -0.267, -0.5750000000000001, -0.1090000000000001, -0.15899999999999992, -0.07800000000000006, -0.2769999999999998, -0.885, -0.138, -0.07100000000000006, -0.3729999999999998, 0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273], "episode_lengths": [238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300, 248, 81, 55, 68, 161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101, 300, 83, 78, 40, 300, 300, 300, 207, 219, 45, 30, 52, 158, 82, 300, 112, 57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298, 233, 61, 75, 173, 191, 205, 300, 81, 268, 44, 22, 115, 58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89], "policy_blue_0_reward": [-0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997, 0.717, -1.009, -1.008, -1.008, -0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675, 0.45599999999999996, -1.008, -1.018, -1.001, -0.037000000000000026, 0.46799999999999997, 0.46599999999999997, -1.033, 0.31899999999999995, -1.0079999999999998, -1.005, -1.005, 0.498, -1.005, 0.46099999999999997, -1.015, -1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544, -1.031, -1.005, 0.761, -1.027, 0.9059999999999999, 0.859, -0.05300000000000004, -1.019, -1.035, -1.01, 0.9319999999999999, -1.0179999999999998, 1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22503088229582746, "mean_inference_ms": 1.5073420881568773, "mean_action_processing_ms": 0.0630085170127263, "mean_env_wait_ms": 0.1050130556859844, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019019126892089844, "StateBufferConnector_ms": 0.001473069190979004, "ViewRequirementAgentConnector_ms": 0.030575871467590332}}, "episode_reward_max": 0.43599999999999994, "episode_reward_min": -0.893, "episode_reward_mean": -0.19473000000000001, "episode_len_mean": 170.03, "episodes_this_iter": 26, "policy_reward_min": {"blue_0": -1.044, "red_0": -1.03}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.924}, "policy_reward_mean": {"blue_0": -0.3208, "red_0": 0.12607000000000002}, "hist_stats": {"episode_reward": [-0.2819999999999999, 0.43399999999999994, -0.8480000000000001, 0.30700000000000005, -0.6090000000000001, 0.42599999999999993, -0.34799999999999986, -0.20000000000000007, -0.41200000000000003, -0.4670000000000001, 0.4069999999999999, -0.18700000000000006, -0.10799999999999998, -0.8580000000000001, -0.46899999999999986, -0.07899999999999996, -0.21300000000000008, -0.5650000000000002, -0.18600000000000005, -0.08200000000000006, -0.08600000000000006, -0.777, -0.17800000000000005, -0.06600000000000006, 0.43299999999999994, -0.31200000000000006, -0.2479999999999999, -0.17300000000000004, -0.21899999999999986, -0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997, 0.43399999999999994, -0.2679999999999999, -0.2509999999999999, -0.124, -0.07600000000000005, 0.41999999999999993, 0.42899999999999994, -0.6819999999999999, -0.7080000000000001, -0.15399999999999991, -0.09699999999999986, -0.17000000000000004, -0.5269999999999999, -0.2569999999999999, 0.43599999999999994, -0.3660000000000001, -0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001, -0.751, -0.18700000000000006, -0.267, -0.5750000000000001, -0.1090000000000001, -0.15899999999999992, -0.07800000000000006, -0.2769999999999998, -0.885, -0.138, -0.07100000000000006, -0.3729999999999998, 0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273], "episode_lengths": [238, 300, 260, 58, 190, 300, 105, 59, 126, 295, 300, 215, 184, 262, 144, 25, 65, 174, 209, 300, 300, 239, 54, 171, 300, 248, 81, 55, 68, 161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101, 300, 83, 78, 40, 300, 300, 300, 207, 219, 45, 30, 52, 158, 82, 300, 112, 57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298, 233, 61, 75, 173, 191, 205, 300, 81, 268, 44, 22, 115, 58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89], "policy_blue_0_reward": [-0.5409999999999999, 0.46399999999999997, -1.044, -0.511, -1.027, 0.45999999999999996, -1.0239999999999998, 0.813, 0.6, -0.537, 0.44999999999999996, -0.523, 0.922, -1.038, -1.029, -1.003, 0.7939999999999999, -1.028, -0.523, -0.05200000000000004, -0.02900000000000002, -1.038, 0.83, 0.961, 0.46099999999999997, 0.717, -1.009, -1.008, -1.008, -0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675, 0.45599999999999996, -1.008, -1.018, -1.001, -0.037000000000000026, 0.46799999999999997, 0.46599999999999997, -1.033, 0.31899999999999995, -1.0079999999999998, -1.005, -1.005, 0.498, -1.005, 0.46099999999999997, -1.015, -1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544, -1.031, -1.005, 0.761, -1.027, 0.9059999999999999, 0.859, -0.05300000000000004, -1.019, -1.035, -1.01, 0.9319999999999999, -1.0179999999999998, 1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22503088229582746, "mean_inference_ms": 1.5073420881568773, "mean_action_processing_ms": 0.0630085170127263, "mean_env_wait_ms": 0.1050130556859844, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019019126892089844, "StateBufferConnector_ms": 0.001473069190979004, "ViewRequirementAgentConnector_ms": 0.030575871467590332}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.64212224080208, "num_env_steps_trained_throughput_per_sec": 101.64212224080208, "timesteps_total": 44000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 88000, "timers": {"training_iteration_time_ms": 39292.278, "sample_time_ms": 7581.596, "learn_time_ms": 31693.184, "learn_throughput": 126.21, "synch_weights_time_ms": 16.994}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "done": false, "episodes_total": 228, "training_iteration": 11, "trial_id": "bb874_00000", "date": "2023-09-28_21-37-27", "timestamp": 1695951447, "time_this_iter_s": 39.35588216781616, "time_total_s": 434.7433171272278, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2aa8bcac0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4076d0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac406d40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 434.7433171272278, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 35.38214285714286, "ram_util_percent": 25.20357142857143}, "win_rate": 0.67, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4127100174625715, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.012161085938714677, "policy_loss": -0.020144344826985617, "vf_loss": 0.06361329855474954, "vf_explained_var": 0.13931623374422392, "kl": 0.011098360430911048, "entropy": 1.7208901514609656, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "sampler_results": {"episode_reward_max": 0.473, "episode_reward_min": -0.893, "episode_reward_mean": -0.20215999999999998, "episode_len_mean": 157.13, "episode_media": {}, "episodes_this_iter": 29, "policy_reward_min": {"blue_0": -1.042, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.919}, "policy_reward_mean": {"blue_0": -0.37947999999999993, "red_0": 0.17732000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997, 0.43399999999999994, -0.2679999999999999, -0.2509999999999999, -0.124, -0.07600000000000005, 0.41999999999999993, 0.42899999999999994, -0.6819999999999999, -0.7080000000000001, -0.15399999999999991, -0.09699999999999986, -0.17000000000000004, -0.5269999999999999, -0.2569999999999999, 0.43599999999999994, -0.3660000000000001, -0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001, -0.751, -0.18700000000000006, -0.267, -0.5750000000000001, -0.1090000000000001, -0.15899999999999992, -0.07800000000000006, -0.2769999999999998, -0.885, -0.138, -0.07100000000000006, -0.3729999999999998, 0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273, 0.4129999999999999, -0.28, -0.2489999999999999, -0.16000000000000003, -0.17800000000000005, 0.4159999999999999, -0.061999999999999944, -0.1399999999999999, -0.08300000000000006, -0.4910000000000001, -0.23199999999999987, -0.7759999999999999, 0.473, -0.11499999999999999, -0.31499999999999995, -0.238, -0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006], "episode_lengths": [161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101, 300, 83, 78, 40, 300, 300, 300, 207, 219, 45, 30, 52, 158, 82, 300, 112, 57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298, 233, 61, 75, 173, 191, 205, 300, 81, 268, 44, 22, 115, 58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89, 300, 87, 76, 48, 59, 300, 166, 41, 300, 143, 71, 235, 157, 39, 98, 73, 46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94], "policy_blue_0_reward": [-0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675, 0.45599999999999996, -1.008, -1.018, -1.001, -0.037000000000000026, 0.46799999999999997, 0.46599999999999997, -1.033, 0.31899999999999995, -1.0079999999999998, -1.005, -1.005, 0.498, -1.005, 0.46099999999999997, -1.015, -1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544, -1.031, -1.005, 0.761, -1.027, 0.9059999999999999, 0.859, -0.05300000000000004, -1.019, -1.035, -1.01, 0.9319999999999999, -1.0179999999999998, 1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011, 0.45499999999999996, 0.724, -1.013, -1.01, 0.814, 0.45799999999999996, -0.5189999999999999, 0.873, -0.05000000000000004, 0.5469999999999999, -1.01, -1.04, -0.025000000000000015, -1.0, -1.012, -1.009, -1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22467914446704945, "mean_inference_ms": 1.5052139380684662, "mean_action_processing_ms": 0.0628667576161359, "mean_env_wait_ms": 0.10489971746675987, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019100427627563477, "StateBufferConnector_ms": 0.0014843940734863281, "ViewRequirementAgentConnector_ms": 0.03063344955444336}}, "episode_reward_max": 0.473, "episode_reward_min": -0.893, "episode_reward_mean": -0.20215999999999998, "episode_len_mean": 157.13, "episodes_this_iter": 29, "policy_reward_min": {"blue_0": -1.042, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.919}, "policy_reward_mean": {"blue_0": -0.37947999999999993, "red_0": 0.17732000000000003}, "hist_stats": {"episode_reward": [-0.02399999999999991, -0.243, -0.08100000000000006, -0.05700000000000005, 0.4129999999999999, -0.30499999999999994, -0.20100000000000007, 0.42899999999999994, -0.684, -0.514, -0.277, -0.509, -0.26, -0.08999999999999986, -0.123, -0.10500000000000008, -0.6409999999999999, -0.33599999999999997, 0.43399999999999994, -0.2679999999999999, -0.2509999999999999, -0.124, -0.07600000000000005, 0.41999999999999993, 0.42899999999999994, -0.6819999999999999, -0.7080000000000001, -0.15399999999999991, -0.09699999999999986, -0.17000000000000004, -0.5269999999999999, -0.2569999999999999, 0.43599999999999994, -0.3660000000000001, -0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001, -0.751, -0.18700000000000006, -0.267, -0.5750000000000001, -0.1090000000000001, -0.15899999999999992, -0.07800000000000006, -0.2769999999999998, -0.885, -0.138, -0.07100000000000006, -0.3729999999999998, 0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273, 0.4129999999999999, -0.28, -0.2489999999999999, -0.16000000000000003, -0.17800000000000005, 0.4159999999999999, -0.061999999999999944, -0.1399999999999999, -0.08300000000000006, -0.4910000000000001, -0.23199999999999987, -0.7759999999999999, 0.473, -0.11499999999999999, -0.31499999999999995, -0.238, -0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006], "episode_lengths": [161, 75, 300, 300, 300, 94, 215, 300, 212, 159, 239, 157, 80, 29, 193, 300, 200, 101, 300, 83, 78, 40, 300, 300, 300, 207, 219, 45, 30, 52, 158, 82, 300, 112, 57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298, 233, 61, 75, 173, 191, 205, 300, 81, 268, 44, 22, 115, 58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89, 300, 87, 76, 48, 59, 300, 166, 41, 300, 143, 71, 235, 157, 39, 98, 73, 46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94], "policy_blue_0_reward": [-0.5279999999999999, -1.008, -0.047000000000000035, -0.03400000000000002, 0.44399999999999995, -1.013, 0.823, 0.45999999999999996, -1.026, -1.022, -0.532, -1.024, -1.013, -1.001, -0.522, -0.03900000000000003, -1.027, 0.675, 0.45599999999999996, -1.008, -1.018, -1.001, -0.037000000000000026, 0.46799999999999997, 0.46599999999999997, -1.033, 0.31899999999999995, -1.0079999999999998, -1.005, -1.005, 0.498, -1.005, 0.46099999999999997, -1.015, -1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544, -1.031, -1.005, 0.761, -1.027, 0.9059999999999999, 0.859, -0.05300000000000004, -1.019, -1.035, -1.01, 0.9319999999999999, -1.0179999999999998, 1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011, 0.45499999999999996, 0.724, -1.013, -1.01, 0.814, 0.45799999999999996, -0.5189999999999999, 0.873, -0.05000000000000004, 0.5469999999999999, -1.01, -1.04, -0.025000000000000015, -1.0, -1.012, -1.009, -1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22467914446704945, "mean_inference_ms": 1.5052139380684662, "mean_action_processing_ms": 0.0628667576161359, "mean_env_wait_ms": 0.10489971746675987, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019100427627563477, "StateBufferConnector_ms": 0.0014843940734863281, "ViewRequirementAgentConnector_ms": 0.03063344955444336}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.61548861033563, "num_env_steps_trained_throughput_per_sec": 101.61548861033563, "timesteps_total": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 39252.208, "sample_time_ms": 7520.865, "learn_time_ms": 31713.584, "learn_throughput": 126.129, "synch_weights_time_ms": 17.251}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 257, "training_iteration": 12, "trial_id": "bb874_00000", "date": "2023-09-28_21-38-06", "timestamp": 1695951486, "time_this_iter_s": 39.366400957107544, "time_total_s": 474.1097180843353, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab0b6470>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4dd2d0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dd1b0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 474.1097180843353, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 35.06428571428571, "ram_util_percent": 25.242857142857144}, "win_rate": 0.7, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.427152757657071, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.00916840032186883, "policy_loss": -0.02361981910119842, "vf_loss": 0.06403902305173688, "vf_explained_var": 0.11676471245785554, "kl": 0.012368316481991382, "entropy": 1.7049551513046026, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "sampler_results": {"episode_reward_max": 0.473, "episode_reward_min": -0.9390000000000001, "episode_reward_mean": -0.22376000000000001, "episode_len_mean": 139.52, "episode_media": {}, "episodes_this_iter": 34, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.919}, "policy_reward_mean": {"blue_0": -0.43223000000000006, "red_0": 0.20847000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001, -0.751, -0.18700000000000006, -0.267, -0.5750000000000001, -0.1090000000000001, -0.15899999999999992, -0.07800000000000006, -0.2769999999999998, -0.885, -0.138, -0.07100000000000006, -0.3729999999999998, 0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273, 0.4129999999999999, -0.28, -0.2489999999999999, -0.16000000000000003, -0.17800000000000005, 0.4159999999999999, -0.061999999999999944, -0.1399999999999999, -0.08300000000000006, -0.4910000000000001, -0.23199999999999987, -0.7759999999999999, 0.473, -0.11499999999999999, -0.31499999999999995, -0.238, -0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006, -0.267, -0.6849999999999999, -0.249, -0.14300000000000013, -0.15100000000000002, -0.7879999999999998, -0.358, 0.387, -0.32600000000000007, -0.20999999999999996, -0.22199999999999998, -0.43000000000000005, -0.613, 0.379, -0.10499999999999998, -0.08900000000000007, -0.275, -0.06999999999999995, -0.17499999999999993, 0.19399999999999995, -0.008000000000000007, -0.2519999999999999, -0.45400000000000007, -0.19600000000000006, -0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987], "episode_lengths": [57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298, 233, 61, 75, 173, 191, 205, 300, 81, 268, 44, 22, 115, 58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89, 300, 87, 76, 48, 59, 300, 166, 41, 300, 143, 71, 235, 157, 39, 98, 73, 46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94, 83, 210, 81, 198, 43, 244, 110, 34, 251, 65, 68, 132, 182, 38, 31, 300, 85, 20, 54, 94, 156, 75, 132, 59, 169, 68, 300, 77, 49, 150, 285, 145, 125, 147], "policy_blue_0_reward": [-1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544, -1.031, -1.005, 0.761, -1.027, 0.9059999999999999, 0.859, -0.05300000000000004, -1.019, -1.035, -1.01, 0.9319999999999999, -1.0179999999999998, 1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011, 0.45499999999999996, 0.724, -1.013, -1.01, 0.814, 0.45799999999999996, -0.5189999999999999, 0.873, -0.05000000000000004, 0.5469999999999999, -1.01, -1.04, -0.025000000000000015, -1.0, -1.012, -1.009, -1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016, -1.009, -1.023, -1.01, -0.536, -1.011, -1.033, 0.652, -0.504, -0.539, -1.006, -1.01, 0.585, -1.025, -0.503, 0.901, -0.04900000000000004, -1.01, 0.939, -1.007, -0.516, -0.52, -1.0119999999999998, -1.022, 0.813, -1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22464941485889917, "mean_inference_ms": 1.5044460126792878, "mean_action_processing_ms": 0.06281328328905139, "mean_env_wait_ms": 0.1049513215179537, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019460678100585938, "StateBufferConnector_ms": 0.0015172958374023438, "ViewRequirementAgentConnector_ms": 0.031047940254211426}}, "episode_reward_max": 0.473, "episode_reward_min": -0.9390000000000001, "episode_reward_mean": -0.22376000000000001, "episode_len_mean": 139.52, "episodes_this_iter": 34, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.919}, "policy_reward_mean": {"blue_0": -0.43223000000000006, "red_0": 0.20847000000000004}, "hist_stats": {"episode_reward": [-0.18700000000000006, 0.18999999999999995, -0.11499999999999988, -0.631, -0.4790000000000001, 0.43599999999999994, 0.238, -0.893, -0.47699999999999987, -0.20900000000000007, -0.4760000000000001, -0.751, -0.18700000000000006, -0.267, -0.5750000000000001, -0.1090000000000001, -0.15899999999999992, -0.07800000000000006, -0.2769999999999998, -0.885, -0.138, -0.07100000000000006, -0.3729999999999998, 0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273, 0.4129999999999999, -0.28, -0.2489999999999999, -0.16000000000000003, -0.17800000000000005, 0.4159999999999999, -0.061999999999999944, -0.1399999999999999, -0.08300000000000006, -0.4910000000000001, -0.23199999999999987, -0.7759999999999999, 0.473, -0.11499999999999999, -0.31499999999999995, -0.238, -0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006, -0.267, -0.6849999999999999, -0.249, -0.14300000000000013, -0.15100000000000002, -0.7879999999999998, -0.358, 0.387, -0.32600000000000007, -0.20999999999999996, -0.22199999999999998, -0.43000000000000005, -0.613, 0.379, -0.10499999999999998, -0.08900000000000007, -0.275, -0.06999999999999995, -0.17499999999999993, 0.19399999999999995, -0.008000000000000007, -0.2519999999999999, -0.45400000000000007, -0.19600000000000006, -0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987], "episode_lengths": [57, 98, 39, 187, 149, 300, 84, 274, 149, 63, 298, 233, 61, 75, 173, 191, 205, 300, 81, 268, 44, 22, 115, 58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89, 300, 87, 76, 48, 59, 300, 166, 41, 300, 143, 71, 235, 157, 39, 98, 73, 46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94, 83, 210, 81, 198, 43, 244, 110, 34, 251, 65, 68, 132, 182, 38, 31, 300, 85, 20, 54, 94, 156, 75, 132, 59, 169, 68, 300, 77, 49, 150, 285, 145, 125, 147], "policy_blue_0_reward": [-1.013, -0.509, 0.879, -1.028, 0.5339999999999999, 0.45699999999999996, -0.512, -1.042, -1.0179999999999998, -1.009, -0.544, -1.031, -1.005, 0.761, -1.027, 0.9059999999999999, 0.859, -0.05300000000000004, -1.019, -1.035, -1.01, 0.9319999999999999, -1.0179999999999998, 1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011, 0.45499999999999996, 0.724, -1.013, -1.01, 0.814, 0.45799999999999996, -0.5189999999999999, 0.873, -0.05000000000000004, 0.5469999999999999, -1.01, -1.04, -0.025000000000000015, -1.0, -1.012, -1.009, -1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016, -1.009, -1.023, -1.01, -0.536, -1.011, -1.033, 0.652, -0.504, -0.539, -1.006, -1.01, 0.585, -1.025, -0.503, 0.901, -0.04900000000000004, -1.01, 0.939, -1.007, -0.516, -0.52, -1.0119999999999998, -1.022, 0.813, -1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22464941485889917, "mean_inference_ms": 1.5044460126792878, "mean_action_processing_ms": 0.06281328328905139, "mean_env_wait_ms": 0.1049513215179537, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019460678100585938, "StateBufferConnector_ms": 0.0015172958374023438, "ViewRequirementAgentConnector_ms": 0.031047940254211426}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.77066129491138, "num_env_steps_trained_throughput_per_sec": 100.77066129491138, "timesteps_total": 52000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 104000, "timers": {"training_iteration_time_ms": 39323.332, "sample_time_ms": 7554.119, "learn_time_ms": 31751.491, "learn_throughput": 125.978, "synch_weights_time_ms": 17.209}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "done": false, "episodes_total": 291, "training_iteration": 13, "trial_id": "bb874_00000", "date": "2023-09-28_21-38-46", "timestamp": 1695951526, "time_this_iter_s": 39.69632601737976, "time_total_s": 513.8060441017151, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac443370>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac406320>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac407e20>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 513.8060441017151, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 36.30535714285714, "ram_util_percent": 25.403571428571432}, "win_rate": 0.74, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.427545697055757, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0003509672339229534, "policy_loss": -0.021794741615788857, "vf_loss": 0.04104852547170594, "vf_explained_var": 0.0747594232360522, "kl": 0.013045240693713822, "entropy": 1.6895360072453818, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "sampler_results": {"episode_reward_max": 0.473, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.22604, "episode_len_mean": 140.96, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"blue_0": -1.054, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.942}, "policy_reward_mean": {"blue_0": -0.4934799999999999, "red_0": 0.26743999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273, 0.4129999999999999, -0.28, -0.2489999999999999, -0.16000000000000003, -0.17800000000000005, 0.4159999999999999, -0.061999999999999944, -0.1399999999999999, -0.08300000000000006, -0.4910000000000001, -0.23199999999999987, -0.7759999999999999, 0.473, -0.11499999999999999, -0.31499999999999995, -0.238, -0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006, -0.267, -0.6849999999999999, -0.249, -0.14300000000000013, -0.15100000000000002, -0.7879999999999998, -0.358, 0.387, -0.32600000000000007, -0.20999999999999996, -0.22199999999999998, -0.43000000000000005, -0.613, 0.379, -0.10499999999999998, -0.08900000000000007, -0.275, -0.06999999999999995, -0.17499999999999993, 0.19399999999999995, -0.008000000000000007, -0.2519999999999999, -0.45400000000000007, -0.19600000000000006, -0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987, -0.626, -0.568, -0.08500000000000008, -0.3510000000000001, -0.405, -0.062000000000000055, -0.8989999999999999, -0.15300000000000002, -0.07499999999999996, 0.395, -0.7570000000000001, -0.372, -0.1369999999999999, -0.08900000000000007, -0.08100000000000006, -0.16999999999999993, -0.4940000000000001, 0.366, -0.769, -0.135, -0.9470000000000001, -0.23299999999999987, -0.05400000000000004], "episode_lengths": [58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89, 300, 87, 76, 48, 59, 300, 166, 41, 300, 143, 71, 235, 157, 39, 98, 73, 46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94, 83, 210, 81, 198, 43, 244, 110, 34, 251, 65, 68, 132, 182, 38, 31, 300, 85, 20, 54, 94, 156, 75, 132, 59, 169, 68, 300, 77, 49, 150, 285, 145, 125, 147, 191, 175, 300, 108, 278, 18, 271, 45, 22, 32, 231, 115, 42, 300, 300, 49, 152, 41, 234, 43, 293, 70, 300], "policy_blue_0_reward": [1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011, 0.45499999999999996, 0.724, -1.013, -1.01, 0.814, 0.45799999999999996, -0.5189999999999999, 0.873, -0.05000000000000004, 0.5469999999999999, -1.01, -1.04, -0.025000000000000015, -1.0, -1.012, -1.009, -1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016, -1.009, -1.023, -1.01, -0.536, -1.011, -1.033, 0.652, -0.504, -0.539, -1.006, -1.01, 0.585, -1.025, -0.503, 0.901, -0.04900000000000004, -1.01, 0.939, -1.007, -0.516, -0.52, -1.0119999999999998, -1.022, 0.813, -1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021, -1.032, -1.023, -0.04500000000000003, 0.6619999999999999, -0.536, -1.004, -1.0319999999999998, -1.005, -1.005, -0.503, -1.032, 0.637, -1.003, -0.035000000000000024, -0.04300000000000003, -1.01, -1.022, -0.504, -1.035, -1.003, -1.054, -1.0079999999999998, -0.035000000000000024]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22465164556354675, "mean_inference_ms": 1.5038888548181415, "mean_action_processing_ms": 0.0627887009296013, "mean_env_wait_ms": 0.10497384196586702, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019710302352905273, "StateBufferConnector_ms": 0.0015166997909545898, "ViewRequirementAgentConnector_ms": 0.031101584434509277}}, "episode_reward_max": 0.473, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.22604, "episode_len_mean": 140.96, "episodes_this_iter": 23, "policy_reward_min": {"blue_0": -1.054, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.318, "red_0": 0.942}, "policy_reward_mean": {"blue_0": -0.4934799999999999, "red_0": 0.26743999999999996}, "hist_stats": {"episode_reward": [0.31200000000000006, -0.10399999999999998, -0.08499999999999996, 0.42699999999999994, 0.3959999999999999, -0.19800000000000006, -0.3410000000000001, -0.605, 0.08899999999999997, -0.06600000000000004, -0.06800000000000006, -0.6549999999999998, -0.29499999999999993, -0.273, 0.4129999999999999, -0.28, -0.2489999999999999, -0.16000000000000003, -0.17800000000000005, 0.4159999999999999, -0.061999999999999944, -0.1399999999999999, -0.08300000000000006, -0.4910000000000001, -0.23199999999999987, -0.7759999999999999, 0.473, -0.11499999999999999, -0.31499999999999995, -0.238, -0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006, -0.267, -0.6849999999999999, -0.249, -0.14300000000000013, -0.15100000000000002, -0.7879999999999998, -0.358, 0.387, -0.32600000000000007, -0.20999999999999996, -0.22199999999999998, -0.43000000000000005, -0.613, 0.379, -0.10499999999999998, -0.08900000000000007, -0.275, -0.06999999999999995, -0.17499999999999993, 0.19399999999999995, -0.008000000000000007, -0.2519999999999999, -0.45400000000000007, -0.19600000000000006, -0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987, -0.626, -0.568, -0.08500000000000008, -0.3510000000000001, -0.405, -0.062000000000000055, -0.8989999999999999, -0.15300000000000002, -0.07499999999999996, 0.395, -0.7570000000000001, -0.372, -0.1369999999999999, -0.08900000000000007, -0.08100000000000006, -0.16999999999999993, -0.4940000000000001, 0.366, -0.769, -0.135, -0.9470000000000001, -0.23299999999999987, -0.05400000000000004], "episode_lengths": [58, 32, 25, 300, 300, 60, 258, 184, 125, 300, 173, 197, 90, 89, 300, 87, 76, 48, 59, 300, 166, 41, 300, 143, 71, 235, 157, 39, 98, 73, 46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94, 83, 210, 81, 198, 43, 244, 110, 34, 251, 65, 68, 132, 182, 38, 31, 300, 85, 20, 54, 94, 156, 75, 132, 59, 169, 68, 300, 77, 49, 150, 285, 145, 125, 147, 191, 175, 300, 108, 278, 18, 271, 45, 22, 32, 231, 115, 42, 300, 300, 49, 152, 41, 234, 43, 293, 70, 300], "policy_blue_0_reward": [1.318, 0.901, -1.004, 0.45599999999999996, 0.46199999999999997, -1.013, -0.536, 0.42100000000000004, -0.513, -0.036000000000000025, -0.523, -1.037, -1.019, -1.011, 0.45499999999999996, 0.724, -1.013, -1.01, 0.814, 0.45799999999999996, -0.5189999999999999, 0.873, -0.05000000000000004, 0.5469999999999999, -1.01, -1.04, -0.025000000000000015, -1.0, -1.012, -1.009, -1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016, -1.009, -1.023, -1.01, -0.536, -1.011, -1.033, 0.652, -0.504, -0.539, -1.006, -1.01, 0.585, -1.025, -0.503, 0.901, -0.04900000000000004, -1.01, 0.939, -1.007, -0.516, -0.52, -1.0119999999999998, -1.022, 0.813, -1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021, -1.032, -1.023, -0.04500000000000003, 0.6619999999999999, -0.536, -1.004, -1.0319999999999998, -1.005, -1.005, -0.503, -1.032, 0.637, -1.003, -0.035000000000000024, -0.04300000000000003, -1.01, -1.022, -0.504, -1.035, -1.003, -1.054, -1.0079999999999998, -0.035000000000000024]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22465164556354675, "mean_inference_ms": 1.5038888548181415, "mean_action_processing_ms": 0.0627887009296013, "mean_env_wait_ms": 0.10497384196586702, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019710302352905273, "StateBufferConnector_ms": 0.0015166997909545898, "ViewRequirementAgentConnector_ms": 0.031101584434509277}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.15133724331446, "num_env_steps_trained_throughput_per_sec": 101.15133724331446, "timesteps_total": 56000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 39366.532, "sample_time_ms": 7563.712, "learn_time_ms": 31785.083, "learn_throughput": 125.845, "synch_weights_time_ms": 17.223}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "episodes_total": 314, "training_iteration": 14, "trial_id": "bb874_00000", "date": "2023-09-28_21-39-25", "timestamp": 1695951565, "time_this_iter_s": 39.54684400558472, "time_total_s": 553.3528881072998, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac445510>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4de290>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dcb80>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 553.3528881072998, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 35.45087719298246, "ram_util_percent": 25.436842105263157}, "win_rate": 0.79, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5059117446343104, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.012451143812722876, "policy_loss": -0.025716339209369228, "vf_loss": 0.07418907413763615, "vf_explained_var": 0.15629148545364538, "kl": 0.013832199739559858, "entropy": 1.6934942378352085, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "sampler_results": {"episode_reward_max": 0.4159999999999999, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.28504999999999997, "episode_len_mean": 138.06, "episode_media": {}, "episodes_this_iter": 30, "policy_reward_min": {"blue_0": -1.054, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.01, "red_0": 0.942}, "policy_reward_mean": {"blue_0": -0.57927, "red_0": 0.29422}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006, -0.267, -0.6849999999999999, -0.249, -0.14300000000000013, -0.15100000000000002, -0.7879999999999998, -0.358, 0.387, -0.32600000000000007, -0.20999999999999996, -0.22199999999999998, -0.43000000000000005, -0.613, 0.379, -0.10499999999999998, -0.08900000000000007, -0.275, -0.06999999999999995, -0.17499999999999993, 0.19399999999999995, -0.008000000000000007, -0.2519999999999999, -0.45400000000000007, -0.19600000000000006, -0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987, -0.626, -0.568, -0.08500000000000008, -0.3510000000000001, -0.405, -0.062000000000000055, -0.8989999999999999, -0.15300000000000002, -0.07499999999999996, 0.395, -0.7570000000000001, -0.372, -0.1369999999999999, -0.08900000000000007, -0.08100000000000006, -0.16999999999999993, -0.4940000000000001, 0.366, -0.769, -0.135, -0.9470000000000001, -0.23299999999999987, -0.05400000000000004, -0.2580000000000001, -0.9049999999999999, -0.05500000000000005, -0.639, -0.32099999999999995, -0.11799999999999988, -0.16000000000000003, -0.5549999999999999, -0.2739999999999999, -0.02100000000000002, -0.22399999999999998, -0.28700000000000003, -0.30400000000000005, -0.4909999999999999, -0.2929999999999999, -0.821, -0.30199999999999994, -0.17900000000000005, -0.08299999999999996, -0.375, 0.361, -0.561, -0.5019999999999999, -0.09599999999999997, 0.2569999999999999, -0.18100000000000005, -0.4139999999999999, -0.655, -0.11499999999999988, -0.813], "episode_lengths": [46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94, 83, 210, 81, 198, 43, 244, 110, 34, 251, 65, 68, 132, 182, 38, 31, 300, 85, 20, 54, 94, 156, 75, 132, 59, 169, 68, 300, 77, 49, 150, 285, 145, 125, 147, 191, 175, 300, 108, 278, 18, 271, 45, 22, 32, 231, 115, 42, 300, 300, 49, 152, 41, 234, 43, 293, 70, 300, 228, 278, 300, 193, 102, 35, 49, 172, 239, 158, 70, 89, 92, 154, 88, 252, 97, 57, 24, 119, 44, 171, 151, 30, 73, 210, 127, 202, 38, 252], "policy_blue_0_reward": [-1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016, -1.009, -1.023, -1.01, -0.536, -1.011, -1.033, 0.652, -0.504, -0.539, -1.006, -1.01, 0.585, -1.025, -0.503, 0.901, -0.04900000000000004, -1.01, 0.939, -1.007, -0.516, -0.52, -1.0119999999999998, -1.022, 0.813, -1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021, -1.032, -1.023, -0.04500000000000003, 0.6619999999999999, -0.536, -1.004, -1.0319999999999998, -1.005, -1.005, -0.503, -1.032, 0.637, -1.003, -0.035000000000000024, -0.04300000000000003, -1.01, -1.022, -0.504, -1.035, -1.003, -1.054, -1.0079999999999998, -0.035000000000000024, -0.529, -1.026, -0.035000000000000024, -1.034, -1.012, -1.01, 0.843, -1.025, 0.753, 1.01, 0.776, -1.02, -1.012, -1.02, -1.011, -1.043, 0.6990000000000001, -1.008, -1.007, -1.013, -0.505, 0.45399999999999996, -1.018, -1.005, -0.512, -0.531, -1.016, 0.366, -1.0059999999999998, -1.033]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22462395324764955, "mean_inference_ms": 1.5030757707660112, "mean_action_processing_ms": 0.06274121413801964, "mean_env_wait_ms": 0.10495660911941526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01986408233642578, "StateBufferConnector_ms": 0.0014978647232055664, "ViewRequirementAgentConnector_ms": 0.031122684478759766}}, "episode_reward_max": 0.4159999999999999, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.28504999999999997, "episode_len_mean": 138.06, "episodes_this_iter": 30, "policy_reward_min": {"blue_0": -1.054, "red_0": -1.055}, "policy_reward_max": {"blue_0": 1.01, "red_0": 0.942}, "policy_reward_mean": {"blue_0": -0.57927, "red_0": 0.29422}, "hist_stats": {"episode_reward": [-0.15400000000000003, -0.5440000000000002, -0.688, -0.19399999999999984, -0.3699999999999999, -0.24599999999999989, -0.20100000000000007, -0.531, -0.09900000000000007, -0.3569999999999999, -0.534, -0.45300000000000007, -0.32000000000000006, -0.267, -0.6849999999999999, -0.249, -0.14300000000000013, -0.15100000000000002, -0.7879999999999998, -0.358, 0.387, -0.32600000000000007, -0.20999999999999996, -0.22199999999999998, -0.43000000000000005, -0.613, 0.379, -0.10499999999999998, -0.08900000000000007, -0.275, -0.06999999999999995, -0.17499999999999993, 0.19399999999999995, -0.008000000000000007, -0.2519999999999999, -0.45400000000000007, -0.19600000000000006, -0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987, -0.626, -0.568, -0.08500000000000008, -0.3510000000000001, -0.405, -0.062000000000000055, -0.8989999999999999, -0.15300000000000002, -0.07499999999999996, 0.395, -0.7570000000000001, -0.372, -0.1369999999999999, -0.08900000000000007, -0.08100000000000006, -0.16999999999999993, -0.4940000000000001, 0.366, -0.769, -0.135, -0.9470000000000001, -0.23299999999999987, -0.05400000000000004, -0.2580000000000001, -0.9049999999999999, -0.05500000000000005, -0.639, -0.32099999999999995, -0.11799999999999988, -0.16000000000000003, -0.5549999999999999, -0.2739999999999999, -0.02100000000000002, -0.22399999999999998, -0.28700000000000003, -0.30400000000000005, -0.4909999999999999, -0.2929999999999999, -0.821, -0.30199999999999994, -0.17900000000000005, -0.08299999999999996, -0.375, 0.361, -0.561, -0.5019999999999999, -0.09599999999999997, 0.2569999999999999, -0.18100000000000005, -0.4139999999999999, -0.655, -0.11499999999999988, -0.813], "episode_lengths": [46, 168, 202, 62, 109, 77, 213, 161, 300, 110, 159, 141, 94, 83, 210, 81, 198, 43, 244, 110, 34, 251, 65, 68, 132, 182, 38, 31, 300, 85, 20, 54, 94, 156, 75, 132, 59, 169, 68, 300, 77, 49, 150, 285, 145, 125, 147, 191, 175, 300, 108, 278, 18, 271, 45, 22, 32, 231, 115, 42, 300, 300, 49, 152, 41, 234, 43, 293, 70, 300, 228, 278, 300, 193, 102, 35, 49, 172, 239, 158, 70, 89, 92, 154, 88, 252, 97, 57, 24, 119, 44, 171, 151, 30, 73, 210, 127, 202, 38, 252], "policy_blue_0_reward": [-1.006, -1.022, 0.367, 0.807, -1.017, -1.0119999999999998, -0.522, -1.03, -0.04500000000000003, -1.016, -1.022, -1.017, -1.016, -1.009, -1.023, -1.01, -0.536, -1.011, -1.033, 0.652, -0.504, -0.539, -1.006, -1.01, 0.585, -1.025, -0.503, 0.901, -0.04900000000000004, -1.01, 0.939, -1.007, -0.516, -0.52, -1.0119999999999998, -1.022, 0.813, -1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021, -1.032, -1.023, -0.04500000000000003, 0.6619999999999999, -0.536, -1.004, -1.0319999999999998, -1.005, -1.005, -0.503, -1.032, 0.637, -1.003, -0.035000000000000024, -0.04300000000000003, -1.01, -1.022, -0.504, -1.035, -1.003, -1.054, -1.0079999999999998, -0.035000000000000024, -0.529, -1.026, -0.035000000000000024, -1.034, -1.012, -1.01, 0.843, -1.025, 0.753, 1.01, 0.776, -1.02, -1.012, -1.02, -1.011, -1.043, 0.6990000000000001, -1.008, -1.007, -1.013, -0.505, 0.45399999999999996, -1.018, -1.005, -0.512, -0.531, -1.016, 0.366, -1.0059999999999998, -1.033]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22462395324764955, "mean_inference_ms": 1.5030757707660112, "mean_action_processing_ms": 0.06274121413801964, "mean_env_wait_ms": 0.10495660911941526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01986408233642578, "StateBufferConnector_ms": 0.0014978647232055664, "ViewRequirementAgentConnector_ms": 0.031122684478759766}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.56685362124941, "num_env_steps_trained_throughput_per_sec": 101.56685362124941, "timesteps_total": 60000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 120000, "timers": {"training_iteration_time_ms": 39398.975, "sample_time_ms": 7572.496, "learn_time_ms": 31808.733, "learn_throughput": 125.752, "synch_weights_time_ms": 17.233}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 344, "training_iteration": 15, "trial_id": "bb874_00000", "date": "2023-09-28_21-40-05", "timestamp": 1695951605, "time_this_iter_s": 39.38502883911133, "time_total_s": 592.7379169464111, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab66e530>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac407130>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac405cf0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 592.7379169464111, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 34.239285714285714, "ram_util_percent": 25.410714285714285}, "win_rate": 0.83, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5925819870705407, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.02748561639940211, "policy_loss": -0.022327652338087017, "vf_loss": 0.09832394119584933, "vf_explained_var": 0.1352302317197124, "kl": 0.011615461656739967, "entropy": 1.671793781593442, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "sampler_results": {"episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.26257, "episode_len_mean": 137.59, "episode_media": {}, "episodes_this_iter": 37, "policy_reward_min": {"blue_0": -1.054, "red_0": -1.031}, "policy_reward_max": {"blue_0": 1.322, "red_0": 0.942}, "policy_reward_mean": {"blue_0": -0.5481900000000001, "red_0": 0.2856200000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987, -0.626, -0.568, -0.08500000000000008, -0.3510000000000001, -0.405, -0.062000000000000055, -0.8989999999999999, -0.15300000000000002, -0.07499999999999996, 0.395, -0.7570000000000001, -0.372, -0.1369999999999999, -0.08900000000000007, -0.08100000000000006, -0.16999999999999993, -0.4940000000000001, 0.366, -0.769, -0.135, -0.9470000000000001, -0.23299999999999987, -0.05400000000000004, -0.2580000000000001, -0.9049999999999999, -0.05500000000000005, -0.639, -0.32099999999999995, -0.11799999999999988, -0.16000000000000003, -0.5549999999999999, -0.2739999999999999, -0.02100000000000002, -0.22399999999999998, -0.28700000000000003, -0.30400000000000005, -0.4909999999999999, -0.2929999999999999, -0.821, -0.30199999999999994, -0.17900000000000005, -0.08299999999999996, -0.375, 0.361, -0.561, -0.5019999999999999, -0.09599999999999997, 0.2569999999999999, -0.18100000000000005, -0.4139999999999999, -0.655, -0.11499999999999988, -0.813, -0.3989999999999999, -0.2729999999999998, -0.17700000000000005, 0.06899999999999995, -0.10400000000000009, -0.19899999999999995, -0.15800000000000003, -0.3520000000000001, -0.08600000000000006, -0.6140000000000001, -0.19999999999999996, 0.31499999999999995, -0.131, -0.43800000000000006, -0.5490000000000002, -0.07399999999999984, -0.4710000000000001, 0.43799999999999994, -0.14, -0.2260000000000001, -0.05700000000000005, 0.19199999999999995, 0.1409999999999999, -0.18400000000000005, -0.18699999999999983, -0.3850000000000001, -0.345, -0.16000000000000003, -0.351, -0.22100000000000009, -0.16300000000000003, -0.31700000000000006, -0.897, 0.03299999999999992, -0.19000000000000006, -0.18700000000000006, -0.502], "episode_lengths": [169, 68, 300, 77, 49, 150, 285, 145, 125, 147, 191, 175, 300, 108, 278, 18, 271, 45, 22, 32, 231, 115, 42, 300, 300, 49, 152, 41, 234, 43, 293, 70, 300, 228, 278, 300, 193, 102, 35, 49, 172, 239, 158, 70, 89, 92, 154, 88, 252, 97, 57, 24, 119, 44, 171, 151, 30, 73, 210, 127, 202, 38, 252, 124, 85, 52, 130, 181, 60, 50, 108, 300, 186, 62, 57, 43, 140, 168, 23, 147, 300, 44, 69, 300, 94, 112, 208, 58, 118, 110, 48, 105, 69, 49, 249, 281, 146, 60, 57, 147], "policy_blue_0_reward": [-1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021, -1.032, -1.023, -0.04500000000000003, 0.6619999999999999, -0.536, -1.004, -1.0319999999999998, -1.005, -1.005, -0.503, -1.032, 0.637, -1.003, -0.035000000000000024, -0.04300000000000003, -1.01, -1.022, -0.504, -1.035, -1.003, -1.054, -1.0079999999999998, -0.035000000000000024, -0.529, -1.026, -0.035000000000000024, -1.034, -1.012, -1.01, 0.843, -1.025, 0.753, 1.01, 0.776, -1.02, -1.012, -1.02, -1.011, -1.043, 0.6990000000000001, -1.008, -1.007, -1.013, -0.505, 0.45399999999999996, -1.018, -1.005, -0.512, -0.531, -1.016, 0.366, -1.0059999999999998, -1.033, -1.019, -1.0099999999999998, 0.832, 1.083, -0.519, -1.015, -1.004, -1.012, -0.04100000000000003, 0.4169999999999999, -1.007, 1.322, -1.009, -1.013, 0.46999999999999986, -1.002, -1.02, 0.46299999999999997, -1.0, 0.7839999999999999, -0.037000000000000026, -0.515, -0.517, -0.52, -1.007, -1.021, 0.655, -1.009, -1.015, -1.013, -1.012, -0.539, -1.041, 1.0459999999999998, -1.011, -1.008, -1.034]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22462388526619295, "mean_inference_ms": 1.5041686877466276, "mean_action_processing_ms": 0.06273721217787619, "mean_env_wait_ms": 0.10501030426941775, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019918203353881836, "StateBufferConnector_ms": 0.001502394676208496, "ViewRequirementAgentConnector_ms": 0.031072497367858887}}, "episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.26257, "episode_len_mean": 137.59, "episodes_this_iter": 37, "policy_reward_min": {"blue_0": -1.054, "red_0": -1.031}, "policy_reward_max": {"blue_0": 1.322, "red_0": 0.942}, "policy_reward_mean": {"blue_0": -0.5481900000000001, "red_0": 0.2856200000000001}, "hist_stats": {"episode_reward": [-0.572, 0.27300000000000013, 0.4159999999999999, -0.251, -0.15999999999999992, -0.5079999999999998, -0.9390000000000001, 0.015999999999999903, -0.42100000000000004, -0.47699999999999987, -0.626, -0.568, -0.08500000000000008, -0.3510000000000001, -0.405, -0.062000000000000055, -0.8989999999999999, -0.15300000000000002, -0.07499999999999996, 0.395, -0.7570000000000001, -0.372, -0.1369999999999999, -0.08900000000000007, -0.08100000000000006, -0.16999999999999993, -0.4940000000000001, 0.366, -0.769, -0.135, -0.9470000000000001, -0.23299999999999987, -0.05400000000000004, -0.2580000000000001, -0.9049999999999999, -0.05500000000000005, -0.639, -0.32099999999999995, -0.11799999999999988, -0.16000000000000003, -0.5549999999999999, -0.2739999999999999, -0.02100000000000002, -0.22399999999999998, -0.28700000000000003, -0.30400000000000005, -0.4909999999999999, -0.2929999999999999, -0.821, -0.30199999999999994, -0.17900000000000005, -0.08299999999999996, -0.375, 0.361, -0.561, -0.5019999999999999, -0.09599999999999997, 0.2569999999999999, -0.18100000000000005, -0.4139999999999999, -0.655, -0.11499999999999988, -0.813, -0.3989999999999999, -0.2729999999999998, -0.17700000000000005, 0.06899999999999995, -0.10400000000000009, -0.19899999999999995, -0.15800000000000003, -0.3520000000000001, -0.08600000000000006, -0.6140000000000001, -0.19999999999999996, 0.31499999999999995, -0.131, -0.43800000000000006, -0.5490000000000002, -0.07399999999999984, -0.4710000000000001, 0.43799999999999994, -0.14, -0.2260000000000001, -0.05700000000000005, 0.19199999999999995, 0.1409999999999999, -0.18400000000000005, -0.18699999999999983, -0.3850000000000001, -0.345, -0.16000000000000003, -0.351, -0.22100000000000009, -0.16300000000000003, -0.31700000000000006, -0.897, 0.03299999999999992, -0.19000000000000006, -0.18700000000000006, -0.502], "episode_lengths": [169, 68, 300, 77, 49, 150, 285, 145, 125, 147, 191, 175, 300, 108, 278, 18, 271, 45, 22, 32, 231, 115, 42, 300, 300, 49, 152, 41, 234, 43, 293, 70, 300, 228, 278, 300, 193, 102, 35, 49, 172, 239, 158, 70, 89, 92, 154, 88, 252, 97, 57, 24, 119, 44, 171, 151, 30, 73, 210, 127, 202, 38, 252, 124, 85, 52, 130, 181, 60, 50, 108, 300, 186, 62, 57, 43, 140, 168, 23, 147, 300, 44, 69, 300, 94, 112, 208, 58, 118, 110, 48, 105, 69, 49, 249, 281, 146, 60, 57, 147], "policy_blue_0_reward": [-1.021, -0.5069999999999999, 0.45599999999999996, -1.011, -1.006, -1.025, -1.048, -0.514, -1.024, -1.021, -1.032, -1.023, -0.04500000000000003, 0.6619999999999999, -0.536, -1.004, -1.0319999999999998, -1.005, -1.005, -0.503, -1.032, 0.637, -1.003, -0.035000000000000024, -0.04300000000000003, -1.01, -1.022, -0.504, -1.035, -1.003, -1.054, -1.0079999999999998, -0.035000000000000024, -0.529, -1.026, -0.035000000000000024, -1.034, -1.012, -1.01, 0.843, -1.025, 0.753, 1.01, 0.776, -1.02, -1.012, -1.02, -1.011, -1.043, 0.6990000000000001, -1.008, -1.007, -1.013, -0.505, 0.45399999999999996, -1.018, -1.005, -0.512, -0.531, -1.016, 0.366, -1.0059999999999998, -1.033, -1.019, -1.0099999999999998, 0.832, 1.083, -0.519, -1.015, -1.004, -1.012, -0.04100000000000003, 0.4169999999999999, -1.007, 1.322, -1.009, -1.013, 0.46999999999999986, -1.002, -1.02, 0.46299999999999997, -1.0, 0.7839999999999999, -0.037000000000000026, -0.515, -0.517, -0.52, -1.007, -1.021, 0.655, -1.009, -1.015, -1.013, -1.012, -0.539, -1.041, 1.0459999999999998, -1.011, -1.008, -1.034]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22462388526619295, "mean_inference_ms": 1.5041686877466276, "mean_action_processing_ms": 0.06273721217787619, "mean_env_wait_ms": 0.10501030426941775, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019918203353881836, "StateBufferConnector_ms": 0.001502394676208496, "ViewRequirementAgentConnector_ms": 0.031072497367858887}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.72467580520075, "num_env_steps_trained_throughput_per_sec": 101.72467580520075, "timesteps_total": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 39402.038, "sample_time_ms": 7580.399, "learn_time_ms": 31803.941, "learn_throughput": 125.771, "synch_weights_time_ms": 17.184}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "episodes_total": 381, "training_iteration": 16, "trial_id": "bb874_00000", "date": "2023-09-28_21-40-44", "timestamp": 1695951644, "time_this_iter_s": 39.3241081237793, "time_total_s": 632.0620250701904, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab0b5240>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf01870>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf01e10>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 632.0620250701904, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 34.041071428571435, "ram_util_percent": 25.458928571428576}, "win_rate": 0.81, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5545801848173142, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.025265140870154332, "policy_loss": -0.02482027639343869, "vf_loss": 0.09747491797121863, "vf_explained_var": 0.12024997174739838, "kl": 0.014842018147559394, "entropy": 1.6204451413204273, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "sampler_results": {"episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.897, "episode_reward_mean": -0.22128, "episode_len_mean": 108.62, "episode_media": {}, "episodes_this_iter": 39, "policy_reward_min": {"blue_0": -1.043, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.322, "red_0": 0.963}, "policy_reward_mean": {"blue_0": -0.5170999999999999, "red_0": 0.29581999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.16000000000000003, -0.5549999999999999, -0.2739999999999999, -0.02100000000000002, -0.22399999999999998, -0.28700000000000003, -0.30400000000000005, -0.4909999999999999, -0.2929999999999999, -0.821, -0.30199999999999994, -0.17900000000000005, -0.08299999999999996, -0.375, 0.361, -0.561, -0.5019999999999999, -0.09599999999999997, 0.2569999999999999, -0.18100000000000005, -0.4139999999999999, -0.655, -0.11499999999999988, -0.813, -0.3989999999999999, -0.2729999999999998, -0.17700000000000005, 0.06899999999999995, -0.10400000000000009, -0.19899999999999995, -0.15800000000000003, -0.3520000000000001, -0.08600000000000006, -0.6140000000000001, -0.19999999999999996, 0.31499999999999995, -0.131, -0.43800000000000006, -0.5490000000000002, -0.07399999999999984, -0.4710000000000001, 0.43799999999999994, -0.14, -0.2260000000000001, -0.05700000000000005, 0.19199999999999995, 0.1409999999999999, -0.18400000000000005, -0.18699999999999983, -0.3850000000000001, -0.345, -0.16000000000000003, -0.351, -0.22100000000000009, -0.16300000000000003, -0.31700000000000006, -0.897, 0.03299999999999992, -0.19000000000000006, -0.18700000000000006, -0.502, -0.23199999999999998, -0.6189999999999999, -0.20399999999999996, -0.265, -0.20999999999999996, -0.6279999999999999, -0.20500000000000007, -0.2779999999999999, 0.17499999999999993, -0.30400000000000005, -0.09199999999999997, -0.33199999999999985, 0.374, -0.06599999999999995, -0.09200000000000008, -0.1269999999999999, -0.08199999999999996, -0.29600000000000004, -0.5519999999999999, -0.279, -0.2639999999999999, -0.038000000000000034, -0.3390000000000001, -0.41700000000000004, -0.05700000000000005, 0.29399999999999993, -0.17700000000000005, -0.32099999999999995, 0.31199999999999994, -0.06300000000000006, -0.28600000000000014, -0.10099999999999998, -0.44700000000000006, -0.04500000000000004, -0.32500000000000007, -0.30899999999999994, -0.1499999999999999, -0.04399999999999993, -0.3999999999999999], "episode_lengths": [49, 172, 239, 158, 70, 89, 92, 154, 88, 252, 97, 57, 24, 119, 44, 171, 151, 30, 73, 210, 127, 202, 38, 252, 124, 85, 52, 130, 181, 60, 50, 108, 300, 186, 62, 57, 43, 140, 168, 23, 147, 300, 44, 69, 300, 94, 112, 208, 58, 118, 110, 48, 105, 69, 49, 249, 281, 146, 60, 57, 147, 229, 185, 63, 81, 62, 193, 61, 85, 96, 94, 33, 101, 39, 19, 175, 38, 25, 91, 171, 87, 81, 12, 261, 130, 17, 63, 53, 95, 57, 19, 89, 31, 139, 13, 99, 94, 45, 13, 125], "policy_blue_0_reward": [0.843, -1.025, 0.753, 1.01, 0.776, -1.02, -1.012, -1.02, -1.011, -1.043, 0.6990000000000001, -1.008, -1.007, -1.013, -0.505, 0.45399999999999996, -1.018, -1.005, -0.512, -0.531, -1.016, 0.366, -1.0059999999999998, -1.033, -1.019, -1.0099999999999998, 0.832, 1.083, -0.519, -1.015, -1.004, -1.012, -0.04100000000000003, 0.4169999999999999, -1.007, 1.322, -1.009, -1.013, 0.46999999999999986, -1.002, -1.02, 0.46299999999999997, -1.0, 0.7839999999999999, -0.037000000000000026, -0.515, -0.517, -0.52, -1.007, -1.021, 0.655, -1.009, -1.015, -1.013, -1.012, -0.539, -1.041, 1.0459999999999998, -1.011, -1.008, -1.034, -0.533, -1.0399999999999998, -1.009, -1.016, -1.008, -1.019, -1.013, -1.012, -0.516, 0.707, -1.002, -1.013, -0.507, -1.002, 0.95, -1.007, 0.921, 0.71, -1.028, -1.011, -1.013, -1.001, -0.534, 0.596, -1.005, -0.509, -1.011, 0.6950000000000001, -0.509, -1.005, -1.012, 0.904, -1.018, -1.001, -1.014, -1.0119999999999998, -1.0099999999999998, -1.005, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2243965027002034, "mean_inference_ms": 1.5023079141244018, "mean_action_processing_ms": 0.06263831320730533, "mean_env_wait_ms": 0.10482103635027094, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01976025104522705, "StateBufferConnector_ms": 0.001475691795349121, "ViewRequirementAgentConnector_ms": 0.0308077335357666}}, "episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.897, "episode_reward_mean": -0.22128, "episode_len_mean": 108.62, "episodes_this_iter": 39, "policy_reward_min": {"blue_0": -1.043, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.322, "red_0": 0.963}, "policy_reward_mean": {"blue_0": -0.5170999999999999, "red_0": 0.29581999999999997}, "hist_stats": {"episode_reward": [-0.16000000000000003, -0.5549999999999999, -0.2739999999999999, -0.02100000000000002, -0.22399999999999998, -0.28700000000000003, -0.30400000000000005, -0.4909999999999999, -0.2929999999999999, -0.821, -0.30199999999999994, -0.17900000000000005, -0.08299999999999996, -0.375, 0.361, -0.561, -0.5019999999999999, -0.09599999999999997, 0.2569999999999999, -0.18100000000000005, -0.4139999999999999, -0.655, -0.11499999999999988, -0.813, -0.3989999999999999, -0.2729999999999998, -0.17700000000000005, 0.06899999999999995, -0.10400000000000009, -0.19899999999999995, -0.15800000000000003, -0.3520000000000001, -0.08600000000000006, -0.6140000000000001, -0.19999999999999996, 0.31499999999999995, -0.131, -0.43800000000000006, -0.5490000000000002, -0.07399999999999984, -0.4710000000000001, 0.43799999999999994, -0.14, -0.2260000000000001, -0.05700000000000005, 0.19199999999999995, 0.1409999999999999, -0.18400000000000005, -0.18699999999999983, -0.3850000000000001, -0.345, -0.16000000000000003, -0.351, -0.22100000000000009, -0.16300000000000003, -0.31700000000000006, -0.897, 0.03299999999999992, -0.19000000000000006, -0.18700000000000006, -0.502, -0.23199999999999998, -0.6189999999999999, -0.20399999999999996, -0.265, -0.20999999999999996, -0.6279999999999999, -0.20500000000000007, -0.2779999999999999, 0.17499999999999993, -0.30400000000000005, -0.09199999999999997, -0.33199999999999985, 0.374, -0.06599999999999995, -0.09200000000000008, -0.1269999999999999, -0.08199999999999996, -0.29600000000000004, -0.5519999999999999, -0.279, -0.2639999999999999, -0.038000000000000034, -0.3390000000000001, -0.41700000000000004, -0.05700000000000005, 0.29399999999999993, -0.17700000000000005, -0.32099999999999995, 0.31199999999999994, -0.06300000000000006, -0.28600000000000014, -0.10099999999999998, -0.44700000000000006, -0.04500000000000004, -0.32500000000000007, -0.30899999999999994, -0.1499999999999999, -0.04399999999999993, -0.3999999999999999], "episode_lengths": [49, 172, 239, 158, 70, 89, 92, 154, 88, 252, 97, 57, 24, 119, 44, 171, 151, 30, 73, 210, 127, 202, 38, 252, 124, 85, 52, 130, 181, 60, 50, 108, 300, 186, 62, 57, 43, 140, 168, 23, 147, 300, 44, 69, 300, 94, 112, 208, 58, 118, 110, 48, 105, 69, 49, 249, 281, 146, 60, 57, 147, 229, 185, 63, 81, 62, 193, 61, 85, 96, 94, 33, 101, 39, 19, 175, 38, 25, 91, 171, 87, 81, 12, 261, 130, 17, 63, 53, 95, 57, 19, 89, 31, 139, 13, 99, 94, 45, 13, 125], "policy_blue_0_reward": [0.843, -1.025, 0.753, 1.01, 0.776, -1.02, -1.012, -1.02, -1.011, -1.043, 0.6990000000000001, -1.008, -1.007, -1.013, -0.505, 0.45399999999999996, -1.018, -1.005, -0.512, -0.531, -1.016, 0.366, -1.0059999999999998, -1.033, -1.019, -1.0099999999999998, 0.832, 1.083, -0.519, -1.015, -1.004, -1.012, -0.04100000000000003, 0.4169999999999999, -1.007, 1.322, -1.009, -1.013, 0.46999999999999986, -1.002, -1.02, 0.46299999999999997, -1.0, 0.7839999999999999, -0.037000000000000026, -0.515, -0.517, -0.52, -1.007, -1.021, 0.655, -1.009, -1.015, -1.013, -1.012, -0.539, -1.041, 1.0459999999999998, -1.011, -1.008, -1.034, -0.533, -1.0399999999999998, -1.009, -1.016, -1.008, -1.019, -1.013, -1.012, -0.516, 0.707, -1.002, -1.013, -0.507, -1.002, 0.95, -1.007, 0.921, 0.71, -1.028, -1.011, -1.013, -1.001, -0.534, 0.596, -1.005, -0.509, -1.011, 0.6950000000000001, -0.509, -1.005, -1.012, 0.904, -1.018, -1.001, -1.014, -1.0119999999999998, -1.0099999999999998, -1.005, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2243965027002034, "mean_inference_ms": 1.5023079141244018, "mean_action_processing_ms": 0.06263831320730533, "mean_env_wait_ms": 0.10482103635027094, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01976025104522705, "StateBufferConnector_ms": 0.001475691795349121, "ViewRequirementAgentConnector_ms": 0.0308077335357666}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.63190065860101, "num_env_steps_trained_throughput_per_sec": 101.63190065860101, "timesteps_total": 68000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 136000, "timers": {"training_iteration_time_ms": 39401.559, "sample_time_ms": 7573.518, "learn_time_ms": 31810.273, "learn_throughput": 125.746, "synch_weights_time_ms": 17.256}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "done": false, "episodes_total": 420, "training_iteration": 17, "trial_id": "bb874_00000", "date": "2023-09-28_21-41-24", "timestamp": 1695951684, "time_this_iter_s": 39.3599910736084, "time_total_s": 671.4220161437988, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac064700>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4dd900>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4de4d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 671.4220161437988, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 34.11071428571429, "ram_util_percent": 25.501785714285713}, "win_rate": 0.77, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5550184064234296, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.017721532984796794, "policy_loss": -0.022831423670625857, "vf_loss": 0.08000350809888915, "vf_explained_var": 0.18322582418719927, "kl": 0.010797316033966957, "entropy": 1.6082604613155127, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "sampler_results": {"episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.897, "episode_reward_mean": -0.17540999999999995, "episode_len_mean": 103.06, "episode_media": {}, "episodes_this_iter": 41, "policy_reward_min": {"blue_0": -1.041, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.0459999999999998, "red_0": 0.97}, "policy_reward_mean": {"blue_0": -0.59266, "red_0": 0.4172499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.43799999999999994, -0.14, -0.2260000000000001, -0.05700000000000005, 0.19199999999999995, 0.1409999999999999, -0.18400000000000005, -0.18699999999999983, -0.3850000000000001, -0.345, -0.16000000000000003, -0.351, -0.22100000000000009, -0.16300000000000003, -0.31700000000000006, -0.897, 0.03299999999999992, -0.19000000000000006, -0.18700000000000006, -0.502, -0.23199999999999998, -0.6189999999999999, -0.20399999999999996, -0.265, -0.20999999999999996, -0.6279999999999999, -0.20500000000000007, -0.2779999999999999, 0.17499999999999993, -0.30400000000000005, -0.09199999999999997, -0.33199999999999985, 0.374, -0.06599999999999995, -0.09200000000000008, -0.1269999999999999, -0.08199999999999996, -0.29600000000000004, -0.5519999999999999, -0.279, -0.2639999999999999, -0.038000000000000034, -0.3390000000000001, -0.41700000000000004, -0.05700000000000005, 0.29399999999999993, -0.17700000000000005, -0.32099999999999995, 0.31199999999999994, -0.06300000000000006, -0.28600000000000014, -0.10099999999999998, -0.44700000000000006, -0.04500000000000004, -0.32500000000000007, -0.30899999999999994, -0.1499999999999999, -0.04399999999999993, -0.3999999999999999, -0.2639999999999999, -0.06700000000000005, -0.33199999999999985, -0.19599999999999995, -0.21499999999999986, 0.14700000000000013, -0.35499999999999976, -0.09699999999999975, -0.376, -0.062000000000000055, -0.18200000000000005, -0.30900000000000005, -0.051000000000000045, -0.28900000000000003, -0.22999999999999998, -0.35599999999999987, -0.15399999999999991, -0.23299999999999998, -0.10799999999999998, -0.05799999999999994, -0.08899999999999975, -0.09999999999999998, -0.718, 0.2649999999999999, -0.030000000000000027, -0.06900000000000005, -0.273, 0.04500000000000004, 0.18899999999999995, -0.2829999999999999, -0.0010000000000000009, -0.17299999999999993, -0.08399999999999996, -0.06599999999999995, -0.781, -0.254, -0.18199999999999994, -0.04800000000000004, -0.05499999999999994, -0.133, 0.2849999999999999], "episode_lengths": [300, 44, 69, 300, 94, 112, 208, 58, 118, 110, 48, 105, 69, 49, 249, 281, 146, 60, 57, 147, 229, 185, 63, 81, 62, 193, 61, 85, 96, 94, 33, 101, 39, 19, 175, 38, 25, 91, 171, 87, 81, 12, 261, 130, 17, 63, 53, 95, 57, 19, 89, 31, 139, 13, 99, 94, 45, 13, 125, 233, 300, 103, 63, 66, 109, 109, 29, 117, 300, 56, 96, 300, 89, 68, 111, 47, 71, 187, 17, 27, 30, 227, 73, 10, 300, 81, 142, 98, 86, 154, 52, 27, 19, 240, 80, 57, 16, 18, 41, 69], "policy_blue_0_reward": [0.46299999999999997, -1.0, 0.7839999999999999, -0.037000000000000026, -0.515, -0.517, -0.52, -1.007, -1.021, 0.655, -1.009, -1.015, -1.013, -1.012, -0.539, -1.041, 1.0459999999999998, -1.011, -1.008, -1.034, -0.533, -1.0399999999999998, -1.009, -1.016, -1.008, -1.019, -1.013, -1.012, -0.516, 0.707, -1.002, -1.013, -0.507, -1.002, 0.95, -1.007, 0.921, 0.71, -1.028, -1.011, -1.013, -1.001, -0.534, 0.596, -1.005, -0.509, -1.011, 0.6950000000000001, -0.509, -1.005, -1.012, 0.904, -1.018, -1.001, -1.014, -1.0119999999999998, -1.0099999999999998, -1.005, -1.016, -0.5399999999999999, -0.04400000000000003, -1.016, -1.009, -1.01, -0.5129999999999999, -1.0219999999999998, -1.0059999999999998, 0.63, -0.03900000000000003, 0.824, 0.7, -0.036000000000000025, -1.01, -1.011, -1.0119999999999998, -1.009, -1.015, -0.531, -1.0039999999999998, -1.003, -1.006, -1.03, -0.51, -1.0, -0.05100000000000004, -1.018, -0.515, -0.514, -1.011, 1.0110000000000001, -1.008, 0.917, -1.004, -1.039, -1.009, -1.008, -1.0, -1.001, -1.006, -0.509]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22427259327093085, "mean_inference_ms": 1.5010827223442595, "mean_action_processing_ms": 0.06257815466196498, "mean_env_wait_ms": 0.10472495422053583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019632458686828613, "StateBufferConnector_ms": 0.0014576911926269531, "ViewRequirementAgentConnector_ms": 0.030881285667419434}}, "episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.897, "episode_reward_mean": -0.17540999999999995, "episode_len_mean": 103.06, "episodes_this_iter": 41, "policy_reward_min": {"blue_0": -1.041, "red_0": -1.042}, "policy_reward_max": {"blue_0": 1.0459999999999998, "red_0": 0.97}, "policy_reward_mean": {"blue_0": -0.59266, "red_0": 0.4172499999999999}, "hist_stats": {"episode_reward": [0.43799999999999994, -0.14, -0.2260000000000001, -0.05700000000000005, 0.19199999999999995, 0.1409999999999999, -0.18400000000000005, -0.18699999999999983, -0.3850000000000001, -0.345, -0.16000000000000003, -0.351, -0.22100000000000009, -0.16300000000000003, -0.31700000000000006, -0.897, 0.03299999999999992, -0.19000000000000006, -0.18700000000000006, -0.502, -0.23199999999999998, -0.6189999999999999, -0.20399999999999996, -0.265, -0.20999999999999996, -0.6279999999999999, -0.20500000000000007, -0.2779999999999999, 0.17499999999999993, -0.30400000000000005, -0.09199999999999997, -0.33199999999999985, 0.374, -0.06599999999999995, -0.09200000000000008, -0.1269999999999999, -0.08199999999999996, -0.29600000000000004, -0.5519999999999999, -0.279, -0.2639999999999999, -0.038000000000000034, -0.3390000000000001, -0.41700000000000004, -0.05700000000000005, 0.29399999999999993, -0.17700000000000005, -0.32099999999999995, 0.31199999999999994, -0.06300000000000006, -0.28600000000000014, -0.10099999999999998, -0.44700000000000006, -0.04500000000000004, -0.32500000000000007, -0.30899999999999994, -0.1499999999999999, -0.04399999999999993, -0.3999999999999999, -0.2639999999999999, -0.06700000000000005, -0.33199999999999985, -0.19599999999999995, -0.21499999999999986, 0.14700000000000013, -0.35499999999999976, -0.09699999999999975, -0.376, -0.062000000000000055, -0.18200000000000005, -0.30900000000000005, -0.051000000000000045, -0.28900000000000003, -0.22999999999999998, -0.35599999999999987, -0.15399999999999991, -0.23299999999999998, -0.10799999999999998, -0.05799999999999994, -0.08899999999999975, -0.09999999999999998, -0.718, 0.2649999999999999, -0.030000000000000027, -0.06900000000000005, -0.273, 0.04500000000000004, 0.18899999999999995, -0.2829999999999999, -0.0010000000000000009, -0.17299999999999993, -0.08399999999999996, -0.06599999999999995, -0.781, -0.254, -0.18199999999999994, -0.04800000000000004, -0.05499999999999994, -0.133, 0.2849999999999999], "episode_lengths": [300, 44, 69, 300, 94, 112, 208, 58, 118, 110, 48, 105, 69, 49, 249, 281, 146, 60, 57, 147, 229, 185, 63, 81, 62, 193, 61, 85, 96, 94, 33, 101, 39, 19, 175, 38, 25, 91, 171, 87, 81, 12, 261, 130, 17, 63, 53, 95, 57, 19, 89, 31, 139, 13, 99, 94, 45, 13, 125, 233, 300, 103, 63, 66, 109, 109, 29, 117, 300, 56, 96, 300, 89, 68, 111, 47, 71, 187, 17, 27, 30, 227, 73, 10, 300, 81, 142, 98, 86, 154, 52, 27, 19, 240, 80, 57, 16, 18, 41, 69], "policy_blue_0_reward": [0.46299999999999997, -1.0, 0.7839999999999999, -0.037000000000000026, -0.515, -0.517, -0.52, -1.007, -1.021, 0.655, -1.009, -1.015, -1.013, -1.012, -0.539, -1.041, 1.0459999999999998, -1.011, -1.008, -1.034, -0.533, -1.0399999999999998, -1.009, -1.016, -1.008, -1.019, -1.013, -1.012, -0.516, 0.707, -1.002, -1.013, -0.507, -1.002, 0.95, -1.007, 0.921, 0.71, -1.028, -1.011, -1.013, -1.001, -0.534, 0.596, -1.005, -0.509, -1.011, 0.6950000000000001, -0.509, -1.005, -1.012, 0.904, -1.018, -1.001, -1.014, -1.0119999999999998, -1.0099999999999998, -1.005, -1.016, -0.5399999999999999, -0.04400000000000003, -1.016, -1.009, -1.01, -0.5129999999999999, -1.0219999999999998, -1.0059999999999998, 0.63, -0.03900000000000003, 0.824, 0.7, -0.036000000000000025, -1.01, -1.011, -1.0119999999999998, -1.009, -1.015, -0.531, -1.0039999999999998, -1.003, -1.006, -1.03, -0.51, -1.0, -0.05100000000000004, -1.018, -0.515, -0.514, -1.011, 1.0110000000000001, -1.008, 0.917, -1.004, -1.039, -1.009, -1.008, -1.0, -1.001, -1.006, -0.509]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22427259327093085, "mean_inference_ms": 1.5010827223442595, "mean_action_processing_ms": 0.06257815466196498, "mean_env_wait_ms": 0.10472495422053583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019632458686828613, "StateBufferConnector_ms": 0.0014576911926269531, "ViewRequirementAgentConnector_ms": 0.030881285667419434}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.0125044061757, "num_env_steps_trained_throughput_per_sec": 102.0125044061757, "timesteps_total": 72000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 39390.088, "sample_time_ms": 7568.125, "learn_time_ms": 31804.227, "learn_throughput": 125.769, "synch_weights_time_ms": 17.222}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 461, "training_iteration": 18, "trial_id": "bb874_00000", "date": "2023-09-28_21-42-03", "timestamp": 1695951723, "time_this_iter_s": 39.213135719299316, "time_total_s": 710.6351518630981, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac446260>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4dd990>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4de830>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 710.6351518630981, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 33.275, "ram_util_percent": 25.521428571428572}, "win_rate": 0.84, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6014049982652068, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03113979125895033, "policy_loss": -0.023434431488082434, "vf_loss": 0.10748754550004377, "vf_explained_var": 0.1079048910488685, "kl": 0.01219980221512742, "entropy": 1.6095105644315482, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "sampler_results": {"episode_reward_max": 0.45299999999999996, "episode_reward_min": -0.781, "episode_reward_mean": -0.14689999999999995, "episode_len_mean": 89.72, "episode_media": {}, "episodes_this_iter": 48, "policy_reward_min": {"blue_0": -1.045, "red_0": -1.016}, "policy_reward_max": {"blue_0": 1.403, "red_0": 0.97}, "policy_reward_mean": {"blue_0": -0.60921, "red_0": 0.46230999999999994}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.31199999999999994, -0.06300000000000006, -0.28600000000000014, -0.10099999999999998, -0.44700000000000006, -0.04500000000000004, -0.32500000000000007, -0.30899999999999994, -0.1499999999999999, -0.04399999999999993, -0.3999999999999999, -0.2639999999999999, -0.06700000000000005, -0.33199999999999985, -0.19599999999999995, -0.21499999999999986, 0.14700000000000013, -0.35499999999999976, -0.09699999999999975, -0.376, -0.062000000000000055, -0.18200000000000005, -0.30900000000000005, -0.051000000000000045, -0.28900000000000003, -0.22999999999999998, -0.35599999999999987, -0.15399999999999991, -0.23299999999999998, -0.10799999999999998, -0.05799999999999994, -0.08899999999999975, -0.09999999999999998, -0.718, 0.2649999999999999, -0.030000000000000027, -0.06900000000000005, -0.273, 0.04500000000000004, 0.18899999999999995, -0.2829999999999999, -0.0010000000000000009, -0.17299999999999993, -0.08399999999999996, -0.06599999999999995, -0.781, -0.254, -0.18199999999999994, -0.04800000000000004, -0.05499999999999994, -0.133, 0.2849999999999999, -0.07500000000000007, -0.16300000000000003, 0.2450000000000001, -0.11599999999999988, -0.07299999999999995, -0.1339999999999999, -0.22199999999999998, -0.23099999999999987, -0.47, -0.07200000000000006, -0.18999999999999995, 0.45299999999999996, -0.5719999999999998, -0.29599999999999993, -0.15599999999999992, 0.119, -0.652, -0.10299999999999987, -0.45799999999999985, -0.33299999999999996, -0.1309999999999999, -0.19999999999999996, -0.10999999999999976, -0.2669999999999999, -0.139, -0.11599999999999988, 0.14400000000000013, -0.11099999999999999, -0.06500000000000006, -0.08199999999999985, -0.3710000000000001, 0.31399999999999995, -0.1379999999999999, -0.06600000000000006, 0.387, -0.31300000000000006, -0.17299999999999993, 0.41300000000000003, -0.16999999999999982, 0.013000000000000012, -0.19799999999999973, -0.07100000000000006, -0.06499999999999995, -0.753, -0.11199999999999999, -0.497, -0.21299999999999986, 0.09900000000000009], "episode_lengths": [57, 19, 89, 31, 139, 13, 99, 94, 45, 13, 125, 233, 300, 103, 63, 66, 109, 109, 29, 117, 300, 56, 96, 300, 89, 68, 111, 47, 71, 187, 17, 27, 30, 227, 73, 10, 300, 81, 142, 98, 86, 154, 52, 27, 19, 240, 80, 57, 16, 18, 41, 69, 300, 48, 80, 37, 22, 41, 70, 74, 142, 22, 59, 300, 172, 93, 49, 117, 200, 34, 140, 101, 40, 61, 34, 82, 45, 35, 111, 32, 20, 25, 112, 56, 43, 20, 37, 93, 54, 30, 50, 148, 62, 21, 20, 222, 34, 152, 64, 126], "policy_blue_0_reward": [-0.509, -1.005, -1.012, 0.904, -1.018, -1.001, -1.014, -1.0119999999999998, -1.0099999999999998, -1.005, -1.016, -0.5399999999999999, -0.04400000000000003, -1.016, -1.009, -1.01, -0.5129999999999999, -1.0219999999999998, -1.0059999999999998, 0.63, -0.03900000000000003, 0.824, 0.7, -0.036000000000000025, -1.01, -1.011, -1.0119999999999998, -1.009, -1.015, -0.531, -1.0039999999999998, -1.003, -1.006, -1.03, -0.51, -1.0, -0.05100000000000004, -1.018, -0.515, -0.514, -1.011, 1.0110000000000001, -1.008, 0.917, -1.004, -1.039, -1.009, -1.008, -1.0, -1.001, -1.006, -0.509, -0.04100000000000003, 0.843, 1.2530000000000001, -1.005, -1.003, -1.006, -1.012, -1.01, -1.035, -1.003, -1.0059999999999998, 0.46399999999999997, -1.035, -1.013, -1.003, -0.521, -1.031, -1.008, -1.017, -1.015, -1.004, -1.009, -1.0039999999999998, -1.013, -1.002, -1.005, -0.5159999999999999, 0.899, 0.9359999999999999, -1.003, 0.6449999999999999, -0.507, -1.006, 0.9349999999999999, -0.502, -1.017, -1.007, 1.403, -1.011, -0.523, -1.011, -1.006, -1.002, -1.045, 0.891, -1.019, -1.008, -0.5209999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22427650059599105, "mean_inference_ms": 1.4999859400908995, "mean_action_processing_ms": 0.0625651352604842, "mean_env_wait_ms": 0.10469482995452148, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019007563591003418, "StateBufferConnector_ms": 0.0014584064483642578, "ViewRequirementAgentConnector_ms": 0.030779361724853516}}, "episode_reward_max": 0.45299999999999996, "episode_reward_min": -0.781, "episode_reward_mean": -0.14689999999999995, "episode_len_mean": 89.72, "episodes_this_iter": 48, "policy_reward_min": {"blue_0": -1.045, "red_0": -1.016}, "policy_reward_max": {"blue_0": 1.403, "red_0": 0.97}, "policy_reward_mean": {"blue_0": -0.60921, "red_0": 0.46230999999999994}, "hist_stats": {"episode_reward": [0.31199999999999994, -0.06300000000000006, -0.28600000000000014, -0.10099999999999998, -0.44700000000000006, -0.04500000000000004, -0.32500000000000007, -0.30899999999999994, -0.1499999999999999, -0.04399999999999993, -0.3999999999999999, -0.2639999999999999, -0.06700000000000005, -0.33199999999999985, -0.19599999999999995, -0.21499999999999986, 0.14700000000000013, -0.35499999999999976, -0.09699999999999975, -0.376, -0.062000000000000055, -0.18200000000000005, -0.30900000000000005, -0.051000000000000045, -0.28900000000000003, -0.22999999999999998, -0.35599999999999987, -0.15399999999999991, -0.23299999999999998, -0.10799999999999998, -0.05799999999999994, -0.08899999999999975, -0.09999999999999998, -0.718, 0.2649999999999999, -0.030000000000000027, -0.06900000000000005, -0.273, 0.04500000000000004, 0.18899999999999995, -0.2829999999999999, -0.0010000000000000009, -0.17299999999999993, -0.08399999999999996, -0.06599999999999995, -0.781, -0.254, -0.18199999999999994, -0.04800000000000004, -0.05499999999999994, -0.133, 0.2849999999999999, -0.07500000000000007, -0.16300000000000003, 0.2450000000000001, -0.11599999999999988, -0.07299999999999995, -0.1339999999999999, -0.22199999999999998, -0.23099999999999987, -0.47, -0.07200000000000006, -0.18999999999999995, 0.45299999999999996, -0.5719999999999998, -0.29599999999999993, -0.15599999999999992, 0.119, -0.652, -0.10299999999999987, -0.45799999999999985, -0.33299999999999996, -0.1309999999999999, -0.19999999999999996, -0.10999999999999976, -0.2669999999999999, -0.139, -0.11599999999999988, 0.14400000000000013, -0.11099999999999999, -0.06500000000000006, -0.08199999999999985, -0.3710000000000001, 0.31399999999999995, -0.1379999999999999, -0.06600000000000006, 0.387, -0.31300000000000006, -0.17299999999999993, 0.41300000000000003, -0.16999999999999982, 0.013000000000000012, -0.19799999999999973, -0.07100000000000006, -0.06499999999999995, -0.753, -0.11199999999999999, -0.497, -0.21299999999999986, 0.09900000000000009], "episode_lengths": [57, 19, 89, 31, 139, 13, 99, 94, 45, 13, 125, 233, 300, 103, 63, 66, 109, 109, 29, 117, 300, 56, 96, 300, 89, 68, 111, 47, 71, 187, 17, 27, 30, 227, 73, 10, 300, 81, 142, 98, 86, 154, 52, 27, 19, 240, 80, 57, 16, 18, 41, 69, 300, 48, 80, 37, 22, 41, 70, 74, 142, 22, 59, 300, 172, 93, 49, 117, 200, 34, 140, 101, 40, 61, 34, 82, 45, 35, 111, 32, 20, 25, 112, 56, 43, 20, 37, 93, 54, 30, 50, 148, 62, 21, 20, 222, 34, 152, 64, 126], "policy_blue_0_reward": [-0.509, -1.005, -1.012, 0.904, -1.018, -1.001, -1.014, -1.0119999999999998, -1.0099999999999998, -1.005, -1.016, -0.5399999999999999, -0.04400000000000003, -1.016, -1.009, -1.01, -0.5129999999999999, -1.0219999999999998, -1.0059999999999998, 0.63, -0.03900000000000003, 0.824, 0.7, -0.036000000000000025, -1.01, -1.011, -1.0119999999999998, -1.009, -1.015, -0.531, -1.0039999999999998, -1.003, -1.006, -1.03, -0.51, -1.0, -0.05100000000000004, -1.018, -0.515, -0.514, -1.011, 1.0110000000000001, -1.008, 0.917, -1.004, -1.039, -1.009, -1.008, -1.0, -1.001, -1.006, -0.509, -0.04100000000000003, 0.843, 1.2530000000000001, -1.005, -1.003, -1.006, -1.012, -1.01, -1.035, -1.003, -1.0059999999999998, 0.46399999999999997, -1.035, -1.013, -1.003, -0.521, -1.031, -1.008, -1.017, -1.015, -1.004, -1.009, -1.0039999999999998, -1.013, -1.002, -1.005, -0.5159999999999999, 0.899, 0.9359999999999999, -1.003, 0.6449999999999999, -0.507, -1.006, 0.9349999999999999, -0.502, -1.017, -1.007, 1.403, -1.011, -0.523, -1.011, -1.006, -1.002, -1.045, 0.891, -1.019, -1.008, -0.5209999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22427650059599105, "mean_inference_ms": 1.4999859400908995, "mean_action_processing_ms": 0.0625651352604842, "mean_env_wait_ms": 0.10469482995452148, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019007563591003418, "StateBufferConnector_ms": 0.0014584064483642578, "ViewRequirementAgentConnector_ms": 0.030779361724853516}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.03795334826692, "num_env_steps_trained_throughput_per_sec": 102.03795334826692, "timesteps_total": 76000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 152000, "timers": {"training_iteration_time_ms": 39377.535, "sample_time_ms": 7562.731, "learn_time_ms": 31797.074, "learn_throughput": 125.798, "synch_weights_time_ms": 17.221}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "done": false, "episodes_total": 509, "training_iteration": 19, "trial_id": "bb874_00000", "date": "2023-09-28_21-42-42", "timestamp": 1695951762, "time_this_iter_s": 39.20346927642822, "time_total_s": 749.8386211395264, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac4ff340>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4def80>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dd6c0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 749.8386211395264, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 34.374545454545455, "ram_util_percent": 25.607272727272715}, "win_rate": 0.85, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6305344951028624, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0324311835255988, "policy_loss": -0.02083943966475393, "vf_loss": 0.10514387062285095, "vf_explained_var": 0.12723195248593885, "kl": 0.011495659770950321, "entropy": 1.6004436353842417, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "sampler_results": {"episode_reward_max": 0.8779999999999999, "episode_reward_min": -0.843, "episode_reward_mean": -0.10769999999999996, "episode_len_mean": 84.65, "episode_media": {}, "episodes_this_iter": 46, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.037}, "policy_reward_max": {"blue_0": 1.403, "red_0": 0.967}, "policy_reward_mean": {"blue_0": -0.55143, "red_0": 0.44372999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.254, -0.18199999999999994, -0.04800000000000004, -0.05499999999999994, -0.133, 0.2849999999999999, -0.07500000000000007, -0.16300000000000003, 0.2450000000000001, -0.11599999999999988, -0.07299999999999995, -0.1339999999999999, -0.22199999999999998, -0.23099999999999987, -0.47, -0.07200000000000006, -0.18999999999999995, 0.45299999999999996, -0.5719999999999998, -0.29599999999999993, -0.15599999999999992, 0.119, -0.652, -0.10299999999999987, -0.45799999999999985, -0.33299999999999996, -0.1309999999999999, -0.19999999999999996, -0.10999999999999976, -0.2669999999999999, -0.139, -0.11599999999999988, 0.14400000000000013, -0.11099999999999999, -0.06500000000000006, -0.08199999999999985, -0.3710000000000001, 0.31399999999999995, -0.1379999999999999, -0.06600000000000006, 0.387, -0.31300000000000006, -0.17299999999999993, 0.41300000000000003, -0.16999999999999982, 0.013000000000000012, -0.19799999999999973, -0.07100000000000006, -0.06499999999999995, -0.753, -0.11199999999999999, -0.497, -0.21299999999999986, 0.09900000000000009, -0.4690000000000001, -0.09100000000000008, -0.1309999999999999, -0.133, 0.28900000000000003, -0.33299999999999996, -0.263, 0.31800000000000006, -0.1389999999999998, 0.20800000000000018, -0.14200000000000002, 0.30499999999999994, -0.44299999999999995, -0.17200000000000004, -0.17400000000000004, -0.10399999999999987, -0.08999999999999997, -0.10099999999999976, 0.359, -0.537, -0.22999999999999987, -0.09599999999999986, -0.20900000000000007, -0.5579999999999999, 0.22799999999999998, -0.03599999999999992, -0.20999999999999996, -0.3710000000000001, 0.025000000000000022, -0.2280000000000001, -0.18500000000000005, -0.08899999999999997, -0.26, 0.41500000000000004, 0.43499999999999994, -0.18900000000000006, -0.17800000000000005, 0.8779999999999999, -0.704, -0.139, -0.843, 0.30300000000000016, 0.376, -0.08199999999999996, -0.03600000000000003, -0.06700000000000006], "episode_lengths": [80, 57, 16, 18, 41, 69, 300, 48, 80, 37, 22, 41, 70, 74, 142, 22, 59, 300, 172, 93, 49, 117, 200, 34, 140, 101, 40, 61, 34, 82, 45, 35, 111, 32, 20, 25, 112, 56, 43, 20, 37, 93, 54, 30, 50, 148, 62, 21, 20, 222, 34, 152, 64, 126, 143, 178, 42, 39, 64, 102, 83, 56, 43, 95, 44, 60, 128, 53, 54, 33, 26, 33, 45, 169, 71, 29, 217, 173, 89, 11, 63, 114, 148, 225, 209, 27, 78, 26, 300, 59, 56, 198, 217, 43, 250, 64, 39, 25, 12, 21], "policy_blue_0_reward": [-1.009, -1.008, -1.0, -1.001, -1.006, -0.509, -0.04100000000000003, 0.843, 1.2530000000000001, -1.005, -1.003, -1.006, -1.012, -1.01, -1.035, -1.003, -1.0059999999999998, 0.46399999999999997, -1.035, -1.013, -1.003, -0.521, -1.031, -1.008, -1.017, -1.015, -1.004, -1.009, -1.0039999999999998, -1.013, -1.002, -1.005, -0.5159999999999999, 0.899, 0.9359999999999999, -1.003, 0.6449999999999999, -0.507, -1.006, 0.9349999999999999, -0.502, -1.017, -1.007, 1.403, -1.011, -0.523, -1.011, -1.006, -1.002, -1.045, 0.891, -1.019, -1.008, -0.5209999999999999, -1.025, 0.946, -1.003, -1.005, -0.505, -1.013, 0.739, -0.5109999999999999, -1.0039999999999998, -0.5159999999999999, -1.006, -0.51, -1.018, 0.837, -1.008, -1.003, -1.006, -1.0059999999999998, -0.505, -1.023, -1.0059999999999998, -1.002, -0.53, -1.033, -0.509, -1.003, -1.011, 0.6379999999999999, -0.517, -0.543, -0.528, -1.003, 0.751, -0.505, 0.45399999999999996, -1.006, -1.007, 0.475, -1.035, 0.868, -1.048, -0.5069999999999999, -0.505, 0.923, 0.964, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22431619255833027, "mean_inference_ms": 1.4992903459346723, "mean_action_processing_ms": 0.06254007398852292, "mean_env_wait_ms": 0.10470308955863139, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019133806228637695, "StateBufferConnector_ms": 0.0014579296112060547, "ViewRequirementAgentConnector_ms": 0.03075242042541504}}, "episode_reward_max": 0.8779999999999999, "episode_reward_min": -0.843, "episode_reward_mean": -0.10769999999999996, "episode_len_mean": 84.65, "episodes_this_iter": 46, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.037}, "policy_reward_max": {"blue_0": 1.403, "red_0": 0.967}, "policy_reward_mean": {"blue_0": -0.55143, "red_0": 0.44372999999999996}, "hist_stats": {"episode_reward": [-0.254, -0.18199999999999994, -0.04800000000000004, -0.05499999999999994, -0.133, 0.2849999999999999, -0.07500000000000007, -0.16300000000000003, 0.2450000000000001, -0.11599999999999988, -0.07299999999999995, -0.1339999999999999, -0.22199999999999998, -0.23099999999999987, -0.47, -0.07200000000000006, -0.18999999999999995, 0.45299999999999996, -0.5719999999999998, -0.29599999999999993, -0.15599999999999992, 0.119, -0.652, -0.10299999999999987, -0.45799999999999985, -0.33299999999999996, -0.1309999999999999, -0.19999999999999996, -0.10999999999999976, -0.2669999999999999, -0.139, -0.11599999999999988, 0.14400000000000013, -0.11099999999999999, -0.06500000000000006, -0.08199999999999985, -0.3710000000000001, 0.31399999999999995, -0.1379999999999999, -0.06600000000000006, 0.387, -0.31300000000000006, -0.17299999999999993, 0.41300000000000003, -0.16999999999999982, 0.013000000000000012, -0.19799999999999973, -0.07100000000000006, -0.06499999999999995, -0.753, -0.11199999999999999, -0.497, -0.21299999999999986, 0.09900000000000009, -0.4690000000000001, -0.09100000000000008, -0.1309999999999999, -0.133, 0.28900000000000003, -0.33299999999999996, -0.263, 0.31800000000000006, -0.1389999999999998, 0.20800000000000018, -0.14200000000000002, 0.30499999999999994, -0.44299999999999995, -0.17200000000000004, -0.17400000000000004, -0.10399999999999987, -0.08999999999999997, -0.10099999999999976, 0.359, -0.537, -0.22999999999999987, -0.09599999999999986, -0.20900000000000007, -0.5579999999999999, 0.22799999999999998, -0.03599999999999992, -0.20999999999999996, -0.3710000000000001, 0.025000000000000022, -0.2280000000000001, -0.18500000000000005, -0.08899999999999997, -0.26, 0.41500000000000004, 0.43499999999999994, -0.18900000000000006, -0.17800000000000005, 0.8779999999999999, -0.704, -0.139, -0.843, 0.30300000000000016, 0.376, -0.08199999999999996, -0.03600000000000003, -0.06700000000000006], "episode_lengths": [80, 57, 16, 18, 41, 69, 300, 48, 80, 37, 22, 41, 70, 74, 142, 22, 59, 300, 172, 93, 49, 117, 200, 34, 140, 101, 40, 61, 34, 82, 45, 35, 111, 32, 20, 25, 112, 56, 43, 20, 37, 93, 54, 30, 50, 148, 62, 21, 20, 222, 34, 152, 64, 126, 143, 178, 42, 39, 64, 102, 83, 56, 43, 95, 44, 60, 128, 53, 54, 33, 26, 33, 45, 169, 71, 29, 217, 173, 89, 11, 63, 114, 148, 225, 209, 27, 78, 26, 300, 59, 56, 198, 217, 43, 250, 64, 39, 25, 12, 21], "policy_blue_0_reward": [-1.009, -1.008, -1.0, -1.001, -1.006, -0.509, -0.04100000000000003, 0.843, 1.2530000000000001, -1.005, -1.003, -1.006, -1.012, -1.01, -1.035, -1.003, -1.0059999999999998, 0.46399999999999997, -1.035, -1.013, -1.003, -0.521, -1.031, -1.008, -1.017, -1.015, -1.004, -1.009, -1.0039999999999998, -1.013, -1.002, -1.005, -0.5159999999999999, 0.899, 0.9359999999999999, -1.003, 0.6449999999999999, -0.507, -1.006, 0.9349999999999999, -0.502, -1.017, -1.007, 1.403, -1.011, -0.523, -1.011, -1.006, -1.002, -1.045, 0.891, -1.019, -1.008, -0.5209999999999999, -1.025, 0.946, -1.003, -1.005, -0.505, -1.013, 0.739, -0.5109999999999999, -1.0039999999999998, -0.5159999999999999, -1.006, -0.51, -1.018, 0.837, -1.008, -1.003, -1.006, -1.0059999999999998, -0.505, -1.023, -1.0059999999999998, -1.002, -0.53, -1.033, -0.509, -1.003, -1.011, 0.6379999999999999, -0.517, -0.543, -0.528, -1.003, 0.751, -0.505, 0.45399999999999996, -1.006, -1.007, 0.475, -1.035, 0.868, -1.048, -0.5069999999999999, -0.505, 0.923, 0.964, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22431619255833027, "mean_inference_ms": 1.4992903459346723, "mean_action_processing_ms": 0.06254007398852292, "mean_env_wait_ms": 0.10470308955863139, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019133806228637695, "StateBufferConnector_ms": 0.0014579296112060547, "ViewRequirementAgentConnector_ms": 0.03075242042541504}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.46379276668449, "num_env_steps_trained_throughput_per_sec": 101.46379276668449, "timesteps_total": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 39385.391, "sample_time_ms": 7555.344, "learn_time_ms": 31812.337, "learn_throughput": 125.737, "synch_weights_time_ms": 17.203}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 555, "training_iteration": 20, "trial_id": "bb874_00000", "date": "2023-09-28_21-43-21", "timestamp": 1695951801, "time_this_iter_s": 39.42524194717407, "time_total_s": 789.2638630867004, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab6ad450>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4051b0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4076d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 789.2638630867004, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 36.10892857142857, "ram_util_percent": 25.719642857142855}, "win_rate": 0.81, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.689831797219813, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.014401740054987991, "policy_loss": -0.024343477824004367, "vf_loss": 0.07581513337014864, "vf_explained_var": 0.2547074407959978, "kl": 0.012175611014223382, "entropy": 1.5974711341162522, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "sampler_results": {"episode_reward_max": 0.8779999999999999, "episode_reward_min": -0.8810000000000001, "episode_reward_mean": -0.12561999999999995, "episode_len_mean": 93.55, "episode_media": {}, "episodes_this_iter": 42, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.047}, "policy_reward_max": {"blue_0": 1.403, "red_0": 0.967}, "policy_reward_mean": {"blue_0": -0.54999, "red_0": 0.42436999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.17299999999999993, 0.41300000000000003, -0.16999999999999982, 0.013000000000000012, -0.19799999999999973, -0.07100000000000006, -0.06499999999999995, -0.753, -0.11199999999999999, -0.497, -0.21299999999999986, 0.09900000000000009, -0.4690000000000001, -0.09100000000000008, -0.1309999999999999, -0.133, 0.28900000000000003, -0.33299999999999996, -0.263, 0.31800000000000006, -0.1389999999999998, 0.20800000000000018, -0.14200000000000002, 0.30499999999999994, -0.44299999999999995, -0.17200000000000004, -0.17400000000000004, -0.10399999999999987, -0.08999999999999997, -0.10099999999999976, 0.359, -0.537, -0.22999999999999987, -0.09599999999999986, -0.20900000000000007, -0.5579999999999999, 0.22799999999999998, -0.03599999999999992, -0.20999999999999996, -0.3710000000000001, 0.025000000000000022, -0.2280000000000001, -0.18500000000000005, -0.08899999999999997, -0.26, 0.41500000000000004, 0.43499999999999994, -0.18900000000000006, -0.17800000000000005, 0.8779999999999999, -0.704, -0.139, -0.843, 0.30300000000000016, 0.376, -0.08199999999999996, -0.03600000000000003, -0.06700000000000006, -0.2469999999999999, -0.05900000000000005, -0.45600000000000007, -0.23199999999999987, -0.2509999999999999, -0.2489999999999999, -0.12299999999999989, 0.121, -0.05999999999999994, -0.23999999999999988, 0.08399999999999996, -0.134, -0.8810000000000001, -0.18699999999999983, -0.4179999999999999, -0.15399999999999991, -0.10699999999999998, -0.11199999999999999, -0.15599999999999992, 0.43299999999999994, -0.137, -0.5790000000000001, -0.21299999999999986, -0.20199999999999996, -0.2719999999999998, -0.6309999999999999, 0.249, -0.1469999999999998, -0.20300000000000007, 0.42899999999999994, -0.07300000000000006, -0.249, -0.0030000000000000027, -0.2759999999999999, -0.10499999999999998, -0.07500000000000007, -0.11199999999999999, 0.132, -0.2819999999999999, -0.2799999999999999, -0.08599999999999985, -0.3989999999999999], "episode_lengths": [54, 30, 50, 148, 62, 21, 20, 222, 34, 152, 64, 126, 143, 178, 42, 39, 64, 102, 83, 56, 43, 95, 44, 60, 128, 53, 54, 33, 26, 33, 45, 169, 71, 29, 217, 173, 89, 11, 63, 114, 148, 225, 209, 27, 78, 26, 300, 59, 56, 198, 217, 43, 250, 64, 39, 25, 12, 21, 76, 22, 138, 75, 80, 78, 38, 118, 19, 75, 129, 39, 266, 58, 136, 49, 190, 34, 47, 300, 46, 181, 70, 61, 84, 200, 81, 43, 65, 300, 21, 76, 158, 85, 33, 24, 187, 115, 87, 85, 27, 122], "policy_blue_0_reward": [-1.007, 1.403, -1.011, -0.523, -1.011, -1.006, -1.002, -1.045, 0.891, -1.019, -1.008, -0.5209999999999999, -1.025, 0.946, -1.003, -1.005, -0.505, -1.013, 0.739, -0.5109999999999999, -1.0039999999999998, -0.5159999999999999, -1.006, -0.51, -1.018, 0.837, -1.008, -1.003, -1.006, -1.0059999999999998, -0.505, -1.023, -1.0059999999999998, -1.002, -0.53, -1.033, -0.509, -1.003, -1.011, 0.6379999999999999, -0.517, -0.543, -0.528, -1.003, 0.751, -0.505, 0.45399999999999996, -1.006, -1.007, 0.475, -1.035, 0.868, -1.048, -0.5069999999999999, -0.505, 0.923, 0.964, -1.004, -1.015, 0.9329999999999999, 0.566, -1.013, -1.013, -1.009, -1.004, -0.516, -1.001, -1.007, -0.513, 0.876, 0.16599999999999993, -1.005, -1.014, -1.007, -0.535, -1.005, -1.008, 0.45499999999999996, -1.008, -1.024, -1.0099999999999998, -1.008, -1.013, -1.02, -0.506, -1.0119999999999998, -1.007, 0.45599999999999996, -1.005, 0.758, -0.519, -1.0139999999999998, -1.005, 0.9269999999999999, -0.527, -0.512, -1.013, -1.01, -1.004, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22435244897313694, "mean_inference_ms": 1.4992637217664342, "mean_action_processing_ms": 0.06251811292899838, "mean_env_wait_ms": 0.10471116405029952, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0191042423248291, "StateBufferConnector_ms": 0.0014545917510986328, "ViewRequirementAgentConnector_ms": 0.03077101707458496}}, "episode_reward_max": 0.8779999999999999, "episode_reward_min": -0.8810000000000001, "episode_reward_mean": -0.12561999999999995, "episode_len_mean": 93.55, "episodes_this_iter": 42, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.047}, "policy_reward_max": {"blue_0": 1.403, "red_0": 0.967}, "policy_reward_mean": {"blue_0": -0.54999, "red_0": 0.42436999999999997}, "hist_stats": {"episode_reward": [-0.17299999999999993, 0.41300000000000003, -0.16999999999999982, 0.013000000000000012, -0.19799999999999973, -0.07100000000000006, -0.06499999999999995, -0.753, -0.11199999999999999, -0.497, -0.21299999999999986, 0.09900000000000009, -0.4690000000000001, -0.09100000000000008, -0.1309999999999999, -0.133, 0.28900000000000003, -0.33299999999999996, -0.263, 0.31800000000000006, -0.1389999999999998, 0.20800000000000018, -0.14200000000000002, 0.30499999999999994, -0.44299999999999995, -0.17200000000000004, -0.17400000000000004, -0.10399999999999987, -0.08999999999999997, -0.10099999999999976, 0.359, -0.537, -0.22999999999999987, -0.09599999999999986, -0.20900000000000007, -0.5579999999999999, 0.22799999999999998, -0.03599999999999992, -0.20999999999999996, -0.3710000000000001, 0.025000000000000022, -0.2280000000000001, -0.18500000000000005, -0.08899999999999997, -0.26, 0.41500000000000004, 0.43499999999999994, -0.18900000000000006, -0.17800000000000005, 0.8779999999999999, -0.704, -0.139, -0.843, 0.30300000000000016, 0.376, -0.08199999999999996, -0.03600000000000003, -0.06700000000000006, -0.2469999999999999, -0.05900000000000005, -0.45600000000000007, -0.23199999999999987, -0.2509999999999999, -0.2489999999999999, -0.12299999999999989, 0.121, -0.05999999999999994, -0.23999999999999988, 0.08399999999999996, -0.134, -0.8810000000000001, -0.18699999999999983, -0.4179999999999999, -0.15399999999999991, -0.10699999999999998, -0.11199999999999999, -0.15599999999999992, 0.43299999999999994, -0.137, -0.5790000000000001, -0.21299999999999986, -0.20199999999999996, -0.2719999999999998, -0.6309999999999999, 0.249, -0.1469999999999998, -0.20300000000000007, 0.42899999999999994, -0.07300000000000006, -0.249, -0.0030000000000000027, -0.2759999999999999, -0.10499999999999998, -0.07500000000000007, -0.11199999999999999, 0.132, -0.2819999999999999, -0.2799999999999999, -0.08599999999999985, -0.3989999999999999], "episode_lengths": [54, 30, 50, 148, 62, 21, 20, 222, 34, 152, 64, 126, 143, 178, 42, 39, 64, 102, 83, 56, 43, 95, 44, 60, 128, 53, 54, 33, 26, 33, 45, 169, 71, 29, 217, 173, 89, 11, 63, 114, 148, 225, 209, 27, 78, 26, 300, 59, 56, 198, 217, 43, 250, 64, 39, 25, 12, 21, 76, 22, 138, 75, 80, 78, 38, 118, 19, 75, 129, 39, 266, 58, 136, 49, 190, 34, 47, 300, 46, 181, 70, 61, 84, 200, 81, 43, 65, 300, 21, 76, 158, 85, 33, 24, 187, 115, 87, 85, 27, 122], "policy_blue_0_reward": [-1.007, 1.403, -1.011, -0.523, -1.011, -1.006, -1.002, -1.045, 0.891, -1.019, -1.008, -0.5209999999999999, -1.025, 0.946, -1.003, -1.005, -0.505, -1.013, 0.739, -0.5109999999999999, -1.0039999999999998, -0.5159999999999999, -1.006, -0.51, -1.018, 0.837, -1.008, -1.003, -1.006, -1.0059999999999998, -0.505, -1.023, -1.0059999999999998, -1.002, -0.53, -1.033, -0.509, -1.003, -1.011, 0.6379999999999999, -0.517, -0.543, -0.528, -1.003, 0.751, -0.505, 0.45399999999999996, -1.006, -1.007, 0.475, -1.035, 0.868, -1.048, -0.5069999999999999, -0.505, 0.923, 0.964, -1.004, -1.015, 0.9329999999999999, 0.566, -1.013, -1.013, -1.009, -1.004, -0.516, -1.001, -1.007, -0.513, 0.876, 0.16599999999999993, -1.005, -1.014, -1.007, -0.535, -1.005, -1.008, 0.45499999999999996, -1.008, -1.024, -1.0099999999999998, -1.008, -1.013, -1.02, -0.506, -1.0119999999999998, -1.007, 0.45599999999999996, -1.005, 0.758, -0.519, -1.0139999999999998, -1.005, 0.9269999999999999, -0.527, -0.512, -1.013, -1.01, -1.004, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22435244897313694, "mean_inference_ms": 1.4992637217664342, "mean_action_processing_ms": 0.06251811292899838, "mean_env_wait_ms": 0.10471116405029952, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0191042423248291, "StateBufferConnector_ms": 0.0014545917510986328, "ViewRequirementAgentConnector_ms": 0.03077101707458496}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.86400656865933, "num_env_steps_trained_throughput_per_sec": 101.86400656865933, "timesteps_total": 84000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 168000, "timers": {"training_iteration_time_ms": 39376.818, "sample_time_ms": 7548.285, "learn_time_ms": 31810.829, "learn_throughput": 125.743, "synch_weights_time_ms": 17.197}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "done": false, "episodes_total": 597, "training_iteration": 21, "trial_id": "bb874_00000", "date": "2023-09-28_21-44-01", "timestamp": 1695951841, "time_this_iter_s": 39.27031087875366, "time_total_s": 828.5341739654541, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac064ac0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac3241f0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf02710>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 828.5341739654541, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 35.35892857142857, "ram_util_percent": 25.8375}, "win_rate": 0.8, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7577862556402881, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.011563329882483231, "policy_loss": -0.02696391837137829, "vf_loss": 0.07421937097484867, "vf_explained_var": 0.22221698872745038, "kl": 0.014958524636552565, "entropy": 1.5741422081987062, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "sampler_results": {"episode_reward_max": 0.768, "episode_reward_min": -0.8810000000000001, "episode_reward_mean": -0.13739999999999994, "episode_len_mean": 83.6, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.047}, "policy_reward_max": {"blue_0": 0.964, "red_0": 0.963}, "policy_reward_mean": {"blue_0": -0.6622800000000001, "red_0": 0.5248799999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.704, -0.139, -0.843, 0.30300000000000016, 0.376, -0.08199999999999996, -0.03600000000000003, -0.06700000000000006, -0.2469999999999999, -0.05900000000000005, -0.45600000000000007, -0.23199999999999987, -0.2509999999999999, -0.2489999999999999, -0.12299999999999989, 0.121, -0.05999999999999994, -0.23999999999999988, 0.08399999999999996, -0.134, -0.8810000000000001, -0.18699999999999983, -0.4179999999999999, -0.15399999999999991, -0.10699999999999998, -0.11199999999999999, -0.15599999999999992, 0.43299999999999994, -0.137, -0.5790000000000001, -0.21299999999999986, -0.20199999999999996, -0.2719999999999998, -0.6309999999999999, 0.249, -0.1469999999999998, -0.20300000000000007, 0.42899999999999994, -0.07300000000000006, -0.249, -0.0030000000000000027, -0.2759999999999999, -0.10499999999999998, -0.07500000000000007, -0.11199999999999999, 0.132, -0.2819999999999999, -0.2799999999999999, -0.08599999999999985, -0.3989999999999999, -0.1649999999999998, -0.1529999999999999, 0.11099999999999999, 0.4169999999999999, -0.1609999999999998, 0.45000000000000007, -0.04299999999999993, -0.21899999999999986, -0.05599999999999994, 0.19199999999999995, -0.126, -0.11099999999999999, -0.06299999999999994, -0.16199999999999992, -0.06300000000000006, -0.12099999999999989, -0.4229999999999998, -0.43999999999999995, -0.15399999999999991, -0.03699999999999992, -0.584, -0.038999999999999924, -0.41900000000000015, -0.17099999999999993, -0.19999999999999996, -0.34499999999999986, -0.07499999999999996, 0.768, -0.32400000000000007, 0.07900000000000007, -0.17700000000000005, 0.44699999999999995, -0.06299999999999994, -0.263, -0.44600000000000006, -0.399, -0.07599999999999985, -0.131, -0.17700000000000005, -0.242, -0.06499999999999995, -0.17000000000000004, -0.04599999999999993, -0.393, -0.10999999999999999, -0.05900000000000005, -0.21999999999999975, -0.15900000000000003, -0.07899999999999996, -0.1409999999999999], "episode_lengths": [217, 43, 250, 64, 39, 25, 12, 21, 76, 22, 138, 75, 80, 78, 38, 118, 19, 75, 129, 39, 266, 58, 136, 49, 190, 34, 47, 300, 46, 181, 70, 61, 84, 200, 81, 43, 65, 300, 21, 76, 158, 85, 33, 24, 187, 115, 87, 85, 27, 122, 51, 48, 122, 300, 47, 16, 14, 69, 17, 98, 38, 35, 20, 51, 171, 38, 133, 131, 49, 12, 185, 12, 128, 52, 62, 110, 24, 77, 100, 136, 53, 17, 21, 82, 138, 125, 23, 39, 53, 76, 20, 52, 15, 117, 34, 174, 68, 49, 25, 44], "policy_blue_0_reward": [-1.035, 0.868, -1.048, -0.5069999999999999, -0.505, 0.923, 0.964, -1.004, -1.015, 0.9329999999999999, 0.566, -1.013, -1.013, -1.009, -1.004, -0.516, -1.001, -1.007, -0.513, 0.876, 0.16599999999999993, -1.005, -1.014, -1.007, -0.535, -1.005, -1.008, 0.45499999999999996, -1.008, -1.024, -1.0099999999999998, -1.008, -1.013, -1.02, -0.506, -1.0119999999999998, -1.007, 0.45599999999999996, -1.005, 0.758, -0.519, -1.0139999999999998, -1.005, 0.9269999999999999, -0.527, -0.512, -1.013, -1.01, -1.004, -1.021, -1.0099999999999998, -1.008, -0.515, 0.46599999999999997, -1.013, -0.5009999999999999, -1.0, -1.013, -1.003, -0.511, -1.006, -1.004, -1.002, -1.0059999999999998, -0.525, -1.004, -1.0199999999999998, -1.021, 0.849, -1.0, -1.03, -1.002, -1.02, -1.005, -1.008, -1.014, -1.001, -0.006, -1.016, -0.514, -1.01, -0.501, -1.0039999999999998, 0.744, -1.02, -1.015, -1.005, -1.006, -1.013, 0.762, -1.002, -1.01, -1.0, -1.021, -1.004, -0.522, -1.0099999999999998, -1.011, -1.004, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22426526949024783, "mean_inference_ms": 1.4971276522853783, "mean_action_processing_ms": 0.06246153393705564, "mean_env_wait_ms": 0.10462882728681873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019147515296936035, "StateBufferConnector_ms": 0.0014458894729614258, "ViewRequirementAgentConnector_ms": 0.0306471586227417}}, "episode_reward_max": 0.768, "episode_reward_min": -0.8810000000000001, "episode_reward_mean": -0.13739999999999994, "episode_len_mean": 83.6, "episodes_this_iter": 50, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.047}, "policy_reward_max": {"blue_0": 0.964, "red_0": 0.963}, "policy_reward_mean": {"blue_0": -0.6622800000000001, "red_0": 0.5248799999999999}, "hist_stats": {"episode_reward": [-0.704, -0.139, -0.843, 0.30300000000000016, 0.376, -0.08199999999999996, -0.03600000000000003, -0.06700000000000006, -0.2469999999999999, -0.05900000000000005, -0.45600000000000007, -0.23199999999999987, -0.2509999999999999, -0.2489999999999999, -0.12299999999999989, 0.121, -0.05999999999999994, -0.23999999999999988, 0.08399999999999996, -0.134, -0.8810000000000001, -0.18699999999999983, -0.4179999999999999, -0.15399999999999991, -0.10699999999999998, -0.11199999999999999, -0.15599999999999992, 0.43299999999999994, -0.137, -0.5790000000000001, -0.21299999999999986, -0.20199999999999996, -0.2719999999999998, -0.6309999999999999, 0.249, -0.1469999999999998, -0.20300000000000007, 0.42899999999999994, -0.07300000000000006, -0.249, -0.0030000000000000027, -0.2759999999999999, -0.10499999999999998, -0.07500000000000007, -0.11199999999999999, 0.132, -0.2819999999999999, -0.2799999999999999, -0.08599999999999985, -0.3989999999999999, -0.1649999999999998, -0.1529999999999999, 0.11099999999999999, 0.4169999999999999, -0.1609999999999998, 0.45000000000000007, -0.04299999999999993, -0.21899999999999986, -0.05599999999999994, 0.19199999999999995, -0.126, -0.11099999999999999, -0.06299999999999994, -0.16199999999999992, -0.06300000000000006, -0.12099999999999989, -0.4229999999999998, -0.43999999999999995, -0.15399999999999991, -0.03699999999999992, -0.584, -0.038999999999999924, -0.41900000000000015, -0.17099999999999993, -0.19999999999999996, -0.34499999999999986, -0.07499999999999996, 0.768, -0.32400000000000007, 0.07900000000000007, -0.17700000000000005, 0.44699999999999995, -0.06299999999999994, -0.263, -0.44600000000000006, -0.399, -0.07599999999999985, -0.131, -0.17700000000000005, -0.242, -0.06499999999999995, -0.17000000000000004, -0.04599999999999993, -0.393, -0.10999999999999999, -0.05900000000000005, -0.21999999999999975, -0.15900000000000003, -0.07899999999999996, -0.1409999999999999], "episode_lengths": [217, 43, 250, 64, 39, 25, 12, 21, 76, 22, 138, 75, 80, 78, 38, 118, 19, 75, 129, 39, 266, 58, 136, 49, 190, 34, 47, 300, 46, 181, 70, 61, 84, 200, 81, 43, 65, 300, 21, 76, 158, 85, 33, 24, 187, 115, 87, 85, 27, 122, 51, 48, 122, 300, 47, 16, 14, 69, 17, 98, 38, 35, 20, 51, 171, 38, 133, 131, 49, 12, 185, 12, 128, 52, 62, 110, 24, 77, 100, 136, 53, 17, 21, 82, 138, 125, 23, 39, 53, 76, 20, 52, 15, 117, 34, 174, 68, 49, 25, 44], "policy_blue_0_reward": [-1.035, 0.868, -1.048, -0.5069999999999999, -0.505, 0.923, 0.964, -1.004, -1.015, 0.9329999999999999, 0.566, -1.013, -1.013, -1.009, -1.004, -0.516, -1.001, -1.007, -0.513, 0.876, 0.16599999999999993, -1.005, -1.014, -1.007, -0.535, -1.005, -1.008, 0.45499999999999996, -1.008, -1.024, -1.0099999999999998, -1.008, -1.013, -1.02, -0.506, -1.0119999999999998, -1.007, 0.45599999999999996, -1.005, 0.758, -0.519, -1.0139999999999998, -1.005, 0.9269999999999999, -0.527, -0.512, -1.013, -1.01, -1.004, -1.021, -1.0099999999999998, -1.008, -0.515, 0.46599999999999997, -1.013, -0.5009999999999999, -1.0, -1.013, -1.003, -0.511, -1.006, -1.004, -1.002, -1.0059999999999998, -0.525, -1.004, -1.0199999999999998, -1.021, 0.849, -1.0, -1.03, -1.002, -1.02, -1.005, -1.008, -1.014, -1.001, -0.006, -1.016, -0.514, -1.01, -0.501, -1.0039999999999998, 0.744, -1.02, -1.015, -1.005, -1.006, -1.013, 0.762, -1.002, -1.01, -1.0, -1.021, -1.004, -0.522, -1.0099999999999998, -1.011, -1.004, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22426526949024783, "mean_inference_ms": 1.4971276522853783, "mean_action_processing_ms": 0.06246153393705564, "mean_env_wait_ms": 0.10462882728681873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019147515296936035, "StateBufferConnector_ms": 0.0014458894729614258, "ViewRequirementAgentConnector_ms": 0.0306471586227417}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.95444649873328, "num_env_steps_trained_throughput_per_sec": 101.95444649873328, "timesteps_total": 88000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 39363.731, "sample_time_ms": 7554.054, "learn_time_ms": 31792.245, "learn_throughput": 125.817, "synch_weights_time_ms": 16.928}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "episodes_total": 647, "training_iteration": 22, "trial_id": "bb874_00000", "date": "2023-09-28_21-44-40", "timestamp": 1695951880, "time_this_iter_s": 39.23555517196655, "time_total_s": 867.7697291374207, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac7a8850>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf02b90>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf028c0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 867.7697291374207, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 34.541071428571435, "ram_util_percent": 25.72678571428571}, "win_rate": 0.85, "league_size": 2}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6923635783294837, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.020445942882603655, "policy_loss": -0.025019647088144362, "vf_loss": 0.0887739944155328, "vf_explained_var": 0.12297413516789675, "kl": 0.013261003915833736, "entropy": 1.5736080825328826, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "sampler_results": {"episode_reward_max": 0.768, "episode_reward_min": -0.8550000000000001, "episode_reward_mean": -0.15224, "episode_len_mean": 77.64, "episode_media": {}, "episodes_this_iter": 50, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.029}, "policy_reward_max": {"blue_0": 1.4140000000000001, "red_0": 0.963}, "policy_reward_mean": {"blue_0": -0.76616, "red_0": 0.6139200000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.1649999999999998, -0.1529999999999999, 0.11099999999999999, 0.4169999999999999, -0.1609999999999998, 0.45000000000000007, -0.04299999999999993, -0.21899999999999986, -0.05599999999999994, 0.19199999999999995, -0.126, -0.11099999999999999, -0.06299999999999994, -0.16199999999999992, -0.06300000000000006, -0.12099999999999989, -0.4229999999999998, -0.43999999999999995, -0.15399999999999991, -0.03699999999999992, -0.584, -0.038999999999999924, -0.41900000000000015, -0.17099999999999993, -0.19999999999999996, -0.34499999999999986, -0.07499999999999996, 0.768, -0.32400000000000007, 0.07900000000000007, -0.17700000000000005, 0.44699999999999995, -0.06299999999999994, -0.263, -0.44600000000000006, -0.399, -0.07599999999999985, -0.131, -0.17700000000000005, -0.242, -0.06499999999999995, -0.17000000000000004, -0.04599999999999993, -0.393, -0.10999999999999999, -0.05900000000000005, -0.21999999999999975, -0.15900000000000003, -0.07899999999999996, -0.1409999999999999, -0.8550000000000001, -0.08099999999999985, 0.28, -0.131, 0.367, -0.07699999999999996, -0.07099999999999995, -0.17500000000000004, -0.04599999999999993, -0.516, -0.11799999999999988, -0.823, -0.33699999999999997, 0.40700000000000003, -0.42300000000000004, -0.126, -0.353, -0.671, -0.22799999999999998, -0.049000000000000044, -0.5339999999999999, -0.16500000000000004, -0.10299999999999998, -0.14100000000000001, -0.43300000000000005, -0.628, -0.1469999999999999, -0.1289999999999999, -0.16800000000000004, -0.42300000000000004, -0.5130000000000001, -0.07199999999999984, -0.19700000000000006, -0.45499999999999985, 0.261, -0.20999999999999996, -0.10199999999999976, -0.44900000000000007, 0.42799999999999994, -0.139, -0.05699999999999994, -0.245, -0.3589999999999999, -0.04300000000000004, -0.051000000000000045, -0.06099999999999994, -0.3129999999999997, 0.3400000000000001, -0.3779999999999999, -0.10599999999999998], "episode_lengths": [51, 48, 122, 300, 47, 16, 14, 69, 17, 98, 38, 35, 20, 51, 171, 38, 133, 131, 49, 12, 185, 12, 128, 52, 62, 110, 24, 77, 100, 136, 53, 17, 21, 82, 138, 125, 23, 39, 53, 76, 20, 52, 15, 117, 34, 174, 68, 49, 25, 44, 265, 26, 68, 40, 42, 25, 23, 57, 15, 164, 37, 258, 108, 28, 126, 38, 107, 205, 70, 15, 163, 53, 33, 42, 133, 195, 46, 40, 52, 135, 155, 23, 61, 142, 72, 62, 30, 139, 300, 45, 18, 75, 110, 13, 19, 18, 103, 50, 117, 32], "policy_blue_0_reward": [-1.0099999999999998, -1.008, -0.515, 0.46599999999999997, -1.013, -0.5009999999999999, -1.0, -1.013, -1.003, -0.511, -1.006, -1.004, -1.002, -1.0059999999999998, -0.525, -1.004, -1.0199999999999998, -1.021, 0.849, -1.0, -1.03, -1.002, -1.02, -1.005, -1.008, -1.014, -1.001, -0.006, -1.016, -0.514, -1.01, -0.501, -1.0039999999999998, 0.744, -1.02, -1.015, -1.005, -1.006, -1.013, 0.762, -1.002, -1.01, -1.0, -1.021, -1.004, -0.522, -1.0099999999999998, -1.011, -1.004, -1.003, -1.039, -1.001, -0.51, 0.872, -0.502, -1.002, -1.002, -1.003, -1.0, -1.0199999999999998, -1.004, -1.034, -1.018, 1.4140000000000001, 0.606, -1.003, -1.021, -1.023, 0.777, -1.002, -1.027, -1.005, -1.003, 0.868, -1.018, -1.027, -1.003, -1.006, -1.01, -1.01, -1.024, -1.003, -1.008, -1.023, -0.516, -1.009, -1.0079999999999998, -1.021, 0.44799999999999995, -1.004, -1.001, -1.009, -1.02, -1.003, -1.002, -1.004, -1.0099999999999998, -0.5039999999999999, -1.015, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22438159830679733, "mean_inference_ms": 1.4967990542603145, "mean_action_processing_ms": 0.06246296712402723, "mean_env_wait_ms": 0.10463929550490628, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019052505493164062, "StateBufferConnector_ms": 0.0014576911926269531, "ViewRequirementAgentConnector_ms": 0.03074359893798828}}, "episode_reward_max": 0.768, "episode_reward_min": -0.8550000000000001, "episode_reward_mean": -0.15224, "episode_len_mean": 77.64, "episodes_this_iter": 50, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.029}, "policy_reward_max": {"blue_0": 1.4140000000000001, "red_0": 0.963}, "policy_reward_mean": {"blue_0": -0.76616, "red_0": 0.6139200000000001}, "hist_stats": {"episode_reward": [-0.1649999999999998, -0.1529999999999999, 0.11099999999999999, 0.4169999999999999, -0.1609999999999998, 0.45000000000000007, -0.04299999999999993, -0.21899999999999986, -0.05599999999999994, 0.19199999999999995, -0.126, -0.11099999999999999, -0.06299999999999994, -0.16199999999999992, -0.06300000000000006, -0.12099999999999989, -0.4229999999999998, -0.43999999999999995, -0.15399999999999991, -0.03699999999999992, -0.584, -0.038999999999999924, -0.41900000000000015, -0.17099999999999993, -0.19999999999999996, -0.34499999999999986, -0.07499999999999996, 0.768, -0.32400000000000007, 0.07900000000000007, -0.17700000000000005, 0.44699999999999995, -0.06299999999999994, -0.263, -0.44600000000000006, -0.399, -0.07599999999999985, -0.131, -0.17700000000000005, -0.242, -0.06499999999999995, -0.17000000000000004, -0.04599999999999993, -0.393, -0.10999999999999999, -0.05900000000000005, -0.21999999999999975, -0.15900000000000003, -0.07899999999999996, -0.1409999999999999, -0.8550000000000001, -0.08099999999999985, 0.28, -0.131, 0.367, -0.07699999999999996, -0.07099999999999995, -0.17500000000000004, -0.04599999999999993, -0.516, -0.11799999999999988, -0.823, -0.33699999999999997, 0.40700000000000003, -0.42300000000000004, -0.126, -0.353, -0.671, -0.22799999999999998, -0.049000000000000044, -0.5339999999999999, -0.16500000000000004, -0.10299999999999998, -0.14100000000000001, -0.43300000000000005, -0.628, -0.1469999999999999, -0.1289999999999999, -0.16800000000000004, -0.42300000000000004, -0.5130000000000001, -0.07199999999999984, -0.19700000000000006, -0.45499999999999985, 0.261, -0.20999999999999996, -0.10199999999999976, -0.44900000000000007, 0.42799999999999994, -0.139, -0.05699999999999994, -0.245, -0.3589999999999999, -0.04300000000000004, -0.051000000000000045, -0.06099999999999994, -0.3129999999999997, 0.3400000000000001, -0.3779999999999999, -0.10599999999999998], "episode_lengths": [51, 48, 122, 300, 47, 16, 14, 69, 17, 98, 38, 35, 20, 51, 171, 38, 133, 131, 49, 12, 185, 12, 128, 52, 62, 110, 24, 77, 100, 136, 53, 17, 21, 82, 138, 125, 23, 39, 53, 76, 20, 52, 15, 117, 34, 174, 68, 49, 25, 44, 265, 26, 68, 40, 42, 25, 23, 57, 15, 164, 37, 258, 108, 28, 126, 38, 107, 205, 70, 15, 163, 53, 33, 42, 133, 195, 46, 40, 52, 135, 155, 23, 61, 142, 72, 62, 30, 139, 300, 45, 18, 75, 110, 13, 19, 18, 103, 50, 117, 32], "policy_blue_0_reward": [-1.0099999999999998, -1.008, -0.515, 0.46599999999999997, -1.013, -0.5009999999999999, -1.0, -1.013, -1.003, -0.511, -1.006, -1.004, -1.002, -1.0059999999999998, -0.525, -1.004, -1.0199999999999998, -1.021, 0.849, -1.0, -1.03, -1.002, -1.02, -1.005, -1.008, -1.014, -1.001, -0.006, -1.016, -0.514, -1.01, -0.501, -1.0039999999999998, 0.744, -1.02, -1.015, -1.005, -1.006, -1.013, 0.762, -1.002, -1.01, -1.0, -1.021, -1.004, -0.522, -1.0099999999999998, -1.011, -1.004, -1.003, -1.039, -1.001, -0.51, 0.872, -0.502, -1.002, -1.002, -1.003, -1.0, -1.0199999999999998, -1.004, -1.034, -1.018, 1.4140000000000001, 0.606, -1.003, -1.021, -1.023, 0.777, -1.002, -1.027, -1.005, -1.003, 0.868, -1.018, -1.027, -1.003, -1.006, -1.01, -1.01, -1.024, -1.003, -1.008, -1.023, -0.516, -1.009, -1.0079999999999998, -1.021, 0.44799999999999995, -1.004, -1.001, -1.009, -1.02, -1.003, -1.002, -1.004, -1.0099999999999998, -0.5039999999999999, -1.015, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22438159830679733, "mean_inference_ms": 1.4967990542603145, "mean_action_processing_ms": 0.06246296712402723, "mean_env_wait_ms": 0.10463929550490628, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019052505493164062, "StateBufferConnector_ms": 0.0014576911926269531, "ViewRequirementAgentConnector_ms": 0.03074359893798828}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.45233340688537, "num_env_steps_trained_throughput_per_sec": 101.45233340688537, "timesteps_total": 92000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 184000, "timers": {"training_iteration_time_ms": 39337.061, "sample_time_ms": 7530.65, "learn_time_ms": 31788.989, "learn_throughput": 125.83, "synch_weights_time_ms": 16.92}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "done": false, "episodes_total": 697, "training_iteration": 23, "trial_id": "bb874_00000", "date": "2023-09-28_21-45-19", "timestamp": 1695951919, "time_this_iter_s": 39.429713010787964, "time_total_s": 907.1994421482086, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4fcb7c0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf02dd0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf00ee0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 907.1994421482086, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 33.57678571428571, "ram_util_percent": 25.782142857142862}, "win_rate": 0.9, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7828355111181735, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0674553361749228, "policy_loss": -0.021352574876315582, "vf_loss": 0.17584348659729584, "vf_explained_var": 0.08424880461146435, "kl": 0.012093403698340407, "entropy": 1.532513429224491, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "sampler_results": {"episode_reward_max": 0.664, "episode_reward_min": -0.864, "episode_reward_mean": -0.13615999999999995, "episode_len_mean": 63.4, "episode_media": {}, "episodes_this_iter": 72, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.009, "red_0_v1": -1.025}, "policy_reward_max": {"blue_0": 0.946, "red_0": 0.97, "red_0_v1": 1.4180000000000001}, "policy_reward_mean": {"blue_0": -0.7476764705882352, "red_0": 0.4615200000000001, "red_0_v1": -0.2789375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.10299999999999998, -0.14100000000000001, -0.43300000000000005, -0.628, -0.1469999999999999, -0.1289999999999999, -0.16800000000000004, -0.42300000000000004, -0.5130000000000001, -0.07199999999999984, -0.19700000000000006, -0.45499999999999985, 0.261, -0.20999999999999996, -0.10199999999999976, -0.44900000000000007, 0.42799999999999994, -0.139, -0.05699999999999994, -0.245, -0.3589999999999999, -0.04300000000000004, -0.051000000000000045, -0.06099999999999994, -0.3129999999999997, 0.3400000000000001, -0.3779999999999999, -0.10599999999999998, -0.23399999999999987, -0.17599999999999993, -0.07899999999999996, -0.07900000000000007, -0.06799999999999995, -0.122, -0.061000000000000054, -0.22399999999999998, -0.03399999999999981, -0.03500000000000003, -0.04600000000000004, -0.129, -0.09499999999999997, -0.5830000000000001, 0.40900000000000003, -0.129, -0.16399999999999992, -0.23699999999999988, -0.19099999999999984, -0.20399999999999996, -0.2889999999999999, -0.16699999999999993, -0.09299999999999997, -0.08299999999999985, 0.356, -0.03700000000000003, -0.11099999999999999, -0.08799999999999997, -0.134, -0.05300000000000005, -0.2579999999999999, -0.21799999999999975, -0.06099999999999994, -0.125, -0.06900000000000006, -0.06299999999999994, -0.41100000000000003, -0.09199999999999975, -0.049000000000000044, -0.19800000000000006, -0.22100000000000009, -0.03500000000000003, -0.04200000000000004, 0.664, -0.06800000000000006, -0.864, -0.10199999999999998, -0.19899999999999984, -0.09899999999999998, -0.03699999999999992, -0.18400000000000005, -0.266, -0.18100000000000005, -0.14600000000000002, -0.049000000000000044, -0.494, -0.1489999999999999, -0.10799999999999998, -0.16600000000000004, 0.14100000000000001, -0.07699999999999996, 0.42999999999999994, -0.050999999999999934, -0.359, -0.11099999999999999, -0.19999999999999996, -0.10799999999999987, -0.14400000000000002, -0.07999999999999985, -0.040999999999999925, -0.5779999999999998, -0.07499999999999996], "episode_lengths": [33, 42, 133, 195, 46, 40, 52, 135, 155, 23, 61, 142, 72, 62, 30, 139, 300, 45, 18, 75, 110, 13, 19, 18, 103, 50, 117, 32, 71, 58, 23, 24, 25, 40, 18, 67, 10, 11, 17, 39, 31, 179, 27, 40, 49, 72, 62, 68, 90, 54, 29, 26, 45, 11, 35, 31, 42, 17, 79, 70, 23, 41, 300, 20, 121, 28, 16, 59, 67, 11, 16, 107, 20, 271, 30, 58, 31, 12, 60, 83, 51, 46, 16, 150, 46, 30, 49, 109, 24, 178, 16, 109, 35, 62, 33, 45, 25, 12, 187, 23], "policy_blue_0_reward": [-1.003, 0.868, -1.018, -1.027, -1.003, -1.006, -1.01, -1.01, -1.024, -1.003, -1.008, -1.023, -0.516, -1.009, -1.0079999999999998, -1.021, 0.44799999999999995, -1.004, -1.001, -1.009, -1.02, -1.003, -1.002, -1.004, -1.0099999999999998, -0.5039999999999999, -1.015, -1.006, -1.013, -1.003, -1.001, -1.0, -1.0039999999999998, -1.002, 0.946, -1.009, 0.873, -1.01, -1.014, -1.016, -1.003, -0.504, -1.004, -1.0, -1.014, -1.007, -0.035000000000000024, -1.005, -1.007, -1.003, -0.013000000000000005, 0.9339999999999999, -1.039, -1.007, -1.004, -1.005, -1.006, -1.026, -1.004, 0.843, -0.515, -0.03000000000000002, -1.026, -1.006, -1.006, 0.862, -1.0039999999999998, -1.004], "policy_red_0_v1_reward": [-1.008, 0.9229999999999999, 0.942, -1.016, 0.907, -1.025, 1.4180000000000001, -1.003, -1.007, -1.001, 0.909, 0.965, -1.003, 0.868, -1.0, -1.006, -1.001, -1.018, 0.951, 0.8099999999999999, -1.001, -1.016, -1.001, 0.819, 0.738, 0.951, -1.006, -1.004, -1.001, -1.004, -1.0019999999999998, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2245403171424175, "mean_inference_ms": 1.4956734995256615, "mean_action_processing_ms": 0.06240681780589795, "mean_env_wait_ms": 0.10459915908441719, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019422531127929688, "StateBufferConnector_ms": 0.001466512680053711, "ViewRequirementAgentConnector_ms": 0.03108680248260498}}, "episode_reward_max": 0.664, "episode_reward_min": -0.864, "episode_reward_mean": -0.13615999999999995, "episode_len_mean": 63.4, "episodes_this_iter": 72, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.009, "red_0_v1": -1.025}, "policy_reward_max": {"blue_0": 0.946, "red_0": 0.97, "red_0_v1": 1.4180000000000001}, "policy_reward_mean": {"blue_0": -0.7476764705882352, "red_0": 0.4615200000000001, "red_0_v1": -0.2789375}, "hist_stats": {"episode_reward": [-0.10299999999999998, -0.14100000000000001, -0.43300000000000005, -0.628, -0.1469999999999999, -0.1289999999999999, -0.16800000000000004, -0.42300000000000004, -0.5130000000000001, -0.07199999999999984, -0.19700000000000006, -0.45499999999999985, 0.261, -0.20999999999999996, -0.10199999999999976, -0.44900000000000007, 0.42799999999999994, -0.139, -0.05699999999999994, -0.245, -0.3589999999999999, -0.04300000000000004, -0.051000000000000045, -0.06099999999999994, -0.3129999999999997, 0.3400000000000001, -0.3779999999999999, -0.10599999999999998, -0.23399999999999987, -0.17599999999999993, -0.07899999999999996, -0.07900000000000007, -0.06799999999999995, -0.122, -0.061000000000000054, -0.22399999999999998, -0.03399999999999981, -0.03500000000000003, -0.04600000000000004, -0.129, -0.09499999999999997, -0.5830000000000001, 0.40900000000000003, -0.129, -0.16399999999999992, -0.23699999999999988, -0.19099999999999984, -0.20399999999999996, -0.2889999999999999, -0.16699999999999993, -0.09299999999999997, -0.08299999999999985, 0.356, -0.03700000000000003, -0.11099999999999999, -0.08799999999999997, -0.134, -0.05300000000000005, -0.2579999999999999, -0.21799999999999975, -0.06099999999999994, -0.125, -0.06900000000000006, -0.06299999999999994, -0.41100000000000003, -0.09199999999999975, -0.049000000000000044, -0.19800000000000006, -0.22100000000000009, -0.03500000000000003, -0.04200000000000004, 0.664, -0.06800000000000006, -0.864, -0.10199999999999998, -0.19899999999999984, -0.09899999999999998, -0.03699999999999992, -0.18400000000000005, -0.266, -0.18100000000000005, -0.14600000000000002, -0.049000000000000044, -0.494, -0.1489999999999999, -0.10799999999999998, -0.16600000000000004, 0.14100000000000001, -0.07699999999999996, 0.42999999999999994, -0.050999999999999934, -0.359, -0.11099999999999999, -0.19999999999999996, -0.10799999999999987, -0.14400000000000002, -0.07999999999999985, -0.040999999999999925, -0.5779999999999998, -0.07499999999999996], "episode_lengths": [33, 42, 133, 195, 46, 40, 52, 135, 155, 23, 61, 142, 72, 62, 30, 139, 300, 45, 18, 75, 110, 13, 19, 18, 103, 50, 117, 32, 71, 58, 23, 24, 25, 40, 18, 67, 10, 11, 17, 39, 31, 179, 27, 40, 49, 72, 62, 68, 90, 54, 29, 26, 45, 11, 35, 31, 42, 17, 79, 70, 23, 41, 300, 20, 121, 28, 16, 59, 67, 11, 16, 107, 20, 271, 30, 58, 31, 12, 60, 83, 51, 46, 16, 150, 46, 30, 49, 109, 24, 178, 16, 109, 35, 62, 33, 45, 25, 12, 187, 23], "policy_blue_0_reward": [-1.003, 0.868, -1.018, -1.027, -1.003, -1.006, -1.01, -1.01, -1.024, -1.003, -1.008, -1.023, -0.516, -1.009, -1.0079999999999998, -1.021, 0.44799999999999995, -1.004, -1.001, -1.009, -1.02, -1.003, -1.002, -1.004, -1.0099999999999998, -0.5039999999999999, -1.015, -1.006, -1.013, -1.003, -1.001, -1.0, -1.0039999999999998, -1.002, 0.946, -1.009, 0.873, -1.01, -1.014, -1.016, -1.003, -0.504, -1.004, -1.0, -1.014, -1.007, -0.035000000000000024, -1.005, -1.007, -1.003, -0.013000000000000005, 0.9339999999999999, -1.039, -1.007, -1.004, -1.005, -1.006, -1.026, -1.004, 0.843, -0.515, -0.03000000000000002, -1.026, -1.006, -1.006, 0.862, -1.0039999999999998, -1.004], "policy_red_0_v1_reward": [-1.008, 0.9229999999999999, 0.942, -1.016, 0.907, -1.025, 1.4180000000000001, -1.003, -1.007, -1.001, 0.909, 0.965, -1.003, 0.868, -1.0, -1.006, -1.001, -1.018, 0.951, 0.8099999999999999, -1.001, -1.016, -1.001, 0.819, 0.738, 0.951, -1.006, -1.004, -1.001, -1.004, -1.0019999999999998, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2245403171424175, "mean_inference_ms": 1.4956734995256615, "mean_action_processing_ms": 0.06240681780589795, "mean_env_wait_ms": 0.10459915908441719, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019422531127929688, "StateBufferConnector_ms": 0.001466512680053711, "ViewRequirementAgentConnector_ms": 0.03108680248260498}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.87106075578755, "num_env_steps_trained_throughput_per_sec": 101.87106075578755, "timesteps_total": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 39309.122, "sample_time_ms": 7532.28, "learn_time_ms": 31759.444, "learn_throughput": 125.947, "synch_weights_time_ms": 16.878}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "episodes_total": 769, "training_iteration": 24, "trial_id": "bb874_00000", "date": "2023-09-28_21-45-59", "timestamp": 1695951959, "time_this_iter_s": 39.26798391342163, "time_total_s": 946.4674260616302, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ac7a8b50>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac756c20>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac755e10>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 946.4674260616302, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 34.31964285714285, "ram_util_percent": 25.89107142857143}, "win_rate": 0.81, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.85521175985535, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1140307035362639, "policy_loss": -0.025791007544709525, "vf_loss": 0.27782473602953056, "vf_explained_var": 0.056151032199462256, "kl": 0.012100954554534532, "entropy": 1.5108467670778434, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "sampler_results": {"episode_reward_max": 0.42999999999999994, "episode_reward_min": -0.6070000000000001, "episode_reward_mean": -0.11366999999999998, "episode_len_mean": 51.2, "episode_media": {}, "episodes_this_iter": 85, "policy_reward_min": {"red_0_v1": -1.033, "red_0": -1.015, "blue_0": -1.026}, "policy_reward_max": {"red_0_v1": 0.979, "red_0": 0.976, "blue_0": 1.374}, "policy_reward_mean": {"red_0_v1": -0.18937704918032786, "red_0": 0.22865, "blue_0": -0.5815384615384616}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.10799999999999998, -0.16600000000000004, 0.14100000000000001, -0.07699999999999996, 0.42999999999999994, -0.050999999999999934, -0.359, -0.11099999999999999, -0.19999999999999996, -0.10799999999999987, -0.14400000000000002, -0.07999999999999985, -0.040999999999999925, -0.5779999999999998, -0.07499999999999996, -0.259, -0.21999999999999997, -0.03200000000000003, -0.07499999999999996, -0.11499999999999999, -0.04200000000000004, -0.278, -0.04500000000000004, -0.1369999999999999, -0.052000000000000046, -0.09099999999999997, -0.20100000000000007, -0.05500000000000005, -0.026999999999999913, -0.03399999999999992, -0.29400000000000004, -0.18299999999999994, -0.15599999999999992, -0.04799999999999993, -0.11299999999999999, -0.05700000000000005, -0.06700000000000006, -0.11599999999999999, -0.02499999999999991, -0.4760000000000001, -0.08699999999999997, -0.3420000000000001, -0.10399999999999998, -0.2579999999999999, -0.05600000000000005, -0.14500000000000002, -0.05799999999999983, -0.030000000000000027, -0.05400000000000005, -0.09399999999999997, -0.18199999999999994, -0.039000000000000035, -0.07099999999999995, -0.11699999999999988, -0.45600000000000007, -0.07499999999999996, -0.07799999999999996, -0.08599999999999985, -0.14600000000000002, 0.118, -0.6070000000000001, -0.04800000000000004, -0.05800000000000005, 0.123, -0.06899999999999995, -0.06000000000000005, 0.20300000000000007, -0.061000000000000054, -0.129, -0.21400000000000008, -0.02100000000000002, -0.049000000000000044, -0.19300000000000006, -0.17800000000000005, -0.051999999999999935, 0.11299999999999999, -0.19299999999999984, -0.252, 0.2789999999999999, -0.128, 0.135, -0.273, -0.11199999999999999, -0.5010000000000001, -0.16100000000000003, -0.127, -0.16700000000000004, -0.06000000000000005, -0.1419999999999999, -0.254, -0.42900000000000005, -0.030000000000000027, -0.07699999999999996, -0.20599999999999996, -0.278, -0.17200000000000004, -0.06799999999999995, -0.041999999999999926, -0.10399999999999998, 0.3799999999999999], "episode_lengths": [30, 49, 109, 24, 178, 16, 109, 35, 62, 33, 45, 25, 12, 187, 23, 87, 72, 10, 22, 36, 17, 88, 15, 44, 16, 29, 59, 17, 8, 11, 92, 56, 49, 15, 40, 17, 20, 37, 8, 140, 27, 106, 33, 83, 18, 47, 18, 10, 17, 29, 58, 12, 22, 38, 138, 23, 29, 27, 48, 117, 201, 14, 18, 117, 22, 18, 93, 18, 43, 69, 7, 15, 63, 52, 17, 124, 58, 78, 69, 41, 110, 84, 35, 153, 51, 41, 52, 18, 45, 72, 133, 10, 24, 66, 87, 54, 21, 13, 32, 40], "policy_red_0_v1_reward": [-1.006, -1.004, -1.001, -1.004, -1.0019999999999998, -1.004, 0.737, -1.002, -1.006, 0.891, -1.001, -1.007, -1.001, -1.002, -1.003, -1.002, -1.0, -1.001, -1.001, 0.947, 0.9369999999999999, 0.885, -1.033, -1.006, -1.003, 0.949, 0.907, 0.8190000000000001, 0.963, -1.001, -1.022, 0.93, -1.0, -1.0, -0.52, -1.005, -1.005, -1.001, -1.001, 0.94, 0.942, 0.871, 0.7889999999999999, 0.979, -1.003, 0.819, -1.001, 0.756, 0.873, -0.509, 0.739, 0.889, 0.842, 0.874, 0.843, -1.003, 0.761, -1.005, 0.831, -1.002, 0.902], "policy_blue_0_reward": [0.843, -0.515, -0.03000000000000002, -1.026, -1.006, -1.006, 0.862, -1.0039999999999998, -1.004, -1.002, -1.0, -1.006, -1.004, -1.006, -1.009, -1.005, -1.001, -1.004, -1.012, 0.899, -1.001, -1.001, -1.0, -1.003, -1.007, -0.523, -0.5129999999999999, -1.003, -0.515, -1.009, 1.2839999999999998, -1.024, -1.005, 0.578, -1.0, -1.003, 0.73, -1.003, 1.374]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2249620411495507, "mean_inference_ms": 1.4961917744488964, "mean_action_processing_ms": 0.06242112933609539, "mean_env_wait_ms": 0.10466576395448193, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01920640468597412, "StateBufferConnector_ms": 0.0014891624450683594, "ViewRequirementAgentConnector_ms": 0.0311509370803833}}, "episode_reward_max": 0.42999999999999994, "episode_reward_min": -0.6070000000000001, "episode_reward_mean": -0.11366999999999998, "episode_len_mean": 51.2, "episodes_this_iter": 85, "policy_reward_min": {"red_0_v1": -1.033, "red_0": -1.015, "blue_0": -1.026}, "policy_reward_max": {"red_0_v1": 0.979, "red_0": 0.976, "blue_0": 1.374}, "policy_reward_mean": {"red_0_v1": -0.18937704918032786, "red_0": 0.22865, "blue_0": -0.5815384615384616}, "hist_stats": {"episode_reward": [-0.10799999999999998, -0.16600000000000004, 0.14100000000000001, -0.07699999999999996, 0.42999999999999994, -0.050999999999999934, -0.359, -0.11099999999999999, -0.19999999999999996, -0.10799999999999987, -0.14400000000000002, -0.07999999999999985, -0.040999999999999925, -0.5779999999999998, -0.07499999999999996, -0.259, -0.21999999999999997, -0.03200000000000003, -0.07499999999999996, -0.11499999999999999, -0.04200000000000004, -0.278, -0.04500000000000004, -0.1369999999999999, -0.052000000000000046, -0.09099999999999997, -0.20100000000000007, -0.05500000000000005, -0.026999999999999913, -0.03399999999999992, -0.29400000000000004, -0.18299999999999994, -0.15599999999999992, -0.04799999999999993, -0.11299999999999999, -0.05700000000000005, -0.06700000000000006, -0.11599999999999999, -0.02499999999999991, -0.4760000000000001, -0.08699999999999997, -0.3420000000000001, -0.10399999999999998, -0.2579999999999999, -0.05600000000000005, -0.14500000000000002, -0.05799999999999983, -0.030000000000000027, -0.05400000000000005, -0.09399999999999997, -0.18199999999999994, -0.039000000000000035, -0.07099999999999995, -0.11699999999999988, -0.45600000000000007, -0.07499999999999996, -0.07799999999999996, -0.08599999999999985, -0.14600000000000002, 0.118, -0.6070000000000001, -0.04800000000000004, -0.05800000000000005, 0.123, -0.06899999999999995, -0.06000000000000005, 0.20300000000000007, -0.061000000000000054, -0.129, -0.21400000000000008, -0.02100000000000002, -0.049000000000000044, -0.19300000000000006, -0.17800000000000005, -0.051999999999999935, 0.11299999999999999, -0.19299999999999984, -0.252, 0.2789999999999999, -0.128, 0.135, -0.273, -0.11199999999999999, -0.5010000000000001, -0.16100000000000003, -0.127, -0.16700000000000004, -0.06000000000000005, -0.1419999999999999, -0.254, -0.42900000000000005, -0.030000000000000027, -0.07699999999999996, -0.20599999999999996, -0.278, -0.17200000000000004, -0.06799999999999995, -0.041999999999999926, -0.10399999999999998, 0.3799999999999999], "episode_lengths": [30, 49, 109, 24, 178, 16, 109, 35, 62, 33, 45, 25, 12, 187, 23, 87, 72, 10, 22, 36, 17, 88, 15, 44, 16, 29, 59, 17, 8, 11, 92, 56, 49, 15, 40, 17, 20, 37, 8, 140, 27, 106, 33, 83, 18, 47, 18, 10, 17, 29, 58, 12, 22, 38, 138, 23, 29, 27, 48, 117, 201, 14, 18, 117, 22, 18, 93, 18, 43, 69, 7, 15, 63, 52, 17, 124, 58, 78, 69, 41, 110, 84, 35, 153, 51, 41, 52, 18, 45, 72, 133, 10, 24, 66, 87, 54, 21, 13, 32, 40], "policy_red_0_v1_reward": [-1.006, -1.004, -1.001, -1.004, -1.0019999999999998, -1.004, 0.737, -1.002, -1.006, 0.891, -1.001, -1.007, -1.001, -1.002, -1.003, -1.002, -1.0, -1.001, -1.001, 0.947, 0.9369999999999999, 0.885, -1.033, -1.006, -1.003, 0.949, 0.907, 0.8190000000000001, 0.963, -1.001, -1.022, 0.93, -1.0, -1.0, -0.52, -1.005, -1.005, -1.001, -1.001, 0.94, 0.942, 0.871, 0.7889999999999999, 0.979, -1.003, 0.819, -1.001, 0.756, 0.873, -0.509, 0.739, 0.889, 0.842, 0.874, 0.843, -1.003, 0.761, -1.005, 0.831, -1.002, 0.902], "policy_blue_0_reward": [0.843, -0.515, -0.03000000000000002, -1.026, -1.006, -1.006, 0.862, -1.0039999999999998, -1.004, -1.002, -1.0, -1.006, -1.004, -1.006, -1.009, -1.005, -1.001, -1.004, -1.012, 0.899, -1.001, -1.001, -1.0, -1.003, -1.007, -0.523, -0.5129999999999999, -1.003, -0.515, -1.009, 1.2839999999999998, -1.024, -1.005, 0.578, -1.0, -1.003, 0.73, -1.003, 1.374]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2249620411495507, "mean_inference_ms": 1.4961917744488964, "mean_action_processing_ms": 0.06242112933609539, "mean_env_wait_ms": 0.10466576395448193, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01920640468597412, "StateBufferConnector_ms": 0.0014891624450683594, "ViewRequirementAgentConnector_ms": 0.0311509370803833}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.62342681970586, "num_env_steps_trained_throughput_per_sec": 101.62342681970586, "timesteps_total": 100000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 200000, "timers": {"training_iteration_time_ms": 39306.93, "sample_time_ms": 7536.912, "learn_time_ms": 31752.557, "learn_throughput": 125.974, "synch_weights_time_ms": 16.91}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 854, "training_iteration": 25, "trial_id": "bb874_00000", "date": "2023-09-28_21-46-38", "timestamp": 1695951998, "time_this_iter_s": 39.36376595497131, "time_total_s": 985.8311920166016, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7dd8f70>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac755a20>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac756440>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 985.8311920166016, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 34.0, "ram_util_percent": 25.939285714285717}, "win_rate": 0.67, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7374185100818673, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05592028246119298, "policy_loss": -0.024332884387210166, "vf_loss": 0.15833128641049068, "vf_explained_var": 0.07080083607385555, "kl": 0.013179632964797579, "entropy": 1.548402081678311, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "sampler_results": {"episode_reward_max": 0.43500000000000005, "episode_reward_min": -0.724, "episode_reward_mean": -0.13373999999999997, "episode_len_mean": 62.14, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"red_0_v1": -1.019, "red_0": -1.029, "blue_0": -1.025}, "policy_reward_max": {"red_0_v1": 1.438, "red_0": 0.97, "blue_0": 1.374}, "policy_reward_mean": {"red_0_v1": -0.014527272727272686, "red_0": 0.20870999999999998, "blue_0": -0.7432444444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.6070000000000001, -0.04800000000000004, -0.05800000000000005, 0.123, -0.06899999999999995, -0.06000000000000005, 0.20300000000000007, -0.061000000000000054, -0.129, -0.21400000000000008, -0.02100000000000002, -0.049000000000000044, -0.19300000000000006, -0.17800000000000005, -0.051999999999999935, 0.11299999999999999, -0.19299999999999984, -0.252, 0.2789999999999999, -0.128, 0.135, -0.273, -0.11199999999999999, -0.5010000000000001, -0.16100000000000003, -0.127, -0.16700000000000004, -0.06000000000000005, -0.1419999999999999, -0.254, -0.42900000000000005, -0.030000000000000027, -0.07699999999999996, -0.20599999999999996, -0.278, -0.17200000000000004, -0.06799999999999995, -0.041999999999999926, -0.10399999999999998, 0.3799999999999999, -0.21599999999999997, -0.18499999999999994, -0.14600000000000002, -0.09999999999999998, -0.03700000000000003, -0.10899999999999987, -0.15699999999999992, -0.20899999999999996, -0.236, 0.013999999999999901, -0.30199999999999994, -0.4159999999999999, -0.6100000000000001, -0.10699999999999987, -0.08399999999999996, -0.16100000000000003, 0.43500000000000005, -0.09399999999999997, -0.241, 0.2749999999999999, -0.1170000000000001, -0.15899999999999992, -0.03200000000000003, -0.4970000000000001, -0.08399999999999985, -0.10899999999999987, -0.06600000000000006, -0.517, -0.19200000000000006, -0.03299999999999992, -0.22599999999999998, -0.03399999999999992, -0.246, -0.514, -0.1399999999999999, 0.41700000000000015, 0.41300000000000003, -0.5960000000000001, -0.17900000000000005, -0.724, 0.32199999999999995, -0.06600000000000006, -0.30999999999999994, -0.384, -0.125, -0.15799999999999992, -0.050999999999999934, -0.08399999999999985, -0.18499999999999983, -0.41900000000000004, -0.08299999999999996, -0.4139999999999999, -0.1459999999999999, -0.30099999999999993, -0.050000000000000044, -0.05800000000000005, -0.10199999999999998, -0.07099999999999995, -0.04300000000000004, -0.04300000000000004], "episode_lengths": [201, 14, 18, 117, 22, 18, 93, 18, 43, 69, 7, 15, 63, 52, 17, 124, 58, 78, 69, 41, 110, 84, 35, 153, 51, 41, 52, 18, 45, 72, 133, 10, 24, 66, 87, 54, 21, 13, 32, 40, 67, 62, 46, 32, 12, 32, 50, 66, 73, 149, 91, 135, 189, 32, 30, 49, 20, 32, 78, 73, 38, 52, 10, 155, 27, 34, 22, 163, 60, 10, 72, 11, 78, 158, 41, 25, 27, 182, 59, 236, 52, 20, 99, 116, 41, 47, 16, 27, 58, 131, 25, 123, 45, 95, 16, 166, 31, 23, 14, 13], "policy_red_0_v1_reward": [-1.005, -1.005, -1.001, -1.001, 0.94, 0.942, 0.871, 0.7889999999999999, 0.979, -1.003, 0.819, -1.001, 0.756, 0.873, -0.509, 0.739, 0.889, 0.842, 0.874, 0.843, -1.003, 0.761, -1.005, 0.831, -1.002, 0.902, -1.004, -1.001, 0.963, 0.797, -1.019, -1.013, 0.41899999999999993, -1.004, -1.002, -1.008, 1.438, 0.762, -1.001, 0.494, -1.006, -1.013, 1.416, -1.002, 0.277, -1.004, 0.876, -1.002, -1.007, -1.007, 0.951, 0.901, 0.93, 0.957, -1.002], "policy_blue_0_reward": [-0.523, -0.5129999999999999, -1.003, -0.515, -1.009, 1.2839999999999998, -1.024, -1.005, 0.578, -1.0, -1.003, 0.73, -1.003, 1.374, -1.008, -1.005, -1.006, -1.003, -1.009, -0.527, -1.001, -0.51, -1.012, -1.0099999999999998, -1.001, -1.025, -1.004, -1.0, -1.002, -1.005, -1.001, -1.008, -1.022, -0.5029999999999999, -1.02, -0.507, -1.01, -1.021, -1.009, -1.002, -1.008, -1.012, -1.025, -1.008, -0.53]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2249600347531935, "mean_inference_ms": 1.4944001229528054, "mean_action_processing_ms": 0.06237933664401574, "mean_env_wait_ms": 0.10458479029688071, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019330263137817383, "StateBufferConnector_ms": 0.0014857053756713867, "ViewRequirementAgentConnector_ms": 0.03103494644165039}}, "episode_reward_max": 0.43500000000000005, "episode_reward_min": -0.724, "episode_reward_mean": -0.13373999999999997, "episode_len_mean": 62.14, "episodes_this_iter": 60, "policy_reward_min": {"red_0_v1": -1.019, "red_0": -1.029, "blue_0": -1.025}, "policy_reward_max": {"red_0_v1": 1.438, "red_0": 0.97, "blue_0": 1.374}, "policy_reward_mean": {"red_0_v1": -0.014527272727272686, "red_0": 0.20870999999999998, "blue_0": -0.7432444444444444}, "hist_stats": {"episode_reward": [-0.6070000000000001, -0.04800000000000004, -0.05800000000000005, 0.123, -0.06899999999999995, -0.06000000000000005, 0.20300000000000007, -0.061000000000000054, -0.129, -0.21400000000000008, -0.02100000000000002, -0.049000000000000044, -0.19300000000000006, -0.17800000000000005, -0.051999999999999935, 0.11299999999999999, -0.19299999999999984, -0.252, 0.2789999999999999, -0.128, 0.135, -0.273, -0.11199999999999999, -0.5010000000000001, -0.16100000000000003, -0.127, -0.16700000000000004, -0.06000000000000005, -0.1419999999999999, -0.254, -0.42900000000000005, -0.030000000000000027, -0.07699999999999996, -0.20599999999999996, -0.278, -0.17200000000000004, -0.06799999999999995, -0.041999999999999926, -0.10399999999999998, 0.3799999999999999, -0.21599999999999997, -0.18499999999999994, -0.14600000000000002, -0.09999999999999998, -0.03700000000000003, -0.10899999999999987, -0.15699999999999992, -0.20899999999999996, -0.236, 0.013999999999999901, -0.30199999999999994, -0.4159999999999999, -0.6100000000000001, -0.10699999999999987, -0.08399999999999996, -0.16100000000000003, 0.43500000000000005, -0.09399999999999997, -0.241, 0.2749999999999999, -0.1170000000000001, -0.15899999999999992, -0.03200000000000003, -0.4970000000000001, -0.08399999999999985, -0.10899999999999987, -0.06600000000000006, -0.517, -0.19200000000000006, -0.03299999999999992, -0.22599999999999998, -0.03399999999999992, -0.246, -0.514, -0.1399999999999999, 0.41700000000000015, 0.41300000000000003, -0.5960000000000001, -0.17900000000000005, -0.724, 0.32199999999999995, -0.06600000000000006, -0.30999999999999994, -0.384, -0.125, -0.15799999999999992, -0.050999999999999934, -0.08399999999999985, -0.18499999999999983, -0.41900000000000004, -0.08299999999999996, -0.4139999999999999, -0.1459999999999999, -0.30099999999999993, -0.050000000000000044, -0.05800000000000005, -0.10199999999999998, -0.07099999999999995, -0.04300000000000004, -0.04300000000000004], "episode_lengths": [201, 14, 18, 117, 22, 18, 93, 18, 43, 69, 7, 15, 63, 52, 17, 124, 58, 78, 69, 41, 110, 84, 35, 153, 51, 41, 52, 18, 45, 72, 133, 10, 24, 66, 87, 54, 21, 13, 32, 40, 67, 62, 46, 32, 12, 32, 50, 66, 73, 149, 91, 135, 189, 32, 30, 49, 20, 32, 78, 73, 38, 52, 10, 155, 27, 34, 22, 163, 60, 10, 72, 11, 78, 158, 41, 25, 27, 182, 59, 236, 52, 20, 99, 116, 41, 47, 16, 27, 58, 131, 25, 123, 45, 95, 16, 166, 31, 23, 14, 13], "policy_red_0_v1_reward": [-1.005, -1.005, -1.001, -1.001, 0.94, 0.942, 0.871, 0.7889999999999999, 0.979, -1.003, 0.819, -1.001, 0.756, 0.873, -0.509, 0.739, 0.889, 0.842, 0.874, 0.843, -1.003, 0.761, -1.005, 0.831, -1.002, 0.902, -1.004, -1.001, 0.963, 0.797, -1.019, -1.013, 0.41899999999999993, -1.004, -1.002, -1.008, 1.438, 0.762, -1.001, 0.494, -1.006, -1.013, 1.416, -1.002, 0.277, -1.004, 0.876, -1.002, -1.007, -1.007, 0.951, 0.901, 0.93, 0.957, -1.002], "policy_blue_0_reward": [-0.523, -0.5129999999999999, -1.003, -0.515, -1.009, 1.2839999999999998, -1.024, -1.005, 0.578, -1.0, -1.003, 0.73, -1.003, 1.374, -1.008, -1.005, -1.006, -1.003, -1.009, -0.527, -1.001, -0.51, -1.012, -1.0099999999999998, -1.001, -1.025, -1.004, -1.0, -1.002, -1.005, -1.001, -1.008, -1.022, -0.5029999999999999, -1.02, -0.507, -1.01, -1.021, -1.009, -1.002, -1.008, -1.012, -1.025, -1.008, -0.53]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2249600347531935, "mean_inference_ms": 1.4944001229528054, "mean_action_processing_ms": 0.06237933664401574, "mean_env_wait_ms": 0.10458479029688071, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019330263137817383, "StateBufferConnector_ms": 0.0014857053756713867, "ViewRequirementAgentConnector_ms": 0.03103494644165039}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.30960345189023, "num_env_steps_trained_throughput_per_sec": 101.30960345189023, "timesteps_total": 104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 39323.04, "sample_time_ms": 7533.494, "learn_time_ms": 31771.968, "learn_throughput": 125.897, "synch_weights_time_ms": 16.987}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "episodes_total": 914, "training_iteration": 26, "trial_id": "bb874_00000", "date": "2023-09-28_21-47-18", "timestamp": 1695952038, "time_this_iter_s": 39.48545289039612, "time_total_s": 1025.3166449069977, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2aa8e13f0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70e0e0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70ed40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1025.3166449069977, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 33.33684210526315, "ram_util_percent": 25.956140350877195}, "win_rate": 0.67, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8146638727436464, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09892246118530844, "policy_loss": -0.022481048795452808, "vf_loss": 0.24082203976189095, "vf_explained_var": 0.10815847596774499, "kl": 0.01249151652742236, "entropy": 1.5058137317498526, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "sampler_results": {"episode_reward_max": 0.44899999999999995, "episode_reward_min": -0.515, "episode_reward_mean": -0.11849999999999998, "episode_len_mean": 49.51, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"red_0_v1": -1.009, "red_0": -1.023, "blue_0": -1.025}, "policy_reward_max": {"red_0_v1": 1.216, "red_0": 0.982, "blue_0": 0.889}, "policy_reward_mean": {"red_0_v1": -0.009019999999999993, "red_0": 0.33048999999999995, "blue_0": -0.8889599999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.06600000000000006, -0.30999999999999994, -0.384, -0.125, -0.15799999999999992, -0.050999999999999934, -0.08399999999999985, -0.18499999999999983, -0.41900000000000004, -0.08299999999999996, -0.4139999999999999, -0.1459999999999999, -0.30099999999999993, -0.050000000000000044, -0.05800000000000005, -0.10199999999999998, -0.07099999999999995, -0.04300000000000004, -0.04300000000000004, -0.3599999999999999, -0.10199999999999998, -0.11199999999999988, 0.33599999999999997, -0.30199999999999994, -0.029000000000000026, -0.19299999999999995, -0.17899999999999994, -0.03599999999999992, -0.09299999999999997, -0.05700000000000005, -0.24599999999999989, -0.06699999999999995, -0.256, -0.038000000000000034, -0.355, 0.09899999999999998, -0.05699999999999994, -0.03700000000000003, -0.15900000000000003, 0.44899999999999995, -0.119, -0.030000000000000027, -0.11499999999999999, -0.21899999999999997, -0.126, -0.049000000000000044, -0.269, -0.515, -0.10599999999999998, -0.03699999999999992, -0.08499999999999985, -0.20999999999999996, -0.17200000000000004, -0.05999999999999994, -0.4670000000000001, -0.10199999999999998, -0.257, -0.21499999999999986, -0.14600000000000002, -0.08299999999999996, -0.03699999999999992, -0.15800000000000003, -0.121, -0.18100000000000005, -0.07299999999999995, -0.10499999999999998, -0.125, -0.040000000000000036, -0.018000000000000016, -0.03700000000000003, -0.121, 0.32099999999999995, 0.363, -0.10199999999999998, -0.16199999999999992, -0.22599999999999976, -0.134, -0.05800000000000005, -0.1609999999999998, -0.08099999999999985, 0.040999999999999925, -0.1319999999999999, -0.06900000000000006, -0.21599999999999997, -0.23399999999999987, -0.14200000000000002, -0.2759999999999999, -0.11099999999999988, -0.128, -0.10099999999999998, -0.04800000000000004, -0.22199999999999998, -0.09099999999999997, -0.19099999999999995, -0.1439999999999999, -0.15400000000000003, -0.08699999999999986, -0.1479999999999999, -0.07699999999999996, 0.20500000000000007], "episode_lengths": [20, 99, 116, 41, 47, 16, 27, 58, 131, 25, 123, 45, 95, 16, 166, 31, 23, 14, 13, 113, 36, 35, 50, 97, 9, 60, 54, 11, 31, 19, 71, 20, 81, 12, 112, 124, 16, 11, 51, 16, 39, 10, 35, 64, 40, 15, 89, 158, 32, 12, 26, 59, 56, 19, 143, 32, 79, 67, 45, 26, 12, 50, 39, 57, 22, 33, 39, 13, 6, 11, 39, 53, 43, 32, 51, 72, 42, 18, 51, 26, 151, 41, 22, 66, 77, 49, 85, 36, 40, 31, 16, 73, 28, 62, 45, 48, 28, 47, 24, 92], "policy_red_0_v1_reward": [-1.004, 0.876, -1.002, -1.007, -1.007, 0.951, 0.901, 0.93, 0.957, -1.002, 0.7040000000000001, -1.001, -1.002, 0.907, -1.0, 0.749, -0.517, -1.004, 0.964, 0.97, 0.789, -1.002, -1.008, 0.826, 0.5509999999999999, 0.86, 0.919, -1.0, 0.849, 0.898, -1.003, 0.96, -1.0, 0.964, -1.003, -1.005, 0.87, 1.036, 0.9319999999999999, -1.005, -1.009, 0.85, -1.001, -1.001, 0.911, 0.805, -1.005, -1.005, -1.003, 1.216], "policy_blue_0_reward": [-1.01, -1.021, -1.009, -1.002, -1.008, -1.012, -1.025, -1.008, -0.53, -1.016, 0.889, -1.005, -0.511, -1.009, -1.009, -1.006, -1.0039999999999998, -1.002, -1.014, -1.003, -0.502, -1.001, -1.007, -1.003, 0.508, -1.004, -1.001, -1.0039999999999998, -1.0099999999999998, -1.002, -1.006, -1.005, -1.0099999999999998, -1.002, -1.009, -1.005, -1.004, -0.506, -0.506, -1.005, -1.002, -1.0059999999999998, -1.003, -1.0079999999999998, -1.0139999999999998, -1.006, -1.004, -1.0, -1.003, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22531646464102242, "mean_inference_ms": 1.4948755248230583, "mean_action_processing_ms": 0.06239286692057975, "mean_env_wait_ms": 0.10463412567206344, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01907634735107422, "StateBufferConnector_ms": 0.0014643669128417969, "ViewRequirementAgentConnector_ms": 0.031072378158569336}}, "episode_reward_max": 0.44899999999999995, "episode_reward_min": -0.515, "episode_reward_mean": -0.11849999999999998, "episode_len_mean": 49.51, "episodes_this_iter": 81, "policy_reward_min": {"red_0_v1": -1.009, "red_0": -1.023, "blue_0": -1.025}, "policy_reward_max": {"red_0_v1": 1.216, "red_0": 0.982, "blue_0": 0.889}, "policy_reward_mean": {"red_0_v1": -0.009019999999999993, "red_0": 0.33048999999999995, "blue_0": -0.8889599999999999}, "hist_stats": {"episode_reward": [-0.06600000000000006, -0.30999999999999994, -0.384, -0.125, -0.15799999999999992, -0.050999999999999934, -0.08399999999999985, -0.18499999999999983, -0.41900000000000004, -0.08299999999999996, -0.4139999999999999, -0.1459999999999999, -0.30099999999999993, -0.050000000000000044, -0.05800000000000005, -0.10199999999999998, -0.07099999999999995, -0.04300000000000004, -0.04300000000000004, -0.3599999999999999, -0.10199999999999998, -0.11199999999999988, 0.33599999999999997, -0.30199999999999994, -0.029000000000000026, -0.19299999999999995, -0.17899999999999994, -0.03599999999999992, -0.09299999999999997, -0.05700000000000005, -0.24599999999999989, -0.06699999999999995, -0.256, -0.038000000000000034, -0.355, 0.09899999999999998, -0.05699999999999994, -0.03700000000000003, -0.15900000000000003, 0.44899999999999995, -0.119, -0.030000000000000027, -0.11499999999999999, -0.21899999999999997, -0.126, -0.049000000000000044, -0.269, -0.515, -0.10599999999999998, -0.03699999999999992, -0.08499999999999985, -0.20999999999999996, -0.17200000000000004, -0.05999999999999994, -0.4670000000000001, -0.10199999999999998, -0.257, -0.21499999999999986, -0.14600000000000002, -0.08299999999999996, -0.03699999999999992, -0.15800000000000003, -0.121, -0.18100000000000005, -0.07299999999999995, -0.10499999999999998, -0.125, -0.040000000000000036, -0.018000000000000016, -0.03700000000000003, -0.121, 0.32099999999999995, 0.363, -0.10199999999999998, -0.16199999999999992, -0.22599999999999976, -0.134, -0.05800000000000005, -0.1609999999999998, -0.08099999999999985, 0.040999999999999925, -0.1319999999999999, -0.06900000000000006, -0.21599999999999997, -0.23399999999999987, -0.14200000000000002, -0.2759999999999999, -0.11099999999999988, -0.128, -0.10099999999999998, -0.04800000000000004, -0.22199999999999998, -0.09099999999999997, -0.19099999999999995, -0.1439999999999999, -0.15400000000000003, -0.08699999999999986, -0.1479999999999999, -0.07699999999999996, 0.20500000000000007], "episode_lengths": [20, 99, 116, 41, 47, 16, 27, 58, 131, 25, 123, 45, 95, 16, 166, 31, 23, 14, 13, 113, 36, 35, 50, 97, 9, 60, 54, 11, 31, 19, 71, 20, 81, 12, 112, 124, 16, 11, 51, 16, 39, 10, 35, 64, 40, 15, 89, 158, 32, 12, 26, 59, 56, 19, 143, 32, 79, 67, 45, 26, 12, 50, 39, 57, 22, 33, 39, 13, 6, 11, 39, 53, 43, 32, 51, 72, 42, 18, 51, 26, 151, 41, 22, 66, 77, 49, 85, 36, 40, 31, 16, 73, 28, 62, 45, 48, 28, 47, 24, 92], "policy_red_0_v1_reward": [-1.004, 0.876, -1.002, -1.007, -1.007, 0.951, 0.901, 0.93, 0.957, -1.002, 0.7040000000000001, -1.001, -1.002, 0.907, -1.0, 0.749, -0.517, -1.004, 0.964, 0.97, 0.789, -1.002, -1.008, 0.826, 0.5509999999999999, 0.86, 0.919, -1.0, 0.849, 0.898, -1.003, 0.96, -1.0, 0.964, -1.003, -1.005, 0.87, 1.036, 0.9319999999999999, -1.005, -1.009, 0.85, -1.001, -1.001, 0.911, 0.805, -1.005, -1.005, -1.003, 1.216], "policy_blue_0_reward": [-1.01, -1.021, -1.009, -1.002, -1.008, -1.012, -1.025, -1.008, -0.53, -1.016, 0.889, -1.005, -0.511, -1.009, -1.009, -1.006, -1.0039999999999998, -1.002, -1.014, -1.003, -0.502, -1.001, -1.007, -1.003, 0.508, -1.004, -1.001, -1.0039999999999998, -1.0099999999999998, -1.002, -1.006, -1.005, -1.0099999999999998, -1.002, -1.009, -1.005, -1.004, -0.506, -0.506, -1.005, -1.002, -1.0059999999999998, -1.003, -1.0079999999999998, -1.0139999999999998, -1.006, -1.004, -1.0, -1.003, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22531646464102242, "mean_inference_ms": 1.4948755248230583, "mean_action_processing_ms": 0.06239286692057975, "mean_env_wait_ms": 0.10463412567206344, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01907634735107422, "StateBufferConnector_ms": 0.0014643669128417969, "ViewRequirementAgentConnector_ms": 0.031072378158569336}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.16022720498313, "num_env_steps_trained_throughput_per_sec": 101.16022720498313, "timesteps_total": 108000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 216000, "timers": {"training_iteration_time_ms": 39341.391, "sample_time_ms": 7550.546, "learn_time_ms": 31773.308, "learn_throughput": 125.892, "synch_weights_time_ms": 16.913}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "done": false, "episodes_total": 995, "training_iteration": 27, "trial_id": "bb874_00000", "date": "2023-09-28_21-47-57", "timestamp": 1695952077, "time_this_iter_s": 39.543967962265015, "time_total_s": 1064.8606128692627, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab6af910>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac407910>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac407130>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1064.8606128692627, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 34.89642857142858, "ram_util_percent": 26.001785714285713}, "win_rate": 0.72, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6895904780055087, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04543982059355282, "policy_loss": -0.026171414799318882, "vf_loss": 0.14120042052430412, "vf_explained_var": 0.12067675155897935, "kl": 0.012695942561487499, "entropy": 1.528163920591275, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.568, "episode_reward_mean": -0.14191999999999996, "episode_len_mean": 56.57, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.037, "red_0_v1": -1.014}, "policy_reward_max": {"blue_0": 0.894, "red_0": 0.982, "red_0_v1": 1.216}, "policy_reward_mean": {"blue_0": -0.87374, "red_0": 0.3428, "red_0_v1": -0.09569999999999995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.257, -0.21499999999999986, -0.14600000000000002, -0.08299999999999996, -0.03699999999999992, -0.15800000000000003, -0.121, -0.18100000000000005, -0.07299999999999995, -0.10499999999999998, -0.125, -0.040000000000000036, -0.018000000000000016, -0.03700000000000003, -0.121, 0.32099999999999995, 0.363, -0.10199999999999998, -0.16199999999999992, -0.22599999999999976, -0.134, -0.05800000000000005, -0.1609999999999998, -0.08099999999999985, 0.040999999999999925, -0.1319999999999999, -0.06900000000000006, -0.21599999999999997, -0.23399999999999987, -0.14200000000000002, -0.2759999999999999, -0.11099999999999988, -0.128, -0.10099999999999998, -0.04800000000000004, -0.22199999999999998, -0.09099999999999997, -0.19099999999999995, -0.1439999999999999, -0.15400000000000003, -0.08699999999999986, -0.1479999999999999, -0.07699999999999996, 0.20500000000000007, -0.509, -0.134, -0.46399999999999997, -0.17599999999999993, -0.23399999999999987, -0.07600000000000007, -0.29400000000000015, -0.568, -0.04800000000000004, -0.118, -0.122, -0.03699999999999992, -0.19100000000000006, -0.30899999999999994, -0.10999999999999999, -0.02400000000000002, -0.4750000000000001, -0.33999999999999986, -0.08999999999999975, -0.08699999999999997, -0.2809999999999999, -0.07899999999999996, -0.09099999999999997, -0.18899999999999995, -0.16799999999999982, -0.19099999999999995, -0.496, -0.367, -0.05500000000000005, -0.10199999999999987, -0.20399999999999996, -0.118, -0.15200000000000002, -0.30000000000000004, 0.43899999999999995, -0.04399999999999993, -0.03299999999999992, -0.10699999999999998, -0.08899999999999986, -0.09499999999999986, -0.23399999999999987, -0.538, -0.09499999999999997, -0.138, -0.029999999999999916, -0.03400000000000003, -0.09099999999999997, -0.258, -0.11699999999999999, -0.15600000000000003, -0.061000000000000054, -0.07799999999999985, -0.08699999999999986, -0.41400000000000003, -0.28500000000000003, -0.16600000000000004], "episode_lengths": [79, 67, 45, 26, 12, 50, 39, 57, 22, 33, 39, 13, 6, 11, 39, 53, 43, 32, 51, 72, 42, 18, 51, 26, 151, 41, 22, 66, 77, 49, 85, 36, 40, 31, 16, 73, 28, 62, 45, 48, 28, 47, 24, 92, 150, 42, 147, 58, 71, 24, 93, 173, 14, 38, 38, 12, 208, 100, 35, 8, 141, 109, 28, 27, 86, 23, 27, 60, 52, 62, 159, 117, 17, 29, 59, 38, 50, 94, 300, 13, 10, 35, 28, 30, 75, 166, 31, 42, 9, 11, 29, 79, 34, 48, 20, 25, 28, 128, 86, 54], "policy_blue_0_reward": [-1.005, -1.0099999999999998, -1.002, -1.009, -1.005, -1.004, -0.506, -0.506, -1.005, -1.002, -1.0059999999999998, -1.003, -1.0079999999999998, -1.0139999999999998, -1.006, -1.004, -1.0, -1.003, -1.003, -1.004, -1.005, -1.0119999999999998, -1.013, -1.029, -1.002, -1.007, -0.53, -1.027, -1.003, -1.005, -1.007, -1.007, -1.007, -1.021, -1.002, -1.012, 0.45299999999999996, -1.002, -1.0019999999999998, -1.001, -1.004, -1.003, -1.009, -1.026, -1.01, -1.009, -1.002, 0.894, 0.845, -1.017], "policy_red_0_v1_reward": [0.86, 0.919, -1.0, 0.849, 0.898, -1.003, 0.96, -1.0, 0.964, -1.003, -1.005, 0.87, 1.036, 0.9319999999999999, -1.005, -1.009, 0.85, -1.001, -1.001, 0.911, 0.805, -1.005, -1.005, -1.003, 1.216, 0.528, -1.005, -1.003, 0.955, -1.001, -1.007, 0.894, -1.0, -1.007, 0.926, -1.007, 0.811, -1.014, -1.012, -1.001, 0.849, -1.005, 0.966, 0.912, 0.744, 0.939, -1.002, -1.001, 0.728, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22534362117690587, "mean_inference_ms": 1.4945209385153355, "mean_action_processing_ms": 0.06235940849525376, "mean_env_wait_ms": 0.10456335041140609, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019377827644348145, "StateBufferConnector_ms": 0.0014785528182983398, "ViewRequirementAgentConnector_ms": 0.031162023544311523}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.568, "episode_reward_mean": -0.14191999999999996, "episode_len_mean": 56.57, "episodes_this_iter": 56, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.037, "red_0_v1": -1.014}, "policy_reward_max": {"blue_0": 0.894, "red_0": 0.982, "red_0_v1": 1.216}, "policy_reward_mean": {"blue_0": -0.87374, "red_0": 0.3428, "red_0_v1": -0.09569999999999995}, "hist_stats": {"episode_reward": [-0.257, -0.21499999999999986, -0.14600000000000002, -0.08299999999999996, -0.03699999999999992, -0.15800000000000003, -0.121, -0.18100000000000005, -0.07299999999999995, -0.10499999999999998, -0.125, -0.040000000000000036, -0.018000000000000016, -0.03700000000000003, -0.121, 0.32099999999999995, 0.363, -0.10199999999999998, -0.16199999999999992, -0.22599999999999976, -0.134, -0.05800000000000005, -0.1609999999999998, -0.08099999999999985, 0.040999999999999925, -0.1319999999999999, -0.06900000000000006, -0.21599999999999997, -0.23399999999999987, -0.14200000000000002, -0.2759999999999999, -0.11099999999999988, -0.128, -0.10099999999999998, -0.04800000000000004, -0.22199999999999998, -0.09099999999999997, -0.19099999999999995, -0.1439999999999999, -0.15400000000000003, -0.08699999999999986, -0.1479999999999999, -0.07699999999999996, 0.20500000000000007, -0.509, -0.134, -0.46399999999999997, -0.17599999999999993, -0.23399999999999987, -0.07600000000000007, -0.29400000000000015, -0.568, -0.04800000000000004, -0.118, -0.122, -0.03699999999999992, -0.19100000000000006, -0.30899999999999994, -0.10999999999999999, -0.02400000000000002, -0.4750000000000001, -0.33999999999999986, -0.08999999999999975, -0.08699999999999997, -0.2809999999999999, -0.07899999999999996, -0.09099999999999997, -0.18899999999999995, -0.16799999999999982, -0.19099999999999995, -0.496, -0.367, -0.05500000000000005, -0.10199999999999987, -0.20399999999999996, -0.118, -0.15200000000000002, -0.30000000000000004, 0.43899999999999995, -0.04399999999999993, -0.03299999999999992, -0.10699999999999998, -0.08899999999999986, -0.09499999999999986, -0.23399999999999987, -0.538, -0.09499999999999997, -0.138, -0.029999999999999916, -0.03400000000000003, -0.09099999999999997, -0.258, -0.11699999999999999, -0.15600000000000003, -0.061000000000000054, -0.07799999999999985, -0.08699999999999986, -0.41400000000000003, -0.28500000000000003, -0.16600000000000004], "episode_lengths": [79, 67, 45, 26, 12, 50, 39, 57, 22, 33, 39, 13, 6, 11, 39, 53, 43, 32, 51, 72, 42, 18, 51, 26, 151, 41, 22, 66, 77, 49, 85, 36, 40, 31, 16, 73, 28, 62, 45, 48, 28, 47, 24, 92, 150, 42, 147, 58, 71, 24, 93, 173, 14, 38, 38, 12, 208, 100, 35, 8, 141, 109, 28, 27, 86, 23, 27, 60, 52, 62, 159, 117, 17, 29, 59, 38, 50, 94, 300, 13, 10, 35, 28, 30, 75, 166, 31, 42, 9, 11, 29, 79, 34, 48, 20, 25, 28, 128, 86, 54], "policy_blue_0_reward": [-1.005, -1.0099999999999998, -1.002, -1.009, -1.005, -1.004, -0.506, -0.506, -1.005, -1.002, -1.0059999999999998, -1.003, -1.0079999999999998, -1.0139999999999998, -1.006, -1.004, -1.0, -1.003, -1.003, -1.004, -1.005, -1.0119999999999998, -1.013, -1.029, -1.002, -1.007, -0.53, -1.027, -1.003, -1.005, -1.007, -1.007, -1.007, -1.021, -1.002, -1.012, 0.45299999999999996, -1.002, -1.0019999999999998, -1.001, -1.004, -1.003, -1.009, -1.026, -1.01, -1.009, -1.002, 0.894, 0.845, -1.017], "policy_red_0_v1_reward": [0.86, 0.919, -1.0, 0.849, 0.898, -1.003, 0.96, -1.0, 0.964, -1.003, -1.005, 0.87, 1.036, 0.9319999999999999, -1.005, -1.009, 0.85, -1.001, -1.001, 0.911, 0.805, -1.005, -1.005, -1.003, 1.216, 0.528, -1.005, -1.003, 0.955, -1.001, -1.007, 0.894, -1.0, -1.007, 0.926, -1.007, 0.811, -1.014, -1.012, -1.001, 0.849, -1.005, 0.966, 0.912, 0.744, 0.939, -1.002, -1.001, 0.728, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22534362117690587, "mean_inference_ms": 1.4945209385153355, "mean_action_processing_ms": 0.06235940849525376, "mean_env_wait_ms": 0.10456335041140609, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019377827644348145, "StateBufferConnector_ms": 0.0014785528182983398, "ViewRequirementAgentConnector_ms": 0.031162023544311523}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.7106637980955, "num_env_steps_trained_throughput_per_sec": 101.7106637980955, "timesteps_total": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 39353.027, "sample_time_ms": 7562.717, "learn_time_ms": 31772.762, "learn_throughput": 125.894, "synch_weights_time_ms": 16.919}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "episodes_total": 1051, "training_iteration": 28, "trial_id": "bb874_00000", "date": "2023-09-28_21-48-37", "timestamp": 1695952117, "time_this_iter_s": 39.3297381401062, "time_total_s": 1104.190351009369, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7dd9c00>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf02ef0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf020e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1104.190351009369, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 34.573214285714286, "ram_util_percent": 26.04642857142857}, "win_rate": 0.73, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8067183384050927, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0661887562154637, "policy_loss": -0.02915103271564779, "vf_loss": 0.18803446347204347, "vf_explained_var": 0.0733858530720075, "kl": 0.014208339051347973, "entropy": 1.5191102530807257, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.7680000000000002, "episode_reward_mean": -0.12165999999999996, "episode_len_mean": 61.61, "episode_media": {}, "episodes_this_iter": 71, "policy_reward_min": {"blue_0": -1.028, "red_0": -1.015, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 0.953, "red_0": 0.976, "red_0_v1": 0.966}, "policy_reward_mean": {"blue_0": -0.6910357142857142, "red_0": 0.32158000000000003, "red_0_v1": -0.12786363636363637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.367, -0.05500000000000005, -0.10199999999999987, -0.20399999999999996, -0.118, -0.15200000000000002, -0.30000000000000004, 0.43899999999999995, -0.04399999999999993, -0.03299999999999992, -0.10699999999999998, -0.08899999999999986, -0.09499999999999986, -0.23399999999999987, -0.538, -0.09499999999999997, -0.138, -0.029999999999999916, -0.03400000000000003, -0.09099999999999997, -0.258, -0.11699999999999999, -0.15600000000000003, -0.061000000000000054, -0.07799999999999985, -0.08699999999999986, -0.41400000000000003, -0.28500000000000003, -0.16600000000000004, -0.15399999999999991, -0.361, -0.21299999999999986, -0.13, -0.05300000000000005, -0.06599999999999995, -0.10699999999999987, -0.09799999999999998, -0.05600000000000005, -0.039999999999999925, -0.253, -0.21799999999999997, -0.11199999999999988, -0.16400000000000003, -0.245, -0.04899999999999993, -0.21100000000000008, -0.10399999999999998, -0.135, -0.11799999999999988, -0.10999999999999988, -0.07999999999999996, -0.691, -0.15499999999999992, 0.2220000000000001, 0.30700000000000005, -0.02499999999999991, -0.08099999999999996, 0.2699999999999999, -0.04599999999999993, -0.1279999999999999, -0.04500000000000004, 0.43599999999999994, -0.12, -0.261, -0.08499999999999996, -0.10799999999999998, -0.10599999999999998, 0.20499999999999996, -0.07099999999999995, -0.041999999999999926, -0.44299999999999995, -0.544, -0.05500000000000005, -0.2909999999999999, -0.24599999999999989, -0.12399999999999989, -0.04400000000000003, -0.04600000000000004, -0.11499999999999999, -0.04299999999999993, -0.07199999999999995, -0.039000000000000035, -0.09299999999999997, -0.265, -0.11299999999999988, -0.09500000000000008, -0.17000000000000004, -0.09599999999999997, -0.09399999999999986, -0.04799999999999993, -0.15600000000000003, -0.061999999999999944, -0.052000000000000046, -0.16300000000000003, -0.050999999999999934, -0.038999999999999924, -0.7680000000000002, -0.18099999999999994, -0.051000000000000045, 0.0030000000000000027], "episode_lengths": [117, 17, 29, 59, 38, 50, 94, 300, 13, 10, 35, 28, 30, 75, 166, 31, 42, 9, 11, 29, 79, 34, 48, 20, 25, 28, 128, 86, 54, 49, 114, 66, 45, 17, 21, 30, 30, 18, 13, 80, 66, 35, 51, 78, 15, 69, 32, 41, 37, 33, 26, 202, 52, 78, 58, 8, 29, 67, 15, 41, 17, 300, 37, 85, 27, 32, 34, 94, 27, 13, 138, 172, 17, 88, 79, 35, 300, 14, 37, 14, 21, 13, 30, 83, 34, 300, 215, 30, 27, 15, 48, 19, 16, 53, 16, 12, 243, 56, 15, 154], "policy_blue_0_reward": [-1.021, -1.002, -1.012, 0.45299999999999996, -1.002, -1.0019999999999998, -1.001, -1.004, -1.003, -1.009, -1.026, -1.01, -1.009, -1.002, 0.894, 0.845, -1.017, -1.014, -1.001, -1.002, -1.0039999999999998, -1.007, -1.0, -1.008, -1.005, 0.839, 0.953, -1.002, -1.006, -1.0, -1.028, -0.5129999999999999, -0.507, -1.001, -0.508, 0.45999999999999996, -0.508, -1.002, -1.0179999999999998, -1.027, -1.0119999999999998, -0.03800000000000003, -1.003, -1.0, 0.9289999999999999, -1.012, -1.004, -1.005, 0.848, -1.003, -1.003, -1.002, -1.003, -1.027, -1.007, -0.519], "policy_red_0_v1_reward": [-1.012, -1.001, 0.849, -1.005, 0.966, 0.912, 0.744, 0.939, -1.002, -1.001, 0.728, -1.002, -1.005, -1.008, -1.005, 0.945, 0.754, 0.76, 0.901, 0.871, -1.004, -1.0059999999999998, -1.002, -1.0, -1.002, -1.004, 0.884, -1.002, 0.918, -1.008, 0.895, -1.0, -1.001, -1.011, -1.012, 0.956, 0.961, 0.908, -1.005, -0.05500000000000004, 0.845, -1.002, 0.84, 0.953]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22566826671513332, "mean_inference_ms": 1.4955073813156168, "mean_action_processing_ms": 0.06237903862260416, "mean_env_wait_ms": 0.10464585712190065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019337773323059082, "StateBufferConnector_ms": 0.001453995704650879, "ViewRequirementAgentConnector_ms": 0.030872225761413574}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.7680000000000002, "episode_reward_mean": -0.12165999999999996, "episode_len_mean": 61.61, "episodes_this_iter": 71, "policy_reward_min": {"blue_0": -1.028, "red_0": -1.015, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 0.953, "red_0": 0.976, "red_0_v1": 0.966}, "policy_reward_mean": {"blue_0": -0.6910357142857142, "red_0": 0.32158000000000003, "red_0_v1": -0.12786363636363637}, "hist_stats": {"episode_reward": [-0.367, -0.05500000000000005, -0.10199999999999987, -0.20399999999999996, -0.118, -0.15200000000000002, -0.30000000000000004, 0.43899999999999995, -0.04399999999999993, -0.03299999999999992, -0.10699999999999998, -0.08899999999999986, -0.09499999999999986, -0.23399999999999987, -0.538, -0.09499999999999997, -0.138, -0.029999999999999916, -0.03400000000000003, -0.09099999999999997, -0.258, -0.11699999999999999, -0.15600000000000003, -0.061000000000000054, -0.07799999999999985, -0.08699999999999986, -0.41400000000000003, -0.28500000000000003, -0.16600000000000004, -0.15399999999999991, -0.361, -0.21299999999999986, -0.13, -0.05300000000000005, -0.06599999999999995, -0.10699999999999987, -0.09799999999999998, -0.05600000000000005, -0.039999999999999925, -0.253, -0.21799999999999997, -0.11199999999999988, -0.16400000000000003, -0.245, -0.04899999999999993, -0.21100000000000008, -0.10399999999999998, -0.135, -0.11799999999999988, -0.10999999999999988, -0.07999999999999996, -0.691, -0.15499999999999992, 0.2220000000000001, 0.30700000000000005, -0.02499999999999991, -0.08099999999999996, 0.2699999999999999, -0.04599999999999993, -0.1279999999999999, -0.04500000000000004, 0.43599999999999994, -0.12, -0.261, -0.08499999999999996, -0.10799999999999998, -0.10599999999999998, 0.20499999999999996, -0.07099999999999995, -0.041999999999999926, -0.44299999999999995, -0.544, -0.05500000000000005, -0.2909999999999999, -0.24599999999999989, -0.12399999999999989, -0.04400000000000003, -0.04600000000000004, -0.11499999999999999, -0.04299999999999993, -0.07199999999999995, -0.039000000000000035, -0.09299999999999997, -0.265, -0.11299999999999988, -0.09500000000000008, -0.17000000000000004, -0.09599999999999997, -0.09399999999999986, -0.04799999999999993, -0.15600000000000003, -0.061999999999999944, -0.052000000000000046, -0.16300000000000003, -0.050999999999999934, -0.038999999999999924, -0.7680000000000002, -0.18099999999999994, -0.051000000000000045, 0.0030000000000000027], "episode_lengths": [117, 17, 29, 59, 38, 50, 94, 300, 13, 10, 35, 28, 30, 75, 166, 31, 42, 9, 11, 29, 79, 34, 48, 20, 25, 28, 128, 86, 54, 49, 114, 66, 45, 17, 21, 30, 30, 18, 13, 80, 66, 35, 51, 78, 15, 69, 32, 41, 37, 33, 26, 202, 52, 78, 58, 8, 29, 67, 15, 41, 17, 300, 37, 85, 27, 32, 34, 94, 27, 13, 138, 172, 17, 88, 79, 35, 300, 14, 37, 14, 21, 13, 30, 83, 34, 300, 215, 30, 27, 15, 48, 19, 16, 53, 16, 12, 243, 56, 15, 154], "policy_blue_0_reward": [-1.021, -1.002, -1.012, 0.45299999999999996, -1.002, -1.0019999999999998, -1.001, -1.004, -1.003, -1.009, -1.026, -1.01, -1.009, -1.002, 0.894, 0.845, -1.017, -1.014, -1.001, -1.002, -1.0039999999999998, -1.007, -1.0, -1.008, -1.005, 0.839, 0.953, -1.002, -1.006, -1.0, -1.028, -0.5129999999999999, -0.507, -1.001, -0.508, 0.45999999999999996, -0.508, -1.002, -1.0179999999999998, -1.027, -1.0119999999999998, -0.03800000000000003, -1.003, -1.0, 0.9289999999999999, -1.012, -1.004, -1.005, 0.848, -1.003, -1.003, -1.002, -1.003, -1.027, -1.007, -0.519], "policy_red_0_v1_reward": [-1.012, -1.001, 0.849, -1.005, 0.966, 0.912, 0.744, 0.939, -1.002, -1.001, 0.728, -1.002, -1.005, -1.008, -1.005, 0.945, 0.754, 0.76, 0.901, 0.871, -1.004, -1.0059999999999998, -1.002, -1.0, -1.002, -1.004, 0.884, -1.002, 0.918, -1.008, 0.895, -1.0, -1.001, -1.011, -1.012, 0.956, 0.961, 0.908, -1.005, -0.05500000000000004, 0.845, -1.002, 0.84, 0.953]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22566826671513332, "mean_inference_ms": 1.4955073813156168, "mean_action_processing_ms": 0.06237903862260416, "mean_env_wait_ms": 0.10464585712190065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019337773323059082, "StateBufferConnector_ms": 0.001453995704650879, "ViewRequirementAgentConnector_ms": 0.030872225761413574}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.48373332634564, "num_env_steps_trained_throughput_per_sec": 101.48373332634564, "timesteps_total": 116000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 232000, "timers": {"training_iteration_time_ms": 39374.436, "sample_time_ms": 7568.476, "learn_time_ms": 31788.35, "learn_throughput": 125.832, "synch_weights_time_ms": 16.978}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "done": false, "episodes_total": 1122, "training_iteration": 29, "trial_id": "bb874_00000", "date": "2023-09-28_21-49-16", "timestamp": 1695952156, "time_this_iter_s": 39.41786313056946, "time_total_s": 1143.6082141399384, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7dd8400>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70dc60>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70f9a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1143.6082141399384, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 33.5375, "ram_util_percent": 26.0125}, "win_rate": 0.72, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.810369844113787, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06387499230828932, "policy_loss": -0.028235625100205653, "vf_loss": 0.18136151430662723, "vf_explained_var": 0.20961479482551415, "kl": 0.014629050639824405, "entropy": 1.49594961690406, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "sampler_results": {"episode_reward_max": 0.357, "episode_reward_min": -0.8190000000000001, "episode_reward_mean": -0.14537999999999995, "episode_len_mean": 61.4, "episode_media": {}, "episodes_this_iter": 69, "policy_reward_min": {"blue_0": -1.027, "red_0": -1.04, "red_0_v1": -1.043}, "policy_reward_max": {"blue_0": 0.9289999999999999, "red_0": 0.966, "red_0_v1": 1.125}, "policy_reward_mean": {"blue_0": -0.8393125, "red_0": 0.31448000000000004, "red_0_v1": -0.10959615384615384}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.041999999999999926, -0.44299999999999995, -0.544, -0.05500000000000005, -0.2909999999999999, -0.24599999999999989, -0.12399999999999989, -0.04400000000000003, -0.04600000000000004, -0.11499999999999999, -0.04299999999999993, -0.07199999999999995, -0.039000000000000035, -0.09299999999999997, -0.265, -0.11299999999999988, -0.09500000000000008, -0.17000000000000004, -0.09599999999999997, -0.09399999999999986, -0.04799999999999993, -0.15600000000000003, -0.061999999999999944, -0.052000000000000046, -0.16300000000000003, -0.050999999999999934, -0.038999999999999924, -0.7680000000000002, -0.18099999999999994, -0.051000000000000045, 0.0030000000000000027, -0.265, -0.2749999999999999, -0.1289999999999999, -0.125, -0.05699999999999994, -0.04400000000000004, -0.32400000000000007, -0.039000000000000035, -0.21299999999999986, 0.357, -0.18299999999999994, -0.16899999999999993, -0.19299999999999984, -0.03700000000000003, -0.14800000000000002, -0.2519999999999999, -0.04200000000000004, -0.15600000000000003, -0.14600000000000002, -0.038000000000000034, -0.30399999999999994, -0.1509999999999998, -0.04600000000000004, -0.17800000000000005, -0.08599999999999997, 0.11299999999999999, -0.1329999999999999, -0.8190000000000001, -0.20599999999999996, -0.06500000000000006, 0.17699999999999994, 0.05799999999999994, -0.12399999999999989, -0.6059999999999999, -0.061999999999999944, -0.08399999999999996, -0.121, -0.29599999999999993, -0.038999999999999924, -0.22799999999999998, -0.061000000000000054, -0.09399999999999997, 0.06700000000000017, -0.07600000000000007, -0.06000000000000005, -0.10299999999999998, -0.07099999999999995, -0.72, -0.08299999999999985, -0.08099999999999996, -0.389, -0.42200000000000004, -0.09599999999999997, -0.2310000000000001, -0.257, -0.20999999999999996, -0.16800000000000004, -0.028000000000000025, -0.07099999999999995, -0.18500000000000005, -0.09199999999999997, -0.28200000000000003, -0.02200000000000002, -0.11599999999999977, -0.09099999999999986, -0.05999999999999994, -0.05899999999999994, -0.1369999999999999, -0.06400000000000006], "episode_lengths": [13, 138, 172, 17, 88, 79, 35, 300, 14, 37, 14, 21, 13, 30, 83, 34, 300, 215, 30, 27, 15, 48, 19, 16, 53, 16, 12, 243, 56, 15, 154, 79, 86, 42, 39, 18, 14, 100, 13, 64, 45, 58, 54, 58, 11, 42, 79, 13, 46, 47, 12, 93, 45, 14, 54, 28, 124, 40, 249, 65, 24, 100, 138, 37, 186, 19, 29, 34, 91, 12, 68, 18, 28, 136, 24, 18, 33, 23, 221, 26, 28, 116, 126, 28, 73, 80, 59, 51, 9, 23, 59, 28, 86, 7, 36, 28, 19, 18, 42, 20], "policy_blue_0_reward": [-1.002, -1.0179999999999998, -1.027, -1.0119999999999998, -0.03800000000000003, -1.003, -1.0, 0.9289999999999999, -1.012, -1.004, -1.005, 0.848, -1.003, -1.003, -1.002, -1.003, -1.027, -1.007, -0.519, -1.015, -1.004, -1.001, -1.017, -1.007, 0.8180000000000001, -1.003, -1.01, -1.009, -1.011, -1.003, -1.006, -1.003, -1.001, -0.514, -1.007, -1.021, -1.003, -1.009, -0.5179999999999999, -1.003, -1.002, -1.007, -1.004, -1.005, -1.003, -1.004, -1.005, -1.002], "policy_red_0_v1_reward": [-1.001, -1.011, -1.012, 0.956, 0.961, 0.908, -1.005, -0.05500000000000004, 0.845, -1.002, 0.84, 0.953, -1.014, -1.005, -1.0, -1.0, -0.502, -1.004, -1.009, -1.013, 0.96, -1.007, 0.858, -1.001, -1.001, 1.125, 0.22099999999999997, -1.006, -0.517, -1.003, 0.908, 0.889, 0.715, 0.943, 0.912, -1.003, -1.004, -1.004, -1.001, -1.043, 0.632, -1.023, 0.908, 0.756, -1.018, 0.844, 0.972, 0.931, 0.82, 0.733, 0.978, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2257683005719275, "mean_inference_ms": 1.4938656017290628, "mean_action_processing_ms": 0.06236105950572947, "mean_env_wait_ms": 0.1046509842478418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018953680992126465, "StateBufferConnector_ms": 0.0014483928680419922, "ViewRequirementAgentConnector_ms": 0.030814766883850098}}, "episode_reward_max": 0.357, "episode_reward_min": -0.8190000000000001, "episode_reward_mean": -0.14537999999999995, "episode_len_mean": 61.4, "episodes_this_iter": 69, "policy_reward_min": {"blue_0": -1.027, "red_0": -1.04, "red_0_v1": -1.043}, "policy_reward_max": {"blue_0": 0.9289999999999999, "red_0": 0.966, "red_0_v1": 1.125}, "policy_reward_mean": {"blue_0": -0.8393125, "red_0": 0.31448000000000004, "red_0_v1": -0.10959615384615384}, "hist_stats": {"episode_reward": [-0.041999999999999926, -0.44299999999999995, -0.544, -0.05500000000000005, -0.2909999999999999, -0.24599999999999989, -0.12399999999999989, -0.04400000000000003, -0.04600000000000004, -0.11499999999999999, -0.04299999999999993, -0.07199999999999995, -0.039000000000000035, -0.09299999999999997, -0.265, -0.11299999999999988, -0.09500000000000008, -0.17000000000000004, -0.09599999999999997, -0.09399999999999986, -0.04799999999999993, -0.15600000000000003, -0.061999999999999944, -0.052000000000000046, -0.16300000000000003, -0.050999999999999934, -0.038999999999999924, -0.7680000000000002, -0.18099999999999994, -0.051000000000000045, 0.0030000000000000027, -0.265, -0.2749999999999999, -0.1289999999999999, -0.125, -0.05699999999999994, -0.04400000000000004, -0.32400000000000007, -0.039000000000000035, -0.21299999999999986, 0.357, -0.18299999999999994, -0.16899999999999993, -0.19299999999999984, -0.03700000000000003, -0.14800000000000002, -0.2519999999999999, -0.04200000000000004, -0.15600000000000003, -0.14600000000000002, -0.038000000000000034, -0.30399999999999994, -0.1509999999999998, -0.04600000000000004, -0.17800000000000005, -0.08599999999999997, 0.11299999999999999, -0.1329999999999999, -0.8190000000000001, -0.20599999999999996, -0.06500000000000006, 0.17699999999999994, 0.05799999999999994, -0.12399999999999989, -0.6059999999999999, -0.061999999999999944, -0.08399999999999996, -0.121, -0.29599999999999993, -0.038999999999999924, -0.22799999999999998, -0.061000000000000054, -0.09399999999999997, 0.06700000000000017, -0.07600000000000007, -0.06000000000000005, -0.10299999999999998, -0.07099999999999995, -0.72, -0.08299999999999985, -0.08099999999999996, -0.389, -0.42200000000000004, -0.09599999999999997, -0.2310000000000001, -0.257, -0.20999999999999996, -0.16800000000000004, -0.028000000000000025, -0.07099999999999995, -0.18500000000000005, -0.09199999999999997, -0.28200000000000003, -0.02200000000000002, -0.11599999999999977, -0.09099999999999986, -0.05999999999999994, -0.05899999999999994, -0.1369999999999999, -0.06400000000000006], "episode_lengths": [13, 138, 172, 17, 88, 79, 35, 300, 14, 37, 14, 21, 13, 30, 83, 34, 300, 215, 30, 27, 15, 48, 19, 16, 53, 16, 12, 243, 56, 15, 154, 79, 86, 42, 39, 18, 14, 100, 13, 64, 45, 58, 54, 58, 11, 42, 79, 13, 46, 47, 12, 93, 45, 14, 54, 28, 124, 40, 249, 65, 24, 100, 138, 37, 186, 19, 29, 34, 91, 12, 68, 18, 28, 136, 24, 18, 33, 23, 221, 26, 28, 116, 126, 28, 73, 80, 59, 51, 9, 23, 59, 28, 86, 7, 36, 28, 19, 18, 42, 20], "policy_blue_0_reward": [-1.002, -1.0179999999999998, -1.027, -1.0119999999999998, -0.03800000000000003, -1.003, -1.0, 0.9289999999999999, -1.012, -1.004, -1.005, 0.848, -1.003, -1.003, -1.002, -1.003, -1.027, -1.007, -0.519, -1.015, -1.004, -1.001, -1.017, -1.007, 0.8180000000000001, -1.003, -1.01, -1.009, -1.011, -1.003, -1.006, -1.003, -1.001, -0.514, -1.007, -1.021, -1.003, -1.009, -0.5179999999999999, -1.003, -1.002, -1.007, -1.004, -1.005, -1.003, -1.004, -1.005, -1.002], "policy_red_0_v1_reward": [-1.001, -1.011, -1.012, 0.956, 0.961, 0.908, -1.005, -0.05500000000000004, 0.845, -1.002, 0.84, 0.953, -1.014, -1.005, -1.0, -1.0, -0.502, -1.004, -1.009, -1.013, 0.96, -1.007, 0.858, -1.001, -1.001, 1.125, 0.22099999999999997, -1.006, -0.517, -1.003, 0.908, 0.889, 0.715, 0.943, 0.912, -1.003, -1.004, -1.004, -1.001, -1.043, 0.632, -1.023, 0.908, 0.756, -1.018, 0.844, 0.972, 0.931, 0.82, 0.733, 0.978, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2257683005719275, "mean_inference_ms": 1.4938656017290628, "mean_action_processing_ms": 0.06236105950572947, "mean_env_wait_ms": 0.1046509842478418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018953680992126465, "StateBufferConnector_ms": 0.0014483928680419922, "ViewRequirementAgentConnector_ms": 0.030814766883850098}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.76210550867633, "num_env_steps_trained_throughput_per_sec": 101.76210550867633, "timesteps_total": 120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 39362.879, "sample_time_ms": 7571.814, "learn_time_ms": 31773.376, "learn_throughput": 125.892, "synch_weights_time_ms": 17.013}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 1191, "training_iteration": 30, "trial_id": "bb874_00000", "date": "2023-09-28_21-49-56", "timestamp": 1695952196, "time_this_iter_s": 39.310001373291016, "time_total_s": 1182.9182155132294, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7dd8a00>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf025f0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf00f70>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1182.9182155132294, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 34.230357142857144, "ram_util_percent": 26.042857142857144}, "win_rate": 0.73, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.752644603823622, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07788832116384584, "policy_loss": -0.020890750547793383, "vf_loss": 0.19607969536446035, "vf_explained_var": 0.10237447973340749, "kl": 0.01103475150624261, "entropy": 1.4677263202766577, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "sampler_results": {"episode_reward_max": 0.43699999999999994, "episode_reward_min": -0.72, "episode_reward_mean": -0.14101999999999998, "episode_len_mean": 58.78, "episode_media": {}, "episodes_this_iter": 70, "policy_reward_min": {"blue_0": -1.0259999999999998, "red_0": -1.038, "red_0_v1": -1.043}, "policy_reward_max": {"blue_0": 0.953, "red_0": 0.973, "red_0_v1": 1.381}, "policy_reward_mean": {"blue_0": -0.7299615384615384, "red_0": 0.27908000000000005, "red_0_v1": -0.08441666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.22799999999999998, -0.061000000000000054, -0.09399999999999997, 0.06700000000000017, -0.07600000000000007, -0.06000000000000005, -0.10299999999999998, -0.07099999999999995, -0.72, -0.08299999999999985, -0.08099999999999996, -0.389, -0.42200000000000004, -0.09599999999999997, -0.2310000000000001, -0.257, -0.20999999999999996, -0.16800000000000004, -0.028000000000000025, -0.07099999999999995, -0.18500000000000005, -0.09199999999999997, -0.28200000000000003, -0.02200000000000002, -0.11599999999999977, -0.09099999999999986, -0.05999999999999994, -0.05899999999999994, -0.1369999999999999, -0.06400000000000006, -0.16000000000000003, -0.21900000000000008, -0.03699999999999992, -0.266, 0.020000000000000018, -0.19199999999999995, -0.594, 0.3740000000000001, -0.05799999999999994, -0.2689999999999998, -0.5069999999999999, -0.10699999999999976, -0.6250000000000001, -0.20299999999999985, -0.10799999999999998, -0.07699999999999996, 0.16400000000000003, -0.34199999999999997, -0.32000000000000006, -0.08499999999999996, -0.11399999999999999, -0.08299999999999985, -0.038999999999999924, -0.08099999999999996, -0.05800000000000005, -0.133, -0.17200000000000004, -0.43999999999999995, -0.08499999999999985, -0.061000000000000054, -0.14800000000000013, -0.049000000000000044, -0.45799999999999974, 0.32799999999999985, -0.051999999999999935, 0.259, -0.039000000000000035, -0.12799999999999978, -0.45799999999999996, 0.43699999999999994, -0.05400000000000005, -0.249, -0.31499999999999995, -0.14, -0.05700000000000005, -0.21200000000000008, -0.2340000000000001, -0.06299999999999994, -0.6180000000000001, -0.06900000000000006, -0.30199999999999994, -0.21999999999999997, -0.15899999999999992, -0.07899999999999996, 0.21100000000000008, -0.06899999999999984, -0.027000000000000024, -0.12199999999999989, -0.121, -0.03300000000000003, -0.06400000000000006, -0.08699999999999997, -0.3720000000000001, -0.118, -0.21599999999999997, -0.22499999999999998, -0.30199999999999994, -0.07699999999999996, -0.278, 0.244], "episode_lengths": [68, 18, 28, 136, 24, 18, 33, 23, 221, 26, 28, 116, 126, 28, 73, 80, 59, 51, 9, 23, 59, 28, 86, 7, 36, 28, 19, 18, 42, 20, 50, 69, 12, 84, 144, 61, 179, 39, 17, 87, 153, 33, 181, 63, 34, 25, 107, 107, 102, 28, 36, 26, 12, 23, 18, 41, 54, 127, 26, 20, 49, 15, 142, 55, 17, 77, 15, 38, 139, 19, 18, 77, 102, 43, 18, 63, 227, 20, 174, 21, 91, 70, 52, 24, 92, 21, 9, 37, 37, 10, 21, 24, 114, 40, 68, 72, 89, 25, 86, 78], "policy_blue_0_reward": [-1.009, -0.5179999999999999, -1.003, -1.002, -1.007, -1.004, -1.005, -1.003, -1.004, -1.005, -1.002, -1.007, -1.008, 0.739, -1.017, -1.0259999999999998, -1.0039999999999998, -1.0119999999999998, -0.509, 0.664, -1.004, -1.004, -1.002, -1.001, -1.003, -1.008, -1.015, 0.953, -1.0239999999999998, -1.001, -0.512, -1.002, -1.0099999999999998, -1.024, -0.503, -1.011, 0.864, 0.8019999999999999, -0.541, -1.004, -1.016, -1.004, -0.5099999999999999, -1.0039999999999998, -1.005, -1.007, 0.9359999999999999, -1.007, -1.019, -1.006, -1.0139999999999998, -0.51], "policy_red_0_v1_reward": [0.943, 0.912, -1.003, -1.004, -1.004, -1.001, -1.043, 0.632, -1.023, 0.908, 0.756, -1.018, 0.844, 0.972, 0.931, 0.82, 0.733, 0.978, -1.003, -1.0, 1.058, -1.004, 1.381, -1.003, -1.007, -1.025, -1.001, -1.0, -1.005, 0.915, -1.009, 0.919, 0.94, -1.005, 1.3319999999999999, 0.946, 0.76, 0.945, -1.003, -1.033, 0.786, -1.0, -1.0, 0.969, -1.011, 0.779, -1.0, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2258229213493994, "mean_inference_ms": 1.4946491960039265, "mean_action_processing_ms": 0.062319546478537935, "mean_env_wait_ms": 0.10462883995914508, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01890432834625244, "StateBufferConnector_ms": 0.001462697982788086, "ViewRequirementAgentConnector_ms": 0.030913114547729492}}, "episode_reward_max": 0.43699999999999994, "episode_reward_min": -0.72, "episode_reward_mean": -0.14101999999999998, "episode_len_mean": 58.78, "episodes_this_iter": 70, "policy_reward_min": {"blue_0": -1.0259999999999998, "red_0": -1.038, "red_0_v1": -1.043}, "policy_reward_max": {"blue_0": 0.953, "red_0": 0.973, "red_0_v1": 1.381}, "policy_reward_mean": {"blue_0": -0.7299615384615384, "red_0": 0.27908000000000005, "red_0_v1": -0.08441666666666664}, "hist_stats": {"episode_reward": [-0.22799999999999998, -0.061000000000000054, -0.09399999999999997, 0.06700000000000017, -0.07600000000000007, -0.06000000000000005, -0.10299999999999998, -0.07099999999999995, -0.72, -0.08299999999999985, -0.08099999999999996, -0.389, -0.42200000000000004, -0.09599999999999997, -0.2310000000000001, -0.257, -0.20999999999999996, -0.16800000000000004, -0.028000000000000025, -0.07099999999999995, -0.18500000000000005, -0.09199999999999997, -0.28200000000000003, -0.02200000000000002, -0.11599999999999977, -0.09099999999999986, -0.05999999999999994, -0.05899999999999994, -0.1369999999999999, -0.06400000000000006, -0.16000000000000003, -0.21900000000000008, -0.03699999999999992, -0.266, 0.020000000000000018, -0.19199999999999995, -0.594, 0.3740000000000001, -0.05799999999999994, -0.2689999999999998, -0.5069999999999999, -0.10699999999999976, -0.6250000000000001, -0.20299999999999985, -0.10799999999999998, -0.07699999999999996, 0.16400000000000003, -0.34199999999999997, -0.32000000000000006, -0.08499999999999996, -0.11399999999999999, -0.08299999999999985, -0.038999999999999924, -0.08099999999999996, -0.05800000000000005, -0.133, -0.17200000000000004, -0.43999999999999995, -0.08499999999999985, -0.061000000000000054, -0.14800000000000013, -0.049000000000000044, -0.45799999999999974, 0.32799999999999985, -0.051999999999999935, 0.259, -0.039000000000000035, -0.12799999999999978, -0.45799999999999996, 0.43699999999999994, -0.05400000000000005, -0.249, -0.31499999999999995, -0.14, -0.05700000000000005, -0.21200000000000008, -0.2340000000000001, -0.06299999999999994, -0.6180000000000001, -0.06900000000000006, -0.30199999999999994, -0.21999999999999997, -0.15899999999999992, -0.07899999999999996, 0.21100000000000008, -0.06899999999999984, -0.027000000000000024, -0.12199999999999989, -0.121, -0.03300000000000003, -0.06400000000000006, -0.08699999999999997, -0.3720000000000001, -0.118, -0.21599999999999997, -0.22499999999999998, -0.30199999999999994, -0.07699999999999996, -0.278, 0.244], "episode_lengths": [68, 18, 28, 136, 24, 18, 33, 23, 221, 26, 28, 116, 126, 28, 73, 80, 59, 51, 9, 23, 59, 28, 86, 7, 36, 28, 19, 18, 42, 20, 50, 69, 12, 84, 144, 61, 179, 39, 17, 87, 153, 33, 181, 63, 34, 25, 107, 107, 102, 28, 36, 26, 12, 23, 18, 41, 54, 127, 26, 20, 49, 15, 142, 55, 17, 77, 15, 38, 139, 19, 18, 77, 102, 43, 18, 63, 227, 20, 174, 21, 91, 70, 52, 24, 92, 21, 9, 37, 37, 10, 21, 24, 114, 40, 68, 72, 89, 25, 86, 78], "policy_blue_0_reward": [-1.009, -0.5179999999999999, -1.003, -1.002, -1.007, -1.004, -1.005, -1.003, -1.004, -1.005, -1.002, -1.007, -1.008, 0.739, -1.017, -1.0259999999999998, -1.0039999999999998, -1.0119999999999998, -0.509, 0.664, -1.004, -1.004, -1.002, -1.001, -1.003, -1.008, -1.015, 0.953, -1.0239999999999998, -1.001, -0.512, -1.002, -1.0099999999999998, -1.024, -0.503, -1.011, 0.864, 0.8019999999999999, -0.541, -1.004, -1.016, -1.004, -0.5099999999999999, -1.0039999999999998, -1.005, -1.007, 0.9359999999999999, -1.007, -1.019, -1.006, -1.0139999999999998, -0.51], "policy_red_0_v1_reward": [0.943, 0.912, -1.003, -1.004, -1.004, -1.001, -1.043, 0.632, -1.023, 0.908, 0.756, -1.018, 0.844, 0.972, 0.931, 0.82, 0.733, 0.978, -1.003, -1.0, 1.058, -1.004, 1.381, -1.003, -1.007, -1.025, -1.001, -1.0, -1.005, 0.915, -1.009, 0.919, 0.94, -1.005, 1.3319999999999999, 0.946, 0.76, 0.945, -1.003, -1.033, 0.786, -1.0, -1.0, 0.969, -1.011, 0.779, -1.0, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2258229213493994, "mean_inference_ms": 1.4946491960039265, "mean_action_processing_ms": 0.062319546478537935, "mean_env_wait_ms": 0.10462883995914508, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01890432834625244, "StateBufferConnector_ms": 0.001462697982788086, "ViewRequirementAgentConnector_ms": 0.030913114547729492}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.86753379283414, "num_env_steps_trained_throughput_per_sec": 100.86753379283414, "timesteps_total": 124000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 248000, "timers": {"training_iteration_time_ms": 39401.672, "sample_time_ms": 7584.266, "learn_time_ms": 31799.705, "learn_throughput": 125.787, "synch_weights_time_ms": 17.02}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "done": false, "episodes_total": 1261, "training_iteration": 31, "trial_id": "bb874_00000", "date": "2023-09-28_21-50-35", "timestamp": 1695952235, "time_this_iter_s": 39.6585648059845, "time_total_s": 1222.5767803192139, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d26380>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70f5b0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70c550>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1222.5767803192139, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 35.39107142857143, "ram_util_percent": 26.175}, "win_rate": 0.71, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7114471197128296, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.049381774498882196, "policy_loss": -0.025086430905018157, "vf_loss": 0.14643231379644325, "vf_explained_var": 0.1751059999068578, "kl": 0.013754429354113522, "entropy": 1.4988372267534336, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "sampler_results": {"episode_reward_max": 0.44000000000000006, "episode_reward_min": -0.8160000000000001, "episode_reward_mean": -0.08282999999999997, "episode_len_mean": 50.03, "episode_media": {}, "episodes_this_iter": 77, "policy_reward_min": {"red_0_v1": -1.033, "red_0": -1.012, "blue_0": -1.036}, "policy_reward_max": {"red_0_v1": 1.388, "red_0": 0.973, "blue_0": 0.968}, "policy_reward_mean": {"red_0_v1": -0.4480212765957447, "red_0": 0.54444, "blue_0": -0.7862264150943397}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.06299999999999994, -0.6180000000000001, -0.06900000000000006, -0.30199999999999994, -0.21999999999999997, -0.15899999999999992, -0.07899999999999996, 0.21100000000000008, -0.06899999999999984, -0.027000000000000024, -0.12199999999999989, -0.121, -0.03300000000000003, -0.06400000000000006, -0.08699999999999997, -0.3720000000000001, -0.118, -0.21599999999999997, -0.22499999999999998, -0.30199999999999994, -0.07699999999999996, -0.278, 0.244, -0.06800000000000006, -0.138, -0.06399999999999995, -0.08399999999999985, -0.125, -0.21499999999999986, -0.05799999999999983, -0.20899999999999985, -0.06000000000000005, 0.33999999999999997, -0.03699999999999992, -0.05300000000000005, -0.15300000000000002, -0.16999999999999993, -0.8160000000000001, -0.23899999999999988, -0.07299999999999995, -0.05900000000000005, 0.32899999999999996, -0.44000000000000006, -0.04399999999999993, 0.3540000000000001, -0.09999999999999987, -0.07000000000000006, -0.2819999999999999, -0.04399999999999993, -0.17100000000000004, 0.31399999999999995, -0.06699999999999995, -0.21699999999999986, -0.06899999999999995, -0.07499999999999996, -0.12099999999999989, -0.027000000000000024, -0.10699999999999998, -0.15100000000000002, 0.21899999999999997, 0.278, -0.047000000000000035, -0.06699999999999995, -0.08899999999999997, -0.20199999999999996, -0.1369999999999999, -0.18300000000000005, -0.03500000000000003, 0.21699999999999997, -0.16800000000000004, 0.14500000000000002, -0.09999999999999987, -0.1389999999999999, -0.039000000000000035, 0.3470000000000001, -0.05400000000000005, -0.10199999999999998, -0.14700000000000002, -0.17600000000000005, 0.379, -0.04999999999999993, -0.4039999999999999, -0.05399999999999994, 0.44000000000000006, -0.062000000000000055, -0.061000000000000054, -0.042999999999999816, -0.07199999999999984, -0.18399999999999994, -0.10999999999999999, -0.23199999999999998, -0.20900000000000007, -0.3320000000000001, -0.09199999999999997, -0.050999999999999934, 0.04700000000000004, -0.05699999999999983, -0.04299999999999993, -0.14700000000000002, -0.03200000000000003], "episode_lengths": [20, 174, 21, 91, 70, 52, 24, 92, 21, 9, 37, 37, 10, 21, 24, 114, 40, 68, 72, 89, 25, 86, 78, 22, 44, 19, 27, 37, 68, 18, 64, 20, 46, 12, 17, 51, 53, 252, 72, 24, 19, 54, 134, 13, 40, 31, 22, 87, 13, 54, 52, 22, 68, 22, 24, 38, 9, 33, 49, 83, 68, 300, 22, 30, 63, 44, 59, 11, 86, 52, 112, 31, 44, 12, 48, 17, 33, 43, 52, 36, 15, 120, 17, 18, 20, 19, 13, 23, 58, 35, 73, 61, 102, 32, 16, 142, 17, 14, 47, 10], "policy_red_0_v1_reward": [-1.003, -1.033, 0.786, -1.0, -1.0, 0.969, -1.011, 0.779, -1.0, -1.006, -1.0, -1.001, -1.004, -1.0, -1.0, -1.0, 0.843, -1.001, -1.001, -1.002, 1.366, -1.015, -1.002, -0.516, -1.008, -1.002, -1.003, -0.025000000000000015, 0.9339999999999999, -1.005, -1.006, -1.002, -0.514, -1.007, 1.153, 0.961, 0.899, -1.006, 1.388, -0.5019999999999999, -1.001, -1.013, 0.891, 0.6729999999999999, -1.002, -1.0039999999999998, -1.004], "policy_blue_0_reward": [-1.004, -1.016, -1.004, -0.5099999999999999, -1.0039999999999998, -1.005, -1.007, 0.9359999999999999, -1.007, -1.019, -1.006, -1.0139999999999998, -0.51, -1.005, -1.003, -1.005, -1.003, -1.0099999999999998, -0.507, -1.009, -1.036, -1.008, -0.506, -1.013, -1.005, -1.003, 0.832, -1.0, -1.003, -1.007, -1.0, -1.007, -0.515, -0.511, -1.009, -1.002, -1.004, -1.005, -0.5049999999999999, 0.947, -1.007, -1.002, -1.013, -1.002, -1.002, -1.003, -1.0, -1.012, -1.008, -1.0, -0.517, -1.0, 0.968]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22621863190021824, "mean_inference_ms": 1.49626599520108, "mean_action_processing_ms": 0.06236807175648756, "mean_env_wait_ms": 0.10478311873857579, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019012451171875, "StateBufferConnector_ms": 0.0014671087265014648, "ViewRequirementAgentConnector_ms": 0.031088590621948242}}, "episode_reward_max": 0.44000000000000006, "episode_reward_min": -0.8160000000000001, "episode_reward_mean": -0.08282999999999997, "episode_len_mean": 50.03, "episodes_this_iter": 77, "policy_reward_min": {"red_0_v1": -1.033, "red_0": -1.012, "blue_0": -1.036}, "policy_reward_max": {"red_0_v1": 1.388, "red_0": 0.973, "blue_0": 0.968}, "policy_reward_mean": {"red_0_v1": -0.4480212765957447, "red_0": 0.54444, "blue_0": -0.7862264150943397}, "hist_stats": {"episode_reward": [-0.06299999999999994, -0.6180000000000001, -0.06900000000000006, -0.30199999999999994, -0.21999999999999997, -0.15899999999999992, -0.07899999999999996, 0.21100000000000008, -0.06899999999999984, -0.027000000000000024, -0.12199999999999989, -0.121, -0.03300000000000003, -0.06400000000000006, -0.08699999999999997, -0.3720000000000001, -0.118, -0.21599999999999997, -0.22499999999999998, -0.30199999999999994, -0.07699999999999996, -0.278, 0.244, -0.06800000000000006, -0.138, -0.06399999999999995, -0.08399999999999985, -0.125, -0.21499999999999986, -0.05799999999999983, -0.20899999999999985, -0.06000000000000005, 0.33999999999999997, -0.03699999999999992, -0.05300000000000005, -0.15300000000000002, -0.16999999999999993, -0.8160000000000001, -0.23899999999999988, -0.07299999999999995, -0.05900000000000005, 0.32899999999999996, -0.44000000000000006, -0.04399999999999993, 0.3540000000000001, -0.09999999999999987, -0.07000000000000006, -0.2819999999999999, -0.04399999999999993, -0.17100000000000004, 0.31399999999999995, -0.06699999999999995, -0.21699999999999986, -0.06899999999999995, -0.07499999999999996, -0.12099999999999989, -0.027000000000000024, -0.10699999999999998, -0.15100000000000002, 0.21899999999999997, 0.278, -0.047000000000000035, -0.06699999999999995, -0.08899999999999997, -0.20199999999999996, -0.1369999999999999, -0.18300000000000005, -0.03500000000000003, 0.21699999999999997, -0.16800000000000004, 0.14500000000000002, -0.09999999999999987, -0.1389999999999999, -0.039000000000000035, 0.3470000000000001, -0.05400000000000005, -0.10199999999999998, -0.14700000000000002, -0.17600000000000005, 0.379, -0.04999999999999993, -0.4039999999999999, -0.05399999999999994, 0.44000000000000006, -0.062000000000000055, -0.061000000000000054, -0.042999999999999816, -0.07199999999999984, -0.18399999999999994, -0.10999999999999999, -0.23199999999999998, -0.20900000000000007, -0.3320000000000001, -0.09199999999999997, -0.050999999999999934, 0.04700000000000004, -0.05699999999999983, -0.04299999999999993, -0.14700000000000002, -0.03200000000000003], "episode_lengths": [20, 174, 21, 91, 70, 52, 24, 92, 21, 9, 37, 37, 10, 21, 24, 114, 40, 68, 72, 89, 25, 86, 78, 22, 44, 19, 27, 37, 68, 18, 64, 20, 46, 12, 17, 51, 53, 252, 72, 24, 19, 54, 134, 13, 40, 31, 22, 87, 13, 54, 52, 22, 68, 22, 24, 38, 9, 33, 49, 83, 68, 300, 22, 30, 63, 44, 59, 11, 86, 52, 112, 31, 44, 12, 48, 17, 33, 43, 52, 36, 15, 120, 17, 18, 20, 19, 13, 23, 58, 35, 73, 61, 102, 32, 16, 142, 17, 14, 47, 10], "policy_red_0_v1_reward": [-1.003, -1.033, 0.786, -1.0, -1.0, 0.969, -1.011, 0.779, -1.0, -1.006, -1.0, -1.001, -1.004, -1.0, -1.0, -1.0, 0.843, -1.001, -1.001, -1.002, 1.366, -1.015, -1.002, -0.516, -1.008, -1.002, -1.003, -0.025000000000000015, 0.9339999999999999, -1.005, -1.006, -1.002, -0.514, -1.007, 1.153, 0.961, 0.899, -1.006, 1.388, -0.5019999999999999, -1.001, -1.013, 0.891, 0.6729999999999999, -1.002, -1.0039999999999998, -1.004], "policy_blue_0_reward": [-1.004, -1.016, -1.004, -0.5099999999999999, -1.0039999999999998, -1.005, -1.007, 0.9359999999999999, -1.007, -1.019, -1.006, -1.0139999999999998, -0.51, -1.005, -1.003, -1.005, -1.003, -1.0099999999999998, -0.507, -1.009, -1.036, -1.008, -0.506, -1.013, -1.005, -1.003, 0.832, -1.0, -1.003, -1.007, -1.0, -1.007, -0.515, -0.511, -1.009, -1.002, -1.004, -1.005, -0.5049999999999999, 0.947, -1.007, -1.002, -1.013, -1.002, -1.002, -1.003, -1.0, -1.012, -1.008, -1.0, -0.517, -1.0, 0.968]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22621863190021824, "mean_inference_ms": 1.49626599520108, "mean_action_processing_ms": 0.06236807175648756, "mean_env_wait_ms": 0.10478311873857579, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019012451171875, "StateBufferConnector_ms": 0.0014671087265014648, "ViewRequirementAgentConnector_ms": 0.031088590621948242}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.6667317995184, "num_env_steps_trained_throughput_per_sec": 101.6667317995184, "timesteps_total": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 39412.775, "sample_time_ms": 7589.009, "learn_time_ms": 31806.058, "learn_throughput": 125.762, "synch_weights_time_ms": 16.988}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "episodes_total": 1338, "training_iteration": 32, "trial_id": "bb874_00000", "date": "2023-09-28_21-51-15", "timestamp": 1695952275, "time_this_iter_s": 39.34689784049988, "time_total_s": 1261.9236781597137, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f31390>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4df910>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4df010>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1261.9236781597137, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 33.637499999999996, "ram_util_percent": 26.176785714285717}, "win_rate": 0.84, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.85662032533437, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07019104166174657, "policy_loss": -0.028225163996588285, "vf_loss": 0.19454165244630228, "vf_explained_var": 0.20426002684980632, "kl": 0.01291788690617371, "entropy": 1.4381979193538428, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "sampler_results": {"episode_reward_max": 1.155, "episode_reward_min": -0.7380000000000001, "episode_reward_mean": -0.08731999999999998, "episode_len_mean": 48.46, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.023, "red_0_v1": -1.018}, "policy_reward_max": {"blue_0": 1.155, "red_0": 0.979, "red_0_v1": 0.968}, "policy_reward_mean": {"blue_0": -0.7709056603773585, "red_0": 0.43661, "red_0_v1": -0.2454255319148936}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.4039999999999999, -0.05399999999999994, 0.44000000000000006, -0.062000000000000055, -0.061000000000000054, -0.042999999999999816, -0.07199999999999984, -0.18399999999999994, -0.10999999999999999, -0.23199999999999998, -0.20900000000000007, -0.3320000000000001, -0.09199999999999997, -0.050999999999999934, 0.04700000000000004, -0.05699999999999983, -0.04299999999999993, -0.14700000000000002, -0.03200000000000003, -0.122, -0.06000000000000005, -0.41100000000000003, -0.11399999999999999, -0.10499999999999998, -0.1409999999999999, -0.038000000000000034, -0.039000000000000035, 0.45699999999999996, -0.06300000000000006, -0.20399999999999996, -0.31300000000000006, -0.14100000000000001, -0.20800000000000007, -0.129, 0.41300000000000003, -0.20200000000000007, -0.04999999999999993, -0.03200000000000003, -0.09799999999999998, -0.07399999999999984, 0.353, -0.42200000000000004, -0.04499999999999993, -0.255, -0.16399999999999992, -0.07599999999999985, -0.10499999999999998, -0.2659999999999999, -0.03300000000000003, -0.11100000000000008, -0.3759999999999999, -0.17300000000000004, -0.19300000000000006, -0.20399999999999996, -0.07600000000000007, -0.2799999999999999, 1.155, -0.09999999999999998, -0.061999999999999944, -0.06499999999999995, -0.235, -0.10599999999999998, -0.1339999999999999, -0.21999999999999986, -0.06800000000000006, -0.02199999999999991, -0.051999999999999935, -0.05399999999999994, -0.16599999999999993, -0.06500000000000006, -0.09899999999999987, -0.09999999999999998, -0.10499999999999998, -0.3889999999999999, -0.07399999999999995, -0.7380000000000001, -0.09999999999999998, -0.1499999999999999, 0.273, -0.08999999999999986, -0.22699999999999998, -0.11599999999999999, -0.04499999999999993, -0.1469999999999998, -0.03599999999999992, -0.401, -0.05700000000000005, -0.062000000000000055, 0.399, -0.07100000000000006, -0.11199999999999999, -0.03399999999999992, -0.18600000000000005, -0.17900000000000005, -0.08699999999999986, -0.07699999999999996, 0.40600000000000014, -0.19800000000000006, 0.10400000000000009, -0.04200000000000004], "episode_lengths": [120, 17, 18, 20, 19, 13, 23, 58, 35, 73, 61, 102, 32, 16, 142, 17, 14, 47, 10, 38, 22, 128, 38, 31, 40, 12, 13, 14, 19, 64, 93, 45, 60, 41, 27, 65, 15, 10, 34, 23, 45, 134, 14, 83, 49, 25, 33, 83, 11, 300, 113, 55, 59, 66, 24, 89, 110, 28, 19, 20, 77, 34, 41, 62, 22, 7, 17, 17, 53, 21, 30, 30, 36, 118, 23, 222, 32, 43, 72, 27, 71, 36, 14, 43, 11, 124, 21, 19, 32, 21, 36, 11, 54, 57, 28, 24, 29, 63, 125, 14], "policy_blue_0_reward": [-1.013, -1.002, -1.002, -1.003, -1.0, -1.012, -1.008, -1.0, -0.517, -1.0, 0.968, -1.006, -1.002, -1.002, -1.007, -1.007, -1.001, 0.961, -0.5, -1.004, -1.004, -0.505, -1.003, -1.011, -1.012, -1.021, -1.007, -1.011, -1.002, 1.155, -1.004, -1.011, 0.9329999999999999, -1.002, -1.006, -1.001, -1.005, -1.008, -1.005, 0.926, -1.029, -1.007, -1.005, -1.009, -1.008, -1.0059999999999998, -1.003, -1.001, -1.005, -1.003, -0.5069999999999999, -0.5139999999999999, -1.0], "policy_red_0_v1_reward": [-0.5019999999999999, -1.001, -1.013, 0.891, 0.6729999999999999, -1.002, -1.0039999999999998, -1.004, 0.6, 0.804, 0.71, -1.003, 0.8059999999999999, -1.003, -0.5, 0.8009999999999999, -1.0039999999999998, 0.968, -1.003, -1.009, 0.747, -1.001, -1.004, -1.0, -0.05400000000000004, -1.007, -1.006, 0.906, -1.004, -1.001, -1.002, 0.801, -1.001, -1.001, -1.018, 0.902, -0.507, -1.002, 0.62, 0.9339999999999999, 0.94, -0.503, -1.005, 0.891, 0.832, -1.003, 0.8059999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22634651067434036, "mean_inference_ms": 1.494481629724297, "mean_action_processing_ms": 0.062336672460914545, "mean_env_wait_ms": 0.10476779510829765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019087672233581543, "StateBufferConnector_ms": 0.0014386177062988281, "ViewRequirementAgentConnector_ms": 0.03077387809753418}}, "episode_reward_max": 1.155, "episode_reward_min": -0.7380000000000001, "episode_reward_mean": -0.08731999999999998, "episode_len_mean": 48.46, "episodes_this_iter": 81, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.023, "red_0_v1": -1.018}, "policy_reward_max": {"blue_0": 1.155, "red_0": 0.979, "red_0_v1": 0.968}, "policy_reward_mean": {"blue_0": -0.7709056603773585, "red_0": 0.43661, "red_0_v1": -0.2454255319148936}, "hist_stats": {"episode_reward": [-0.4039999999999999, -0.05399999999999994, 0.44000000000000006, -0.062000000000000055, -0.061000000000000054, -0.042999999999999816, -0.07199999999999984, -0.18399999999999994, -0.10999999999999999, -0.23199999999999998, -0.20900000000000007, -0.3320000000000001, -0.09199999999999997, -0.050999999999999934, 0.04700000000000004, -0.05699999999999983, -0.04299999999999993, -0.14700000000000002, -0.03200000000000003, -0.122, -0.06000000000000005, -0.41100000000000003, -0.11399999999999999, -0.10499999999999998, -0.1409999999999999, -0.038000000000000034, -0.039000000000000035, 0.45699999999999996, -0.06300000000000006, -0.20399999999999996, -0.31300000000000006, -0.14100000000000001, -0.20800000000000007, -0.129, 0.41300000000000003, -0.20200000000000007, -0.04999999999999993, -0.03200000000000003, -0.09799999999999998, -0.07399999999999984, 0.353, -0.42200000000000004, -0.04499999999999993, -0.255, -0.16399999999999992, -0.07599999999999985, -0.10499999999999998, -0.2659999999999999, -0.03300000000000003, -0.11100000000000008, -0.3759999999999999, -0.17300000000000004, -0.19300000000000006, -0.20399999999999996, -0.07600000000000007, -0.2799999999999999, 1.155, -0.09999999999999998, -0.061999999999999944, -0.06499999999999995, -0.235, -0.10599999999999998, -0.1339999999999999, -0.21999999999999986, -0.06800000000000006, -0.02199999999999991, -0.051999999999999935, -0.05399999999999994, -0.16599999999999993, -0.06500000000000006, -0.09899999999999987, -0.09999999999999998, -0.10499999999999998, -0.3889999999999999, -0.07399999999999995, -0.7380000000000001, -0.09999999999999998, -0.1499999999999999, 0.273, -0.08999999999999986, -0.22699999999999998, -0.11599999999999999, -0.04499999999999993, -0.1469999999999998, -0.03599999999999992, -0.401, -0.05700000000000005, -0.062000000000000055, 0.399, -0.07100000000000006, -0.11199999999999999, -0.03399999999999992, -0.18600000000000005, -0.17900000000000005, -0.08699999999999986, -0.07699999999999996, 0.40600000000000014, -0.19800000000000006, 0.10400000000000009, -0.04200000000000004], "episode_lengths": [120, 17, 18, 20, 19, 13, 23, 58, 35, 73, 61, 102, 32, 16, 142, 17, 14, 47, 10, 38, 22, 128, 38, 31, 40, 12, 13, 14, 19, 64, 93, 45, 60, 41, 27, 65, 15, 10, 34, 23, 45, 134, 14, 83, 49, 25, 33, 83, 11, 300, 113, 55, 59, 66, 24, 89, 110, 28, 19, 20, 77, 34, 41, 62, 22, 7, 17, 17, 53, 21, 30, 30, 36, 118, 23, 222, 32, 43, 72, 27, 71, 36, 14, 43, 11, 124, 21, 19, 32, 21, 36, 11, 54, 57, 28, 24, 29, 63, 125, 14], "policy_blue_0_reward": [-1.013, -1.002, -1.002, -1.003, -1.0, -1.012, -1.008, -1.0, -0.517, -1.0, 0.968, -1.006, -1.002, -1.002, -1.007, -1.007, -1.001, 0.961, -0.5, -1.004, -1.004, -0.505, -1.003, -1.011, -1.012, -1.021, -1.007, -1.011, -1.002, 1.155, -1.004, -1.011, 0.9329999999999999, -1.002, -1.006, -1.001, -1.005, -1.008, -1.005, 0.926, -1.029, -1.007, -1.005, -1.009, -1.008, -1.0059999999999998, -1.003, -1.001, -1.005, -1.003, -0.5069999999999999, -0.5139999999999999, -1.0], "policy_red_0_v1_reward": [-0.5019999999999999, -1.001, -1.013, 0.891, 0.6729999999999999, -1.002, -1.0039999999999998, -1.004, 0.6, 0.804, 0.71, -1.003, 0.8059999999999999, -1.003, -0.5, 0.8009999999999999, -1.0039999999999998, 0.968, -1.003, -1.009, 0.747, -1.001, -1.004, -1.0, -0.05400000000000004, -1.007, -1.006, 0.906, -1.004, -1.001, -1.002, 0.801, -1.001, -1.001, -1.018, 0.902, -0.507, -1.002, 0.62, 0.9339999999999999, 0.94, -0.503, -1.005, 0.891, 0.832, -1.003, 0.8059999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22634651067434036, "mean_inference_ms": 1.494481629724297, "mean_action_processing_ms": 0.062336672460914545, "mean_env_wait_ms": 0.10476779510829765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019087672233581543, "StateBufferConnector_ms": 0.0014386177062988281, "ViewRequirementAgentConnector_ms": 0.03077387809753418}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.8937712957943, "num_env_steps_trained_throughput_per_sec": 101.8937712957943, "timesteps_total": 132000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 264000, "timers": {"training_iteration_time_ms": 39395.693, "sample_time_ms": 7597.309, "learn_time_ms": 31780.628, "learn_throughput": 125.863, "synch_weights_time_ms": 16.999}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "done": false, "episodes_total": 1419, "training_iteration": 33, "trial_id": "bb874_00000", "date": "2023-09-28_21-51-54", "timestamp": 1695952314, "time_this_iter_s": 39.25926494598389, "time_total_s": 1301.1829431056976, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d27730>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac756dd0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac7541f0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1301.1829431056976, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 35.16607142857143, "ram_util_percent": 26.289285714285718}, "win_rate": 0.77, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8019622308512528, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05038563805089022, "policy_loss": -0.028060020667423184, "vf_loss": 0.15416595675051212, "vf_explained_var": 0.14173317750295003, "kl": 0.013977772416882816, "entropy": 1.4328737204273543, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "sampler_results": {"episode_reward_max": 0.44399999999999995, "episode_reward_min": -0.877, "episode_reward_mean": -0.07188999999999997, "episode_len_mean": 55.34, "episode_media": {}, "episodes_this_iter": 70, "policy_reward_min": {"blue_0": -1.037, "red_0": -1.021, "red_0_v1": -1.025}, "policy_reward_max": {"blue_0": 1.444, "red_0": 0.979, "red_0_v1": 1.384}, "policy_reward_mean": {"blue_0": -0.7330357142857142, "red_0": 0.45179, "red_0_v1": -0.2572272727272727}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.09899999999999987, -0.09999999999999998, -0.10499999999999998, -0.3889999999999999, -0.07399999999999995, -0.7380000000000001, -0.09999999999999998, -0.1499999999999999, 0.273, -0.08999999999999986, -0.22699999999999998, -0.11599999999999999, -0.04499999999999993, -0.1469999999999998, -0.03599999999999992, -0.401, -0.05700000000000005, -0.062000000000000055, 0.399, -0.07100000000000006, -0.11199999999999999, -0.03399999999999992, -0.18600000000000005, -0.17900000000000005, -0.08699999999999986, -0.07699999999999996, 0.40600000000000014, -0.19800000000000006, 0.10400000000000009, -0.04200000000000004, -0.04399999999999993, -0.10899999999999987, -0.43400000000000005, 0.30300000000000005, -0.05599999999999994, -0.29499999999999993, -0.06600000000000006, -0.488, -0.09699999999999998, 0.249, 0.28900000000000003, 0.34299999999999997, -0.19999999999999984, -0.2799999999999999, -0.05499999999999983, -0.1439999999999999, -0.877, 0.43699999999999994, 0.32600000000000007, -0.14500000000000002, -0.0229999999999998, -0.05800000000000005, 0.375, -0.47, -0.08899999999999986, -0.02499999999999991, -0.2659999999999999, -0.026000000000000023, -0.051999999999999935, -0.4059999999999999, 0.378, -0.10099999999999998, -0.28900000000000003, -0.277, -0.08499999999999996, 0.34199999999999997, -0.061999999999999944, -0.14600000000000002, -0.4550000000000002, -0.039000000000000035, -0.09000000000000008, -0.10699999999999987, -0.07700000000000007, -0.04499999999999993, -0.07399999999999984, -0.07299999999999995, 0.43299999999999994, 0.3820000000000001, -0.20999999999999996, -0.07200000000000006, -0.2250000000000001, -0.16900000000000004, -0.12199999999999989, -0.09999999999999987, -0.17300000000000004, -0.06800000000000006, -0.027999999999999914, -0.17799999999999994, -0.131, -0.15000000000000002, 0.44399999999999995, -0.18799999999999994, 0.21299999999999997, -0.30499999999999994, -0.14400000000000002, -0.07800000000000007, 0.42000000000000004, -0.17000000000000004, -0.11499999999999988, -0.1319999999999999], "episode_lengths": [30, 30, 36, 118, 23, 222, 32, 43, 72, 27, 71, 36, 14, 43, 11, 124, 21, 19, 32, 21, 36, 11, 54, 57, 28, 24, 29, 63, 125, 14, 13, 34, 130, 59, 17, 95, 18, 144, 29, 78, 66, 48, 60, 93, 17, 45, 260, 300, 55, 45, 7, 18, 39, 143, 28, 8, 79, 8, 17, 121, 39, 32, 89, 87, 25, 46, 19, 49, 140, 13, 300, 32, 24, 14, 23, 24, 19, 38, 66, 22, 69, 52, 39, 31, 55, 20, 9, 53, 41, 46, 18, 57, 87, 96, 42, 24, 25, 52, 36, 41], "policy_blue_0_reward": [-1.005, -1.008, -1.005, 0.926, -1.029, -1.007, -1.005, -1.009, -1.008, -1.0059999999999998, -1.003, -1.001, -1.005, -1.003, -0.5069999999999999, -0.5139999999999999, -1.0, -1.0039999999999998, -1.005, -1.018, -0.5059999999999999, -1.002, 0.7040000000000001, -1.015, -1.005, -0.511, -1.009, -1.003, -1.006, -1.037, 0.46099999999999997, -1.0019999999999998, -1.007, -1.0, -1.011, -0.501, -1.009, -0.51, -1.004, 0.845, 0.9229999999999999, -1.003, -0.503, -1.003, -1.006, -1.004, -1.006, -1.005, -1.001, -1.007, 1.444, -0.513, -1.012, -1.004, -1.002, -1.004], "policy_red_0_v1_reward": [-1.018, 0.902, -0.507, -1.002, 0.62, 0.9339999999999999, 0.94, -0.503, -1.005, 0.891, 0.832, -1.003, 0.8059999999999999, -1.005, -0.506, -0.504, -1.005, 1.326, -1.004, 0.944, -0.504, -1.017, -1.003, -1.001, -1.002, 0.9, 0.731, -1.005, -1.025, 0.961, -0.04200000000000003, -1.005, -1.004, -1.001, 1.384, -1.009, 0.838, -1.001, -1.008, 0.875, -1.003, -0.502, -1.006, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2263483683693413, "mean_inference_ms": 1.494239636473527, "mean_action_processing_ms": 0.062288026804552234, "mean_env_wait_ms": 0.1047123144334067, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019277334213256836, "StateBufferConnector_ms": 0.0014586448669433594, "ViewRequirementAgentConnector_ms": 0.031010985374450684}}, "episode_reward_max": 0.44399999999999995, "episode_reward_min": -0.877, "episode_reward_mean": -0.07188999999999997, "episode_len_mean": 55.34, "episodes_this_iter": 70, "policy_reward_min": {"blue_0": -1.037, "red_0": -1.021, "red_0_v1": -1.025}, "policy_reward_max": {"blue_0": 1.444, "red_0": 0.979, "red_0_v1": 1.384}, "policy_reward_mean": {"blue_0": -0.7330357142857142, "red_0": 0.45179, "red_0_v1": -0.2572272727272727}, "hist_stats": {"episode_reward": [-0.09899999999999987, -0.09999999999999998, -0.10499999999999998, -0.3889999999999999, -0.07399999999999995, -0.7380000000000001, -0.09999999999999998, -0.1499999999999999, 0.273, -0.08999999999999986, -0.22699999999999998, -0.11599999999999999, -0.04499999999999993, -0.1469999999999998, -0.03599999999999992, -0.401, -0.05700000000000005, -0.062000000000000055, 0.399, -0.07100000000000006, -0.11199999999999999, -0.03399999999999992, -0.18600000000000005, -0.17900000000000005, -0.08699999999999986, -0.07699999999999996, 0.40600000000000014, -0.19800000000000006, 0.10400000000000009, -0.04200000000000004, -0.04399999999999993, -0.10899999999999987, -0.43400000000000005, 0.30300000000000005, -0.05599999999999994, -0.29499999999999993, -0.06600000000000006, -0.488, -0.09699999999999998, 0.249, 0.28900000000000003, 0.34299999999999997, -0.19999999999999984, -0.2799999999999999, -0.05499999999999983, -0.1439999999999999, -0.877, 0.43699999999999994, 0.32600000000000007, -0.14500000000000002, -0.0229999999999998, -0.05800000000000005, 0.375, -0.47, -0.08899999999999986, -0.02499999999999991, -0.2659999999999999, -0.026000000000000023, -0.051999999999999935, -0.4059999999999999, 0.378, -0.10099999999999998, -0.28900000000000003, -0.277, -0.08499999999999996, 0.34199999999999997, -0.061999999999999944, -0.14600000000000002, -0.4550000000000002, -0.039000000000000035, -0.09000000000000008, -0.10699999999999987, -0.07700000000000007, -0.04499999999999993, -0.07399999999999984, -0.07299999999999995, 0.43299999999999994, 0.3820000000000001, -0.20999999999999996, -0.07200000000000006, -0.2250000000000001, -0.16900000000000004, -0.12199999999999989, -0.09999999999999987, -0.17300000000000004, -0.06800000000000006, -0.027999999999999914, -0.17799999999999994, -0.131, -0.15000000000000002, 0.44399999999999995, -0.18799999999999994, 0.21299999999999997, -0.30499999999999994, -0.14400000000000002, -0.07800000000000007, 0.42000000000000004, -0.17000000000000004, -0.11499999999999988, -0.1319999999999999], "episode_lengths": [30, 30, 36, 118, 23, 222, 32, 43, 72, 27, 71, 36, 14, 43, 11, 124, 21, 19, 32, 21, 36, 11, 54, 57, 28, 24, 29, 63, 125, 14, 13, 34, 130, 59, 17, 95, 18, 144, 29, 78, 66, 48, 60, 93, 17, 45, 260, 300, 55, 45, 7, 18, 39, 143, 28, 8, 79, 8, 17, 121, 39, 32, 89, 87, 25, 46, 19, 49, 140, 13, 300, 32, 24, 14, 23, 24, 19, 38, 66, 22, 69, 52, 39, 31, 55, 20, 9, 53, 41, 46, 18, 57, 87, 96, 42, 24, 25, 52, 36, 41], "policy_blue_0_reward": [-1.005, -1.008, -1.005, 0.926, -1.029, -1.007, -1.005, -1.009, -1.008, -1.0059999999999998, -1.003, -1.001, -1.005, -1.003, -0.5069999999999999, -0.5139999999999999, -1.0, -1.0039999999999998, -1.005, -1.018, -0.5059999999999999, -1.002, 0.7040000000000001, -1.015, -1.005, -0.511, -1.009, -1.003, -1.006, -1.037, 0.46099999999999997, -1.0019999999999998, -1.007, -1.0, -1.011, -0.501, -1.009, -0.51, -1.004, 0.845, 0.9229999999999999, -1.003, -0.503, -1.003, -1.006, -1.004, -1.006, -1.005, -1.001, -1.007, 1.444, -0.513, -1.012, -1.004, -1.002, -1.004], "policy_red_0_v1_reward": [-1.018, 0.902, -0.507, -1.002, 0.62, 0.9339999999999999, 0.94, -0.503, -1.005, 0.891, 0.832, -1.003, 0.8059999999999999, -1.005, -0.506, -0.504, -1.005, 1.326, -1.004, 0.944, -0.504, -1.017, -1.003, -1.001, -1.002, 0.9, 0.731, -1.005, -1.025, 0.961, -0.04200000000000003, -1.005, -1.004, -1.001, 1.384, -1.009, 0.838, -1.001, -1.008, 0.875, -1.003, -0.502, -1.006, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2263483683693413, "mean_inference_ms": 1.494239636473527, "mean_action_processing_ms": 0.062288026804552234, "mean_env_wait_ms": 0.1047123144334067, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019277334213256836, "StateBufferConnector_ms": 0.0014586448669433594, "ViewRequirementAgentConnector_ms": 0.031010985374450684}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.66622107091808, "num_env_steps_trained_throughput_per_sec": 101.66622107091808, "timesteps_total": 136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 39403.605, "sample_time_ms": 7601.084, "learn_time_ms": 31784.774, "learn_throughput": 125.846, "synch_weights_time_ms": 17.007}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "episodes_total": 1489, "training_iteration": 34, "trial_id": "bb874_00000", "date": "2023-09-28_21-52-33", "timestamp": 1695952353, "time_this_iter_s": 39.3470299243927, "time_total_s": 1340.5299730300903, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f32ce0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf03010>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf00ee0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1340.5299730300903, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 35.066071428571426, "ram_util_percent": 26.316071428571433}, "win_rate": 0.79, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9455975429465373, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.058042933153289296, "policy_loss": -0.028685274677021273, "vf_loss": 0.1702431507098178, "vf_explained_var": 0.2848702964062492, "kl": 0.015015837412726307, "entropy": 1.396534683679541, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "sampler_results": {"episode_reward_max": 0.44899999999999995, "episode_reward_min": -0.853, "episode_reward_mean": -0.09163999999999994, "episode_len_mean": 46.9, "episode_media": {}, "episodes_this_iter": 84, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.034, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 1.444, "red_0": 0.979, "red_0_v1": 1.24}, "policy_reward_mean": {"blue_0": -0.8446491228070174, "red_0": 0.50532, "red_0_v1": -0.2686279069767442}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.17300000000000004, -0.06800000000000006, -0.027999999999999914, -0.17799999999999994, -0.131, -0.15000000000000002, 0.44399999999999995, -0.18799999999999994, 0.21299999999999997, -0.30499999999999994, -0.14400000000000002, -0.07800000000000007, 0.42000000000000004, -0.17000000000000004, -0.11499999999999988, -0.1319999999999999, -0.30300000000000005, -0.126, -0.07799999999999985, -0.853, -0.16300000000000003, -0.18200000000000005, -0.04899999999999982, -0.122, 0.359, -0.24299999999999977, -0.15399999999999991, -0.22199999999999998, -0.15500000000000003, -0.15000000000000002, -0.31099999999999994, 0.14400000000000002, -0.05999999999999994, -0.10499999999999976, -0.06900000000000006, 0.44899999999999995, -0.15899999999999992, -0.11599999999999988, -0.22899999999999987, -0.516, -0.08899999999999986, -0.18899999999999983, -0.027000000000000024, -0.07599999999999996, -0.04700000000000004, -0.19099999999999995, -0.06899999999999995, -0.41100000000000003, -0.08699999999999986, -0.062000000000000055, -0.133, -0.07099999999999995, -0.238, -0.040999999999999814, -0.16100000000000003, -0.09199999999999997, -0.061000000000000054, -0.252, -0.04300000000000004, -0.06099999999999983, -0.040999999999999814, -0.269, -0.04700000000000004, -0.02199999999999991, 0.43800000000000006, -0.09199999999999986, -0.08699999999999974, -0.136, -0.03699999999999992, -0.11099999999999999, 0.31399999999999995, -0.052000000000000046, -0.051999999999999824, -0.20900000000000007, -0.5470000000000002, -0.11399999999999999, -0.11899999999999988, -0.06399999999999995, -0.06499999999999995, -0.09799999999999986, -0.05899999999999994, -0.364, -0.07500000000000007, 0.23299999999999998, -0.263, 0.09399999999999986, 0.2290000000000001, -0.03699999999999992, -0.05999999999999994, 0.33899999999999997, -0.4249999999999998, -0.07400000000000007, -0.041999999999999926, -0.18600000000000005, -0.026000000000000023, -0.051999999999999824, -0.04299999999999993, -0.11499999999999988, -0.21199999999999997, -0.019000000000000017], "episode_lengths": [55, 20, 9, 53, 41, 46, 18, 57, 87, 96, 42, 24, 25, 52, 36, 41, 93, 40, 23, 258, 51, 51, 15, 38, 43, 75, 47, 71, 49, 46, 90, 110, 19, 33, 21, 16, 48, 35, 74, 154, 28, 62, 9, 25, 15, 58, 22, 127, 26, 20, 41, 22, 76, 13, 50, 28, 20, 80, 14, 19, 13, 83, 15, 7, 18, 29, 27, 46, 12, 33, 57, 15, 16, 67, 172, 40, 34, 19, 20, 31, 18, 113, 24, 83, 81, 124, 84, 12, 19, 51, 136, 22, 13, 54, 12, 16, 14, 36, 61, 6], "policy_blue_0_reward": [-1.006, -1.005, -1.001, -1.007, 1.444, -0.513, -1.012, -1.004, -1.002, -1.004, -1.01, -1.004, -1.006, -1.033, -1.006, -1.0039999999999998, -0.504, -1.0099999999999998, -1.009, -1.007, -1.007, -1.011, -0.514, -1.002, -1.0039999999999998, -1.007, -1.011, -1.003, -1.0, -1.002, -1.001, -1.006, -1.007, -1.0019999999999998, -1.005, -1.0019999999999998, -1.001, -1.007, -1.002, -0.5049999999999999, -1.0059999999999998, -1.001, -0.513, -1.026, -1.003, -1.005, 0.645, -1.009, 1.1139999999999999, -1.001, -1.002, -0.505, -1.014, -1.001, -1.0, -1.0039999999999998, -1.012], "policy_red_0_v1_reward": [-1.008, 0.875, -1.003, -0.502, -1.006, -1.002, 0.834, -1.004, 0.778, 0.9339999999999999, -0.502, -1.011, 0.518, -1.001, 0.925, 0.8170000000000001, 0.607, -1.002, -1.002, -1.005, 0.849, 0.94, -1.005, 0.958, -1.001, -1.006, -1.005, -1.006, 0.95, -1.001, -1.004, -1.001, -1.008, -1.001, -1.003, 0.9269999999999999, -0.509, 1.24, 0.9289999999999999, -1.012, -1.001, -1.002, 0.981]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22639060592051216, "mean_inference_ms": 1.4933756734564565, "mean_action_processing_ms": 0.06225655291126983, "mean_env_wait_ms": 0.10467800685002292, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019245505332946777, "StateBufferConnector_ms": 0.0014865398406982422, "ViewRequirementAgentConnector_ms": 0.03105342388153076}}, "episode_reward_max": 0.44899999999999995, "episode_reward_min": -0.853, "episode_reward_mean": -0.09163999999999994, "episode_len_mean": 46.9, "episodes_this_iter": 84, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.034, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 1.444, "red_0": 0.979, "red_0_v1": 1.24}, "policy_reward_mean": {"blue_0": -0.8446491228070174, "red_0": 0.50532, "red_0_v1": -0.2686279069767442}, "hist_stats": {"episode_reward": [-0.17300000000000004, -0.06800000000000006, -0.027999999999999914, -0.17799999999999994, -0.131, -0.15000000000000002, 0.44399999999999995, -0.18799999999999994, 0.21299999999999997, -0.30499999999999994, -0.14400000000000002, -0.07800000000000007, 0.42000000000000004, -0.17000000000000004, -0.11499999999999988, -0.1319999999999999, -0.30300000000000005, -0.126, -0.07799999999999985, -0.853, -0.16300000000000003, -0.18200000000000005, -0.04899999999999982, -0.122, 0.359, -0.24299999999999977, -0.15399999999999991, -0.22199999999999998, -0.15500000000000003, -0.15000000000000002, -0.31099999999999994, 0.14400000000000002, -0.05999999999999994, -0.10499999999999976, -0.06900000000000006, 0.44899999999999995, -0.15899999999999992, -0.11599999999999988, -0.22899999999999987, -0.516, -0.08899999999999986, -0.18899999999999983, -0.027000000000000024, -0.07599999999999996, -0.04700000000000004, -0.19099999999999995, -0.06899999999999995, -0.41100000000000003, -0.08699999999999986, -0.062000000000000055, -0.133, -0.07099999999999995, -0.238, -0.040999999999999814, -0.16100000000000003, -0.09199999999999997, -0.061000000000000054, -0.252, -0.04300000000000004, -0.06099999999999983, -0.040999999999999814, -0.269, -0.04700000000000004, -0.02199999999999991, 0.43800000000000006, -0.09199999999999986, -0.08699999999999974, -0.136, -0.03699999999999992, -0.11099999999999999, 0.31399999999999995, -0.052000000000000046, -0.051999999999999824, -0.20900000000000007, -0.5470000000000002, -0.11399999999999999, -0.11899999999999988, -0.06399999999999995, -0.06499999999999995, -0.09799999999999986, -0.05899999999999994, -0.364, -0.07500000000000007, 0.23299999999999998, -0.263, 0.09399999999999986, 0.2290000000000001, -0.03699999999999992, -0.05999999999999994, 0.33899999999999997, -0.4249999999999998, -0.07400000000000007, -0.041999999999999926, -0.18600000000000005, -0.026000000000000023, -0.051999999999999824, -0.04299999999999993, -0.11499999999999988, -0.21199999999999997, -0.019000000000000017], "episode_lengths": [55, 20, 9, 53, 41, 46, 18, 57, 87, 96, 42, 24, 25, 52, 36, 41, 93, 40, 23, 258, 51, 51, 15, 38, 43, 75, 47, 71, 49, 46, 90, 110, 19, 33, 21, 16, 48, 35, 74, 154, 28, 62, 9, 25, 15, 58, 22, 127, 26, 20, 41, 22, 76, 13, 50, 28, 20, 80, 14, 19, 13, 83, 15, 7, 18, 29, 27, 46, 12, 33, 57, 15, 16, 67, 172, 40, 34, 19, 20, 31, 18, 113, 24, 83, 81, 124, 84, 12, 19, 51, 136, 22, 13, 54, 12, 16, 14, 36, 61, 6], "policy_blue_0_reward": [-1.006, -1.005, -1.001, -1.007, 1.444, -0.513, -1.012, -1.004, -1.002, -1.004, -1.01, -1.004, -1.006, -1.033, -1.006, -1.0039999999999998, -0.504, -1.0099999999999998, -1.009, -1.007, -1.007, -1.011, -0.514, -1.002, -1.0039999999999998, -1.007, -1.011, -1.003, -1.0, -1.002, -1.001, -1.006, -1.007, -1.0019999999999998, -1.005, -1.0019999999999998, -1.001, -1.007, -1.002, -0.5049999999999999, -1.0059999999999998, -1.001, -0.513, -1.026, -1.003, -1.005, 0.645, -1.009, 1.1139999999999999, -1.001, -1.002, -0.505, -1.014, -1.001, -1.0, -1.0039999999999998, -1.012], "policy_red_0_v1_reward": [-1.008, 0.875, -1.003, -0.502, -1.006, -1.002, 0.834, -1.004, 0.778, 0.9339999999999999, -0.502, -1.011, 0.518, -1.001, 0.925, 0.8170000000000001, 0.607, -1.002, -1.002, -1.005, 0.849, 0.94, -1.005, 0.958, -1.001, -1.006, -1.005, -1.006, 0.95, -1.001, -1.004, -1.001, -1.008, -1.001, -1.003, 0.9269999999999999, -0.509, 1.24, 0.9289999999999999, -1.012, -1.001, -1.002, 0.981]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22639060592051216, "mean_inference_ms": 1.4933756734564565, "mean_action_processing_ms": 0.06225655291126983, "mean_env_wait_ms": 0.10467800685002292, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019245505332946777, "StateBufferConnector_ms": 0.0014865398406982422, "ViewRequirementAgentConnector_ms": 0.03105342388153076}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.19604317647884, "num_env_steps_trained_throughput_per_sec": 101.19604317647884, "timesteps_total": 140000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 280000, "timers": {"training_iteration_time_ms": 39420.228, "sample_time_ms": 7608.96, "learn_time_ms": 31793.56, "learn_throughput": 125.812, "synch_weights_time_ms": 16.962}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 1573, "training_iteration": 35, "trial_id": "bb874_00000", "date": "2023-09-28_21-53-13", "timestamp": 1695952393, "time_this_iter_s": 39.529921770095825, "time_total_s": 1380.0598948001862, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d27940>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac7564d0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac755870>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1380.0598948001862, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 35.5859649122807, "ram_util_percent": 26.429824561403514}, "win_rate": 0.81, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9064814789841573, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04052585082730123, "policy_loss": -0.027048028499120847, "vf_loss": 0.1326797205915985, "vf_explained_var": 0.26217565648257735, "kl": 0.012759781612599184, "entropy": 1.3179375821103652, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "sampler_results": {"episode_reward_max": 0.42300000000000004, "episode_reward_min": -0.588, "episode_reward_mean": -0.10726999999999996, "episode_len_mean": 54.81, "episode_media": {}, "episodes_this_iter": 73, "policy_reward_min": {"red_0_v1": -1.015, "red_0": -1.02, "blue_0": -1.026}, "policy_reward_max": {"red_0_v1": 1.24, "red_0": 0.982, "blue_0": 1.343}, "policy_reward_mean": {"red_0_v1": -0.4669387755102041, "red_0": 0.49742, "blue_0": -0.7370392156862745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.20900000000000007, -0.5470000000000002, -0.11399999999999999, -0.11899999999999988, -0.06399999999999995, -0.06499999999999995, -0.09799999999999986, -0.05899999999999994, -0.364, -0.07500000000000007, 0.23299999999999998, -0.263, 0.09399999999999986, 0.2290000000000001, -0.03699999999999992, -0.05999999999999994, 0.33899999999999997, -0.4249999999999998, -0.07400000000000007, -0.041999999999999926, -0.18600000000000005, -0.026000000000000023, -0.051999999999999824, -0.04299999999999993, -0.11499999999999988, -0.21199999999999997, -0.019000000000000017, -0.45899999999999985, -0.07499999999999996, -0.05500000000000005, -0.07899999999999996, -0.17999999999999994, -0.03200000000000003, -0.06499999999999984, -0.19600000000000006, -0.31400000000000006, -0.04999999999999993, -0.12, 0.20999999999999996, -0.041999999999999926, -0.04999999999999993, 0.31300000000000006, -0.04500000000000004, -0.256, -0.06399999999999995, -0.15699999999999992, -0.12999999999999978, -0.1359999999999999, -0.08899999999999997, -0.08199999999999985, -0.10899999999999987, -0.07499999999999996, -0.131, -0.030000000000000027, -0.03200000000000003, -0.15400000000000003, -0.11699999999999999, 0.351, -0.018000000000000016, -0.040000000000000036, -0.10299999999999998, -0.31000000000000005, -0.10599999999999987, -0.08299999999999996, -0.03600000000000003, -0.15000000000000002, -0.18900000000000006, 0.13, -0.10499999999999998, -0.03400000000000003, 0.42300000000000004, -0.03700000000000003, -0.121, -0.25, -0.22699999999999987, -0.538, -0.07600000000000007, -0.038999999999999924, -0.13299999999999979, -0.11199999999999988, -0.08899999999999997, -0.5330000000000001, -0.259, -0.588, 0.29899999999999993, -0.07599999999999985, -0.04299999999999993, -0.20899999999999985, -0.24, -0.03699999999999992, -0.21599999999999997, -0.1399999999999999, -0.05999999999999994, -0.11199999999999999, -0.16100000000000003, -0.357, -0.4169999999999999, -0.11199999999999999, -0.20099999999999985, -0.19900000000000007], "episode_lengths": [67, 172, 40, 34, 19, 20, 31, 18, 113, 24, 83, 81, 124, 84, 12, 19, 51, 136, 22, 13, 54, 12, 16, 14, 36, 61, 6, 137, 24, 17, 24, 55, 10, 23, 63, 241, 15, 36, 88, 13, 15, 59, 15, 230, 21, 44, 40, 43, 29, 27, 34, 23, 41, 10, 10, 46, 191, 50, 6, 12, 31, 98, 35, 25, 12, 51, 56, 110, 33, 14, 25, 12, 39, 73, 72, 162, 22, 12, 43, 33, 29, 170, 77, 183, 67, 23, 14, 68, 74, 12, 64, 200, 19, 34, 51, 100, 124, 35, 62, 63], "policy_red_0_v1_reward": [-1.004, -1.001, -1.008, -1.001, -1.003, 0.9269999999999999, -0.509, 1.24, 0.9289999999999999, -1.012, -1.001, -1.002, 0.981, -1.001, -1.002, 0.8019999999999999, -1.002, 0.955, -1.001, -1.003, -1.002, -1.001, -1.003, 0.97, -1.0, -1.0, -1.002, -1.0, -1.0, 0.822, -0.517, -1.003, -0.501, -1.002, -1.013, -1.01, -1.015, -1.003, -1.0019999999999998, 0.912, 0.756, -1.0, -1.008, 0.769, -1.002, -1.005, -1.003, 0.892, 0.8069999999999999], "policy_blue_0_reward": [-1.026, -1.003, -1.005, 0.645, -1.009, 1.1139999999999999, -1.001, -1.002, -0.505, -1.014, -1.001, -1.0, -1.0039999999999998, -1.012, -1.025, -1.003, -1.005, -1.009, -1.003, -0.533, -1.001, -1.011, -0.515, -1.004, -0.5079999999999999, -0.5369999999999999, -1.007, -1.0079999999999998, -1.002, -1.004, -1.009, -0.5289999999999999, 1.343, -1.008, -1.011, -1.002, -1.003, -1.002, 0.964, -1.005, -1.0079999999999998, -1.019, -1.026, -0.505, -1.002, -1.0, 0.799, -0.5169999999999999, -1.014, -1.024, -1.013]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22653869758600675, "mean_inference_ms": 1.4944131163576386, "mean_action_processing_ms": 0.06227266773358877, "mean_env_wait_ms": 0.1047773542755882, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019465088844299316, "StateBufferConnector_ms": 0.001462101936340332, "ViewRequirementAgentConnector_ms": 0.031081676483154297}}, "episode_reward_max": 0.42300000000000004, "episode_reward_min": -0.588, "episode_reward_mean": -0.10726999999999996, "episode_len_mean": 54.81, "episodes_this_iter": 73, "policy_reward_min": {"red_0_v1": -1.015, "red_0": -1.02, "blue_0": -1.026}, "policy_reward_max": {"red_0_v1": 1.24, "red_0": 0.982, "blue_0": 1.343}, "policy_reward_mean": {"red_0_v1": -0.4669387755102041, "red_0": 0.49742, "blue_0": -0.7370392156862745}, "hist_stats": {"episode_reward": [-0.20900000000000007, -0.5470000000000002, -0.11399999999999999, -0.11899999999999988, -0.06399999999999995, -0.06499999999999995, -0.09799999999999986, -0.05899999999999994, -0.364, -0.07500000000000007, 0.23299999999999998, -0.263, 0.09399999999999986, 0.2290000000000001, -0.03699999999999992, -0.05999999999999994, 0.33899999999999997, -0.4249999999999998, -0.07400000000000007, -0.041999999999999926, -0.18600000000000005, -0.026000000000000023, -0.051999999999999824, -0.04299999999999993, -0.11499999999999988, -0.21199999999999997, -0.019000000000000017, -0.45899999999999985, -0.07499999999999996, -0.05500000000000005, -0.07899999999999996, -0.17999999999999994, -0.03200000000000003, -0.06499999999999984, -0.19600000000000006, -0.31400000000000006, -0.04999999999999993, -0.12, 0.20999999999999996, -0.041999999999999926, -0.04999999999999993, 0.31300000000000006, -0.04500000000000004, -0.256, -0.06399999999999995, -0.15699999999999992, -0.12999999999999978, -0.1359999999999999, -0.08899999999999997, -0.08199999999999985, -0.10899999999999987, -0.07499999999999996, -0.131, -0.030000000000000027, -0.03200000000000003, -0.15400000000000003, -0.11699999999999999, 0.351, -0.018000000000000016, -0.040000000000000036, -0.10299999999999998, -0.31000000000000005, -0.10599999999999987, -0.08299999999999996, -0.03600000000000003, -0.15000000000000002, -0.18900000000000006, 0.13, -0.10499999999999998, -0.03400000000000003, 0.42300000000000004, -0.03700000000000003, -0.121, -0.25, -0.22699999999999987, -0.538, -0.07600000000000007, -0.038999999999999924, -0.13299999999999979, -0.11199999999999988, -0.08899999999999997, -0.5330000000000001, -0.259, -0.588, 0.29899999999999993, -0.07599999999999985, -0.04299999999999993, -0.20899999999999985, -0.24, -0.03699999999999992, -0.21599999999999997, -0.1399999999999999, -0.05999999999999994, -0.11199999999999999, -0.16100000000000003, -0.357, -0.4169999999999999, -0.11199999999999999, -0.20099999999999985, -0.19900000000000007], "episode_lengths": [67, 172, 40, 34, 19, 20, 31, 18, 113, 24, 83, 81, 124, 84, 12, 19, 51, 136, 22, 13, 54, 12, 16, 14, 36, 61, 6, 137, 24, 17, 24, 55, 10, 23, 63, 241, 15, 36, 88, 13, 15, 59, 15, 230, 21, 44, 40, 43, 29, 27, 34, 23, 41, 10, 10, 46, 191, 50, 6, 12, 31, 98, 35, 25, 12, 51, 56, 110, 33, 14, 25, 12, 39, 73, 72, 162, 22, 12, 43, 33, 29, 170, 77, 183, 67, 23, 14, 68, 74, 12, 64, 200, 19, 34, 51, 100, 124, 35, 62, 63], "policy_red_0_v1_reward": [-1.004, -1.001, -1.008, -1.001, -1.003, 0.9269999999999999, -0.509, 1.24, 0.9289999999999999, -1.012, -1.001, -1.002, 0.981, -1.001, -1.002, 0.8019999999999999, -1.002, 0.955, -1.001, -1.003, -1.002, -1.001, -1.003, 0.97, -1.0, -1.0, -1.002, -1.0, -1.0, 0.822, -0.517, -1.003, -0.501, -1.002, -1.013, -1.01, -1.015, -1.003, -1.0019999999999998, 0.912, 0.756, -1.0, -1.008, 0.769, -1.002, -1.005, -1.003, 0.892, 0.8069999999999999], "policy_blue_0_reward": [-1.026, -1.003, -1.005, 0.645, -1.009, 1.1139999999999999, -1.001, -1.002, -0.505, -1.014, -1.001, -1.0, -1.0039999999999998, -1.012, -1.025, -1.003, -1.005, -1.009, -1.003, -0.533, -1.001, -1.011, -0.515, -1.004, -0.5079999999999999, -0.5369999999999999, -1.007, -1.0079999999999998, -1.002, -1.004, -1.009, -0.5289999999999999, 1.343, -1.008, -1.011, -1.002, -1.003, -1.002, 0.964, -1.005, -1.0079999999999998, -1.019, -1.026, -0.505, -1.002, -1.0, 0.799, -0.5169999999999999, -1.014, -1.024, -1.013]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22653869758600675, "mean_inference_ms": 1.4944131163576386, "mean_action_processing_ms": 0.06227266773358877, "mean_env_wait_ms": 0.1047773542755882, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019465088844299316, "StateBufferConnector_ms": 0.001462101936340332, "ViewRequirementAgentConnector_ms": 0.031081676483154297}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.01658166154397, "num_env_steps_trained_throughput_per_sec": 102.01658166154397, "timesteps_total": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 39392.866, "sample_time_ms": 7610.267, "learn_time_ms": 31764.954, "learn_throughput": 125.925, "synch_weights_time_ms": 16.91}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "episodes_total": 1646, "training_iteration": 36, "trial_id": "bb874_00000", "date": "2023-09-28_21-53-52", "timestamp": 1695952432, "time_this_iter_s": 39.21193599700928, "time_total_s": 1419.2718307971954, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f33190>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac755900>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac754e50>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1419.2718307971954, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 35.152727272727276, "ram_util_percent": 26.350909090909095}, "win_rate": 0.82, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.036477288976312, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06132117946605528, "policy_loss": -0.025230064406059682, "vf_loss": 0.170427877176553, "vf_explained_var": 0.17428019599368175, "kl": 0.013254693660645484, "entropy": 1.3136331602931022, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "sampler_results": {"episode_reward_max": 0.42799999999999994, "episode_reward_min": -0.6789999999999999, "episode_reward_mean": -0.10573999999999999, "episode_len_mean": 59.53, "episode_media": {}, "episodes_this_iter": 71, "policy_reward_min": {"blue_0": -1.03, "red_0": -1.02, "red_0_v1": -1.026}, "policy_reward_max": {"blue_0": 0.964, "red_0": 0.982, "red_0_v1": 1.429}, "policy_reward_mean": {"blue_0": -0.663304347826087, "red_0": 0.38293999999999995, "red_0_v1": -0.3399259259259259}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.03700000000000003, -0.121, -0.25, -0.22699999999999987, -0.538, -0.07600000000000007, -0.038999999999999924, -0.13299999999999979, -0.11199999999999988, -0.08899999999999997, -0.5330000000000001, -0.259, -0.588, 0.29899999999999993, -0.07599999999999985, -0.04299999999999993, -0.20899999999999985, -0.24, -0.03699999999999992, -0.21599999999999997, -0.1399999999999999, -0.05999999999999994, -0.11199999999999999, -0.16100000000000003, -0.357, -0.4169999999999999, -0.11199999999999999, -0.20099999999999985, -0.19900000000000007, -0.18300000000000005, -0.07699999999999996, -0.122, -0.20200000000000007, -0.30699999999999994, -0.07600000000000007, -0.17800000000000005, -0.06799999999999995, -0.05800000000000005, -0.05500000000000005, -0.1269999999999999, -0.32499999999999996, -0.06900000000000006, 0.35199999999999987, -0.07700000000000007, 0.24199999999999988, -0.018000000000000016, -0.07200000000000005, -0.06700000000000006, -0.11099999999999999, -0.029000000000000026, -0.10899999999999999, -0.17299999999999993, -0.257, -0.22399999999999998, 0.42799999999999994, -0.12799999999999978, -0.1329999999999999, 0.267, -0.06800000000000006, -0.08999999999999986, -0.051999999999999935, -0.04499999999999993, -0.03500000000000003, -0.17599999999999993, -0.43900000000000006, 0.42600000000000005, 0.03399999999999992, 0.40900000000000003, -0.04200000000000004, -0.24599999999999977, -0.08499999999999996, -0.06899999999999995, 0.3689999999999999, 0.386, -0.18700000000000006, -0.1499999999999999, -0.6789999999999999, -0.06999999999999995, -0.10799999999999987, -0.031000000000000028, -0.03300000000000003, -0.118, -0.14900000000000002, 0.242, -0.17199999999999993, -0.02400000000000002, -0.1359999999999999, -0.02100000000000002, -0.492, -0.039000000000000035, -0.040000000000000036, -0.08799999999999997, -0.19899999999999984, -0.19199999999999995, -0.17199999999999993, -0.132, -0.06299999999999994, -0.08999999999999997, -0.17600000000000005, -0.29300000000000004], "episode_lengths": [12, 39, 73, 72, 162, 22, 12, 43, 33, 29, 170, 77, 183, 67, 23, 14, 68, 74, 12, 64, 200, 19, 34, 51, 100, 124, 35, 62, 63, 208, 28, 38, 63, 98, 24, 51, 21, 17, 17, 42, 100, 21, 43, 24, 73, 6, 300, 21, 36, 9, 31, 56, 75, 72, 23, 42, 40, 72, 20, 27, 17, 12, 11, 218, 135, 23, 140, 30, 14, 70, 24, 22, 300, 34, 59, 47, 196, 25, 35, 10, 11, 38, 41, 81, 53, 8, 43, 7, 156, 12, 12, 28, 64, 62, 55, 42, 18, 30, 50, 85], "policy_blue_0_reward": [0.964, -1.005, -1.0079999999999998, -1.019, -1.026, -0.505, -1.002, -1.0, 0.799, -0.5169999999999999, -1.014, -1.024, -1.013, -0.53, -1.001, -1.007, 0.7999999999999999, -1.012, -1.001, -1.004, 0.943, -1.001, -1.014, 0.9319999999999999, -0.512, -0.05200000000000004, -1.001, -1.01, -1.007, -1.008, -0.512, -1.004, -1.005, -1.001, -1.002, -0.502, -0.516, -1.0139999999999998, 0.46399999999999997, -0.507, -1.03, -1.007, -1.0, -1.016, -1.003, -1.002], "policy_red_0_v1_reward": [-1.002, -1.013, -1.01, -1.015, -1.003, -1.0019999999999998, 0.912, 0.756, -1.0, -1.008, 0.769, -1.002, -1.005, -1.003, 0.892, 0.8069999999999999, 0.84, -1.0, 1.362, 0.9259999999999999, -1.0, 0.891, -1.001, -1.009, -1.016, -1.003, 1.429, -1.006, -0.5039999999999999, 0.581, 1.4100000000000001, -1.0, -1.009, -1.001, 0.818, -1.006, -1.002, -1.0, 0.969, -1.0, -1.001, 0.87, 1.251, -1.0, -1.002, 0.961, -1.0, -1.004, -1.002, -1.004, 0.865, -1.0, -1.006, -1.026]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22675328582889487, "mean_inference_ms": 1.495031006575627, "mean_action_processing_ms": 0.0622773236104834, "mean_env_wait_ms": 0.10481928592382139, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01916193962097168, "StateBufferConnector_ms": 0.0014717578887939453, "ViewRequirementAgentConnector_ms": 0.03085184097290039}}, "episode_reward_max": 0.42799999999999994, "episode_reward_min": -0.6789999999999999, "episode_reward_mean": -0.10573999999999999, "episode_len_mean": 59.53, "episodes_this_iter": 71, "policy_reward_min": {"blue_0": -1.03, "red_0": -1.02, "red_0_v1": -1.026}, "policy_reward_max": {"blue_0": 0.964, "red_0": 0.982, "red_0_v1": 1.429}, "policy_reward_mean": {"blue_0": -0.663304347826087, "red_0": 0.38293999999999995, "red_0_v1": -0.3399259259259259}, "hist_stats": {"episode_reward": [-0.03700000000000003, -0.121, -0.25, -0.22699999999999987, -0.538, -0.07600000000000007, -0.038999999999999924, -0.13299999999999979, -0.11199999999999988, -0.08899999999999997, -0.5330000000000001, -0.259, -0.588, 0.29899999999999993, -0.07599999999999985, -0.04299999999999993, -0.20899999999999985, -0.24, -0.03699999999999992, -0.21599999999999997, -0.1399999999999999, -0.05999999999999994, -0.11199999999999999, -0.16100000000000003, -0.357, -0.4169999999999999, -0.11199999999999999, -0.20099999999999985, -0.19900000000000007, -0.18300000000000005, -0.07699999999999996, -0.122, -0.20200000000000007, -0.30699999999999994, -0.07600000000000007, -0.17800000000000005, -0.06799999999999995, -0.05800000000000005, -0.05500000000000005, -0.1269999999999999, -0.32499999999999996, -0.06900000000000006, 0.35199999999999987, -0.07700000000000007, 0.24199999999999988, -0.018000000000000016, -0.07200000000000005, -0.06700000000000006, -0.11099999999999999, -0.029000000000000026, -0.10899999999999999, -0.17299999999999993, -0.257, -0.22399999999999998, 0.42799999999999994, -0.12799999999999978, -0.1329999999999999, 0.267, -0.06800000000000006, -0.08999999999999986, -0.051999999999999935, -0.04499999999999993, -0.03500000000000003, -0.17599999999999993, -0.43900000000000006, 0.42600000000000005, 0.03399999999999992, 0.40900000000000003, -0.04200000000000004, -0.24599999999999977, -0.08499999999999996, -0.06899999999999995, 0.3689999999999999, 0.386, -0.18700000000000006, -0.1499999999999999, -0.6789999999999999, -0.06999999999999995, -0.10799999999999987, -0.031000000000000028, -0.03300000000000003, -0.118, -0.14900000000000002, 0.242, -0.17199999999999993, -0.02400000000000002, -0.1359999999999999, -0.02100000000000002, -0.492, -0.039000000000000035, -0.040000000000000036, -0.08799999999999997, -0.19899999999999984, -0.19199999999999995, -0.17199999999999993, -0.132, -0.06299999999999994, -0.08999999999999997, -0.17600000000000005, -0.29300000000000004], "episode_lengths": [12, 39, 73, 72, 162, 22, 12, 43, 33, 29, 170, 77, 183, 67, 23, 14, 68, 74, 12, 64, 200, 19, 34, 51, 100, 124, 35, 62, 63, 208, 28, 38, 63, 98, 24, 51, 21, 17, 17, 42, 100, 21, 43, 24, 73, 6, 300, 21, 36, 9, 31, 56, 75, 72, 23, 42, 40, 72, 20, 27, 17, 12, 11, 218, 135, 23, 140, 30, 14, 70, 24, 22, 300, 34, 59, 47, 196, 25, 35, 10, 11, 38, 41, 81, 53, 8, 43, 7, 156, 12, 12, 28, 64, 62, 55, 42, 18, 30, 50, 85], "policy_blue_0_reward": [0.964, -1.005, -1.0079999999999998, -1.019, -1.026, -0.505, -1.002, -1.0, 0.799, -0.5169999999999999, -1.014, -1.024, -1.013, -0.53, -1.001, -1.007, 0.7999999999999999, -1.012, -1.001, -1.004, 0.943, -1.001, -1.014, 0.9319999999999999, -0.512, -0.05200000000000004, -1.001, -1.01, -1.007, -1.008, -0.512, -1.004, -1.005, -1.001, -1.002, -0.502, -0.516, -1.0139999999999998, 0.46399999999999997, -0.507, -1.03, -1.007, -1.0, -1.016, -1.003, -1.002], "policy_red_0_v1_reward": [-1.002, -1.013, -1.01, -1.015, -1.003, -1.0019999999999998, 0.912, 0.756, -1.0, -1.008, 0.769, -1.002, -1.005, -1.003, 0.892, 0.8069999999999999, 0.84, -1.0, 1.362, 0.9259999999999999, -1.0, 0.891, -1.001, -1.009, -1.016, -1.003, 1.429, -1.006, -0.5039999999999999, 0.581, 1.4100000000000001, -1.0, -1.009, -1.001, 0.818, -1.006, -1.002, -1.0, 0.969, -1.0, -1.001, 0.87, 1.251, -1.0, -1.002, 0.961, -1.0, -1.004, -1.002, -1.004, 0.865, -1.0, -1.006, -1.026]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22675328582889487, "mean_inference_ms": 1.495031006575627, "mean_action_processing_ms": 0.0622773236104834, "mean_env_wait_ms": 0.10481928592382139, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01916193962097168, "StateBufferConnector_ms": 0.0014717578887939453, "ViewRequirementAgentConnector_ms": 0.03085184097290039}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.91986933041045, "num_env_steps_trained_throughput_per_sec": 101.91986933041045, "timesteps_total": 148000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 296000, "timers": {"training_iteration_time_ms": 39363.395, "sample_time_ms": 7596.145, "learn_time_ms": 31749.561, "learn_throughput": 125.986, "synch_weights_time_ms": 16.949}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "done": false, "episodes_total": 1717, "training_iteration": 37, "trial_id": "bb874_00000", "date": "2023-09-28_21-54-31", "timestamp": 1695952471, "time_this_iter_s": 39.2491340637207, "time_total_s": 1458.5209648609161, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4fcacb0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4de710>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dcc10>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1458.5209648609161, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 34.566071428571426, "ram_util_percent": 26.435714285714287}, "win_rate": 0.76, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.051541205743949, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06025698031238183, "policy_loss": -0.02633194546603287, "vf_loss": 0.170352053293027, "vf_explained_var": 0.25487438701093196, "kl": 0.013538932512555498, "entropy": 1.2948871909330288, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "sampler_results": {"episode_reward_max": 0.44399999999999995, "episode_reward_min": -0.7150000000000002, "episode_reward_mean": -0.09795999999999998, "episode_len_mean": 45.24, "episode_media": {}, "episodes_this_iter": 92, "policy_reward_min": {"red_0_v1": -1.026, "red_0": -1.0219999999999998, "blue_0": -1.022}, "policy_reward_max": {"red_0_v1": 0.978, "red_0": 0.976, "blue_0": 0.959}, "policy_reward_mean": {"red_0_v1": -0.43996153846153846, "red_0": 0.51685, "blue_0": -0.8042291666666666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19899999999999984, -0.19199999999999995, -0.17199999999999993, -0.132, -0.06299999999999994, -0.08999999999999997, -0.17600000000000005, -0.29300000000000004, -0.062000000000000055, 0.44399999999999995, -0.10299999999999987, -0.647, -0.10799999999999998, -0.038999999999999924, -0.07599999999999985, -0.08199999999999996, -0.04999999999999993, -0.10199999999999998, -0.06800000000000006, -0.02200000000000002, -0.06600000000000006, -0.07899999999999996, -0.05899999999999994, 0.27400000000000013, -0.3360000000000001, -0.1469999999999999, -0.22499999999999987, 0.10099999999999998, -0.33199999999999985, -0.03799999999999992, -0.15500000000000003, -0.127, -0.07400000000000007, -0.07699999999999996, 0.43499999999999994, -0.21099999999999985, -0.5820000000000001, -0.10899999999999999, -0.09899999999999975, -0.124, -0.32700000000000007, -0.10199999999999998, 0.22999999999999998, -0.7150000000000002, -0.08799999999999997, -0.05499999999999994, 0.43799999999999994, -0.17400000000000004, -0.12, -0.06299999999999994, -0.04999999999999993, -0.17699999999999994, -0.038000000000000034, -0.29300000000000004, -0.09099999999999986, -0.08299999999999996, -0.10499999999999998, -0.07899999999999996, -0.09499999999999986, -0.05900000000000005, -0.06900000000000006, -0.06699999999999984, -0.05899999999999994, -0.09399999999999997, -0.07299999999999995, -0.2609999999999999, -0.2509999999999999, -0.10699999999999987, -0.132, -0.1439999999999999, -0.05899999999999983, -0.06900000000000006, -0.17099999999999993, -0.050000000000000044, -0.46599999999999997, 0.241, -0.12, -0.061000000000000054, -0.05800000000000005, -0.039999999999999925, -0.07699999999999996, -0.07899999999999996, -0.04700000000000004, -0.15600000000000003, -0.135, -0.02400000000000002, -0.05700000000000005, -0.15300000000000002, -0.08799999999999997, -0.07999999999999996, -0.10799999999999998, -0.038999999999999924, -0.04599999999999993, -0.11399999999999999, -0.514, -0.027999999999999914, 0.10199999999999998, 0.42700000000000005, -0.04600000000000004, -0.11599999999999999], "episode_lengths": [64, 62, 55, 42, 18, 30, 50, 85, 18, 17, 34, 207, 31, 12, 23, 29, 15, 31, 19, 7, 20, 24, 18, 66, 100, 42, 70, 123, 95, 11, 47, 38, 24, 27, 21, 66, 178, 33, 31, 42, 245, 35, 80, 201, 28, 20, 19, 52, 38, 20, 15, 54, 12, 93, 30, 27, 31, 25, 30, 19, 19, 21, 18, 30, 22, 78, 78, 34, 42, 45, 17, 22, 49, 16, 137, 80, 38, 19, 18, 13, 26, 21, 13, 46, 39, 8, 17, 49, 32, 25, 35, 12, 15, 36, 153, 9, 122, 23, 14, 34], "policy_red_0_v1_reward": [-1.004, -1.002, -1.004, 0.865, -1.0, -1.006, -1.026, -1.0, -1.01, 0.899, -1.003, 0.904, 0.9349999999999999, 0.978, 0.9359999999999999, -1.009, -1.008, -1.015, -1.003, 0.854, 0.878, -1.0, -1.002, -0.5, -1.0039999999999998, -1.002, -1.009, -1.006, -1.002, -1.001, -1.001, -1.001, -1.001, -1.002, 0.9339999999999999, -1.004, -1.01, 0.9339999999999999, 0.842, -1.002, 0.5559999999999999, -1.002, -1.0, 0.9329999999999999, -1.0, -1.002, -1.001, 0.922, 0.895, -1.0, -1.0, -0.501], "policy_blue_0_reward": [-1.002, -1.004, -0.501, -1.002, -1.005, -1.004, -1.005, -1.005, -0.5099999999999999, -1.022, -0.518, -1.007, -1.02, -1.002, -1.005, -0.545, -1.004, -0.511, -1.022, -1.003, -0.503, -1.0039999999999998, -1.008, -1.001, -1.005, -1.002, -1.003, -1.002, -1.004, -1.0119999999999998, -1.005, -1.002, -1.004, -1.003, -0.512, -1.003, -1.001, -1.004, 0.959, -1.004, 0.877, -1.001, -1.002, 0.889, -1.02, -0.519, -1.001, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22690273655924964, "mean_inference_ms": 1.4939441992788232, "mean_action_processing_ms": 0.06225447462999068, "mean_env_wait_ms": 0.10487408829314596, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019108295440673828, "StateBufferConnector_ms": 0.0014799833297729492, "ViewRequirementAgentConnector_ms": 0.03090381622314453}}, "episode_reward_max": 0.44399999999999995, "episode_reward_min": -0.7150000000000002, "episode_reward_mean": -0.09795999999999998, "episode_len_mean": 45.24, "episodes_this_iter": 92, "policy_reward_min": {"red_0_v1": -1.026, "red_0": -1.0219999999999998, "blue_0": -1.022}, "policy_reward_max": {"red_0_v1": 0.978, "red_0": 0.976, "blue_0": 0.959}, "policy_reward_mean": {"red_0_v1": -0.43996153846153846, "red_0": 0.51685, "blue_0": -0.8042291666666666}, "hist_stats": {"episode_reward": [-0.19899999999999984, -0.19199999999999995, -0.17199999999999993, -0.132, -0.06299999999999994, -0.08999999999999997, -0.17600000000000005, -0.29300000000000004, -0.062000000000000055, 0.44399999999999995, -0.10299999999999987, -0.647, -0.10799999999999998, -0.038999999999999924, -0.07599999999999985, -0.08199999999999996, -0.04999999999999993, -0.10199999999999998, -0.06800000000000006, -0.02200000000000002, -0.06600000000000006, -0.07899999999999996, -0.05899999999999994, 0.27400000000000013, -0.3360000000000001, -0.1469999999999999, -0.22499999999999987, 0.10099999999999998, -0.33199999999999985, -0.03799999999999992, -0.15500000000000003, -0.127, -0.07400000000000007, -0.07699999999999996, 0.43499999999999994, -0.21099999999999985, -0.5820000000000001, -0.10899999999999999, -0.09899999999999975, -0.124, -0.32700000000000007, -0.10199999999999998, 0.22999999999999998, -0.7150000000000002, -0.08799999999999997, -0.05499999999999994, 0.43799999999999994, -0.17400000000000004, -0.12, -0.06299999999999994, -0.04999999999999993, -0.17699999999999994, -0.038000000000000034, -0.29300000000000004, -0.09099999999999986, -0.08299999999999996, -0.10499999999999998, -0.07899999999999996, -0.09499999999999986, -0.05900000000000005, -0.06900000000000006, -0.06699999999999984, -0.05899999999999994, -0.09399999999999997, -0.07299999999999995, -0.2609999999999999, -0.2509999999999999, -0.10699999999999987, -0.132, -0.1439999999999999, -0.05899999999999983, -0.06900000000000006, -0.17099999999999993, -0.050000000000000044, -0.46599999999999997, 0.241, -0.12, -0.061000000000000054, -0.05800000000000005, -0.039999999999999925, -0.07699999999999996, -0.07899999999999996, -0.04700000000000004, -0.15600000000000003, -0.135, -0.02400000000000002, -0.05700000000000005, -0.15300000000000002, -0.08799999999999997, -0.07999999999999996, -0.10799999999999998, -0.038999999999999924, -0.04599999999999993, -0.11399999999999999, -0.514, -0.027999999999999914, 0.10199999999999998, 0.42700000000000005, -0.04600000000000004, -0.11599999999999999], "episode_lengths": [64, 62, 55, 42, 18, 30, 50, 85, 18, 17, 34, 207, 31, 12, 23, 29, 15, 31, 19, 7, 20, 24, 18, 66, 100, 42, 70, 123, 95, 11, 47, 38, 24, 27, 21, 66, 178, 33, 31, 42, 245, 35, 80, 201, 28, 20, 19, 52, 38, 20, 15, 54, 12, 93, 30, 27, 31, 25, 30, 19, 19, 21, 18, 30, 22, 78, 78, 34, 42, 45, 17, 22, 49, 16, 137, 80, 38, 19, 18, 13, 26, 21, 13, 46, 39, 8, 17, 49, 32, 25, 35, 12, 15, 36, 153, 9, 122, 23, 14, 34], "policy_red_0_v1_reward": [-1.004, -1.002, -1.004, 0.865, -1.0, -1.006, -1.026, -1.0, -1.01, 0.899, -1.003, 0.904, 0.9349999999999999, 0.978, 0.9359999999999999, -1.009, -1.008, -1.015, -1.003, 0.854, 0.878, -1.0, -1.002, -0.5, -1.0039999999999998, -1.002, -1.009, -1.006, -1.002, -1.001, -1.001, -1.001, -1.001, -1.002, 0.9339999999999999, -1.004, -1.01, 0.9339999999999999, 0.842, -1.002, 0.5559999999999999, -1.002, -1.0, 0.9329999999999999, -1.0, -1.002, -1.001, 0.922, 0.895, -1.0, -1.0, -0.501], "policy_blue_0_reward": [-1.002, -1.004, -0.501, -1.002, -1.005, -1.004, -1.005, -1.005, -0.5099999999999999, -1.022, -0.518, -1.007, -1.02, -1.002, -1.005, -0.545, -1.004, -0.511, -1.022, -1.003, -0.503, -1.0039999999999998, -1.008, -1.001, -1.005, -1.002, -1.003, -1.002, -1.004, -1.0119999999999998, -1.005, -1.002, -1.004, -1.003, -0.512, -1.003, -1.001, -1.004, 0.959, -1.004, 0.877, -1.001, -1.002, 0.889, -1.02, -0.519, -1.001, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22690273655924964, "mean_inference_ms": 1.4939441992788232, "mean_action_processing_ms": 0.06225447462999068, "mean_env_wait_ms": 0.10487408829314596, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019108295440673828, "StateBufferConnector_ms": 0.0014799833297729492, "ViewRequirementAgentConnector_ms": 0.03090381622314453}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.5852735813262, "num_env_steps_trained_throughput_per_sec": 101.5852735813262, "timesteps_total": 152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 39368.249, "sample_time_ms": 7592.165, "learn_time_ms": 31758.396, "learn_throughput": 125.951, "synch_weights_time_ms": 16.914}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "episodes_total": 1809, "training_iteration": 38, "trial_id": "bb874_00000", "date": "2023-09-28_21-55-11", "timestamp": 1695952511, "time_this_iter_s": 39.37861728668213, "time_total_s": 1497.8995821475983, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x352fd0040>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac405000>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac406710>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1497.8995821475983, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 34.05535714285714, "ram_util_percent": 26.433928571428574}, "win_rate": 0.82, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0548655172189076, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07690982062146455, "policy_loss": -0.022749960106739308, "vf_loss": 0.19701897900085896, "vf_explained_var": 0.1586997087424, "kl": 0.012260381876124165, "entropy": 1.3017846655100584, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "sampler_results": {"episode_reward_max": 0.44999999999999996, "episode_reward_min": -0.5089999999999999, "episode_reward_mean": -0.08468999999999997, "episode_len_mean": 40.02, "episode_media": {}, "episodes_this_iter": 96, "policy_reward_min": {"blue_0": -1.0159999999999998, "red_0": -1.018, "red_0_v1": -1.018}, "policy_reward_max": {"blue_0": -0.503, "red_0": 0.98, "red_0_v1": 1.324}, "policy_reward_mean": {"blue_0": -0.9652599999999998, "red_0": 0.5949500000000001, "red_0_v1": -0.3940199999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.10199999999999998, 0.42700000000000005, -0.04600000000000004, -0.11599999999999999, -0.23199999999999976, -0.050999999999999934, -0.09399999999999986, -0.30800000000000005, -0.17899999999999994, 0.387, -0.264, -0.127, -0.21299999999999997, -0.06699999999999995, -0.06699999999999995, -0.09099999999999997, -0.121, -0.5089999999999999, 0.19899999999999995, -0.05899999999999994, -0.050999999999999934, -0.11699999999999999, -0.03300000000000003, -0.1409999999999999, -0.06500000000000006, -0.04600000000000004, -0.07600000000000007, -0.19999999999999996, 0.44999999999999996, -0.07199999999999995, -0.20800000000000018, -0.29799999999999993, -0.243, -0.32600000000000007, -0.07699999999999996, -0.06299999999999994, -0.30200000000000005, -0.08099999999999996, -0.04899999999999982, -0.09099999999999986, -0.19400000000000006, -0.04200000000000004, -0.08799999999999997, -0.11199999999999999, -0.121, -0.08299999999999985, 0.31499999999999995, -0.18999999999999995, -0.03200000000000003, -0.18199999999999994, -0.20000000000000007, -0.07200000000000006, -0.132, -0.08199999999999996, -0.11299999999999999, -0.11799999999999988, -0.02300000000000002, -0.15900000000000003, -0.09999999999999987, -0.09299999999999986, -0.16899999999999993, -0.052000000000000046, -0.038999999999999924, -0.09099999999999997, -0.050000000000000044, -0.06599999999999995, -0.18999999999999995, -0.03500000000000003, -0.09399999999999997, -0.04200000000000004, -0.10699999999999998, -0.1289999999999999, -0.17900000000000005, -0.05999999999999994, -0.24499999999999988, -0.122, -0.08899999999999997, -0.07099999999999995, -0.06699999999999995, -0.126, 0.22399999999999998, -0.030999999999999917, 0.44799999999999995, -0.11299999999999999, -0.10399999999999998, -0.36099999999999977, -0.07399999999999984, -0.122, -0.07399999999999984, -0.11899999999999988, -0.030999999999999917, -0.03500000000000003, 0.32199999999999995, -0.07000000000000006, -0.03399999999999992, -0.22299999999999998, -0.18899999999999983, -0.262, -0.07399999999999984, -0.18500000000000016], "episode_lengths": [122, 23, 14, 34, 68, 16, 29, 98, 54, 37, 82, 41, 66, 22, 20, 29, 39, 156, 89, 18, 16, 35, 11, 40, 21, 15, 25, 64, 15, 24, 63, 87, 75, 102, 23, 20, 92, 23, 15, 26, 56, 13, 28, 34, 35, 26, 58, 63, 10, 55, 60, 22, 42, 26, 35, 37, 10, 53, 31, 28, 52, 16, 12, 31, 16, 21, 59, 14, 30, 16, 33, 40, 52, 19, 70, 35, 27, 23, 20, 39, 81, 10, 16, 35, 34, 111, 23, 36, 23, 38, 10, 11, 54, 22, 11, 70, 58, 80, 23, 60], "policy_blue_0_reward": [-0.519, -1.001, -1.006, -1.01, -0.503, -1.008, -1.001, -1.002, -1.002, -0.507, -1.005, -1.003, -1.0019999999999998, -1.0159999999999998, -1.015, -1.006, -1.005, -1.003, -1.002, -1.006, -1.001, -1.006, -1.013, -1.002, -1.004, -1.002, -1.005, -1.002, -1.003, -1.005, -1.007, -1.002, -1.009, -1.0, -1.004, -1.007, -1.001, -1.006, -1.001, -1.013, -1.005, -1.0019999999999998, -1.004, -1.001, -0.509, -1.004, -1.001, -1.01, -1.003, -1.009], "policy_red_0_v1_reward": [-0.501, -1.009, -1.002, -1.0, -1.002, 0.875, 0.796, 0.881, -1.018, 0.894, -1.0, -1.0079999999999998, -1.0, 0.955, -1.005, -1.004, -0.5, -1.012, -1.004, -1.002, 0.716, -1.007, -1.013, 0.958, 0.892, -1.003, 1.324, -1.004, -1.003, -1.003, -1.004, -1.002, -1.0019999999999998, -1.0, 0.907, -1.005, 0.83, -1.001, -1.009, 0.887, -1.005, 0.882, -0.518, -0.501, 0.891, -1.0, -1.009, -1.001, 0.783, -1.015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22697403675399813, "mean_inference_ms": 1.493457412833085, "mean_action_processing_ms": 0.06222820323008174, "mean_env_wait_ms": 0.10486202962068532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019001007080078125, "StateBufferConnector_ms": 0.001433253288269043, "ViewRequirementAgentConnector_ms": 0.030900955200195312}}, "episode_reward_max": 0.44999999999999996, "episode_reward_min": -0.5089999999999999, "episode_reward_mean": -0.08468999999999997, "episode_len_mean": 40.02, "episodes_this_iter": 96, "policy_reward_min": {"blue_0": -1.0159999999999998, "red_0": -1.018, "red_0_v1": -1.018}, "policy_reward_max": {"blue_0": -0.503, "red_0": 0.98, "red_0_v1": 1.324}, "policy_reward_mean": {"blue_0": -0.9652599999999998, "red_0": 0.5949500000000001, "red_0_v1": -0.3940199999999999}, "hist_stats": {"episode_reward": [0.10199999999999998, 0.42700000000000005, -0.04600000000000004, -0.11599999999999999, -0.23199999999999976, -0.050999999999999934, -0.09399999999999986, -0.30800000000000005, -0.17899999999999994, 0.387, -0.264, -0.127, -0.21299999999999997, -0.06699999999999995, -0.06699999999999995, -0.09099999999999997, -0.121, -0.5089999999999999, 0.19899999999999995, -0.05899999999999994, -0.050999999999999934, -0.11699999999999999, -0.03300000000000003, -0.1409999999999999, -0.06500000000000006, -0.04600000000000004, -0.07600000000000007, -0.19999999999999996, 0.44999999999999996, -0.07199999999999995, -0.20800000000000018, -0.29799999999999993, -0.243, -0.32600000000000007, -0.07699999999999996, -0.06299999999999994, -0.30200000000000005, -0.08099999999999996, -0.04899999999999982, -0.09099999999999986, -0.19400000000000006, -0.04200000000000004, -0.08799999999999997, -0.11199999999999999, -0.121, -0.08299999999999985, 0.31499999999999995, -0.18999999999999995, -0.03200000000000003, -0.18199999999999994, -0.20000000000000007, -0.07200000000000006, -0.132, -0.08199999999999996, -0.11299999999999999, -0.11799999999999988, -0.02300000000000002, -0.15900000000000003, -0.09999999999999987, -0.09299999999999986, -0.16899999999999993, -0.052000000000000046, -0.038999999999999924, -0.09099999999999997, -0.050000000000000044, -0.06599999999999995, -0.18999999999999995, -0.03500000000000003, -0.09399999999999997, -0.04200000000000004, -0.10699999999999998, -0.1289999999999999, -0.17900000000000005, -0.05999999999999994, -0.24499999999999988, -0.122, -0.08899999999999997, -0.07099999999999995, -0.06699999999999995, -0.126, 0.22399999999999998, -0.030999999999999917, 0.44799999999999995, -0.11299999999999999, -0.10399999999999998, -0.36099999999999977, -0.07399999999999984, -0.122, -0.07399999999999984, -0.11899999999999988, -0.030999999999999917, -0.03500000000000003, 0.32199999999999995, -0.07000000000000006, -0.03399999999999992, -0.22299999999999998, -0.18899999999999983, -0.262, -0.07399999999999984, -0.18500000000000016], "episode_lengths": [122, 23, 14, 34, 68, 16, 29, 98, 54, 37, 82, 41, 66, 22, 20, 29, 39, 156, 89, 18, 16, 35, 11, 40, 21, 15, 25, 64, 15, 24, 63, 87, 75, 102, 23, 20, 92, 23, 15, 26, 56, 13, 28, 34, 35, 26, 58, 63, 10, 55, 60, 22, 42, 26, 35, 37, 10, 53, 31, 28, 52, 16, 12, 31, 16, 21, 59, 14, 30, 16, 33, 40, 52, 19, 70, 35, 27, 23, 20, 39, 81, 10, 16, 35, 34, 111, 23, 36, 23, 38, 10, 11, 54, 22, 11, 70, 58, 80, 23, 60], "policy_blue_0_reward": [-0.519, -1.001, -1.006, -1.01, -0.503, -1.008, -1.001, -1.002, -1.002, -0.507, -1.005, -1.003, -1.0019999999999998, -1.0159999999999998, -1.015, -1.006, -1.005, -1.003, -1.002, -1.006, -1.001, -1.006, -1.013, -1.002, -1.004, -1.002, -1.005, -1.002, -1.003, -1.005, -1.007, -1.002, -1.009, -1.0, -1.004, -1.007, -1.001, -1.006, -1.001, -1.013, -1.005, -1.0019999999999998, -1.004, -1.001, -0.509, -1.004, -1.001, -1.01, -1.003, -1.009], "policy_red_0_v1_reward": [-0.501, -1.009, -1.002, -1.0, -1.002, 0.875, 0.796, 0.881, -1.018, 0.894, -1.0, -1.0079999999999998, -1.0, 0.955, -1.005, -1.004, -0.5, -1.012, -1.004, -1.002, 0.716, -1.007, -1.013, 0.958, 0.892, -1.003, 1.324, -1.004, -1.003, -1.003, -1.004, -1.002, -1.0019999999999998, -1.0, 0.907, -1.005, 0.83, -1.001, -1.009, 0.887, -1.005, 0.882, -0.518, -0.501, 0.891, -1.0, -1.009, -1.001, 0.783, -1.015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22697403675399813, "mean_inference_ms": 1.493457412833085, "mean_action_processing_ms": 0.06222820323008174, "mean_env_wait_ms": 0.10486202962068532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019001007080078125, "StateBufferConnector_ms": 0.001433253288269043, "ViewRequirementAgentConnector_ms": 0.030900955200195312}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.55159665660881, "num_env_steps_trained_throughput_per_sec": 101.55159665660881, "timesteps_total": 156000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 312000, "timers": {"training_iteration_time_ms": 39365.615, "sample_time_ms": 7604.546, "learn_time_ms": 31743.431, "learn_throughput": 126.01, "synch_weights_time_ms": 16.86}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "done": false, "episodes_total": 1905, "training_iteration": 39, "trial_id": "bb874_00000", "date": "2023-09-28_21-55-50", "timestamp": 1695952550, "time_this_iter_s": 39.39178776741028, "time_total_s": 1537.2913699150085, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d5f9d0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4de9e0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dc160>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1537.2913699150085, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 36.41250000000001, "ram_util_percent": 26.526785714285715}, "win_rate": 0.85, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1577630205700795, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.08796244180381715, "policy_loss": -0.02427085809855877, "vf_loss": 0.2215466181281954, "vf_explained_var": 0.08911334878454606, "kl": 0.013640280855168632, "entropy": 1.2680655611058076, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "sampler_results": {"episode_reward_max": 0.874, "episode_reward_min": -0.649, "episode_reward_mean": -0.09311999999999998, "episode_len_mean": 45.72, "episode_media": {}, "episodes_this_iter": 85, "policy_reward_min": {"blue_0": -1.018, "red_0": -1.0519999999999998, "red_0_v1": -1.016}, "policy_reward_max": {"blue_0": 1.05, "red_0": 0.979, "red_0_v1": 0.978}, "policy_reward_mean": {"blue_0": -0.6395599999999999, "red_0": 0.37746, "red_0_v1": -0.3016}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.36099999999999977, -0.07399999999999984, -0.122, -0.07399999999999984, -0.11899999999999988, -0.030999999999999917, -0.03500000000000003, 0.32199999999999995, -0.07000000000000006, -0.03399999999999992, -0.22299999999999998, -0.18899999999999983, -0.262, -0.07399999999999984, -0.18500000000000016, -0.19200000000000017, -0.06500000000000006, -0.23599999999999988, -0.06700000000000006, -0.16699999999999993, -0.02199999999999991, -0.05800000000000005, -0.05600000000000005, -0.02200000000000002, -0.06900000000000006, -0.137, -0.04500000000000004, -0.05799999999999994, -0.19300000000000006, -0.12499999999999989, -0.15100000000000002, -0.052000000000000046, -0.27300000000000013, -0.06400000000000006, -0.06800000000000006, -0.14, -0.07299999999999995, -0.11599999999999999, -0.09899999999999998, -0.05500000000000005, -0.03400000000000003, -0.1409999999999999, -0.09099999999999997, -0.2649999999999999, -0.07499999999999996, -0.1529999999999999, -0.19699999999999995, -0.09599999999999986, -0.04600000000000004, -0.07699999999999996, -0.08399999999999996, -0.07700000000000007, -0.04499999999999993, 0.874, -0.11199999999999988, -0.0019999999999998908, -0.05600000000000005, -0.07199999999999984, -0.09999999999999998, 0.33199999999999996, -0.07899999999999985, -0.17700000000000005, -0.049000000000000044, -0.21500000000000008, -0.20999999999999996, -0.05700000000000005, -0.10199999999999987, 0.42900000000000005, -0.03600000000000003, -0.05600000000000005, -0.05300000000000005, -0.22499999999999987, -0.03500000000000003, -0.07600000000000007, -0.053999999999999826, -0.16599999999999993, -0.19999999999999996, -0.06600000000000006, -0.649, -0.07899999999999996, -0.21799999999999997, -0.1379999999999999, -0.04499999999999993, -0.11999999999999988, -0.123, -0.2569999999999999, 0.386, -0.18100000000000005, -0.041000000000000036, -0.04800000000000004, -0.08299999999999996, -0.18599999999999994, -0.06800000000000006, -0.6269999999999999, -0.1279999999999999, -0.08699999999999997, 0.2480000000000001, -0.15200000000000002, -0.43700000000000017, -0.20099999999999996], "episode_lengths": [111, 23, 36, 23, 38, 10, 11, 54, 22, 11, 70, 58, 80, 23, 60, 63, 19, 71, 22, 50, 7, 19, 18, 7, 21, 44, 14, 17, 59, 38, 43, 16, 230, 20, 22, 43, 23, 36, 31, 17, 10, 44, 29, 84, 23, 46, 56, 29, 14, 24, 187, 21, 14, 187, 35, 144, 22, 23, 32, 53, 26, 55, 15, 63, 63, 20, 33, 26, 12, 20, 17, 70, 11, 24, 16, 51, 64, 20, 207, 25, 65, 45, 12, 37, 38, 74, 35, 59, 13, 15, 28, 57, 20, 190, 39, 30, 75, 51, 138, 56], "policy_blue_0_reward": [-1.013, -1.005, -1.0019999999999998, -1.004, -1.001, -0.509, -1.004, -1.001, -1.01, -1.003, -1.009, -1.009, -1.004, -1.005, -1.004, -1.005, -1.008, -1.002, -0.533, 0.863, 0.886, 0.929, -1.008, -1.009, -1.002, -1.001, 0.911, -1.005, 1.05, -1.002, -0.503, 0.829, -1.009, -1.0099999999999998, -0.502, -1.008, -1.003, -1.004, -1.012, -1.005, 0.88, -0.503, 0.96, -1.002, -1.0059999999999998, -1.006, -1.008, -0.5149999999999999, -1.018, -1.014], "policy_red_0_v1_reward": [-1.009, -1.001, 0.783, -1.015, -1.007, 0.9329999999999999, -1.001, 0.942, -1.001, 0.978, 0.867, 0.955, -1.012, 0.951, -1.003, -1.001, -1.004, -1.002, 0.949, 0.968, -1.004, 0.912, -1.001, -1.005, -0.507, -1.006, -1.0, 0.9339999999999999, -1.002, -1.001, 0.953, -1.004, -1.002, -1.0, -1.003, 0.949, 0.966, -1.002, 0.804, 0.938, -1.006, -1.001, -1.002, -1.006, -1.01, 0.82, 0.955, -1.016, -1.002, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22739124059880375, "mean_inference_ms": 1.495379052013122, "mean_action_processing_ms": 0.062285709813769664, "mean_env_wait_ms": 0.10503275778672957, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019095659255981445, "StateBufferConnector_ms": 0.0014592409133911133, "ViewRequirementAgentConnector_ms": 0.030993938446044922}}, "episode_reward_max": 0.874, "episode_reward_min": -0.649, "episode_reward_mean": -0.09311999999999998, "episode_len_mean": 45.72, "episodes_this_iter": 85, "policy_reward_min": {"blue_0": -1.018, "red_0": -1.0519999999999998, "red_0_v1": -1.016}, "policy_reward_max": {"blue_0": 1.05, "red_0": 0.979, "red_0_v1": 0.978}, "policy_reward_mean": {"blue_0": -0.6395599999999999, "red_0": 0.37746, "red_0_v1": -0.3016}, "hist_stats": {"episode_reward": [-0.36099999999999977, -0.07399999999999984, -0.122, -0.07399999999999984, -0.11899999999999988, -0.030999999999999917, -0.03500000000000003, 0.32199999999999995, -0.07000000000000006, -0.03399999999999992, -0.22299999999999998, -0.18899999999999983, -0.262, -0.07399999999999984, -0.18500000000000016, -0.19200000000000017, -0.06500000000000006, -0.23599999999999988, -0.06700000000000006, -0.16699999999999993, -0.02199999999999991, -0.05800000000000005, -0.05600000000000005, -0.02200000000000002, -0.06900000000000006, -0.137, -0.04500000000000004, -0.05799999999999994, -0.19300000000000006, -0.12499999999999989, -0.15100000000000002, -0.052000000000000046, -0.27300000000000013, -0.06400000000000006, -0.06800000000000006, -0.14, -0.07299999999999995, -0.11599999999999999, -0.09899999999999998, -0.05500000000000005, -0.03400000000000003, -0.1409999999999999, -0.09099999999999997, -0.2649999999999999, -0.07499999999999996, -0.1529999999999999, -0.19699999999999995, -0.09599999999999986, -0.04600000000000004, -0.07699999999999996, -0.08399999999999996, -0.07700000000000007, -0.04499999999999993, 0.874, -0.11199999999999988, -0.0019999999999998908, -0.05600000000000005, -0.07199999999999984, -0.09999999999999998, 0.33199999999999996, -0.07899999999999985, -0.17700000000000005, -0.049000000000000044, -0.21500000000000008, -0.20999999999999996, -0.05700000000000005, -0.10199999999999987, 0.42900000000000005, -0.03600000000000003, -0.05600000000000005, -0.05300000000000005, -0.22499999999999987, -0.03500000000000003, -0.07600000000000007, -0.053999999999999826, -0.16599999999999993, -0.19999999999999996, -0.06600000000000006, -0.649, -0.07899999999999996, -0.21799999999999997, -0.1379999999999999, -0.04499999999999993, -0.11999999999999988, -0.123, -0.2569999999999999, 0.386, -0.18100000000000005, -0.041000000000000036, -0.04800000000000004, -0.08299999999999996, -0.18599999999999994, -0.06800000000000006, -0.6269999999999999, -0.1279999999999999, -0.08699999999999997, 0.2480000000000001, -0.15200000000000002, -0.43700000000000017, -0.20099999999999996], "episode_lengths": [111, 23, 36, 23, 38, 10, 11, 54, 22, 11, 70, 58, 80, 23, 60, 63, 19, 71, 22, 50, 7, 19, 18, 7, 21, 44, 14, 17, 59, 38, 43, 16, 230, 20, 22, 43, 23, 36, 31, 17, 10, 44, 29, 84, 23, 46, 56, 29, 14, 24, 187, 21, 14, 187, 35, 144, 22, 23, 32, 53, 26, 55, 15, 63, 63, 20, 33, 26, 12, 20, 17, 70, 11, 24, 16, 51, 64, 20, 207, 25, 65, 45, 12, 37, 38, 74, 35, 59, 13, 15, 28, 57, 20, 190, 39, 30, 75, 51, 138, 56], "policy_blue_0_reward": [-1.013, -1.005, -1.0019999999999998, -1.004, -1.001, -0.509, -1.004, -1.001, -1.01, -1.003, -1.009, -1.009, -1.004, -1.005, -1.004, -1.005, -1.008, -1.002, -0.533, 0.863, 0.886, 0.929, -1.008, -1.009, -1.002, -1.001, 0.911, -1.005, 1.05, -1.002, -0.503, 0.829, -1.009, -1.0099999999999998, -0.502, -1.008, -1.003, -1.004, -1.012, -1.005, 0.88, -0.503, 0.96, -1.002, -1.0059999999999998, -1.006, -1.008, -0.5149999999999999, -1.018, -1.014], "policy_red_0_v1_reward": [-1.009, -1.001, 0.783, -1.015, -1.007, 0.9329999999999999, -1.001, 0.942, -1.001, 0.978, 0.867, 0.955, -1.012, 0.951, -1.003, -1.001, -1.004, -1.002, 0.949, 0.968, -1.004, 0.912, -1.001, -1.005, -0.507, -1.006, -1.0, 0.9339999999999999, -1.002, -1.001, 0.953, -1.004, -1.002, -1.0, -1.003, 0.949, 0.966, -1.002, 0.804, 0.938, -1.006, -1.001, -1.002, -1.006, -1.01, 0.82, 0.955, -1.016, -1.002, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22739124059880375, "mean_inference_ms": 1.495379052013122, "mean_action_processing_ms": 0.062285709813769664, "mean_env_wait_ms": 0.10503275778672957, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019095659255981445, "StateBufferConnector_ms": 0.0014592409133911133, "ViewRequirementAgentConnector_ms": 0.030993938446044922}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.38133442706483, "num_env_steps_trained_throughput_per_sec": 99.38133442706483, "timesteps_total": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 39459.779, "sample_time_ms": 7612.006, "learn_time_ms": 31830.168, "learn_throughput": 125.667, "synch_weights_time_ms": 16.867}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 1990, "training_iteration": 40, "trial_id": "bb874_00000", "date": "2023-09-28_21-56-31", "timestamp": 1695952591, "time_this_iter_s": 40.251750230789185, "time_total_s": 1577.5431201457977, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7ddbca0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac406050>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4071c0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1577.5431201457977, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 37.94310344827585, "ram_util_percent": 27.015517241379317}, "win_rate": 0.74, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0651379386583963, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06285372240272409, "policy_loss": -0.02205900795912991, "vf_loss": 0.16758867440900455, "vf_explained_var": 0.15211183112114668, "kl": 0.012016754729002817, "entropy": 1.28495796918869, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "sampler_results": {"episode_reward_max": 0.41800000000000004, "episode_reward_min": -0.649, "episode_reward_mean": -0.11512999999999998, "episode_len_mean": 53.1, "episode_media": {}, "episodes_this_iter": 78, "policy_reward_min": {"red_0_v1": -1.016, "red_0": -1.026, "blue_0": -1.018}, "policy_reward_max": {"red_0_v1": 0.97, "red_0": 0.979, "blue_0": 0.96}, "policy_reward_mean": {"red_0_v1": -0.4237, "red_0": 0.51658, "blue_0": -0.7703833333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.649, -0.07899999999999996, -0.21799999999999997, -0.1379999999999999, -0.04499999999999993, -0.11999999999999988, -0.123, -0.2569999999999999, 0.386, -0.18100000000000005, -0.041000000000000036, -0.04800000000000004, -0.08299999999999996, -0.18599999999999994, -0.06800000000000006, -0.6269999999999999, -0.1279999999999999, -0.08699999999999997, 0.2480000000000001, -0.15200000000000002, -0.43700000000000017, -0.20099999999999996, -0.08199999999999985, -0.3580000000000001, -0.030000000000000027, -0.04999999999999993, -0.030999999999999917, -0.15500000000000003, -0.10499999999999998, -0.19900000000000007, -0.31599999999999984, -0.32699999999999996, -0.34099999999999997, -0.05700000000000005, -0.391, -0.19900000000000007, -0.15800000000000003, -0.139, -0.030000000000000027, -0.11299999999999988, -0.09099999999999986, -0.07099999999999995, -0.2779999999999999, -0.11600000000000009, -0.026000000000000023, -0.039000000000000035, 0.09499999999999997, 0.3789999999999999, -0.3340000000000001, -0.09699999999999998, -0.15999999999999992, -0.2909999999999999, -0.05899999999999994, -0.06899999999999995, -0.05999999999999994, -0.17300000000000004, -0.06699999999999995, -0.11699999999999988, 0.22299999999999998, -0.05800000000000005, -0.23899999999999988, -0.06599999999999995, -0.23199999999999998, -0.08999999999999997, -0.07499999999999996, -0.1479999999999999, 0.281, -0.07000000000000006, -0.07599999999999985, -0.15699999999999992, -0.09699999999999986, -0.05799999999999994, -0.02100000000000002, -0.040000000000000036, -0.06500000000000006, 0.277, -0.04899999999999993, -0.07499999999999996, -0.052000000000000046, -0.17100000000000004, -0.09899999999999998, -0.252, -0.07299999999999995, 0.41800000000000004, -0.129, -0.31999999999999984, -0.08399999999999985, -0.07699999999999996, -0.09799999999999986, -0.14300000000000002, -0.06700000000000006, -0.08599999999999997, -0.11399999999999999, -0.30299999999999994, -0.4770000000000001, -0.14100000000000001, -0.1479999999999999, -0.252, -0.06899999999999995, -0.052000000000000046], "episode_lengths": [207, 25, 65, 45, 12, 37, 38, 74, 35, 59, 13, 15, 28, 57, 20, 190, 39, 30, 75, 51, 138, 56, 25, 108, 10, 15, 10, 50, 35, 59, 95, 101, 104, 19, 118, 59, 46, 39, 10, 39, 26, 22, 83, 300, 8, 13, 125, 300, 104, 31, 49, 88, 18, 23, 22, 55, 20, 36, 85, 18, 70, 21, 78, 26, 22, 45, 63, 22, 23, 50, 28, 17, 7, 12, 21, 72, 16, 24, 16, 53, 31, 72, 22, 26, 43, 105, 25, 24, 29, 41, 21, 28, 36, 96, 143, 43, 47, 77, 22, 16], "policy_red_0_v1_reward": [-1.006, -1.001, -1.002, -1.006, -1.01, 0.82, 0.955, -1.016, -1.002, -1.001, 0.846, -1.002, -1.012, -1.008, 0.943, 0.629, 0.853, 0.873, 0.97, -1.002, -1.0, -0.516, -1.01, -1.003, -1.002, -1.005, -1.007, -1.004, -1.003, 0.766, -1.009, -1.001, -0.5, -1.002, 0.865, -1.004, 0.915, -1.006, 0.757, -1.0], "policy_blue_0_reward": [-1.012, -1.005, 0.88, -0.503, 0.96, -1.002, -1.0059999999999998, -1.006, -1.008, -0.5149999999999999, -1.018, -1.014, -1.002, -1.016, -1.0, -1.005, -1.001, -1.0139999999999998, -1.016, -1.009, -1.005, -1.004, -1.002, -1.015, -0.047000000000000035, 0.45599999999999996, -1.006, -1.012, -1.005, -1.002, -1.0019999999999998, -0.511, -1.0, -1.006, -1.004, -1.005, -0.5099999999999999, -1.004, -1.008, -1.0, -1.004, -1.0, -1.004, -1.0, -1.001, -1.003, -1.005, -1.005, -1.013, -0.505, -1.008, -1.005, -1.009, -1.005, 0.9359999999999999, 0.888, -1.015, 0.5489999999999999, -1.007, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22767136620125591, "mean_inference_ms": 1.495631775004285, "mean_action_processing_ms": 0.062323999953778436, "mean_env_wait_ms": 0.10513820891073046, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019695043563842773, "StateBufferConnector_ms": 0.0015475749969482422, "ViewRequirementAgentConnector_ms": 0.03208160400390625}}, "episode_reward_max": 0.41800000000000004, "episode_reward_min": -0.649, "episode_reward_mean": -0.11512999999999998, "episode_len_mean": 53.1, "episodes_this_iter": 78, "policy_reward_min": {"red_0_v1": -1.016, "red_0": -1.026, "blue_0": -1.018}, "policy_reward_max": {"red_0_v1": 0.97, "red_0": 0.979, "blue_0": 0.96}, "policy_reward_mean": {"red_0_v1": -0.4237, "red_0": 0.51658, "blue_0": -0.7703833333333333}, "hist_stats": {"episode_reward": [-0.649, -0.07899999999999996, -0.21799999999999997, -0.1379999999999999, -0.04499999999999993, -0.11999999999999988, -0.123, -0.2569999999999999, 0.386, -0.18100000000000005, -0.041000000000000036, -0.04800000000000004, -0.08299999999999996, -0.18599999999999994, -0.06800000000000006, -0.6269999999999999, -0.1279999999999999, -0.08699999999999997, 0.2480000000000001, -0.15200000000000002, -0.43700000000000017, -0.20099999999999996, -0.08199999999999985, -0.3580000000000001, -0.030000000000000027, -0.04999999999999993, -0.030999999999999917, -0.15500000000000003, -0.10499999999999998, -0.19900000000000007, -0.31599999999999984, -0.32699999999999996, -0.34099999999999997, -0.05700000000000005, -0.391, -0.19900000000000007, -0.15800000000000003, -0.139, -0.030000000000000027, -0.11299999999999988, -0.09099999999999986, -0.07099999999999995, -0.2779999999999999, -0.11600000000000009, -0.026000000000000023, -0.039000000000000035, 0.09499999999999997, 0.3789999999999999, -0.3340000000000001, -0.09699999999999998, -0.15999999999999992, -0.2909999999999999, -0.05899999999999994, -0.06899999999999995, -0.05999999999999994, -0.17300000000000004, -0.06699999999999995, -0.11699999999999988, 0.22299999999999998, -0.05800000000000005, -0.23899999999999988, -0.06599999999999995, -0.23199999999999998, -0.08999999999999997, -0.07499999999999996, -0.1479999999999999, 0.281, -0.07000000000000006, -0.07599999999999985, -0.15699999999999992, -0.09699999999999986, -0.05799999999999994, -0.02100000000000002, -0.040000000000000036, -0.06500000000000006, 0.277, -0.04899999999999993, -0.07499999999999996, -0.052000000000000046, -0.17100000000000004, -0.09899999999999998, -0.252, -0.07299999999999995, 0.41800000000000004, -0.129, -0.31999999999999984, -0.08399999999999985, -0.07699999999999996, -0.09799999999999986, -0.14300000000000002, -0.06700000000000006, -0.08599999999999997, -0.11399999999999999, -0.30299999999999994, -0.4770000000000001, -0.14100000000000001, -0.1479999999999999, -0.252, -0.06899999999999995, -0.052000000000000046], "episode_lengths": [207, 25, 65, 45, 12, 37, 38, 74, 35, 59, 13, 15, 28, 57, 20, 190, 39, 30, 75, 51, 138, 56, 25, 108, 10, 15, 10, 50, 35, 59, 95, 101, 104, 19, 118, 59, 46, 39, 10, 39, 26, 22, 83, 300, 8, 13, 125, 300, 104, 31, 49, 88, 18, 23, 22, 55, 20, 36, 85, 18, 70, 21, 78, 26, 22, 45, 63, 22, 23, 50, 28, 17, 7, 12, 21, 72, 16, 24, 16, 53, 31, 72, 22, 26, 43, 105, 25, 24, 29, 41, 21, 28, 36, 96, 143, 43, 47, 77, 22, 16], "policy_red_0_v1_reward": [-1.006, -1.001, -1.002, -1.006, -1.01, 0.82, 0.955, -1.016, -1.002, -1.001, 0.846, -1.002, -1.012, -1.008, 0.943, 0.629, 0.853, 0.873, 0.97, -1.002, -1.0, -0.516, -1.01, -1.003, -1.002, -1.005, -1.007, -1.004, -1.003, 0.766, -1.009, -1.001, -0.5, -1.002, 0.865, -1.004, 0.915, -1.006, 0.757, -1.0], "policy_blue_0_reward": [-1.012, -1.005, 0.88, -0.503, 0.96, -1.002, -1.0059999999999998, -1.006, -1.008, -0.5149999999999999, -1.018, -1.014, -1.002, -1.016, -1.0, -1.005, -1.001, -1.0139999999999998, -1.016, -1.009, -1.005, -1.004, -1.002, -1.015, -0.047000000000000035, 0.45599999999999996, -1.006, -1.012, -1.005, -1.002, -1.0019999999999998, -0.511, -1.0, -1.006, -1.004, -1.005, -0.5099999999999999, -1.004, -1.008, -1.0, -1.004, -1.0, -1.004, -1.0, -1.001, -1.003, -1.005, -1.005, -1.013, -0.505, -1.008, -1.005, -1.009, -1.005, 0.9359999999999999, 0.888, -1.015, 0.5489999999999999, -1.007, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22767136620125591, "mean_inference_ms": 1.495631775004285, "mean_action_processing_ms": 0.062323999953778436, "mean_env_wait_ms": 0.10513820891073046, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019695043563842773, "StateBufferConnector_ms": 0.0015475749969482422, "ViewRequirementAgentConnector_ms": 0.03208160400390625}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.81733096892884, "num_env_steps_trained_throughput_per_sec": 100.81733096892884, "timesteps_total": 164000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 328000, "timers": {"training_iteration_time_ms": 39461.754, "sample_time_ms": 7634.752, "learn_time_ms": 31809.398, "learn_throughput": 125.749, "synch_weights_time_ms": 16.864}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "done": false, "episodes_total": 2068, "training_iteration": 41, "trial_id": "bb874_00000", "date": "2023-09-28_21-57-10", "timestamp": 1695952630, "time_this_iter_s": 39.6783812046051, "time_total_s": 1617.2215013504028, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7dd9a20>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4de4d0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4df400>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1617.2215013504028, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 35.089285714285715, "ram_util_percent": 27.571428571428573}, "win_rate": 0.82, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0730481882890066, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07317052266820004, "policy_loss": -0.02280213393290372, "vf_loss": 0.18960486609333504, "vf_explained_var": 0.17381455780317387, "kl": 0.012174328117061662, "entropy": 1.2646422106772661, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "sampler_results": {"episode_reward_max": 0.46299999999999997, "episode_reward_min": -0.558, "episode_reward_mean": -0.11362999999999995, "episode_len_mean": 41.42, "episode_media": {}, "episodes_this_iter": 94, "policy_reward_min": {"blue_0": -1.023, "red_0": -1.026, "red_0_v1": -1.019}, "policy_reward_max": {"blue_0": 0.966, "red_0": 0.979, "red_0_v1": 1.2}, "policy_reward_mean": {"blue_0": -0.7567499999999999, "red_0": 0.52008, "red_0_v1": -0.5201346153846154}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.4770000000000001, -0.14100000000000001, -0.1479999999999999, -0.252, -0.06899999999999995, -0.052000000000000046, -0.3599999999999999, -0.4780000000000001, -0.15699999999999992, -0.24499999999999988, -0.11499999999999977, -0.42699999999999994, -0.15399999999999991, -0.06000000000000005, -0.2539999999999999, -0.1499999999999998, -0.030999999999999917, -0.16600000000000004, -0.041999999999999926, 0.2660000000000001, -0.05800000000000005, -0.018000000000000016, -0.061000000000000054, -0.1329999999999999, -0.038999999999999924, -0.11099999999999988, -0.04700000000000004, -0.372, -0.22899999999999998, -0.041000000000000036, -0.139, -0.28700000000000003, -0.02199999999999991, -0.049000000000000044, -0.06800000000000006, -0.09999999999999998, -0.03299999999999992, -0.11399999999999988, -0.14900000000000002, -0.12399999999999989, -0.052000000000000046, -0.388, -0.10499999999999987, -0.16000000000000003, -0.08799999999999997, -0.03799999999999992, -0.038999999999999924, -0.06900000000000006, -0.121, -0.03699999999999992, -0.08899999999999986, -0.275, -0.11799999999999988, -0.038000000000000034, -0.16400000000000003, -0.119, -0.16199999999999992, -0.09599999999999997, -0.21000000000000008, -0.18799999999999994, -0.04800000000000004, -0.027999999999999914, -0.038000000000000034, -0.12099999999999989, -0.08899999999999997, -0.05499999999999994, -0.08099999999999996, 0.19599999999999995, -0.16599999999999981, -0.19399999999999995, -0.05999999999999994, 0.46299999999999997, -0.07400000000000007, -0.06900000000000006, -0.038000000000000034, -0.06900000000000006, -0.029000000000000026, -0.03599999999999992, -0.03299999999999992, -0.07200000000000006, -0.14100000000000001, -0.04800000000000004, -0.10599999999999998, -0.558, -0.11299999999999988, -0.061999999999999944, -0.10599999999999998, -0.049000000000000044, -0.0229999999999998, -0.11099999999999988, -0.33299999999999996, -0.06900000000000006, -0.041999999999999926, -0.07800000000000007, -0.07099999999999984, -0.21999999999999997, 0.15799999999999992, -0.03200000000000003, -0.32799999999999985, -0.128], "episode_lengths": [143, 43, 47, 77, 22, 16, 112, 146, 52, 74, 35, 138, 47, 21, 79, 46, 10, 50, 13, 72, 22, 6, 19, 42, 12, 34, 15, 109, 71, 13, 41, 84, 7, 15, 20, 34, 10, 35, 43, 39, 17, 126, 32, 52, 25, 11, 12, 19, 39, 12, 26, 87, 35, 12, 50, 37, 49, 33, 67, 57, 16, 9, 12, 38, 27, 18, 25, 99, 50, 62, 19, 12, 22, 21, 12, 21, 12, 10, 10, 22, 43, 14, 36, 170, 34, 19, 34, 16, 7, 36, 103, 21, 13, 24, 21, 65, 104, 10, 101, 42], "policy_blue_0_reward": [0.5489999999999999, -1.007, -1.003, -1.0159999999999998, -1.009, -1.007, -1.004, -1.011, -1.0059999999999998, -1.007, -0.5059999999999999, -1.003, -1.003, -1.003, -1.003, -1.005, -1.005, -1.007, -1.002, 0.837, -1.0, -1.005, -1.006, -1.004, -1.01, 0.7869999999999999, -1.009, -1.001, -1.005, -1.006, 0.92, -1.007, -1.002, -1.002, 0.966, -1.002, -1.003, -1.002, -1.006, -1.023, -1.007, -1.003, -1.003, -1.0019999999999998, -1.012, -0.513, -1.01, 0.867], "policy_red_0_v1_reward": [-1.006, 0.757, -1.0, -1.019, -1.0119999999999998, -1.003, -1.007, -1.001, -1.001, -1.002, 0.982, -1.002, -1.005, 0.954, 0.652, 0.778, -1.002, 0.731, -1.001, -1.003, -1.005, -1.004, 0.948, -1.004, 0.922, -1.003, -1.002, -1.007, -1.002, -1.002, -1.003, -1.001, 0.898, 0.952, -1.001, -1.001, 1.2, -1.008, -0.501, -1.003, -1.002, -1.004, -1.003, 0.867, 0.952, -1.0019999999999998, -1.002, -1.008, -1.001, -1.001, -1.004, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22760665356491777, "mean_inference_ms": 1.4948972869171524, "mean_action_processing_ms": 0.06229251064087106, "mean_env_wait_ms": 0.10504526572749909, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01936054229736328, "StateBufferConnector_ms": 0.001529693603515625, "ViewRequirementAgentConnector_ms": 0.03138935565948486}}, "episode_reward_max": 0.46299999999999997, "episode_reward_min": -0.558, "episode_reward_mean": -0.11362999999999995, "episode_len_mean": 41.42, "episodes_this_iter": 94, "policy_reward_min": {"blue_0": -1.023, "red_0": -1.026, "red_0_v1": -1.019}, "policy_reward_max": {"blue_0": 0.966, "red_0": 0.979, "red_0_v1": 1.2}, "policy_reward_mean": {"blue_0": -0.7567499999999999, "red_0": 0.52008, "red_0_v1": -0.5201346153846154}, "hist_stats": {"episode_reward": [-0.4770000000000001, -0.14100000000000001, -0.1479999999999999, -0.252, -0.06899999999999995, -0.052000000000000046, -0.3599999999999999, -0.4780000000000001, -0.15699999999999992, -0.24499999999999988, -0.11499999999999977, -0.42699999999999994, -0.15399999999999991, -0.06000000000000005, -0.2539999999999999, -0.1499999999999998, -0.030999999999999917, -0.16600000000000004, -0.041999999999999926, 0.2660000000000001, -0.05800000000000005, -0.018000000000000016, -0.061000000000000054, -0.1329999999999999, -0.038999999999999924, -0.11099999999999988, -0.04700000000000004, -0.372, -0.22899999999999998, -0.041000000000000036, -0.139, -0.28700000000000003, -0.02199999999999991, -0.049000000000000044, -0.06800000000000006, -0.09999999999999998, -0.03299999999999992, -0.11399999999999988, -0.14900000000000002, -0.12399999999999989, -0.052000000000000046, -0.388, -0.10499999999999987, -0.16000000000000003, -0.08799999999999997, -0.03799999999999992, -0.038999999999999924, -0.06900000000000006, -0.121, -0.03699999999999992, -0.08899999999999986, -0.275, -0.11799999999999988, -0.038000000000000034, -0.16400000000000003, -0.119, -0.16199999999999992, -0.09599999999999997, -0.21000000000000008, -0.18799999999999994, -0.04800000000000004, -0.027999999999999914, -0.038000000000000034, -0.12099999999999989, -0.08899999999999997, -0.05499999999999994, -0.08099999999999996, 0.19599999999999995, -0.16599999999999981, -0.19399999999999995, -0.05999999999999994, 0.46299999999999997, -0.07400000000000007, -0.06900000000000006, -0.038000000000000034, -0.06900000000000006, -0.029000000000000026, -0.03599999999999992, -0.03299999999999992, -0.07200000000000006, -0.14100000000000001, -0.04800000000000004, -0.10599999999999998, -0.558, -0.11299999999999988, -0.061999999999999944, -0.10599999999999998, -0.049000000000000044, -0.0229999999999998, -0.11099999999999988, -0.33299999999999996, -0.06900000000000006, -0.041999999999999926, -0.07800000000000007, -0.07099999999999984, -0.21999999999999997, 0.15799999999999992, -0.03200000000000003, -0.32799999999999985, -0.128], "episode_lengths": [143, 43, 47, 77, 22, 16, 112, 146, 52, 74, 35, 138, 47, 21, 79, 46, 10, 50, 13, 72, 22, 6, 19, 42, 12, 34, 15, 109, 71, 13, 41, 84, 7, 15, 20, 34, 10, 35, 43, 39, 17, 126, 32, 52, 25, 11, 12, 19, 39, 12, 26, 87, 35, 12, 50, 37, 49, 33, 67, 57, 16, 9, 12, 38, 27, 18, 25, 99, 50, 62, 19, 12, 22, 21, 12, 21, 12, 10, 10, 22, 43, 14, 36, 170, 34, 19, 34, 16, 7, 36, 103, 21, 13, 24, 21, 65, 104, 10, 101, 42], "policy_blue_0_reward": [0.5489999999999999, -1.007, -1.003, -1.0159999999999998, -1.009, -1.007, -1.004, -1.011, -1.0059999999999998, -1.007, -0.5059999999999999, -1.003, -1.003, -1.003, -1.003, -1.005, -1.005, -1.007, -1.002, 0.837, -1.0, -1.005, -1.006, -1.004, -1.01, 0.7869999999999999, -1.009, -1.001, -1.005, -1.006, 0.92, -1.007, -1.002, -1.002, 0.966, -1.002, -1.003, -1.002, -1.006, -1.023, -1.007, -1.003, -1.003, -1.0019999999999998, -1.012, -0.513, -1.01, 0.867], "policy_red_0_v1_reward": [-1.006, 0.757, -1.0, -1.019, -1.0119999999999998, -1.003, -1.007, -1.001, -1.001, -1.002, 0.982, -1.002, -1.005, 0.954, 0.652, 0.778, -1.002, 0.731, -1.001, -1.003, -1.005, -1.004, 0.948, -1.004, 0.922, -1.003, -1.002, -1.007, -1.002, -1.002, -1.003, -1.001, 0.898, 0.952, -1.001, -1.001, 1.2, -1.008, -0.501, -1.003, -1.002, -1.004, -1.003, 0.867, 0.952, -1.0019999999999998, -1.002, -1.008, -1.001, -1.001, -1.004, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22760665356491777, "mean_inference_ms": 1.4948972869171524, "mean_action_processing_ms": 0.06229251064087106, "mean_env_wait_ms": 0.10504526572749909, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01936054229736328, "StateBufferConnector_ms": 0.001529693603515625, "ViewRequirementAgentConnector_ms": 0.03138935565948486}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.95433199408048, "num_env_steps_trained_throughput_per_sec": 100.95433199408048, "timesteps_total": 168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 39489.518, "sample_time_ms": 7644.027, "learn_time_ms": 31827.865, "learn_throughput": 125.676, "synch_weights_time_ms": 16.885}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "episodes_total": 2162, "training_iteration": 42, "trial_id": "bb874_00000", "date": "2023-09-28_21-57-50", "timestamp": 1695952670, "time_this_iter_s": 39.62474799156189, "time_total_s": 1656.8462493419647, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4fc98d0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf01cf0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf00940>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1656.8462493419647, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 35.989285714285714, "ram_util_percent": 27.528571428571432}, "win_rate": 0.81, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0638434919218223, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06708138576347361, "policy_loss": -0.022035661545426896, "vf_loss": 0.17632199004292487, "vf_explained_var": 0.16045400891453027, "kl": 0.01101557437085603, "entropy": 1.2470624713848035, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "sampler_results": {"episode_reward_max": 0.46099999999999997, "episode_reward_min": -0.726, "episode_reward_mean": -0.08741999999999997, "episode_len_mean": 47.67, "episode_media": {}, "episodes_this_iter": 85, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.026, "red_0_v1": -1.019}, "policy_reward_max": {"blue_0": 0.867, "red_0": 0.979, "red_0_v1": 1.383}, "policy_reward_mean": {"blue_0": -0.8486346153846154, "red_0": 0.5168499999999999, "red_0_v1": -0.33954166666666663}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.061999999999999944, -0.10599999999999998, -0.049000000000000044, -0.0229999999999998, -0.11099999999999988, -0.33299999999999996, -0.06900000000000006, -0.041999999999999926, -0.07800000000000007, -0.07099999999999984, -0.21999999999999997, 0.15799999999999992, -0.03200000000000003, -0.32799999999999985, -0.128, -0.16000000000000011, -0.05800000000000005, -0.08699999999999997, -0.06099999999999994, -0.353, -0.30099999999999993, 0.15499999999999992, -0.22999999999999998, -0.10499999999999998, -0.11599999999999999, -0.06400000000000006, -0.45399999999999996, -0.029000000000000026, -0.16000000000000003, -0.050999999999999934, -0.049000000000000044, -0.038999999999999924, -0.15000000000000002, -0.08399999999999985, -0.2599999999999999, -0.03699999999999992, -0.18500000000000005, -0.07899999999999996, -0.04999999999999993, -0.04700000000000004, -0.15600000000000003, -0.05400000000000005, 0.43999999999999995, -0.06800000000000006, -0.04399999999999993, -0.02200000000000002, -0.19199999999999995, -0.18199999999999994, -0.061000000000000054, 0.3780000000000001, 0.20000000000000007, -0.061999999999999944, -0.08299999999999996, -0.02400000000000002, 0.46099999999999997, -0.09599999999999997, -0.18400000000000005, -0.07899999999999996, -0.16200000000000003, 0.43599999999999994, -0.039999999999999925, -0.2489999999999999, -0.05899999999999994, -0.07000000000000006, -0.029000000000000026, -0.06000000000000005, -0.05800000000000005, -0.4089999999999999, -0.14700000000000002, -0.049000000000000044, -0.07200000000000006, -0.704, -0.05400000000000005, -0.09399999999999986, 0.33499999999999996, -0.06099999999999994, -0.124, 0.388, -0.24, -0.375, -0.397, 0.262, -0.118, -0.11699999999999999, -0.18999999999999995, -0.05699999999999994, -0.05399999999999994, -0.04799999999999993, -0.18699999999999983, -0.17199999999999993, -0.726, -0.126, -0.040000000000000036, -0.22899999999999998, 0.43399999999999994, -0.1439999999999999, -0.07100000000000006, -0.29800000000000004, -0.10699999999999987, -0.08399999999999996], "episode_lengths": [19, 34, 16, 7, 36, 103, 21, 13, 24, 21, 65, 104, 10, 101, 42, 300, 18, 27, 18, 111, 248, 108, 68, 34, 38, 20, 135, 9, 48, 16, 15, 12, 44, 25, 83, 12, 55, 25, 15, 15, 48, 16, 18, 22, 13, 10, 59, 55, 17, 37, 95, 19, 24, 8, 15, 32, 51, 25, 50, 20, 13, 80, 18, 22, 9, 18, 18, 122, 47, 19, 22, 207, 16, 31, 51, 20, 38, 34, 78, 117, 116, 71, 35, 38, 61, 18, 15, 15, 58, 51, 215, 38, 12, 66, 20, 43, 22, 86, 32, 26], "policy_blue_0_reward": [-1.003, -1.003, -1.0019999999999998, -1.012, -0.513, -1.01, 0.867, -0.04300000000000003, -1.002, -1.001, -1.012, 0.725, -0.51, -1.0, -1.009, -1.002, -1.002, -1.002, -1.005, -1.003, -1.01, -1.001, -1.009, -1.001, -1.002, -1.001, -1.011, -0.504, -1.003, -1.012, -1.006, -1.0, -0.502, -1.0039999999999998, -1.001, -1.013, -1.003, -1.001, -1.002, -1.039, -1.003, -1.001, -1.005, 0.636, -1.009, -1.003, -1.039, -1.008, -1.008, -1.018, -1.004, -1.0], "policy_red_0_v1_reward": [0.952, -1.0019999999999998, -1.002, -1.008, -1.001, -1.001, -1.004, -1.002, 0.943, -1.009, 0.894, -1.0, -1.019, -1.0, -1.003, -1.002, 0.97, -1.007, 0.942, 1.383, -0.513, -1.001, -0.501, -1.008, 0.834, -1.001, -1.008, -1.001, -1.003, 0.9319999999999999, 0.943, 0.944, -1.003, -0.502, -0.507, -1.003, 0.629, -0.514, 0.882, 0.885, -1.003, -1.002, -1.003, -1.006, -1.002, 0.782, -0.502, 0.9299999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22811341513239414, "mean_inference_ms": 1.4958691466662726, "mean_action_processing_ms": 0.062350616314897085, "mean_env_wait_ms": 0.10520566521559623, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019563674926757812, "StateBufferConnector_ms": 0.0015592575073242188, "ViewRequirementAgentConnector_ms": 0.031973958015441895}}, "episode_reward_max": 0.46099999999999997, "episode_reward_min": -0.726, "episode_reward_mean": -0.08741999999999997, "episode_len_mean": 47.67, "episodes_this_iter": 85, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.026, "red_0_v1": -1.019}, "policy_reward_max": {"blue_0": 0.867, "red_0": 0.979, "red_0_v1": 1.383}, "policy_reward_mean": {"blue_0": -0.8486346153846154, "red_0": 0.5168499999999999, "red_0_v1": -0.33954166666666663}, "hist_stats": {"episode_reward": [-0.061999999999999944, -0.10599999999999998, -0.049000000000000044, -0.0229999999999998, -0.11099999999999988, -0.33299999999999996, -0.06900000000000006, -0.041999999999999926, -0.07800000000000007, -0.07099999999999984, -0.21999999999999997, 0.15799999999999992, -0.03200000000000003, -0.32799999999999985, -0.128, -0.16000000000000011, -0.05800000000000005, -0.08699999999999997, -0.06099999999999994, -0.353, -0.30099999999999993, 0.15499999999999992, -0.22999999999999998, -0.10499999999999998, -0.11599999999999999, -0.06400000000000006, -0.45399999999999996, -0.029000000000000026, -0.16000000000000003, -0.050999999999999934, -0.049000000000000044, -0.038999999999999924, -0.15000000000000002, -0.08399999999999985, -0.2599999999999999, -0.03699999999999992, -0.18500000000000005, -0.07899999999999996, -0.04999999999999993, -0.04700000000000004, -0.15600000000000003, -0.05400000000000005, 0.43999999999999995, -0.06800000000000006, -0.04399999999999993, -0.02200000000000002, -0.19199999999999995, -0.18199999999999994, -0.061000000000000054, 0.3780000000000001, 0.20000000000000007, -0.061999999999999944, -0.08299999999999996, -0.02400000000000002, 0.46099999999999997, -0.09599999999999997, -0.18400000000000005, -0.07899999999999996, -0.16200000000000003, 0.43599999999999994, -0.039999999999999925, -0.2489999999999999, -0.05899999999999994, -0.07000000000000006, -0.029000000000000026, -0.06000000000000005, -0.05800000000000005, -0.4089999999999999, -0.14700000000000002, -0.049000000000000044, -0.07200000000000006, -0.704, -0.05400000000000005, -0.09399999999999986, 0.33499999999999996, -0.06099999999999994, -0.124, 0.388, -0.24, -0.375, -0.397, 0.262, -0.118, -0.11699999999999999, -0.18999999999999995, -0.05699999999999994, -0.05399999999999994, -0.04799999999999993, -0.18699999999999983, -0.17199999999999993, -0.726, -0.126, -0.040000000000000036, -0.22899999999999998, 0.43399999999999994, -0.1439999999999999, -0.07100000000000006, -0.29800000000000004, -0.10699999999999987, -0.08399999999999996], "episode_lengths": [19, 34, 16, 7, 36, 103, 21, 13, 24, 21, 65, 104, 10, 101, 42, 300, 18, 27, 18, 111, 248, 108, 68, 34, 38, 20, 135, 9, 48, 16, 15, 12, 44, 25, 83, 12, 55, 25, 15, 15, 48, 16, 18, 22, 13, 10, 59, 55, 17, 37, 95, 19, 24, 8, 15, 32, 51, 25, 50, 20, 13, 80, 18, 22, 9, 18, 18, 122, 47, 19, 22, 207, 16, 31, 51, 20, 38, 34, 78, 117, 116, 71, 35, 38, 61, 18, 15, 15, 58, 51, 215, 38, 12, 66, 20, 43, 22, 86, 32, 26], "policy_blue_0_reward": [-1.003, -1.003, -1.0019999999999998, -1.012, -0.513, -1.01, 0.867, -0.04300000000000003, -1.002, -1.001, -1.012, 0.725, -0.51, -1.0, -1.009, -1.002, -1.002, -1.002, -1.005, -1.003, -1.01, -1.001, -1.009, -1.001, -1.002, -1.001, -1.011, -0.504, -1.003, -1.012, -1.006, -1.0, -0.502, -1.0039999999999998, -1.001, -1.013, -1.003, -1.001, -1.002, -1.039, -1.003, -1.001, -1.005, 0.636, -1.009, -1.003, -1.039, -1.008, -1.008, -1.018, -1.004, -1.0], "policy_red_0_v1_reward": [0.952, -1.0019999999999998, -1.002, -1.008, -1.001, -1.001, -1.004, -1.002, 0.943, -1.009, 0.894, -1.0, -1.019, -1.0, -1.003, -1.002, 0.97, -1.007, 0.942, 1.383, -0.513, -1.001, -0.501, -1.008, 0.834, -1.001, -1.008, -1.001, -1.003, 0.9319999999999999, 0.943, 0.944, -1.003, -0.502, -0.507, -1.003, 0.629, -0.514, 0.882, 0.885, -1.003, -1.002, -1.003, -1.006, -1.002, 0.782, -0.502, 0.9299999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22811341513239414, "mean_inference_ms": 1.4958691466662726, "mean_action_processing_ms": 0.062350616314897085, "mean_env_wait_ms": 0.10520566521559623, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019563674926757812, "StateBufferConnector_ms": 0.0015592575073242188, "ViewRequirementAgentConnector_ms": 0.031973958015441895}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.93790134026514, "num_env_steps_trained_throughput_per_sec": 99.93790134026514, "timesteps_total": 172000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 344000, "timers": {"training_iteration_time_ms": 39566.346, "sample_time_ms": 7674.194, "learn_time_ms": 31874.567, "learn_throughput": 125.492, "synch_weights_time_ms": 16.871}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "done": false, "episodes_total": 2247, "training_iteration": 43, "trial_id": "bb874_00000", "date": "2023-09-28_21-58-30", "timestamp": 1695952710, "time_this_iter_s": 40.02757811546326, "time_total_s": 1696.873827457428, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f3d900>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4079a0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac406440>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1696.873827457428, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 36.03793103448275, "ram_util_percent": 27.5}, "win_rate": 0.82, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.196314417819182, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0869239066875404, "policy_loss": -0.02743050008211867, "vf_loss": 0.22496860224443177, "vf_explained_var": 0.11703007941444715, "kl": 0.015717289897128783, "entropy": 1.273352115849654, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "sampler_results": {"episode_reward_max": 0.46199999999999997, "episode_reward_min": -0.726, "episode_reward_mean": -0.10469999999999997, "episode_len_mean": 47.54, "episode_media": {}, "episodes_this_iter": 85, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.047, "red_0_v1": -1.027}, "policy_reward_max": {"blue_0": 1.331, "red_0": 0.972, "red_0_v1": 1.463}, "policy_reward_mean": {"blue_0": -0.7885869565217388, "red_0": 0.4264899999999999, "red_0_v1": -0.3119259259259259}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.05699999999999994, -0.05399999999999994, -0.04799999999999993, -0.18699999999999983, -0.17199999999999993, -0.726, -0.126, -0.040000000000000036, -0.22899999999999998, 0.43399999999999994, -0.1439999999999999, -0.07100000000000006, -0.29800000000000004, -0.10699999999999987, -0.08399999999999996, -0.09299999999999997, -0.10699999999999998, -0.136, -0.052000000000000046, -0.21399999999999997, -0.07599999999999985, -0.2479999999999999, -0.18599999999999994, -0.41100000000000003, -0.041000000000000036, -0.07100000000000006, 0.46199999999999997, -0.07599999999999996, -0.05800000000000005, -0.07000000000000006, -0.05399999999999994, -0.05799999999999994, -0.18199999999999994, -0.08899999999999997, -0.11799999999999988, -0.236, -0.05500000000000005, -0.122, -0.06099999999999994, -0.06399999999999995, -0.03700000000000003, -0.09099999999999997, -0.16500000000000004, -0.02399999999999991, -0.09599999999999986, 0.258, -0.18700000000000006, -0.10099999999999998, -0.269, -0.07200000000000006, -0.2390000000000001, -0.09299999999999997, -0.14800000000000002, 0.356, -0.08099999999999996, -0.238, -0.04799999999999993, -0.15000000000000002, -0.11499999999999999, -0.04799999999999993, -0.14400000000000002, -0.2469999999999999, -0.050999999999999934, -0.030999999999999917, -0.6910000000000001, -0.10999999999999999, 0.3340000000000001, -0.062000000000000055, -0.10799999999999998, -0.04600000000000004, -0.09199999999999997, -0.04699999999999993, -0.119, -0.09999999999999987, -0.031000000000000028, -0.11199999999999999, -0.08399999999999985, -0.039999999999999925, -0.45699999999999985, -0.05399999999999994, -0.04499999999999993, -0.278, -0.04799999999999993, -0.28800000000000003, -0.24, -0.3700000000000001, -0.07600000000000007, -0.05800000000000005, -0.04999999999999993, -0.04400000000000004, -0.3069999999999997, -0.05499999999999994, -0.041999999999999926, 0.16800000000000004, -0.23899999999999988, -0.1289999999999999, 0.43299999999999994, -0.3919999999999998, -0.05500000000000005, -0.1499999999999999], "episode_lengths": [18, 15, 15, 58, 51, 215, 38, 12, 66, 20, 43, 22, 86, 32, 26, 29, 32, 40, 19, 68, 23, 79, 57, 132, 13, 22, 12, 26, 18, 22, 20, 17, 59, 29, 33, 74, 21, 38, 20, 19, 11, 31, 55, 160, 31, 75, 56, 32, 84, 22, 73, 33, 46, 41, 25, 223, 15, 203, 34, 15, 44, 76, 16, 10, 219, 32, 55, 18, 32, 15, 28, 14, 40, 31, 9, 34, 25, 13, 136, 17, 14, 82, 15, 86, 71, 112, 24, 20, 15, 14, 95, 16, 13, 107, 70, 40, 21, 110, 16, 45], "policy_blue_0_reward": [-1.003, -1.039, -1.008, -1.008, -1.018, -1.004, -1.0, -1.004, -1.005, -1.0139999999999998, -1.002, -1.002, -1.003, -1.003, -1.005, -1.0079999999999998, -1.005, -1.005, -1.005, -1.004, -1.004, -0.5239999999999999, -0.509, -1.007, -0.523, 0.892, 0.864, -1.006, -1.001, -1.005, 1.331, -1.0039999999999998, -1.003, -1.001, -1.014, -1.001, -1.014, -1.002, -1.012, -1.001, -1.006, -1.013, -1.004, -1.009, -0.504, 0.95], "policy_red_0_v1_reward": [-1.003, -1.002, -1.003, -1.006, -1.002, 0.782, -0.502, 0.9299999999999999, 0.898, 0.939, 0.79, -1.005, -1.006, 0.592, 0.9339999999999999, 1.463, -1.002, 0.9309999999999999, 0.912, -1.001, -1.0, 0.831, -1.002, 0.82, 0.901, 0.745, -1.003, 0.899, -1.003, -0.509, -1.002, 0.809, -1.001, -1.0019999999999998, -1.003, -1.012, -1.004, 0.899, 0.954, -1.002, -1.002, -1.002, -1.003, -1.004, -1.0, 0.777, -1.014, -1.003, -1.002, -1.0019999999999998, -0.501, -1.008, -1.027, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22829013835872125, "mean_inference_ms": 1.4969977600436124, "mean_action_processing_ms": 0.06240117276325242, "mean_env_wait_ms": 0.10537872150269362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018987059593200684, "StateBufferConnector_ms": 0.001517176628112793, "ViewRequirementAgentConnector_ms": 0.0313417911529541}}, "episode_reward_max": 0.46199999999999997, "episode_reward_min": -0.726, "episode_reward_mean": -0.10469999999999997, "episode_len_mean": 47.54, "episodes_this_iter": 85, "policy_reward_min": {"blue_0": -1.039, "red_0": -1.047, "red_0_v1": -1.027}, "policy_reward_max": {"blue_0": 1.331, "red_0": 0.972, "red_0_v1": 1.463}, "policy_reward_mean": {"blue_0": -0.7885869565217388, "red_0": 0.4264899999999999, "red_0_v1": -0.3119259259259259}, "hist_stats": {"episode_reward": [-0.05699999999999994, -0.05399999999999994, -0.04799999999999993, -0.18699999999999983, -0.17199999999999993, -0.726, -0.126, -0.040000000000000036, -0.22899999999999998, 0.43399999999999994, -0.1439999999999999, -0.07100000000000006, -0.29800000000000004, -0.10699999999999987, -0.08399999999999996, -0.09299999999999997, -0.10699999999999998, -0.136, -0.052000000000000046, -0.21399999999999997, -0.07599999999999985, -0.2479999999999999, -0.18599999999999994, -0.41100000000000003, -0.041000000000000036, -0.07100000000000006, 0.46199999999999997, -0.07599999999999996, -0.05800000000000005, -0.07000000000000006, -0.05399999999999994, -0.05799999999999994, -0.18199999999999994, -0.08899999999999997, -0.11799999999999988, -0.236, -0.05500000000000005, -0.122, -0.06099999999999994, -0.06399999999999995, -0.03700000000000003, -0.09099999999999997, -0.16500000000000004, -0.02399999999999991, -0.09599999999999986, 0.258, -0.18700000000000006, -0.10099999999999998, -0.269, -0.07200000000000006, -0.2390000000000001, -0.09299999999999997, -0.14800000000000002, 0.356, -0.08099999999999996, -0.238, -0.04799999999999993, -0.15000000000000002, -0.11499999999999999, -0.04799999999999993, -0.14400000000000002, -0.2469999999999999, -0.050999999999999934, -0.030999999999999917, -0.6910000000000001, -0.10999999999999999, 0.3340000000000001, -0.062000000000000055, -0.10799999999999998, -0.04600000000000004, -0.09199999999999997, -0.04699999999999993, -0.119, -0.09999999999999987, -0.031000000000000028, -0.11199999999999999, -0.08399999999999985, -0.039999999999999925, -0.45699999999999985, -0.05399999999999994, -0.04499999999999993, -0.278, -0.04799999999999993, -0.28800000000000003, -0.24, -0.3700000000000001, -0.07600000000000007, -0.05800000000000005, -0.04999999999999993, -0.04400000000000004, -0.3069999999999997, -0.05499999999999994, -0.041999999999999926, 0.16800000000000004, -0.23899999999999988, -0.1289999999999999, 0.43299999999999994, -0.3919999999999998, -0.05500000000000005, -0.1499999999999999], "episode_lengths": [18, 15, 15, 58, 51, 215, 38, 12, 66, 20, 43, 22, 86, 32, 26, 29, 32, 40, 19, 68, 23, 79, 57, 132, 13, 22, 12, 26, 18, 22, 20, 17, 59, 29, 33, 74, 21, 38, 20, 19, 11, 31, 55, 160, 31, 75, 56, 32, 84, 22, 73, 33, 46, 41, 25, 223, 15, 203, 34, 15, 44, 76, 16, 10, 219, 32, 55, 18, 32, 15, 28, 14, 40, 31, 9, 34, 25, 13, 136, 17, 14, 82, 15, 86, 71, 112, 24, 20, 15, 14, 95, 16, 13, 107, 70, 40, 21, 110, 16, 45], "policy_blue_0_reward": [-1.003, -1.039, -1.008, -1.008, -1.018, -1.004, -1.0, -1.004, -1.005, -1.0139999999999998, -1.002, -1.002, -1.003, -1.003, -1.005, -1.0079999999999998, -1.005, -1.005, -1.005, -1.004, -1.004, -0.5239999999999999, -0.509, -1.007, -0.523, 0.892, 0.864, -1.006, -1.001, -1.005, 1.331, -1.0039999999999998, -1.003, -1.001, -1.014, -1.001, -1.014, -1.002, -1.012, -1.001, -1.006, -1.013, -1.004, -1.009, -0.504, 0.95], "policy_red_0_v1_reward": [-1.003, -1.002, -1.003, -1.006, -1.002, 0.782, -0.502, 0.9299999999999999, 0.898, 0.939, 0.79, -1.005, -1.006, 0.592, 0.9339999999999999, 1.463, -1.002, 0.9309999999999999, 0.912, -1.001, -1.0, 0.831, -1.002, 0.82, 0.901, 0.745, -1.003, 0.899, -1.003, -0.509, -1.002, 0.809, -1.001, -1.0019999999999998, -1.003, -1.012, -1.004, 0.899, 0.954, -1.002, -1.002, -1.002, -1.003, -1.004, -1.0, 0.777, -1.014, -1.003, -1.002, -1.0019999999999998, -0.501, -1.008, -1.027, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22829013835872125, "mean_inference_ms": 1.4969977600436124, "mean_action_processing_ms": 0.06240117276325242, "mean_env_wait_ms": 0.10537872150269362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018987059593200684, "StateBufferConnector_ms": 0.001517176628112793, "ViewRequirementAgentConnector_ms": 0.0313417911529541}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.75374081956639, "num_env_steps_trained_throughput_per_sec": 100.75374081956639, "timesteps_total": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 39601.979, "sample_time_ms": 7684.361, "learn_time_ms": 31900.045, "learn_throughput": 125.392, "synch_weights_time_ms": 16.86}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "episodes_total": 2332, "training_iteration": 44, "trial_id": "bb874_00000", "date": "2023-09-28_21-59-10", "timestamp": 1695952750, "time_this_iter_s": 39.70348525047302, "time_total_s": 1736.577312707901, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4fcba90>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70fc70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70d480>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1736.577312707901, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 34.558928571428574, "ram_util_percent": 27.508928571428577}, "win_rate": 0.77, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1803558602929116, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.08134476779523539, "policy_loss": -0.02414175352168968, "vf_loss": 0.2083877454744652, "vf_explained_var": 0.18442908159146706, "kl": 0.012869610074803806, "entropy": 1.2812722012400628, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "sampler_results": {"episode_reward_max": 0.43299999999999994, "episode_reward_min": -1.0030000000000001, "episode_reward_mean": -0.11928999999999997, "episode_len_mean": 45.61, "episode_media": {}, "episodes_this_iter": 93, "policy_reward_min": {"red_0_v1": -1.027, "red_0": -1.057, "blue_0": -1.05}, "policy_reward_max": {"red_0_v1": 1.403, "red_0": 0.979, "blue_0": 0.966}, "policy_reward_mean": {"red_0_v1": -0.2742727272727272, "red_0": 0.46656, "blue_0": -0.8306607142857142}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.16800000000000004, -0.23899999999999988, -0.1289999999999999, 0.43299999999999994, -0.3919999999999998, -0.05500000000000005, -0.1499999999999999, -0.23199999999999987, -0.09099999999999997, -0.30700000000000005, -0.10799999999999987, -0.04399999999999993, -0.04299999999999993, -0.11799999999999988, -0.03400000000000003, -0.10099999999999998, -0.1639999999999998, -0.04999999999999982, -0.12099999999999989, -0.19600000000000006, -0.049000000000000044, -0.16900000000000004, -0.1359999999999999, -0.10399999999999998, -0.09999999999999998, -0.09099999999999997, -0.041999999999999926, -0.11999999999999988, -0.1419999999999998, -0.10699999999999987, -0.21199999999999997, -0.08299999999999985, -0.10099999999999987, -0.05700000000000005, -0.19999999999999996, -0.04300000000000004, 0.32799999999999985, -0.07200000000000006, -0.07899999999999996, -0.029000000000000026, -0.06400000000000006, -0.041000000000000036, -0.06499999999999995, -0.31099999999999994, 0.401, -0.062000000000000055, -0.02199999999999991, -0.041000000000000036, -0.2539999999999999, -0.04200000000000004, 0.4169999999999999, -1.0030000000000001, -0.521, -0.2499999999999999, -0.345, -0.07499999999999996, -0.06599999999999995, -0.06599999999999995, -0.07000000000000006, -0.050000000000000044, -0.20999999999999996, -0.03400000000000003, 0.42700000000000005, -0.22000000000000008, -0.06900000000000006, -0.4750000000000001, -0.13, -0.08999999999999997, -0.05599999999999994, -0.11099999999999988, -0.136, -0.026000000000000023, -0.20699999999999985, -0.05900000000000005, -0.28400000000000003, -0.11299999999999988, -0.18499999999999983, -0.121, -0.19700000000000006, -0.04700000000000004, -0.15499999999999992, -0.31299999999999994, -0.34599999999999986, -0.08299999999999985, -0.623, -0.10999999999999999, -0.529, -0.041000000000000036, -0.08000000000000007, -0.10299999999999998, -0.04599999999999993, -0.029000000000000026, -0.07299999999999995, -0.22299999999999986, -0.04399999999999993, -0.42700000000000005, -0.08299999999999996, -0.08199999999999996, -0.03699999999999992, -0.04800000000000004], "episode_lengths": [107, 70, 40, 21, 110, 16, 45, 71, 33, 91, 35, 13, 14, 39, 11, 29, 52, 14, 36, 60, 15, 53, 41, 32, 32, 29, 13, 35, 44, 34, 65, 26, 28, 17, 57, 16, 55, 21, 25, 9, 19, 13, 20, 94, 32, 18, 7, 13, 77, 17, 24, 300, 161, 83, 98, 27, 19, 23, 22, 15, 63, 14, 23, 63, 21, 140, 42, 28, 17, 34, 42, 8, 66, 19, 87, 36, 58, 37, 59, 15, 46, 97, 109, 26, 188, 31, 151, 13, 24, 33, 15, 9, 23, 66, 13, 131, 25, 26, 12, 15], "policy_red_0_v1_reward": [-0.501, -1.008, -1.027, -1.007, 0.901, -1.013, -1.0, -1.0059999999999998, -1.004, 0.954, 0.836, 0.91, -1.009, -1.008, -1.012, 1.33, 0.9319999999999999, 0.972, -1.002, -1.008, 1.403, -1.002, -0.506, 0.512, -1.002, -1.027, 0.929, 0.9309999999999999, 0.953, -1.001, -0.502, 0.8039999999999999, 0.5539999999999999, -1.005, -1.001, -1.0, 0.727, -1.005, -1.001, -1.008, -1.002, -1.001, -1.002, 0.954], "policy_blue_0_reward": [-1.009, -0.504, 0.95, -1.011, -1.004, -1.003, -1.006, 0.966, -1.003, -1.0079999999999998, -1.006, -1.001, -1.003, -1.003, -1.002, -1.0059999999999998, -1.004, -1.0079999999999998, -1.003, -1.003, -1.002, -1.003, 0.94, -1.0, -1.002, -1.001, -1.013, -1.001, -1.05, -1.002, -1.004, -1.009, -1.006, -1.0, -1.004, -1.003, -1.005, -1.004, -1.006, -1.003, -1.009, -1.01, -1.012, -1.002, -1.02, 0.901, 0.528, -1.002, -1.005, -1.001, -1.009, -1.003, -1.021, -1.003, -1.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22848886177526181, "mean_inference_ms": 1.4976790402180666, "mean_action_processing_ms": 0.062409027661311296, "mean_env_wait_ms": 0.1054529942581161, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018688082695007324, "StateBufferConnector_ms": 0.0014787912368774414, "ViewRequirementAgentConnector_ms": 0.03104841709136963}}, "episode_reward_max": 0.43299999999999994, "episode_reward_min": -1.0030000000000001, "episode_reward_mean": -0.11928999999999997, "episode_len_mean": 45.61, "episodes_this_iter": 93, "policy_reward_min": {"red_0_v1": -1.027, "red_0": -1.057, "blue_0": -1.05}, "policy_reward_max": {"red_0_v1": 1.403, "red_0": 0.979, "blue_0": 0.966}, "policy_reward_mean": {"red_0_v1": -0.2742727272727272, "red_0": 0.46656, "blue_0": -0.8306607142857142}, "hist_stats": {"episode_reward": [0.16800000000000004, -0.23899999999999988, -0.1289999999999999, 0.43299999999999994, -0.3919999999999998, -0.05500000000000005, -0.1499999999999999, -0.23199999999999987, -0.09099999999999997, -0.30700000000000005, -0.10799999999999987, -0.04399999999999993, -0.04299999999999993, -0.11799999999999988, -0.03400000000000003, -0.10099999999999998, -0.1639999999999998, -0.04999999999999982, -0.12099999999999989, -0.19600000000000006, -0.049000000000000044, -0.16900000000000004, -0.1359999999999999, -0.10399999999999998, -0.09999999999999998, -0.09099999999999997, -0.041999999999999926, -0.11999999999999988, -0.1419999999999998, -0.10699999999999987, -0.21199999999999997, -0.08299999999999985, -0.10099999999999987, -0.05700000000000005, -0.19999999999999996, -0.04300000000000004, 0.32799999999999985, -0.07200000000000006, -0.07899999999999996, -0.029000000000000026, -0.06400000000000006, -0.041000000000000036, -0.06499999999999995, -0.31099999999999994, 0.401, -0.062000000000000055, -0.02199999999999991, -0.041000000000000036, -0.2539999999999999, -0.04200000000000004, 0.4169999999999999, -1.0030000000000001, -0.521, -0.2499999999999999, -0.345, -0.07499999999999996, -0.06599999999999995, -0.06599999999999995, -0.07000000000000006, -0.050000000000000044, -0.20999999999999996, -0.03400000000000003, 0.42700000000000005, -0.22000000000000008, -0.06900000000000006, -0.4750000000000001, -0.13, -0.08999999999999997, -0.05599999999999994, -0.11099999999999988, -0.136, -0.026000000000000023, -0.20699999999999985, -0.05900000000000005, -0.28400000000000003, -0.11299999999999988, -0.18499999999999983, -0.121, -0.19700000000000006, -0.04700000000000004, -0.15499999999999992, -0.31299999999999994, -0.34599999999999986, -0.08299999999999985, -0.623, -0.10999999999999999, -0.529, -0.041000000000000036, -0.08000000000000007, -0.10299999999999998, -0.04599999999999993, -0.029000000000000026, -0.07299999999999995, -0.22299999999999986, -0.04399999999999993, -0.42700000000000005, -0.08299999999999996, -0.08199999999999996, -0.03699999999999992, -0.04800000000000004], "episode_lengths": [107, 70, 40, 21, 110, 16, 45, 71, 33, 91, 35, 13, 14, 39, 11, 29, 52, 14, 36, 60, 15, 53, 41, 32, 32, 29, 13, 35, 44, 34, 65, 26, 28, 17, 57, 16, 55, 21, 25, 9, 19, 13, 20, 94, 32, 18, 7, 13, 77, 17, 24, 300, 161, 83, 98, 27, 19, 23, 22, 15, 63, 14, 23, 63, 21, 140, 42, 28, 17, 34, 42, 8, 66, 19, 87, 36, 58, 37, 59, 15, 46, 97, 109, 26, 188, 31, 151, 13, 24, 33, 15, 9, 23, 66, 13, 131, 25, 26, 12, 15], "policy_red_0_v1_reward": [-0.501, -1.008, -1.027, -1.007, 0.901, -1.013, -1.0, -1.0059999999999998, -1.004, 0.954, 0.836, 0.91, -1.009, -1.008, -1.012, 1.33, 0.9319999999999999, 0.972, -1.002, -1.008, 1.403, -1.002, -0.506, 0.512, -1.002, -1.027, 0.929, 0.9309999999999999, 0.953, -1.001, -0.502, 0.8039999999999999, 0.5539999999999999, -1.005, -1.001, -1.0, 0.727, -1.005, -1.001, -1.008, -1.002, -1.001, -1.002, 0.954], "policy_blue_0_reward": [-1.009, -0.504, 0.95, -1.011, -1.004, -1.003, -1.006, 0.966, -1.003, -1.0079999999999998, -1.006, -1.001, -1.003, -1.003, -1.002, -1.0059999999999998, -1.004, -1.0079999999999998, -1.003, -1.003, -1.002, -1.003, 0.94, -1.0, -1.002, -1.001, -1.013, -1.001, -1.05, -1.002, -1.004, -1.009, -1.006, -1.0, -1.004, -1.003, -1.005, -1.004, -1.006, -1.003, -1.009, -1.01, -1.012, -1.002, -1.02, 0.901, 0.528, -1.002, -1.005, -1.001, -1.009, -1.003, -1.021, -1.003, -1.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22848886177526181, "mean_inference_ms": 1.4976790402180666, "mean_action_processing_ms": 0.062409027661311296, "mean_env_wait_ms": 0.1054529942581161, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018688082695007324, "StateBufferConnector_ms": 0.0014787912368774414, "ViewRequirementAgentConnector_ms": 0.03104841709136963}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.9071913049711, "num_env_steps_trained_throughput_per_sec": 100.9071913049711, "timesteps_total": 180000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 360000, "timers": {"training_iteration_time_ms": 39613.294, "sample_time_ms": 7676.682, "learn_time_ms": 31918.994, "learn_throughput": 125.317, "synch_weights_time_ms": 16.915}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 2425, "training_iteration": 45, "trial_id": "bb874_00000", "date": "2023-09-28_21-59-49", "timestamp": 1695952789, "time_this_iter_s": 39.64321517944336, "time_total_s": 1776.2205278873444, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7dd8280>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4dc670>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4df370>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1776.2205278873444, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 35.95087719298245, "ram_util_percent": 27.471929824561403}, "win_rate": 0.79, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1836254068960748, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06487474027793118, "policy_loss": -0.023570927721933307, "vf_loss": 0.174700620258227, "vf_explained_var": 0.18490335904061794, "kl": 0.01153681880787, "entropy": 1.2120064246157805, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "sampler_results": {"episode_reward_max": 0.45099999999999996, "episode_reward_min": -0.4700000000000001, "episode_reward_mean": -0.08046999999999997, "episode_len_mean": 44.45, "episode_media": {}, "episodes_this_iter": 87, "policy_reward_min": {"blue_0": -1.021, "red_0": -1.022, "red_0_v1": -1.016}, "policy_reward_max": {"blue_0": 0.953, "red_0": 0.973, "red_0_v1": 1.451}, "policy_reward_mean": {"blue_0": -0.8142962962962963, "red_0": 0.54256, "red_0_v1": -0.3984999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.041000000000000036, -0.08000000000000007, -0.10299999999999998, -0.04599999999999993, -0.029000000000000026, -0.07299999999999995, -0.22299999999999986, -0.04399999999999993, -0.42700000000000005, -0.08299999999999996, -0.08199999999999996, -0.03699999999999992, -0.04800000000000004, -0.118, 0.252, -0.07499999999999996, -0.040000000000000036, -0.139, -0.11299999999999988, -0.21499999999999986, -0.32700000000000007, 0.45099999999999996, -0.06400000000000006, -0.4, -0.20199999999999996, 0.18600000000000017, -0.05500000000000005, 0.32299999999999995, -0.135, -0.09599999999999997, 0.44999999999999996, -0.15400000000000003, -0.04599999999999993, 0.375, -0.06500000000000006, -0.10799999999999987, -0.11099999999999988, -0.4039999999999999, -0.261, -0.029000000000000026, -0.08000000000000007, -0.03500000000000003, -0.16199999999999992, -0.40000000000000013, -0.19299999999999984, -0.4700000000000001, -0.041000000000000036, -0.17900000000000005, -0.133, -0.04300000000000004, -0.15799999999999992, -0.08699999999999986, -0.08599999999999985, -0.11399999999999988, 0.42000000000000004, -0.05400000000000005, -0.19600000000000006, -0.062000000000000055, -0.08399999999999985, -0.07199999999999984, -0.2609999999999999, -0.32399999999999984, -0.04800000000000004, -0.031000000000000028, -0.242, -0.04599999999999982, -0.040000000000000036, -0.19699999999999995, -0.06400000000000006, -0.05399999999999994, -0.04399999999999993, -0.04499999999999993, -0.137, -0.20399999999999996, -0.07999999999999985, -0.08099999999999996, -0.08499999999999996, -0.03500000000000003, -0.08999999999999986, -0.03399999999999992, 0.40400000000000014, -0.04200000000000004, 0.368, -0.10399999999999998, -0.062000000000000055, -0.05300000000000005, -0.10099999999999987, -0.05300000000000005, -0.41100000000000003, 0.38, -0.04599999999999993, -0.04500000000000004, -0.14800000000000002, -0.2519999999999999, -0.09799999999999975, -0.04800000000000004, -0.17000000000000004, -0.10399999999999998, -0.33499999999999996, -0.31999999999999995], "episode_lengths": [13, 24, 33, 15, 9, 23, 66, 13, 131, 25, 26, 12, 15, 35, 74, 23, 12, 41, 36, 70, 100, 15, 20, 275, 63, 95, 17, 56, 43, 28, 16, 48, 15, 38, 21, 33, 32, 121, 80, 9, 24, 11, 49, 120, 58, 152, 13, 57, 37, 13, 47, 26, 27, 35, 25, 16, 60, 18, 25, 22, 78, 97, 18, 9, 74, 14, 12, 60, 20, 17, 13, 14, 43, 65, 25, 28, 27, 300, 25, 11, 28, 13, 43, 32, 20, 16, 30, 19, 124, 38, 15, 13, 44, 79, 30, 15, 54, 30, 103, 93], "policy_blue_0_reward": [-1.002, -1.005, -1.001, -1.009, -1.003, -1.021, -1.003, -1.0, -1.0, -0.514, -1.003, -0.502, -0.544, -1.008, -0.5129999999999999, -1.003, -0.505, -1.004, -1.008, -1.02, -1.002, 0.9249999999999999, -1.002, -1.006, -1.014, -1.009, -1.004, -1.001, -1.004, -0.502, -1.004, -1.004, -1.0019999999999998, -1.016, -1.01, -1.0039999999999998, -1.003, -1.012, -1.001, -1.003, -1.002, -1.002, -1.005, -1.002, -1.001, -1.003, 0.611, -1.001, -1.005, 0.862, -1.005, 0.953, -1.012, -1.014], "policy_red_0_v1_reward": [-1.002, -1.001, -1.002, 0.954, 0.889, 0.962, -1.013, -1.003, -1.001, 0.694, -1.002, -1.004, -1.006, 1.451, -1.0, -0.505, -1.0, -1.002, 0.75, 0.5389999999999999, -1.0, -1.016, -1.0039999999999998, -1.006, -1.001, -1.011, -1.003, -1.013, -1.002, -1.003, -1.001, -1.003, -1.003, -0.02100000000000001, -1.006, -0.5079999999999999, 0.959, -0.502, 0.9, 0.94, 0.947, 0.94, -0.502, -1.006, -1.003, 0.899]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22869763487942346, "mean_inference_ms": 1.4966826986455675, "mean_action_processing_ms": 0.0624249971000924, "mean_env_wait_ms": 0.10551468434228767, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01946735382080078, "StateBufferConnector_ms": 0.0015511512756347656, "ViewRequirementAgentConnector_ms": 0.03192925453186035}}, "episode_reward_max": 0.45099999999999996, "episode_reward_min": -0.4700000000000001, "episode_reward_mean": -0.08046999999999997, "episode_len_mean": 44.45, "episodes_this_iter": 87, "policy_reward_min": {"blue_0": -1.021, "red_0": -1.022, "red_0_v1": -1.016}, "policy_reward_max": {"blue_0": 0.953, "red_0": 0.973, "red_0_v1": 1.451}, "policy_reward_mean": {"blue_0": -0.8142962962962963, "red_0": 0.54256, "red_0_v1": -0.3984999999999999}, "hist_stats": {"episode_reward": [-0.041000000000000036, -0.08000000000000007, -0.10299999999999998, -0.04599999999999993, -0.029000000000000026, -0.07299999999999995, -0.22299999999999986, -0.04399999999999993, -0.42700000000000005, -0.08299999999999996, -0.08199999999999996, -0.03699999999999992, -0.04800000000000004, -0.118, 0.252, -0.07499999999999996, -0.040000000000000036, -0.139, -0.11299999999999988, -0.21499999999999986, -0.32700000000000007, 0.45099999999999996, -0.06400000000000006, -0.4, -0.20199999999999996, 0.18600000000000017, -0.05500000000000005, 0.32299999999999995, -0.135, -0.09599999999999997, 0.44999999999999996, -0.15400000000000003, -0.04599999999999993, 0.375, -0.06500000000000006, -0.10799999999999987, -0.11099999999999988, -0.4039999999999999, -0.261, -0.029000000000000026, -0.08000000000000007, -0.03500000000000003, -0.16199999999999992, -0.40000000000000013, -0.19299999999999984, -0.4700000000000001, -0.041000000000000036, -0.17900000000000005, -0.133, -0.04300000000000004, -0.15799999999999992, -0.08699999999999986, -0.08599999999999985, -0.11399999999999988, 0.42000000000000004, -0.05400000000000005, -0.19600000000000006, -0.062000000000000055, -0.08399999999999985, -0.07199999999999984, -0.2609999999999999, -0.32399999999999984, -0.04800000000000004, -0.031000000000000028, -0.242, -0.04599999999999982, -0.040000000000000036, -0.19699999999999995, -0.06400000000000006, -0.05399999999999994, -0.04399999999999993, -0.04499999999999993, -0.137, -0.20399999999999996, -0.07999999999999985, -0.08099999999999996, -0.08499999999999996, -0.03500000000000003, -0.08999999999999986, -0.03399999999999992, 0.40400000000000014, -0.04200000000000004, 0.368, -0.10399999999999998, -0.062000000000000055, -0.05300000000000005, -0.10099999999999987, -0.05300000000000005, -0.41100000000000003, 0.38, -0.04599999999999993, -0.04500000000000004, -0.14800000000000002, -0.2519999999999999, -0.09799999999999975, -0.04800000000000004, -0.17000000000000004, -0.10399999999999998, -0.33499999999999996, -0.31999999999999995], "episode_lengths": [13, 24, 33, 15, 9, 23, 66, 13, 131, 25, 26, 12, 15, 35, 74, 23, 12, 41, 36, 70, 100, 15, 20, 275, 63, 95, 17, 56, 43, 28, 16, 48, 15, 38, 21, 33, 32, 121, 80, 9, 24, 11, 49, 120, 58, 152, 13, 57, 37, 13, 47, 26, 27, 35, 25, 16, 60, 18, 25, 22, 78, 97, 18, 9, 74, 14, 12, 60, 20, 17, 13, 14, 43, 65, 25, 28, 27, 300, 25, 11, 28, 13, 43, 32, 20, 16, 30, 19, 124, 38, 15, 13, 44, 79, 30, 15, 54, 30, 103, 93], "policy_blue_0_reward": [-1.002, -1.005, -1.001, -1.009, -1.003, -1.021, -1.003, -1.0, -1.0, -0.514, -1.003, -0.502, -0.544, -1.008, -0.5129999999999999, -1.003, -0.505, -1.004, -1.008, -1.02, -1.002, 0.9249999999999999, -1.002, -1.006, -1.014, -1.009, -1.004, -1.001, -1.004, -0.502, -1.004, -1.004, -1.0019999999999998, -1.016, -1.01, -1.0039999999999998, -1.003, -1.012, -1.001, -1.003, -1.002, -1.002, -1.005, -1.002, -1.001, -1.003, 0.611, -1.001, -1.005, 0.862, -1.005, 0.953, -1.012, -1.014], "policy_red_0_v1_reward": [-1.002, -1.001, -1.002, 0.954, 0.889, 0.962, -1.013, -1.003, -1.001, 0.694, -1.002, -1.004, -1.006, 1.451, -1.0, -0.505, -1.0, -1.002, 0.75, 0.5389999999999999, -1.0, -1.016, -1.0039999999999998, -1.006, -1.001, -1.011, -1.003, -1.013, -1.002, -1.003, -1.001, -1.003, -1.003, -0.02100000000000001, -1.006, -0.5079999999999999, 0.959, -0.502, 0.9, 0.94, 0.947, 0.94, -0.502, -1.006, -1.003, 0.899]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22869763487942346, "mean_inference_ms": 1.4966826986455675, "mean_action_processing_ms": 0.0624249971000924, "mean_env_wait_ms": 0.10551468434228767, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01946735382080078, "StateBufferConnector_ms": 0.0015511512756347656, "ViewRequirementAgentConnector_ms": 0.03192925453186035}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.49869600088712, "num_env_steps_trained_throughput_per_sec": 99.49869600088712, "timesteps_total": 184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 39712.516, "sample_time_ms": 7711.097, "learn_time_ms": 31983.8, "learn_throughput": 125.063, "synch_weights_time_ms": 16.935}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "episodes_total": 2512, "training_iteration": 46, "trial_id": "bb874_00000", "date": "2023-09-28_22-00-30", "timestamp": 1695952830, "time_this_iter_s": 40.204282999038696, "time_total_s": 1816.424810886383, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d24e20>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4055a0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac406f80>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1816.424810886383, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 36.77368421052631, "ram_util_percent": 27.673684210526318}, "win_rate": 0.83, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2156421739608048, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0698380223406275, "policy_loss": -0.026318528792762662, "vf_loss": 0.19005071363644674, "vf_explained_var": 0.1748872141664227, "kl": 0.011737821792389712, "entropy": 1.216370956103007, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "sampler_results": {"episode_reward_max": 0.377, "episode_reward_min": -0.634, "episode_reward_mean": -0.0873725490196078, "episode_len_mean": 35.833333333333336, "episode_media": {}, "episodes_this_iter": 102, "policy_reward_min": {"red_0_v1": -1.0139999999999998, "red_0": -1.018, "blue_0": -1.018}, "policy_reward_max": {"red_0_v1": 1.361, "red_0": 0.982, "blue_0": 0.956}, "policy_reward_mean": {"red_0_v1": -0.4488928571428571, "red_0": 0.5502254901960786, "blue_0": -0.8673260869565219}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.06200000000000005, -0.050999999999999934, -0.1309999999999999, -0.07499999999999996, -0.239, -0.11599999999999988, -0.07899999999999996, -0.03799999999999992, -0.20399999999999996, 0.26, -0.062000000000000055, -0.137, -0.22999999999999998, -0.0259999999999998, -0.05599999999999994, -0.139, -0.05300000000000005, -0.018999999999999906, -0.07400000000000007, -0.027999999999999914, -0.21099999999999997, -0.03299999999999992, -0.07100000000000006, -0.07699999999999996, -0.08899999999999986, -0.20999999999999996, -0.19599999999999973, -0.04700000000000004, -0.06400000000000006, -0.039999999999999925, -0.14, -0.24299999999999977, -0.122, 0.2749999999999999, -0.07299999999999995, -0.03300000000000003, -0.050999999999999934, -0.09599999999999975, -0.09099999999999997, -0.15000000000000002, -0.2719999999999999, -0.052000000000000046, -0.07200000000000006, -0.06700000000000006, -0.09499999999999997, -0.21799999999999997, -0.04299999999999993, -0.634, -0.05799999999999994, -0.10299999999999998, -0.12299999999999989, -0.050000000000000044, -0.04400000000000004, -0.15000000000000002, 0.377, -0.06600000000000006, -0.07200000000000006, 0.34299999999999997, -0.10799999999999987, -0.21100000000000008, -0.15799999999999992, -0.07499999999999996, -0.21899999999999986, -0.124, -0.11299999999999999, -0.129, -0.09099999999999986, -0.1299999999999999, -0.07699999999999996, -0.07299999999999995, -0.09199999999999986, -0.1529999999999999, -0.08099999999999996, -0.052000000000000046, -0.08999999999999997, -0.05399999999999994, -0.10499999999999998, -0.11699999999999999, -0.05599999999999994, -0.03200000000000003, -0.030999999999999917, -0.052999999999999936, -0.04499999999999993, -0.052999999999999936, -0.08899999999999986, -0.07799999999999996, -0.09999999999999998, -0.18600000000000005, -0.10099999999999998, -0.04899999999999993, -0.18499999999999983, -0.06799999999999995, -0.09999999999999998, -0.041000000000000036, -0.10399999999999998, -0.08599999999999997, -0.06099999999999994, -0.11499999999999999, -0.1409999999999999, -0.049000000000000044, -0.07099999999999995, -0.04600000000000004], "episode_lengths": [300, 16, 42, 22, 71, 35, 24, 11, 62, 72, 20, 45, 72, 8, 17, 45, 17, 6, 24, 9, 66, 10, 21, 23, 28, 64, 62, 15, 20, 11, 42, 75, 38, 67, 22, 10, 16, 30, 27, 50, 83, 16, 22, 20, 26, 65, 12, 194, 17, 34, 38, 15, 14, 48, 37, 20, 22, 45, 31, 65, 49, 21, 68, 38, 35, 39, 28, 37, 24, 23, 29, 46, 27, 16, 28, 17, 31, 37, 17, 10, 10, 16, 14, 16, 28, 27, 34, 57, 33, 16, 58, 21, 35, 13, 33, 26, 18, 37, 46, 19, 25, 14], "policy_red_0_v1_reward": [-0.013000000000000005, -1.002, -1.001, -0.506, 0.864, -1.0, -1.001, 0.793, -1.003, -1.003, -1.007, -1.0039999999999998, -1.002, -1.003, -1.005, -1.005, -1.005, -1.003, -0.514, -1.0, 0.968, 0.913, -1.007, 0.9329999999999999, 0.9359999999999999, 0.91, -1.007, -1.0039999999999998, -1.001, 0.894, -1.007, 0.952, 1.361, -1.011, -1.008, -1.005, 0.9329999999999999, -1.002, -1.002, -1.003, -1.0139999999999998, -1.003, -1.004, 0.951, 0.905, -1.001, -1.001, -1.003, 0.824, 0.9, -1.0, -1.006, -1.004, -1.003, -1.001, -1.001], "policy_blue_0_reward": [-1.0, -1.005, -1.009, -1.0079999999999998, -1.003, -1.009, -1.002, -1.004, -1.0019999999999998, -1.0039999999999998, -1.01, -1.002, -1.0, -1.001, -1.004, -1.002, -1.0039999999999998, -1.011, -1.004, -1.018, 0.956, -1.005, -0.504, 0.938, -1.004, -1.005, -1.005, -1.003, -1.002, -1.008, -1.004, -1.003, -1.003, -1.003, -1.0039999999999998, -1.0019999999999998, -1.003, -1.001, -1.006, -1.0, 0.897, -1.002, -1.006, -1.007, -1.002, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22897079256790676, "mean_inference_ms": 1.4974088635533935, "mean_action_processing_ms": 0.062437154622893426, "mean_env_wait_ms": 0.10556195825994014, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019023582047107173, "StateBufferConnector_ms": 0.0014648717992446002, "ViewRequirementAgentConnector_ms": 0.030962392395617915}}, "episode_reward_max": 0.377, "episode_reward_min": -0.634, "episode_reward_mean": -0.0873725490196078, "episode_len_mean": 35.833333333333336, "episodes_this_iter": 102, "policy_reward_min": {"red_0_v1": -1.0139999999999998, "red_0": -1.018, "blue_0": -1.018}, "policy_reward_max": {"red_0_v1": 1.361, "red_0": 0.982, "blue_0": 0.956}, "policy_reward_mean": {"red_0_v1": -0.4488928571428571, "red_0": 0.5502254901960786, "blue_0": -0.8673260869565219}, "hist_stats": {"episode_reward": [-0.06200000000000005, -0.050999999999999934, -0.1309999999999999, -0.07499999999999996, -0.239, -0.11599999999999988, -0.07899999999999996, -0.03799999999999992, -0.20399999999999996, 0.26, -0.062000000000000055, -0.137, -0.22999999999999998, -0.0259999999999998, -0.05599999999999994, -0.139, -0.05300000000000005, -0.018999999999999906, -0.07400000000000007, -0.027999999999999914, -0.21099999999999997, -0.03299999999999992, -0.07100000000000006, -0.07699999999999996, -0.08899999999999986, -0.20999999999999996, -0.19599999999999973, -0.04700000000000004, -0.06400000000000006, -0.039999999999999925, -0.14, -0.24299999999999977, -0.122, 0.2749999999999999, -0.07299999999999995, -0.03300000000000003, -0.050999999999999934, -0.09599999999999975, -0.09099999999999997, -0.15000000000000002, -0.2719999999999999, -0.052000000000000046, -0.07200000000000006, -0.06700000000000006, -0.09499999999999997, -0.21799999999999997, -0.04299999999999993, -0.634, -0.05799999999999994, -0.10299999999999998, -0.12299999999999989, -0.050000000000000044, -0.04400000000000004, -0.15000000000000002, 0.377, -0.06600000000000006, -0.07200000000000006, 0.34299999999999997, -0.10799999999999987, -0.21100000000000008, -0.15799999999999992, -0.07499999999999996, -0.21899999999999986, -0.124, -0.11299999999999999, -0.129, -0.09099999999999986, -0.1299999999999999, -0.07699999999999996, -0.07299999999999995, -0.09199999999999986, -0.1529999999999999, -0.08099999999999996, -0.052000000000000046, -0.08999999999999997, -0.05399999999999994, -0.10499999999999998, -0.11699999999999999, -0.05599999999999994, -0.03200000000000003, -0.030999999999999917, -0.052999999999999936, -0.04499999999999993, -0.052999999999999936, -0.08899999999999986, -0.07799999999999996, -0.09999999999999998, -0.18600000000000005, -0.10099999999999998, -0.04899999999999993, -0.18499999999999983, -0.06799999999999995, -0.09999999999999998, -0.041000000000000036, -0.10399999999999998, -0.08599999999999997, -0.06099999999999994, -0.11499999999999999, -0.1409999999999999, -0.049000000000000044, -0.07099999999999995, -0.04600000000000004], "episode_lengths": [300, 16, 42, 22, 71, 35, 24, 11, 62, 72, 20, 45, 72, 8, 17, 45, 17, 6, 24, 9, 66, 10, 21, 23, 28, 64, 62, 15, 20, 11, 42, 75, 38, 67, 22, 10, 16, 30, 27, 50, 83, 16, 22, 20, 26, 65, 12, 194, 17, 34, 38, 15, 14, 48, 37, 20, 22, 45, 31, 65, 49, 21, 68, 38, 35, 39, 28, 37, 24, 23, 29, 46, 27, 16, 28, 17, 31, 37, 17, 10, 10, 16, 14, 16, 28, 27, 34, 57, 33, 16, 58, 21, 35, 13, 33, 26, 18, 37, 46, 19, 25, 14], "policy_red_0_v1_reward": [-0.013000000000000005, -1.002, -1.001, -0.506, 0.864, -1.0, -1.001, 0.793, -1.003, -1.003, -1.007, -1.0039999999999998, -1.002, -1.003, -1.005, -1.005, -1.005, -1.003, -0.514, -1.0, 0.968, 0.913, -1.007, 0.9329999999999999, 0.9359999999999999, 0.91, -1.007, -1.0039999999999998, -1.001, 0.894, -1.007, 0.952, 1.361, -1.011, -1.008, -1.005, 0.9329999999999999, -1.002, -1.002, -1.003, -1.0139999999999998, -1.003, -1.004, 0.951, 0.905, -1.001, -1.001, -1.003, 0.824, 0.9, -1.0, -1.006, -1.004, -1.003, -1.001, -1.001], "policy_blue_0_reward": [-1.0, -1.005, -1.009, -1.0079999999999998, -1.003, -1.009, -1.002, -1.004, -1.0019999999999998, -1.0039999999999998, -1.01, -1.002, -1.0, -1.001, -1.004, -1.002, -1.0039999999999998, -1.011, -1.004, -1.018, 0.956, -1.005, -0.504, 0.938, -1.004, -1.005, -1.005, -1.003, -1.002, -1.008, -1.004, -1.003, -1.003, -1.003, -1.0039999999999998, -1.0019999999999998, -1.003, -1.001, -1.006, -1.0, 0.897, -1.002, -1.006, -1.007, -1.002, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22897079256790676, "mean_inference_ms": 1.4974088635533935, "mean_action_processing_ms": 0.062437154622893426, "mean_env_wait_ms": 0.10556195825994014, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019023582047107173, "StateBufferConnector_ms": 0.0014648717992446002, "ViewRequirementAgentConnector_ms": 0.030962392395617915}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.31681478456413, "num_env_steps_trained_throughput_per_sec": 101.31681478456413, "timesteps_total": 188000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 376000, "timers": {"training_iteration_time_ms": 39735.876, "sample_time_ms": 7718.075, "learn_time_ms": 32000.248, "learn_throughput": 124.999, "synch_weights_time_ms": 16.907}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "done": false, "episodes_total": 2614, "training_iteration": 47, "trial_id": "bb874_00000", "date": "2023-09-28_22-01-09", "timestamp": 1695952869, "time_this_iter_s": 39.483015060424805, "time_total_s": 1855.9078259468079, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d26ec0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ad625b40>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ad625fc0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1855.9078259468079, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 33.5875, "ram_util_percent": 27.564285714285713}, "win_rate": 0.8235294117647058, "league_size": 3}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.11573238906761, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06347180952343479, "policy_loss": -0.023410949733806773, "vf_loss": 0.17174637907495102, "vf_explained_var": 0.15053638219833373, "kl": 0.011213397627888729, "entropy": 1.233110128218929, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "sampler_results": {"episode_reward_max": 0.44499999999999984, "episode_reward_min": -0.503, "episode_reward_mean": -0.07247999999999998, "episode_len_mean": 43.53, "episode_media": {}, "episodes_this_iter": 94, "policy_reward_min": {"blue_0": -1.015, "red_0": -1.017, "red_0_v1": -1.0299999999999998}, "policy_reward_max": {"blue_0": 0.734, "red_0": 0.975, "red_0_v1": 1.4489999999999998}, "policy_reward_mean": {"blue_0": -0.838282608695652, "red_0": 0.60015, "red_0_v1": -0.5315185185185185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.06099999999999994, -0.11499999999999999, -0.1409999999999999, -0.049000000000000044, -0.07099999999999995, -0.04600000000000004, -0.44000000000000006, -0.503, -0.10199999999999976, -0.10199999999999998, -0.051999999999999935, -0.10999999999999988, -0.04300000000000004, -0.06399999999999995, -0.02499999999999991, -0.049000000000000044, -0.05899999999999994, -0.11599999999999999, -0.33000000000000007, -0.20700000000000007, -0.3849999999999999, -0.03500000000000003, -0.248, -0.05899999999999994, -0.04299999999999993, -0.1489999999999999, -0.040999999999999925, 0.131, -0.08800000000000008, -0.07699999999999996, -0.05699999999999994, -0.17100000000000004, -0.07199999999999984, 0.10699999999999998, -0.138, 0.367, -0.030999999999999917, -0.09399999999999997, 0.364, -0.15800000000000003, -0.05899999999999994, -0.11299999999999988, -0.08599999999999997, -0.08599999999999997, -0.03400000000000003, 0.33299999999999996, -0.030000000000000027, -0.07100000000000006, -0.10299999999999998, -0.03299999999999992, -0.06300000000000006, -0.10799999999999987, -0.04799999999999993, -0.09499999999999997, -0.07099999999999995, -0.16300000000000003, 0.18800000000000006, -0.137, -0.3930000000000001, -0.07099999999999995, -0.48099999999999987, -0.07299999999999995, 0.44499999999999984, -0.119, -0.08399999999999996, -0.03500000000000003, 0.41900000000000015, -0.123, -0.2230000000000001, -0.07299999999999995, 0.32299999999999995, -0.06499999999999995, -0.1220000000000001, -0.1559999999999998, -0.07199999999999995, -0.1259999999999999, -0.19800000000000006, -0.03399999999999992, -0.05399999999999994, -0.10399999999999998, -0.135, 0.43699999999999994, -0.07499999999999996, -0.04699999999999993, 0.391, -0.19200000000000006, -0.07800000000000007, -0.029000000000000026, -0.281, -0.10399999999999998, -0.29699999999999993, -0.11099999999999988, -0.11099999999999988, -0.04500000000000004, -0.10199999999999998, -0.19199999999999984, -0.052000000000000046, -0.1509999999999999, -0.12399999999999989, -0.19000000000000006], "episode_lengths": [18, 37, 46, 19, 25, 14, 138, 156, 28, 33, 15, 31, 14, 19, 8, 15, 18, 38, 249, 61, 116, 11, 80, 18, 12, 42, 12, 116, 24, 27, 18, 55, 23, 124, 44, 43, 10, 30, 41, 44, 18, 38, 27, 28, 11, 50, 10, 21, 36, 10, 21, 33, 18, 33, 22, 49, 95, 43, 126, 22, 144, 24, 17, 37, 26, 11, 25, 35, 73, 22, 56, 20, 300, 44, 21, 39, 56, 11, 17, 32, 43, 19, 24, 14, 32, 60, 24, 9, 84, 30, 90, 34, 36, 17, 30, 60, 17, 44, 39, 54], "policy_blue_0_reward": [-1.006, -1.007, -1.002, -1.004, -1.015, 0.512, -1.0039999999999998, -1.005, -1.004, -1.002, -0.546, -1.011, -1.014, -1.002, -1.011, -1.002, -1.003, -1.0019999999999998, -0.515, -1.003, -0.502, -1.012, -1.003, -1.0039999999999998, -1.0, -1.0, -1.003, -1.001, -1.008, -0.512, -1.006, -1.004, -0.5049999999999999, -0.504, -0.035000000000000024, -1.0099999999999998, -1.005, -1.004, -1.005, -1.004, -0.503, -1.003, 0.734, -1.006, -1.003, -1.007], "policy_red_0_v1_reward": [-1.001, -1.001, 0.9, -1.008, 0.958, -1.002, -1.0, -1.0, -1.007, -1.003, -1.001, -0.509, -1.007, -1.003, -1.002, -0.501, -1.001, 0.908, 0.918, -1.0, 0.966, 1.347, -1.002, -1.001, -1.0019999999999998, -1.005, -1.001, -1.01, -1.003, -1.0299999999999998, 1.4489999999999998, 0.885, -1.002, -1.001, -1.012, -1.008, -1.005, -1.003, -1.01, -1.0, -1.001, -1.003, -0.502, -1.003, -1.002, 0.973, 0.904, -1.012, -1.003, -1.007, -1.007, 0.949, -1.005, 0.827]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22877886579383155, "mean_inference_ms": 1.4968599189231697, "mean_action_processing_ms": 0.06239290598149143, "mean_env_wait_ms": 0.1055389586521056, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019295334815979004, "StateBufferConnector_ms": 0.0014837980270385742, "ViewRequirementAgentConnector_ms": 0.03105926513671875}}, "episode_reward_max": 0.44499999999999984, "episode_reward_min": -0.503, "episode_reward_mean": -0.07247999999999998, "episode_len_mean": 43.53, "episodes_this_iter": 94, "policy_reward_min": {"blue_0": -1.015, "red_0": -1.017, "red_0_v1": -1.0299999999999998}, "policy_reward_max": {"blue_0": 0.734, "red_0": 0.975, "red_0_v1": 1.4489999999999998}, "policy_reward_mean": {"blue_0": -0.838282608695652, "red_0": 0.60015, "red_0_v1": -0.5315185185185185}, "hist_stats": {"episode_reward": [-0.06099999999999994, -0.11499999999999999, -0.1409999999999999, -0.049000000000000044, -0.07099999999999995, -0.04600000000000004, -0.44000000000000006, -0.503, -0.10199999999999976, -0.10199999999999998, -0.051999999999999935, -0.10999999999999988, -0.04300000000000004, -0.06399999999999995, -0.02499999999999991, -0.049000000000000044, -0.05899999999999994, -0.11599999999999999, -0.33000000000000007, -0.20700000000000007, -0.3849999999999999, -0.03500000000000003, -0.248, -0.05899999999999994, -0.04299999999999993, -0.1489999999999999, -0.040999999999999925, 0.131, -0.08800000000000008, -0.07699999999999996, -0.05699999999999994, -0.17100000000000004, -0.07199999999999984, 0.10699999999999998, -0.138, 0.367, -0.030999999999999917, -0.09399999999999997, 0.364, -0.15800000000000003, -0.05899999999999994, -0.11299999999999988, -0.08599999999999997, -0.08599999999999997, -0.03400000000000003, 0.33299999999999996, -0.030000000000000027, -0.07100000000000006, -0.10299999999999998, -0.03299999999999992, -0.06300000000000006, -0.10799999999999987, -0.04799999999999993, -0.09499999999999997, -0.07099999999999995, -0.16300000000000003, 0.18800000000000006, -0.137, -0.3930000000000001, -0.07099999999999995, -0.48099999999999987, -0.07299999999999995, 0.44499999999999984, -0.119, -0.08399999999999996, -0.03500000000000003, 0.41900000000000015, -0.123, -0.2230000000000001, -0.07299999999999995, 0.32299999999999995, -0.06499999999999995, -0.1220000000000001, -0.1559999999999998, -0.07199999999999995, -0.1259999999999999, -0.19800000000000006, -0.03399999999999992, -0.05399999999999994, -0.10399999999999998, -0.135, 0.43699999999999994, -0.07499999999999996, -0.04699999999999993, 0.391, -0.19200000000000006, -0.07800000000000007, -0.029000000000000026, -0.281, -0.10399999999999998, -0.29699999999999993, -0.11099999999999988, -0.11099999999999988, -0.04500000000000004, -0.10199999999999998, -0.19199999999999984, -0.052000000000000046, -0.1509999999999999, -0.12399999999999989, -0.19000000000000006], "episode_lengths": [18, 37, 46, 19, 25, 14, 138, 156, 28, 33, 15, 31, 14, 19, 8, 15, 18, 38, 249, 61, 116, 11, 80, 18, 12, 42, 12, 116, 24, 27, 18, 55, 23, 124, 44, 43, 10, 30, 41, 44, 18, 38, 27, 28, 11, 50, 10, 21, 36, 10, 21, 33, 18, 33, 22, 49, 95, 43, 126, 22, 144, 24, 17, 37, 26, 11, 25, 35, 73, 22, 56, 20, 300, 44, 21, 39, 56, 11, 17, 32, 43, 19, 24, 14, 32, 60, 24, 9, 84, 30, 90, 34, 36, 17, 30, 60, 17, 44, 39, 54], "policy_blue_0_reward": [-1.006, -1.007, -1.002, -1.004, -1.015, 0.512, -1.0039999999999998, -1.005, -1.004, -1.002, -0.546, -1.011, -1.014, -1.002, -1.011, -1.002, -1.003, -1.0019999999999998, -0.515, -1.003, -0.502, -1.012, -1.003, -1.0039999999999998, -1.0, -1.0, -1.003, -1.001, -1.008, -0.512, -1.006, -1.004, -0.5049999999999999, -0.504, -0.035000000000000024, -1.0099999999999998, -1.005, -1.004, -1.005, -1.004, -0.503, -1.003, 0.734, -1.006, -1.003, -1.007], "policy_red_0_v1_reward": [-1.001, -1.001, 0.9, -1.008, 0.958, -1.002, -1.0, -1.0, -1.007, -1.003, -1.001, -0.509, -1.007, -1.003, -1.002, -0.501, -1.001, 0.908, 0.918, -1.0, 0.966, 1.347, -1.002, -1.001, -1.0019999999999998, -1.005, -1.001, -1.01, -1.003, -1.0299999999999998, 1.4489999999999998, 0.885, -1.002, -1.001, -1.012, -1.008, -1.005, -1.003, -1.01, -1.0, -1.001, -1.003, -0.502, -1.003, -1.002, 0.973, 0.904, -1.012, -1.003, -1.007, -1.007, 0.949, -1.005, 0.827]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22877886579383155, "mean_inference_ms": 1.4968599189231697, "mean_action_processing_ms": 0.06239290598149143, "mean_env_wait_ms": 0.1055389586521056, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019295334815979004, "StateBufferConnector_ms": 0.0014837980270385742, "ViewRequirementAgentConnector_ms": 0.03105926513671875}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.6637629917763, "num_env_steps_trained_throughput_per_sec": 101.6637629917763, "timesteps_total": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 39732.836, "sample_time_ms": 7718.806, "learn_time_ms": 31996.434, "learn_throughput": 125.014, "synch_weights_time_ms": 16.987}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "episodes_total": 2708, "training_iteration": 48, "trial_id": "bb874_00000", "date": "2023-09-28_22-01-49", "timestamp": 1695952909, "time_this_iter_s": 39.34817290306091, "time_total_s": 1895.2559988498688, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355093e50>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac755000>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac755240>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1895.2559988498688, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 34.69285714285714, "ram_util_percent": 27.55535714285714}, "win_rate": 0.86, "league_size": 4}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0954708052178224, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0503927205876001, "policy_loss": -0.02705248528169856, "vf_loss": 0.15276023492915555, "vf_explained_var": 0.20209673612068096, "kl": 0.011220390445366017, "entropy": 1.1789896295716364, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "sampler_results": {"episode_reward_max": 0.46599999999999997, "episode_reward_min": -0.6300000000000001, "episode_reward_mean": -0.06380999999999998, "episode_len_mean": 41.65, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"red_0_v1": -1.013, "red_0": -1.007, "blue_0": -1.017, "red_0_v2": -1.056}, "policy_reward_max": {"red_0_v1": 1.389, "red_0": 0.986, "blue_0": 1.391, "red_0_v2": 1.3479999999999999}, "policy_reward_mean": {"red_0_v1": -0.7524399999999999, "red_0": 0.62248, "blue_0": -0.8165087719298245, "red_0_v2": -0.18205555555555553}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.11099999999999988, -0.05300000000000005, -0.038999999999999924, -0.04400000000000004, -0.6300000000000001, -0.21799999999999997, 0.3839999999999999, -0.11399999999999999, -0.02400000000000002, -0.15599999999999992, -0.29999999999999993, -0.030999999999999917, -0.08099999999999985, -0.042999999999999816, -0.18399999999999994, -0.32499999999999996, -0.2879999999999999, -0.07699999999999985, -0.18200000000000005, -0.21999999999999997, -0.05899999999999994, -0.1489999999999999, -0.061000000000000054, -0.029000000000000026, -0.07100000000000006, 0.46599999999999997, -0.07600000000000007, -0.09299999999999997, -0.12199999999999989, -0.08299999999999996, -0.039999999999999813, -0.03399999999999992, -0.17100000000000004, -0.10199999999999998, -0.05399999999999994, -0.1339999999999999, -0.05999999999999994, -0.12299999999999989, -0.040999999999999925, 0.43899999999999995, -0.08899999999999997, 0.346, -0.06500000000000006, -0.08699999999999986, -0.014000000000000012, -0.3330000000000001, -0.06300000000000006, -0.07100000000000006, -0.05900000000000005, -0.07699999999999996, 0.347, -0.20899999999999985, -0.08899999999999975, -0.04800000000000004, 0.3799999999999999, -0.3819999999999999, -0.10999999999999988, -0.08399999999999996, -0.028000000000000025, -0.03599999999999992, -0.122, 0.27, -0.02100000000000002, -0.041000000000000036, -0.04499999999999993, -0.10899999999999999, -0.038000000000000034, -0.258, -0.09199999999999986, -0.5510000000000002, 0.34099999999999997, -0.19900000000000007, -0.08899999999999986, -0.04500000000000004, -0.11699999999999999, -0.05399999999999994, -0.08599999999999974, -0.1160000000000001, -0.20999999999999996, -0.131, -0.040000000000000036, -0.08399999999999996, -0.06299999999999983, -0.14100000000000001, -0.10799999999999998, -0.08300000000000007, -0.08399999999999996, 0.356, -0.03700000000000003, 0.3820000000000001, -0.15500000000000003, -0.03599999999999992, -0.1479999999999999, -0.062000000000000055, -0.05800000000000005, -0.06600000000000006, 0.32399999999999995, -0.11699999999999999, -0.06900000000000006, -0.275], "episode_lengths": [32, 20, 12, 14, 180, 64, 35, 34, 8, 45, 94, 10, 28, 13, 53, 96, 91, 28, 56, 69, 18, 46, 19, 12, 21, 11, 24, 31, 37, 23, 12, 11, 53, 32, 17, 41, 19, 40, 12, 19, 27, 44, 21, 28, 8, 106, 19, 21, 17, 24, 47, 62, 23, 16, 300, 117, 35, 26, 9, 11, 38, 70, 7, 13, 14, 33, 12, 80, 29, 159, 48, 61, 28, 17, 33, 17, 26, 300, 63, 41, 12, 26, 19, 43, 32, 24, 29, 42, 14, 37, 47, 11, 49, 20, 18, 20, 53, 35, 21, 83], "policy_red_0_v1_reward": [-1.0039999999999998, -1.002, -1.0, -1.003, -1.0, -1.002, -1.002, -1.002, -1.001, -1.0, -1.002, -1.007, -1.002, -1.013, 0.92, -1.002, -1.0, -1.001, -1.005, -1.002, 1.389, -1.002, 0.944, -1.003, -1.009], "policy_blue_0_reward": [-1.002, 1.391, -1.0, -1.007, 0.707, -1.0039999999999998, -1.0039999999999998, -1.007, -1.017, -1.015, -1.004, -1.003, -1.009, -1.001, -0.501, -1.001, -1.001, -1.001, -1.005, -1.003, -1.0039999999999998, -1.003, -1.003, -0.502, -1.004, -0.51, -1.003, 0.6719999999999999, -1.003, -1.01, 0.46599999999999997, -1.004, -1.001, -1.004, -1.001, -1.006, -1.001, -1.012, -1.003, -0.51, -1.006, -1.002, -1.006, -1.003, -1.0039999999999998, -0.046000000000000034, -1.004, -1.003, -1.005, -1.005, -1.001, -0.503, -1.006, -1.007, -1.001, -1.005, -1.001], "policy_red_0_v2_reward": [-1.003, -1.002, -1.056, -1.02, 0.819, -1.005, 0.919, -1.006, 1.3479999999999999, -1.0179999999999998, 0.945, 0.973, -0.508, 0.979, -1.048, -1.001, 0.9189999999999999, -0.512]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22917362106289774, "mean_inference_ms": 1.4976535339232862, "mean_action_processing_ms": 0.062409017738119237, "mean_env_wait_ms": 0.10561828290702774, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019016504287719727, "StateBufferConnector_ms": 0.0014603137969970703, "ViewRequirementAgentConnector_ms": 0.03100597858428955}}, "episode_reward_max": 0.46599999999999997, "episode_reward_min": -0.6300000000000001, "episode_reward_mean": -0.06380999999999998, "episode_len_mean": 41.65, "episodes_this_iter": 100, "policy_reward_min": {"red_0_v1": -1.013, "red_0": -1.007, "blue_0": -1.017, "red_0_v2": -1.056}, "policy_reward_max": {"red_0_v1": 1.389, "red_0": 0.986, "blue_0": 1.391, "red_0_v2": 1.3479999999999999}, "policy_reward_mean": {"red_0_v1": -0.7524399999999999, "red_0": 0.62248, "blue_0": -0.8165087719298245, "red_0_v2": -0.18205555555555553}, "hist_stats": {"episode_reward": [-0.11099999999999988, -0.05300000000000005, -0.038999999999999924, -0.04400000000000004, -0.6300000000000001, -0.21799999999999997, 0.3839999999999999, -0.11399999999999999, -0.02400000000000002, -0.15599999999999992, -0.29999999999999993, -0.030999999999999917, -0.08099999999999985, -0.042999999999999816, -0.18399999999999994, -0.32499999999999996, -0.2879999999999999, -0.07699999999999985, -0.18200000000000005, -0.21999999999999997, -0.05899999999999994, -0.1489999999999999, -0.061000000000000054, -0.029000000000000026, -0.07100000000000006, 0.46599999999999997, -0.07600000000000007, -0.09299999999999997, -0.12199999999999989, -0.08299999999999996, -0.039999999999999813, -0.03399999999999992, -0.17100000000000004, -0.10199999999999998, -0.05399999999999994, -0.1339999999999999, -0.05999999999999994, -0.12299999999999989, -0.040999999999999925, 0.43899999999999995, -0.08899999999999997, 0.346, -0.06500000000000006, -0.08699999999999986, -0.014000000000000012, -0.3330000000000001, -0.06300000000000006, -0.07100000000000006, -0.05900000000000005, -0.07699999999999996, 0.347, -0.20899999999999985, -0.08899999999999975, -0.04800000000000004, 0.3799999999999999, -0.3819999999999999, -0.10999999999999988, -0.08399999999999996, -0.028000000000000025, -0.03599999999999992, -0.122, 0.27, -0.02100000000000002, -0.041000000000000036, -0.04499999999999993, -0.10899999999999999, -0.038000000000000034, -0.258, -0.09199999999999986, -0.5510000000000002, 0.34099999999999997, -0.19900000000000007, -0.08899999999999986, -0.04500000000000004, -0.11699999999999999, -0.05399999999999994, -0.08599999999999974, -0.1160000000000001, -0.20999999999999996, -0.131, -0.040000000000000036, -0.08399999999999996, -0.06299999999999983, -0.14100000000000001, -0.10799999999999998, -0.08300000000000007, -0.08399999999999996, 0.356, -0.03700000000000003, 0.3820000000000001, -0.15500000000000003, -0.03599999999999992, -0.1479999999999999, -0.062000000000000055, -0.05800000000000005, -0.06600000000000006, 0.32399999999999995, -0.11699999999999999, -0.06900000000000006, -0.275], "episode_lengths": [32, 20, 12, 14, 180, 64, 35, 34, 8, 45, 94, 10, 28, 13, 53, 96, 91, 28, 56, 69, 18, 46, 19, 12, 21, 11, 24, 31, 37, 23, 12, 11, 53, 32, 17, 41, 19, 40, 12, 19, 27, 44, 21, 28, 8, 106, 19, 21, 17, 24, 47, 62, 23, 16, 300, 117, 35, 26, 9, 11, 38, 70, 7, 13, 14, 33, 12, 80, 29, 159, 48, 61, 28, 17, 33, 17, 26, 300, 63, 41, 12, 26, 19, 43, 32, 24, 29, 42, 14, 37, 47, 11, 49, 20, 18, 20, 53, 35, 21, 83], "policy_red_0_v1_reward": [-1.0039999999999998, -1.002, -1.0, -1.003, -1.0, -1.002, -1.002, -1.002, -1.001, -1.0, -1.002, -1.007, -1.002, -1.013, 0.92, -1.002, -1.0, -1.001, -1.005, -1.002, 1.389, -1.002, 0.944, -1.003, -1.009], "policy_blue_0_reward": [-1.002, 1.391, -1.0, -1.007, 0.707, -1.0039999999999998, -1.0039999999999998, -1.007, -1.017, -1.015, -1.004, -1.003, -1.009, -1.001, -0.501, -1.001, -1.001, -1.001, -1.005, -1.003, -1.0039999999999998, -1.003, -1.003, -0.502, -1.004, -0.51, -1.003, 0.6719999999999999, -1.003, -1.01, 0.46599999999999997, -1.004, -1.001, -1.004, -1.001, -1.006, -1.001, -1.012, -1.003, -0.51, -1.006, -1.002, -1.006, -1.003, -1.0039999999999998, -0.046000000000000034, -1.004, -1.003, -1.005, -1.005, -1.001, -0.503, -1.006, -1.007, -1.001, -1.005, -1.001], "policy_red_0_v2_reward": [-1.003, -1.002, -1.056, -1.02, 0.819, -1.005, 0.919, -1.006, 1.3479999999999999, -1.0179999999999998, 0.945, 0.973, -0.508, 0.979, -1.048, -1.001, 0.9189999999999999, -0.512]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22917362106289774, "mean_inference_ms": 1.4976535339232862, "mean_action_processing_ms": 0.062409017738119237, "mean_env_wait_ms": 0.10561828290702774, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019016504287719727, "StateBufferConnector_ms": 0.0014603137969970703, "ViewRequirementAgentConnector_ms": 0.03100597858428955}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.10714849553783, "num_env_steps_trained_throughput_per_sec": 101.10714849553783, "timesteps_total": 196000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 392000, "timers": {"training_iteration_time_ms": 39750.151, "sample_time_ms": 7713.079, "learn_time_ms": 32019.408, "learn_throughput": 124.924, "synch_weights_time_ms": 17.055}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "done": false, "episodes_total": 2808, "training_iteration": 49, "trial_id": "bb874_00000", "date": "2023-09-28_22-02-28", "timestamp": 1695952948, "time_this_iter_s": 39.5648980140686, "time_total_s": 1934.8208968639374, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab3173a0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70e950>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70f250>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1934.8208968639374, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 33.739285714285714, "ram_util_percent": 27.66428571428571}, "win_rate": 0.86, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.207722186173002, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07476967234409433, "policy_loss": -0.023650311222687983, "vf_loss": 0.19405500089439254, "vf_explained_var": 0.1631064208224416, "kl": 0.012905082830595157, "entropy": 1.1885324340313672, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "sampler_results": {"episode_reward_max": 0.46199999999999997, "episode_reward_min": -0.9220000000000003, "episode_reward_mean": -0.08612999999999998, "episode_len_mean": 46.82, "episode_media": {}, "episodes_this_iter": 76, "policy_reward_min": {"blue_0": -1.026, "red_0": -1.0299999999999998, "red_0_v1": -1.009, "red_0_v2": -1.066, "red_0_v3": -1.016}, "policy_reward_max": {"blue_0": -0.046000000000000034, "red_0": 0.975, "red_0_v1": 1.389, "red_0_v2": 1.326, "red_0_v3": 1.463}, "policy_reward_mean": {"blue_0": -0.930282608695652, "red_0": 0.3830800000000001, "red_0_v1": -0.4952857142857144, "red_0_v2": 0.07652941176470586, "red_0_v3": 0.31074999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.08599999999999974, -0.1160000000000001, -0.20999999999999996, -0.131, -0.040000000000000036, -0.08399999999999996, -0.06299999999999983, -0.14100000000000001, -0.10799999999999998, -0.08300000000000007, -0.08399999999999996, 0.356, -0.03700000000000003, 0.3820000000000001, -0.15500000000000003, -0.03599999999999992, -0.1479999999999999, -0.062000000000000055, -0.05800000000000005, -0.06600000000000006, 0.32399999999999995, -0.11699999999999999, -0.06900000000000006, -0.275, -0.06699999999999995, -0.08899999999999997, -0.049000000000000044, -0.3560000000000001, -0.123, -0.09899999999999998, -0.10099999999999987, -0.07099999999999995, -0.09999999999999976, -0.04300000000000004, 0.33299999999999996, -0.049000000000000044, 0.22199999999999998, -0.05800000000000005, -0.12499999999999989, -0.04600000000000004, -0.08599999999999997, -0.32600000000000007, -0.14100000000000001, -0.06299999999999994, -0.9220000000000003, -0.133, -0.11799999999999988, -0.04599999999999982, -0.06799999999999995, -0.04699999999999993, -0.06500000000000006, -0.038000000000000034, -0.14600000000000002, -0.18800000000000006, -0.19300000000000006, -0.383, -0.04300000000000004, -0.029000000000000026, -0.2340000000000001, -0.09599999999999997, -0.08199999999999985, -0.03600000000000003, -0.04799999999999993, -0.1289999999999999, 0.46199999999999997, -0.026000000000000023, -0.21300000000000008, -0.03599999999999992, -0.06399999999999995, -0.727, 0.15100000000000013, -0.02499999999999991, -0.514, -0.16100000000000014, -0.1479999999999999, -0.20299999999999985, -0.05600000000000005, -0.13, -0.05800000000000005, -0.05600000000000005, -0.16300000000000003, 0.32299999999999995, 0.3550000000000001, -0.10499999999999998, -0.08200000000000007, -0.11599999999999999, -0.19800000000000006, 0.44699999999999995, -0.698, -0.11199999999999999, -0.07799999999999985, -0.09299999999999997, -0.06299999999999983, 0.41500000000000004, -0.07399999999999984, -0.08100000000000007, -0.027000000000000024, -0.499, -0.031000000000000028, -0.34099999999999997], "episode_lengths": [26, 300, 63, 41, 12, 26, 19, 43, 32, 24, 29, 42, 14, 37, 47, 11, 49, 20, 18, 20, 53, 35, 21, 83, 20, 26, 13, 112, 37, 29, 32, 23, 30, 13, 51, 15, 79, 17, 34, 13, 26, 96, 41, 20, 273, 44, 39, 14, 25, 15, 21, 12, 42, 57, 55, 115, 17, 9, 69, 30, 25, 10, 15, 36, 11, 11, 53, 11, 19, 224, 105, 8, 153, 201, 45, 62, 18, 40, 18, 16, 51, 54, 45, 33, 22, 38, 48, 16, 208, 38, 23, 32, 23, 26, 23, 22, 8, 146, 12, 104], "policy_blue_0_reward": [-1.0039999999999998, -0.046000000000000034, -1.004, -1.003, -1.005, -1.005, -1.001, -0.503, -1.006, -1.007, -1.001, -1.005, -1.001, -1.004, -1.003, -1.003, -1.0039999999999998, -1.001, -0.512, -1.005, -1.001, -1.0039999999999998, -1.001, -1.008, -1.017, -1.0, -1.005, -1.004, -1.005, -1.002, -1.003, -0.5169999999999999, -1.026, -1.013, -1.002, -1.004, -1.005, -1.0, -0.503, -1.005, -1.004, -1.003, -0.504, -1.003, -1.022, -1.009], "policy_red_0_v1_reward": [-1.0, -1.001, -1.005, -1.002, 1.389, -1.002, 0.944, -1.003, -1.009, -1.002, -1.001, -1.001, 0.954, -1.0, -1.001, -0.506, -1.006, -1.002, -1.003, 0.882, 0.974], "policy_red_0_v2_reward": [0.9189999999999999, -0.512, 0.903, 0.952, 0.955, -1.03, -1.066, 0.8059999999999999, -1.005, 0.8069999999999999, -1.044, -1.0, 0.876, 1.326, -0.5059999999999999, -1.04, 0.96], "policy_red_0_v3_reward": [0.6509999999999999, -1.006, 1.335, 0.952, 0.942, -1.016, -1.006, 0.858, 0.819, 0.7709999999999999, -1.003, 1.463, 0.966, -1.006, 0.33199999999999996, 0.9199999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22922469579717103, "mean_inference_ms": 1.4978208131977806, "mean_action_processing_ms": 0.062438916472437676, "mean_env_wait_ms": 0.10565928550255275, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018802762031555176, "StateBufferConnector_ms": 0.0014437437057495117, "ViewRequirementAgentConnector_ms": 0.03094923496246338}}, "episode_reward_max": 0.46199999999999997, "episode_reward_min": -0.9220000000000003, "episode_reward_mean": -0.08612999999999998, "episode_len_mean": 46.82, "episodes_this_iter": 76, "policy_reward_min": {"blue_0": -1.026, "red_0": -1.0299999999999998, "red_0_v1": -1.009, "red_0_v2": -1.066, "red_0_v3": -1.016}, "policy_reward_max": {"blue_0": -0.046000000000000034, "red_0": 0.975, "red_0_v1": 1.389, "red_0_v2": 1.326, "red_0_v3": 1.463}, "policy_reward_mean": {"blue_0": -0.930282608695652, "red_0": 0.3830800000000001, "red_0_v1": -0.4952857142857144, "red_0_v2": 0.07652941176470586, "red_0_v3": 0.31074999999999997}, "hist_stats": {"episode_reward": [-0.08599999999999974, -0.1160000000000001, -0.20999999999999996, -0.131, -0.040000000000000036, -0.08399999999999996, -0.06299999999999983, -0.14100000000000001, -0.10799999999999998, -0.08300000000000007, -0.08399999999999996, 0.356, -0.03700000000000003, 0.3820000000000001, -0.15500000000000003, -0.03599999999999992, -0.1479999999999999, -0.062000000000000055, -0.05800000000000005, -0.06600000000000006, 0.32399999999999995, -0.11699999999999999, -0.06900000000000006, -0.275, -0.06699999999999995, -0.08899999999999997, -0.049000000000000044, -0.3560000000000001, -0.123, -0.09899999999999998, -0.10099999999999987, -0.07099999999999995, -0.09999999999999976, -0.04300000000000004, 0.33299999999999996, -0.049000000000000044, 0.22199999999999998, -0.05800000000000005, -0.12499999999999989, -0.04600000000000004, -0.08599999999999997, -0.32600000000000007, -0.14100000000000001, -0.06299999999999994, -0.9220000000000003, -0.133, -0.11799999999999988, -0.04599999999999982, -0.06799999999999995, -0.04699999999999993, -0.06500000000000006, -0.038000000000000034, -0.14600000000000002, -0.18800000000000006, -0.19300000000000006, -0.383, -0.04300000000000004, -0.029000000000000026, -0.2340000000000001, -0.09599999999999997, -0.08199999999999985, -0.03600000000000003, -0.04799999999999993, -0.1289999999999999, 0.46199999999999997, -0.026000000000000023, -0.21300000000000008, -0.03599999999999992, -0.06399999999999995, -0.727, 0.15100000000000013, -0.02499999999999991, -0.514, -0.16100000000000014, -0.1479999999999999, -0.20299999999999985, -0.05600000000000005, -0.13, -0.05800000000000005, -0.05600000000000005, -0.16300000000000003, 0.32299999999999995, 0.3550000000000001, -0.10499999999999998, -0.08200000000000007, -0.11599999999999999, -0.19800000000000006, 0.44699999999999995, -0.698, -0.11199999999999999, -0.07799999999999985, -0.09299999999999997, -0.06299999999999983, 0.41500000000000004, -0.07399999999999984, -0.08100000000000007, -0.027000000000000024, -0.499, -0.031000000000000028, -0.34099999999999997], "episode_lengths": [26, 300, 63, 41, 12, 26, 19, 43, 32, 24, 29, 42, 14, 37, 47, 11, 49, 20, 18, 20, 53, 35, 21, 83, 20, 26, 13, 112, 37, 29, 32, 23, 30, 13, 51, 15, 79, 17, 34, 13, 26, 96, 41, 20, 273, 44, 39, 14, 25, 15, 21, 12, 42, 57, 55, 115, 17, 9, 69, 30, 25, 10, 15, 36, 11, 11, 53, 11, 19, 224, 105, 8, 153, 201, 45, 62, 18, 40, 18, 16, 51, 54, 45, 33, 22, 38, 48, 16, 208, 38, 23, 32, 23, 26, 23, 22, 8, 146, 12, 104], "policy_blue_0_reward": [-1.0039999999999998, -0.046000000000000034, -1.004, -1.003, -1.005, -1.005, -1.001, -0.503, -1.006, -1.007, -1.001, -1.005, -1.001, -1.004, -1.003, -1.003, -1.0039999999999998, -1.001, -0.512, -1.005, -1.001, -1.0039999999999998, -1.001, -1.008, -1.017, -1.0, -1.005, -1.004, -1.005, -1.002, -1.003, -0.5169999999999999, -1.026, -1.013, -1.002, -1.004, -1.005, -1.0, -0.503, -1.005, -1.004, -1.003, -0.504, -1.003, -1.022, -1.009], "policy_red_0_v1_reward": [-1.0, -1.001, -1.005, -1.002, 1.389, -1.002, 0.944, -1.003, -1.009, -1.002, -1.001, -1.001, 0.954, -1.0, -1.001, -0.506, -1.006, -1.002, -1.003, 0.882, 0.974], "policy_red_0_v2_reward": [0.9189999999999999, -0.512, 0.903, 0.952, 0.955, -1.03, -1.066, 0.8059999999999999, -1.005, 0.8069999999999999, -1.044, -1.0, 0.876, 1.326, -0.5059999999999999, -1.04, 0.96], "policy_red_0_v3_reward": [0.6509999999999999, -1.006, 1.335, 0.952, 0.942, -1.016, -1.006, 0.858, 0.819, 0.7709999999999999, -1.003, 1.463, 0.966, -1.006, 0.33199999999999996, 0.9199999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22922469579717103, "mean_inference_ms": 1.4978208131977806, "mean_action_processing_ms": 0.062438916472437676, "mean_env_wait_ms": 0.10565928550255275, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018802762031555176, "StateBufferConnector_ms": 0.0014437437057495117, "ViewRequirementAgentConnector_ms": 0.03094923496246338}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.68460067310133, "num_env_steps_trained_throughput_per_sec": 101.68460067310133, "timesteps_total": 200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 39658.982, "sample_time_ms": 7709.149, "learn_time_ms": 31932.185, "learn_throughput": 125.265, "synch_weights_time_ms": 17.039}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 2884, "training_iteration": 50, "trial_id": "bb874_00000", "date": "2023-09-28_22-03-08", "timestamp": 1695952988, "time_this_iter_s": 39.34005308151245, "time_total_s": 1974.1609499454498, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f3ded0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac405990>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac406cb0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1974.1609499454498, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 34.48947368421053, "ram_util_percent": 27.636842105263156}, "win_rate": 0.75, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2977774262428285, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0791060246238582, "policy_loss": -0.026783541458523057, "vf_loss": 0.208318524955151, "vf_explained_var": 0.11227250577261051, "kl": 0.014592079428801752, "entropy": 1.1881124431888261, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "sampler_results": {"episode_reward_max": 0.45399999999999996, "episode_reward_min": -0.8510000000000001, "episode_reward_mean": -0.08587999999999997, "episode_len_mean": 47.66, "episode_media": {}, "episodes_this_iter": 84, "policy_reward_min": {"red_0_v3": -1.037, "red_0": -1.0299999999999998, "blue_0": -1.035, "red_0_v2": -1.04, "red_0_v1": -1.016}, "policy_reward_max": {"red_0_v3": 0.96, "red_0": 0.978, "blue_0": 0.794, "red_0_v2": 1.458, "red_0_v1": 0.975}, "policy_reward_mean": {"red_0_v3": -0.24513333333333334, "red_0": 0.35875, "blue_0": -0.8153999999999999, "red_0_v2": 0.1215882352941177, "red_0_v1": -0.11572222222222218}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.08200000000000007, -0.11599999999999999, -0.19800000000000006, 0.44699999999999995, -0.698, -0.11199999999999999, -0.07799999999999985, -0.09299999999999997, -0.06299999999999983, 0.41500000000000004, -0.07399999999999984, -0.08100000000000007, -0.027000000000000024, -0.499, -0.031000000000000028, -0.34099999999999997, -0.6250000000000001, 0.42000000000000004, -0.025000000000000022, -0.19900000000000007, -0.03500000000000003, -0.04700000000000004, -0.3920000000000001, -0.03200000000000003, -0.05399999999999994, -0.2779999999999999, -0.038000000000000034, -0.02199999999999991, -0.05800000000000005, -0.11099999999999999, -0.062000000000000055, -0.08599999999999997, -0.041000000000000036, -0.03500000000000003, -0.22699999999999987, -0.8510000000000001, -0.12, -0.05799999999999994, -0.30600000000000005, -0.1269999999999999, -0.039000000000000035, -0.07199999999999984, -0.3629999999999999, -0.126, -0.04200000000000004, -0.15799999999999992, -0.04699999999999993, -0.062000000000000055, 0.356, -0.05599999999999994, -0.14700000000000002, -0.09799999999999998, -0.09399999999999986, -0.029999999999999916, -0.04499999999999993, -0.10700000000000008, -0.06400000000000006, -0.06700000000000006, -0.09799999999999986, -0.18099999999999994, 0.3930000000000001, -0.04700000000000004, -0.20300000000000007, 0.247, -0.08299999999999985, 0.253, -0.17199999999999982, -0.12, -0.11399999999999988, 0.45399999999999996, -0.21899999999999997, -0.18599999999999994, -0.07900000000000007, 0.45199999999999996, -0.4199999999999998, -0.06900000000000006, -0.18899999999999983, -0.1479999999999999, -0.14600000000000002, -0.14900000000000002, -0.18499999999999983, -0.07999999999999985, -0.05499999999999994, -0.17100000000000004, 0.44299999999999995, -0.04799999999999993, -0.21699999999999997, -0.43200000000000005, -0.06000000000000005, -0.06899999999999995, 0.352, -0.06500000000000006, -0.22799999999999998, -0.04200000000000004, -0.18899999999999995, -0.10600000000000008, -0.07899999999999996, -0.09099999999999997, -0.10699999999999998, -0.03399999999999992], "episode_lengths": [22, 38, 48, 16, 208, 38, 23, 32, 23, 26, 23, 22, 8, 146, 12, 104, 195, 25, 8, 63, 11, 15, 111, 10, 17, 79, 14, 7, 18, 36, 20, 27, 12, 11, 68, 251, 37, 17, 81, 40, 11, 23, 116, 34, 16, 43, 14, 20, 43, 17, 42, 30, 29, 9, 14, 300, 20, 19, 31, 54, 34, 13, 61, 66, 26, 70, 52, 34, 33, 13, 68, 59, 24, 15, 126, 21, 58, 45, 49, 45, 58, 25, 16, 47, 18, 15, 66, 131, 18, 23, 46, 17, 66, 13, 52, 300, 25, 27, 33, 11], "policy_red_0_v3_reward": [-1.006, 0.33199999999999996, 0.9199999999999999, -1.037, 0.96, -1.021, -1.003, -1.014, -0.535, 0.884, -1.004, -1.003, 0.959, 0.904, -1.013], "policy_blue_0_reward": [-1.0, -0.503, -1.005, -1.004, -1.003, -0.504, -1.003, -1.022, -1.009, -1.0279999999999998, -0.502, -1.009, -1.0, -1.001, -1.012, -1.035, -1.004, -1.005, -1.003, -1.001, -1.0, -0.505, -1.003, -1.005, -1.004, -1.0, -0.04000000000000003, -1.001, -0.5019999999999999, -1.011, -1.002, -0.506, -1.008, 0.789, -0.502, -1.017, -1.011, -1.01, -1.005, -1.007, -1.007, -1.003, -1.002, 0.794, -1.001, -1.004, -0.503, -0.037000000000000026, -1.003, -1.001], "policy_red_0_v2_reward": [-1.04, 0.96, -1.037, 0.916, 0.965, 0.715, 0.963, -1.017, 0.882, 0.863, 0.9329999999999999, -1.013, 1.458, 0.578, -1.011, -1.019, -1.029], "policy_red_0_v1_reward": [0.882, 0.974, 0.975, 0.967, -1.0, -1.002, -1.002, 0.954, -1.002, 0.892, 0.885, -1.004, -1.003, -1.005, 0.9249999999999999, -1.001, -1.016, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22925536942058852, "mean_inference_ms": 1.4972904093913042, "mean_action_processing_ms": 0.06239951484726029, "mean_env_wait_ms": 0.10560950260957584, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01929032802581787, "StateBufferConnector_ms": 0.0014737844467163086, "ViewRequirementAgentConnector_ms": 0.031154394149780273}}, "episode_reward_max": 0.45399999999999996, "episode_reward_min": -0.8510000000000001, "episode_reward_mean": -0.08587999999999997, "episode_len_mean": 47.66, "episodes_this_iter": 84, "policy_reward_min": {"red_0_v3": -1.037, "red_0": -1.0299999999999998, "blue_0": -1.035, "red_0_v2": -1.04, "red_0_v1": -1.016}, "policy_reward_max": {"red_0_v3": 0.96, "red_0": 0.978, "blue_0": 0.794, "red_0_v2": 1.458, "red_0_v1": 0.975}, "policy_reward_mean": {"red_0_v3": -0.24513333333333334, "red_0": 0.35875, "blue_0": -0.8153999999999999, "red_0_v2": 0.1215882352941177, "red_0_v1": -0.11572222222222218}, "hist_stats": {"episode_reward": [-0.08200000000000007, -0.11599999999999999, -0.19800000000000006, 0.44699999999999995, -0.698, -0.11199999999999999, -0.07799999999999985, -0.09299999999999997, -0.06299999999999983, 0.41500000000000004, -0.07399999999999984, -0.08100000000000007, -0.027000000000000024, -0.499, -0.031000000000000028, -0.34099999999999997, -0.6250000000000001, 0.42000000000000004, -0.025000000000000022, -0.19900000000000007, -0.03500000000000003, -0.04700000000000004, -0.3920000000000001, -0.03200000000000003, -0.05399999999999994, -0.2779999999999999, -0.038000000000000034, -0.02199999999999991, -0.05800000000000005, -0.11099999999999999, -0.062000000000000055, -0.08599999999999997, -0.041000000000000036, -0.03500000000000003, -0.22699999999999987, -0.8510000000000001, -0.12, -0.05799999999999994, -0.30600000000000005, -0.1269999999999999, -0.039000000000000035, -0.07199999999999984, -0.3629999999999999, -0.126, -0.04200000000000004, -0.15799999999999992, -0.04699999999999993, -0.062000000000000055, 0.356, -0.05599999999999994, -0.14700000000000002, -0.09799999999999998, -0.09399999999999986, -0.029999999999999916, -0.04499999999999993, -0.10700000000000008, -0.06400000000000006, -0.06700000000000006, -0.09799999999999986, -0.18099999999999994, 0.3930000000000001, -0.04700000000000004, -0.20300000000000007, 0.247, -0.08299999999999985, 0.253, -0.17199999999999982, -0.12, -0.11399999999999988, 0.45399999999999996, -0.21899999999999997, -0.18599999999999994, -0.07900000000000007, 0.45199999999999996, -0.4199999999999998, -0.06900000000000006, -0.18899999999999983, -0.1479999999999999, -0.14600000000000002, -0.14900000000000002, -0.18499999999999983, -0.07999999999999985, -0.05499999999999994, -0.17100000000000004, 0.44299999999999995, -0.04799999999999993, -0.21699999999999997, -0.43200000000000005, -0.06000000000000005, -0.06899999999999995, 0.352, -0.06500000000000006, -0.22799999999999998, -0.04200000000000004, -0.18899999999999995, -0.10600000000000008, -0.07899999999999996, -0.09099999999999997, -0.10699999999999998, -0.03399999999999992], "episode_lengths": [22, 38, 48, 16, 208, 38, 23, 32, 23, 26, 23, 22, 8, 146, 12, 104, 195, 25, 8, 63, 11, 15, 111, 10, 17, 79, 14, 7, 18, 36, 20, 27, 12, 11, 68, 251, 37, 17, 81, 40, 11, 23, 116, 34, 16, 43, 14, 20, 43, 17, 42, 30, 29, 9, 14, 300, 20, 19, 31, 54, 34, 13, 61, 66, 26, 70, 52, 34, 33, 13, 68, 59, 24, 15, 126, 21, 58, 45, 49, 45, 58, 25, 16, 47, 18, 15, 66, 131, 18, 23, 46, 17, 66, 13, 52, 300, 25, 27, 33, 11], "policy_red_0_v3_reward": [-1.006, 0.33199999999999996, 0.9199999999999999, -1.037, 0.96, -1.021, -1.003, -1.014, -0.535, 0.884, -1.004, -1.003, 0.959, 0.904, -1.013], "policy_blue_0_reward": [-1.0, -0.503, -1.005, -1.004, -1.003, -0.504, -1.003, -1.022, -1.009, -1.0279999999999998, -0.502, -1.009, -1.0, -1.001, -1.012, -1.035, -1.004, -1.005, -1.003, -1.001, -1.0, -0.505, -1.003, -1.005, -1.004, -1.0, -0.04000000000000003, -1.001, -0.5019999999999999, -1.011, -1.002, -0.506, -1.008, 0.789, -0.502, -1.017, -1.011, -1.01, -1.005, -1.007, -1.007, -1.003, -1.002, 0.794, -1.001, -1.004, -0.503, -0.037000000000000026, -1.003, -1.001], "policy_red_0_v2_reward": [-1.04, 0.96, -1.037, 0.916, 0.965, 0.715, 0.963, -1.017, 0.882, 0.863, 0.9329999999999999, -1.013, 1.458, 0.578, -1.011, -1.019, -1.029], "policy_red_0_v1_reward": [0.882, 0.974, 0.975, 0.967, -1.0, -1.002, -1.002, 0.954, -1.002, 0.892, 0.885, -1.004, -1.003, -1.005, 0.9249999999999999, -1.001, -1.016, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22925536942058852, "mean_inference_ms": 1.4972904093913042, "mean_action_processing_ms": 0.06239951484726029, "mean_env_wait_ms": 0.10560950260957584, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01929032802581787, "StateBufferConnector_ms": 0.0014737844467163086, "ViewRequirementAgentConnector_ms": 0.031154394149780273}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.56409859423795, "num_env_steps_trained_throughput_per_sec": 99.56409859423795, "timesteps_total": 204000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 408000, "timers": {"training_iteration_time_ms": 39708.923, "sample_time_ms": 7687.286, "learn_time_ms": 32004.023, "learn_throughput": 124.984, "synch_weights_time_ms": 17.002}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "done": false, "episodes_total": 2968, "training_iteration": 51, "trial_id": "bb874_00000", "date": "2023-09-28_22-03-48", "timestamp": 1695953028, "time_this_iter_s": 40.177976846694946, "time_total_s": 2014.3389267921448, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f486a0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70cf70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70c160>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2014.3389267921448, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 40.22280701754386, "ram_util_percent": 27.80877192982457}, "win_rate": 0.74, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3949085044364136, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09199423873894072, "policy_loss": -0.02222007868307022, "vf_loss": 0.2261948235332966, "vf_explained_var": 0.18017439674586058, "kl": 0.011369501625631951, "entropy": 1.1569948725402355, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "sampler_results": {"episode_reward_max": 0.45799999999999996, "episode_reward_min": -0.811, "episode_reward_mean": -0.09032999999999998, "episode_len_mean": 45.26, "episode_media": {}, "episodes_this_iter": 97, "policy_reward_min": {"red_0_v3": -1.02, "red_0": -1.026, "blue_0": -1.019, "red_0_v1": -1.032, "red_0_v2": -1.019}, "policy_reward_max": {"red_0_v3": 1.3399999999999999, "red_0": 0.977, "blue_0": 0.856, "red_0_v1": 1.4140000000000001, "red_0_v2": 0.953}, "policy_reward_mean": {"red_0_v3": 0.41924999999999996, "red_0": 0.45132, "blue_0": -0.8865918367346939, "red_0_v1": -0.6200625, "red_0_v2": -0.39521052631578946}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.09099999999999997, -0.10699999999999998, -0.03399999999999992, -0.3700000000000001, -0.22999999999999987, -0.030999999999999917, -0.135, 0.41300000000000003, -0.06099999999999994, 0.19399999999999995, -0.11099999999999999, -0.22299999999999986, -0.2689999999999998, -0.17300000000000004, -0.052000000000000046, -0.06499999999999995, -0.16300000000000003, -0.20299999999999996, -0.09499999999999997, -0.10399999999999976, -0.21599999999999997, 0.45799999999999996, -0.06400000000000006, -0.16600000000000004, -0.2490000000000001, 0.247, -0.16399999999999992, -0.11399999999999988, -0.26, -0.12, -0.039999999999999925, -0.08099999999999985, -0.08899999999999975, -0.03399999999999992, -0.16000000000000003, -0.2899999999999998, -0.12399999999999989, -0.04799999999999993, 0.397, -0.16300000000000003, -0.17000000000000004, -0.05800000000000005, -0.06799999999999995, -0.33699999999999997, -0.04399999999999993, -0.052999999999999936, -0.12099999999999989, -0.04800000000000004, -0.1160000000000001, -0.29599999999999993, -0.02300000000000002, -0.2529999999999999, -0.038999999999999924, -0.22599999999999998, -0.09499999999999997, 0.376, -0.040000000000000036, -0.43200000000000005, -0.04300000000000004, -0.16399999999999992, -0.16699999999999993, -0.277, 0.33299999999999996, -0.041000000000000036, -0.15900000000000003, -0.06800000000000006, -0.08899999999999986, -0.127, -0.627, -0.1339999999999999, -0.03200000000000003, -0.11599999999999999, -0.049000000000000044, -0.3769999999999999, -0.030999999999999917, -0.05699999999999994, -0.05500000000000005, -0.15500000000000003, -0.04500000000000004, -0.811, -0.2889999999999999, -0.18000000000000005, 0.278, -0.16399999999999992, -0.126, -0.30299999999999994, -0.038999999999999924, -0.041000000000000036, -0.17400000000000004, -0.1509999999999999, -0.03899999999999981, 0.2619999999999999, -0.05900000000000005, 0.362, -0.04999999999999993, -0.07299999999999995, -0.05700000000000005, -0.02400000000000002, -0.062000000000000055, 0.42000000000000004], "episode_lengths": [27, 33, 11, 108, 71, 10, 39, 28, 20, 88, 35, 66, 77, 52, 16, 20, 45, 66, 30, 32, 68, 13, 22, 50, 67, 79, 47, 31, 75, 34, 13, 21, 25, 11, 48, 88, 36, 15, 30, 51, 52, 18, 23, 100, 13, 16, 187, 12, 37, 87, 11, 80, 12, 67, 29, 37, 12, 132, 13, 53, 54, 85, 49, 11, 49, 22, 26, 41, 182, 41, 10, 38, 15, 110, 10, 16, 17, 41, 12, 247, 90, 50, 71, 47, 38, 90, 12, 13, 54, 48, 11, 73, 19, 37, 15, 23, 20, 8, 17, 25], "policy_red_0_v3_reward": [0.904, -1.013, 0.874, 0.89, 0.905, 0.7739999999999999, 0.747, 0.926, -1.02, -1.004, 0.587, 0.957, 1.3399999999999999, 0.885, 0.958, -1.002], "policy_blue_0_reward": [-1.001, -1.014, -1.011, -1.001, -0.51, -1.011, -1.0119999999999998, -1.002, -1.004, 0.856, -1.005, -0.5, -1.003, -1.006, -0.51, -1.005, -1.007, -1.007, -1.001, -1.006, -1.0139999999999998, -1.003, -0.505, -1.004, -1.003, -1.0159999999999998, -0.5259999999999999, -1.005, -1.0, -1.006, -1.003, -0.507, -1.005, -1.009, -1.002, -1.003, -1.005, -1.001, -1.003, -1.019, -0.507, -1.008, -1.0019999999999998, -1.007, -1.002, -0.513, -1.002, -1.003, -1.0], "policy_red_0_v1_reward": [1.4140000000000001, -1.0, 0.838, -1.002, -1.001, 0.89, -1.003, -1.002, -1.001, -1.007, -1.007, -1.001, -1.032, -1.0, -1.003, -1.004], "policy_red_0_v2_reward": [0.8, -1.012, -1.015, 0.839, 0.953, -1.014, -1.006, -1.005, -1.002, -1.018, 0.21499999999999997, -1.019, 0.88, -1.011, -1.0059999999999998, -0.517, -1.006, 0.938, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22923778545860102, "mean_inference_ms": 1.4974531401432603, "mean_action_processing_ms": 0.062400198687296585, "mean_env_wait_ms": 0.10568930007864522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019122719764709473, "StateBufferConnector_ms": 0.0014520883560180664, "ViewRequirementAgentConnector_ms": 0.031046390533447266}}, "episode_reward_max": 0.45799999999999996, "episode_reward_min": -0.811, "episode_reward_mean": -0.09032999999999998, "episode_len_mean": 45.26, "episodes_this_iter": 97, "policy_reward_min": {"red_0_v3": -1.02, "red_0": -1.026, "blue_0": -1.019, "red_0_v1": -1.032, "red_0_v2": -1.019}, "policy_reward_max": {"red_0_v3": 1.3399999999999999, "red_0": 0.977, "blue_0": 0.856, "red_0_v1": 1.4140000000000001, "red_0_v2": 0.953}, "policy_reward_mean": {"red_0_v3": 0.41924999999999996, "red_0": 0.45132, "blue_0": -0.8865918367346939, "red_0_v1": -0.6200625, "red_0_v2": -0.39521052631578946}, "hist_stats": {"episode_reward": [-0.09099999999999997, -0.10699999999999998, -0.03399999999999992, -0.3700000000000001, -0.22999999999999987, -0.030999999999999917, -0.135, 0.41300000000000003, -0.06099999999999994, 0.19399999999999995, -0.11099999999999999, -0.22299999999999986, -0.2689999999999998, -0.17300000000000004, -0.052000000000000046, -0.06499999999999995, -0.16300000000000003, -0.20299999999999996, -0.09499999999999997, -0.10399999999999976, -0.21599999999999997, 0.45799999999999996, -0.06400000000000006, -0.16600000000000004, -0.2490000000000001, 0.247, -0.16399999999999992, -0.11399999999999988, -0.26, -0.12, -0.039999999999999925, -0.08099999999999985, -0.08899999999999975, -0.03399999999999992, -0.16000000000000003, -0.2899999999999998, -0.12399999999999989, -0.04799999999999993, 0.397, -0.16300000000000003, -0.17000000000000004, -0.05800000000000005, -0.06799999999999995, -0.33699999999999997, -0.04399999999999993, -0.052999999999999936, -0.12099999999999989, -0.04800000000000004, -0.1160000000000001, -0.29599999999999993, -0.02300000000000002, -0.2529999999999999, -0.038999999999999924, -0.22599999999999998, -0.09499999999999997, 0.376, -0.040000000000000036, -0.43200000000000005, -0.04300000000000004, -0.16399999999999992, -0.16699999999999993, -0.277, 0.33299999999999996, -0.041000000000000036, -0.15900000000000003, -0.06800000000000006, -0.08899999999999986, -0.127, -0.627, -0.1339999999999999, -0.03200000000000003, -0.11599999999999999, -0.049000000000000044, -0.3769999999999999, -0.030999999999999917, -0.05699999999999994, -0.05500000000000005, -0.15500000000000003, -0.04500000000000004, -0.811, -0.2889999999999999, -0.18000000000000005, 0.278, -0.16399999999999992, -0.126, -0.30299999999999994, -0.038999999999999924, -0.041000000000000036, -0.17400000000000004, -0.1509999999999999, -0.03899999999999981, 0.2619999999999999, -0.05900000000000005, 0.362, -0.04999999999999993, -0.07299999999999995, -0.05700000000000005, -0.02400000000000002, -0.062000000000000055, 0.42000000000000004], "episode_lengths": [27, 33, 11, 108, 71, 10, 39, 28, 20, 88, 35, 66, 77, 52, 16, 20, 45, 66, 30, 32, 68, 13, 22, 50, 67, 79, 47, 31, 75, 34, 13, 21, 25, 11, 48, 88, 36, 15, 30, 51, 52, 18, 23, 100, 13, 16, 187, 12, 37, 87, 11, 80, 12, 67, 29, 37, 12, 132, 13, 53, 54, 85, 49, 11, 49, 22, 26, 41, 182, 41, 10, 38, 15, 110, 10, 16, 17, 41, 12, 247, 90, 50, 71, 47, 38, 90, 12, 13, 54, 48, 11, 73, 19, 37, 15, 23, 20, 8, 17, 25], "policy_red_0_v3_reward": [0.904, -1.013, 0.874, 0.89, 0.905, 0.7739999999999999, 0.747, 0.926, -1.02, -1.004, 0.587, 0.957, 1.3399999999999999, 0.885, 0.958, -1.002], "policy_blue_0_reward": [-1.001, -1.014, -1.011, -1.001, -0.51, -1.011, -1.0119999999999998, -1.002, -1.004, 0.856, -1.005, -0.5, -1.003, -1.006, -0.51, -1.005, -1.007, -1.007, -1.001, -1.006, -1.0139999999999998, -1.003, -0.505, -1.004, -1.003, -1.0159999999999998, -0.5259999999999999, -1.005, -1.0, -1.006, -1.003, -0.507, -1.005, -1.009, -1.002, -1.003, -1.005, -1.001, -1.003, -1.019, -0.507, -1.008, -1.0019999999999998, -1.007, -1.002, -0.513, -1.002, -1.003, -1.0], "policy_red_0_v1_reward": [1.4140000000000001, -1.0, 0.838, -1.002, -1.001, 0.89, -1.003, -1.002, -1.001, -1.007, -1.007, -1.001, -1.032, -1.0, -1.003, -1.004], "policy_red_0_v2_reward": [0.8, -1.012, -1.015, 0.839, 0.953, -1.014, -1.006, -1.005, -1.002, -1.018, 0.21499999999999997, -1.019, 0.88, -1.011, -1.0059999999999998, -0.517, -1.006, 0.938, -0.503]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22923778545860102, "mean_inference_ms": 1.4974531401432603, "mean_action_processing_ms": 0.062400198687296585, "mean_env_wait_ms": 0.10568930007864522, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019122719764709473, "StateBufferConnector_ms": 0.0014520883560180664, "ViewRequirementAgentConnector_ms": 0.031046390533447266}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.13774184483994, "num_env_steps_trained_throughput_per_sec": 101.13774184483994, "timesteps_total": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 39701.738, "sample_time_ms": 7686.141, "learn_time_ms": 31998.027, "learn_throughput": 125.008, "synch_weights_time_ms": 16.989}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "episodes_total": 3065, "training_iteration": 52, "trial_id": "bb874_00000", "date": "2023-09-28_22-04-28", "timestamp": 1695953068, "time_this_iter_s": 39.552907943725586, "time_total_s": 2053.8918347358704, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d80b20>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac405bd0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac405a20>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2053.8918347358704, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 33.25892857142857, "ram_util_percent": 28.003571428571426}, "win_rate": 0.78, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3380525957793, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09232231240954812, "policy_loss": -0.023166766803963887, "vf_loss": 0.2282189023370544, "vf_explained_var": 0.14677671833584707, "kl": 0.012799849818589355, "entropy": 1.18034183246394, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "sampler_results": {"episode_reward_max": 0.46099999999999997, "episode_reward_min": -0.6200000000000001, "episode_reward_mean": -0.07289108910891089, "episode_len_mean": 39.89108910891089, "episode_media": {}, "episodes_this_iter": 101, "policy_reward_min": {"blue_0": -1.021, "red_0": -1.021, "red_0_v1": -1.007, "red_0_v3": -1.013, "red_0_v2": -1.042}, "policy_reward_max": {"blue_0": 0.941, "red_0": 0.976, "red_0_v1": 1.264, "red_0_v3": 0.967, "red_0_v2": 1.432}, "policy_reward_mean": {"blue_0": -0.8898723404255318, "red_0": 0.4813267326732673, "red_0_v1": -0.5726521739130436, "red_0_v3": -0.03647058823529409, "red_0_v2": -0.02578571428571427}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.17900000000000005, -0.132, -0.03300000000000003, -0.10599999999999987, -0.08999999999999997, -0.138, -0.03299999999999992, -0.052999999999999936, -0.027999999999999914, -0.05800000000000005, -0.08599999999999985, 0.16200000000000003, -0.04400000000000004, -0.03200000000000003, -0.31600000000000006, -0.31900000000000006, -0.125, 0.42799999999999994, -0.1429999999999999, -0.07999999999999985, -0.030000000000000027, -0.08699999999999997, -0.07000000000000006, 0.401, -0.11599999999999999, 0.46099999999999997, -0.05400000000000005, -0.05499999999999994, 0.24299999999999988, -0.030999999999999917, -0.04700000000000004, -0.10099999999999998, -0.04600000000000004, -0.049000000000000044, -0.359, -0.05899999999999994, -0.08499999999999996, -0.3330000000000001, -0.07999999999999996, -0.23299999999999998, -0.252, -0.03300000000000003, 0.44999999999999996, -0.051999999999999935, -0.6200000000000001, -0.05400000000000005, -0.04799999999999993, -0.06699999999999995, 0.41800000000000004, -0.08799999999999997, -0.15799999999999992, -0.18800000000000006, -0.123, 0.33099999999999996, -0.07100000000000006, -0.02400000000000002, -0.10599999999999987, -0.2779999999999999, -0.05699999999999994, -0.07399999999999995, -0.03599999999999992, -0.061000000000000054, -0.23199999999999998, -0.03699999999999992, -0.18200000000000005, -0.08199999999999996, -0.2659999999999998, -0.15400000000000003, -0.12399999999999989, -0.04799999999999993, -0.06300000000000006, -0.050000000000000044, -0.28500000000000003, 0.31799999999999995, -0.19100000000000006, -0.06300000000000006, -0.05900000000000005, -0.10199999999999998, -0.027999999999999803, -0.3959999999999999, -0.08899999999999997, -0.09200000000000008, -0.07800000000000007, -0.050000000000000044, -0.03300000000000003, -0.07600000000000007, -0.08100000000000007, -0.07199999999999995, -0.04799999999999982, -0.349, -0.03200000000000003, -0.049000000000000044, -0.134, -0.039000000000000035, -0.20599999999999996, -0.134, -0.17300000000000004, -0.1349999999999999, -0.029000000000000026, -0.03799999999999992, -0.05500000000000005], "episode_lengths": [55, 42, 9, 29, 28, 42, 10, 16, 9, 18, 27, 103, 14, 10, 100, 253, 39, 21, 42, 23, 10, 25, 20, 30, 34, 13, 16, 18, 77, 10, 13, 31, 12, 15, 109, 16, 25, 96, 26, 75, 76, 13, 16, 17, 186, 16, 13, 23, 25, 25, 51, 53, 36, 54, 24, 8, 31, 87, 18, 21, 11, 19, 70, 12, 48, 26, 80, 50, 39, 15, 18, 16, 87, 57, 59, 19, 21, 32, 8, 115, 27, 300, 24, 16, 9, 24, 21, 23, 14, 98, 10, 19, 38, 11, 64, 40, 53, 42, 12, 11, 17], "policy_blue_0_reward": [-1.005, -1.004, -1.005, -1.001, -1.003, -0.518, -1.002, -0.53, -1.003, -0.506, -0.5, -1.003, -1.001, -1.021, -1.006, -1.002, -1.005, -1.001, -1.005, -1.001, -0.503, -1.007, -0.504, -1.012, -1.001, -1.0059999999999998, -1.001, -1.001, -1.013, -1.005, -1.001, -1.002, -1.011, -0.504, -1.011, -1.004, -1.003, -1.005, -1.018, -1.0, -1.003, -1.013, 0.941, -1.009, -1.003, -1.002, -1.001], "policy_red_0_v1_reward": [0.873, -1.003, -1.001, -1.006, -1.004, -1.006, -1.0, -1.005, -1.001, 1.264, -1.003, -1.003, -1.003, 0.915, 0.891, -1.007, -1.001, -1.001, -1.002, 0.942, -1.002, -1.002, -1.006], "policy_red_0_v3_reward": [0.967, -1.013, -1.003, 0.9319999999999999, -1.009, -1.002, -1.005, 0.6769999999999999, 0.753, -0.502, 0.816, -1.0, -1.003, 0.914, -0.03200000000000002, 0.929, 0.961], "policy_red_0_v2_reward": [-1.003, 1.432, 0.919, -1.003, -1.042, 0.782, -1.023, -1.0039999999999998, 0.9249999999999999, -1.006, 0.9289999999999999, 0.874, 0.864, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22950798053170487, "mean_inference_ms": 1.49766373403224, "mean_action_processing_ms": 0.06241225622027122, "mean_env_wait_ms": 0.10575248604000784, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0189978297394101, "StateBufferConnector_ms": 0.0014876375103941059, "ViewRequirementAgentConnector_ms": 0.03093492866742729}}, "episode_reward_max": 0.46099999999999997, "episode_reward_min": -0.6200000000000001, "episode_reward_mean": -0.07289108910891089, "episode_len_mean": 39.89108910891089, "episodes_this_iter": 101, "policy_reward_min": {"blue_0": -1.021, "red_0": -1.021, "red_0_v1": -1.007, "red_0_v3": -1.013, "red_0_v2": -1.042}, "policy_reward_max": {"blue_0": 0.941, "red_0": 0.976, "red_0_v1": 1.264, "red_0_v3": 0.967, "red_0_v2": 1.432}, "policy_reward_mean": {"blue_0": -0.8898723404255318, "red_0": 0.4813267326732673, "red_0_v1": -0.5726521739130436, "red_0_v3": -0.03647058823529409, "red_0_v2": -0.02578571428571427}, "hist_stats": {"episode_reward": [-0.17900000000000005, -0.132, -0.03300000000000003, -0.10599999999999987, -0.08999999999999997, -0.138, -0.03299999999999992, -0.052999999999999936, -0.027999999999999914, -0.05800000000000005, -0.08599999999999985, 0.16200000000000003, -0.04400000000000004, -0.03200000000000003, -0.31600000000000006, -0.31900000000000006, -0.125, 0.42799999999999994, -0.1429999999999999, -0.07999999999999985, -0.030000000000000027, -0.08699999999999997, -0.07000000000000006, 0.401, -0.11599999999999999, 0.46099999999999997, -0.05400000000000005, -0.05499999999999994, 0.24299999999999988, -0.030999999999999917, -0.04700000000000004, -0.10099999999999998, -0.04600000000000004, -0.049000000000000044, -0.359, -0.05899999999999994, -0.08499999999999996, -0.3330000000000001, -0.07999999999999996, -0.23299999999999998, -0.252, -0.03300000000000003, 0.44999999999999996, -0.051999999999999935, -0.6200000000000001, -0.05400000000000005, -0.04799999999999993, -0.06699999999999995, 0.41800000000000004, -0.08799999999999997, -0.15799999999999992, -0.18800000000000006, -0.123, 0.33099999999999996, -0.07100000000000006, -0.02400000000000002, -0.10599999999999987, -0.2779999999999999, -0.05699999999999994, -0.07399999999999995, -0.03599999999999992, -0.061000000000000054, -0.23199999999999998, -0.03699999999999992, -0.18200000000000005, -0.08199999999999996, -0.2659999999999998, -0.15400000000000003, -0.12399999999999989, -0.04799999999999993, -0.06300000000000006, -0.050000000000000044, -0.28500000000000003, 0.31799999999999995, -0.19100000000000006, -0.06300000000000006, -0.05900000000000005, -0.10199999999999998, -0.027999999999999803, -0.3959999999999999, -0.08899999999999997, -0.09200000000000008, -0.07800000000000007, -0.050000000000000044, -0.03300000000000003, -0.07600000000000007, -0.08100000000000007, -0.07199999999999995, -0.04799999999999982, -0.349, -0.03200000000000003, -0.049000000000000044, -0.134, -0.039000000000000035, -0.20599999999999996, -0.134, -0.17300000000000004, -0.1349999999999999, -0.029000000000000026, -0.03799999999999992, -0.05500000000000005], "episode_lengths": [55, 42, 9, 29, 28, 42, 10, 16, 9, 18, 27, 103, 14, 10, 100, 253, 39, 21, 42, 23, 10, 25, 20, 30, 34, 13, 16, 18, 77, 10, 13, 31, 12, 15, 109, 16, 25, 96, 26, 75, 76, 13, 16, 17, 186, 16, 13, 23, 25, 25, 51, 53, 36, 54, 24, 8, 31, 87, 18, 21, 11, 19, 70, 12, 48, 26, 80, 50, 39, 15, 18, 16, 87, 57, 59, 19, 21, 32, 8, 115, 27, 300, 24, 16, 9, 24, 21, 23, 14, 98, 10, 19, 38, 11, 64, 40, 53, 42, 12, 11, 17], "policy_blue_0_reward": [-1.005, -1.004, -1.005, -1.001, -1.003, -0.518, -1.002, -0.53, -1.003, -0.506, -0.5, -1.003, -1.001, -1.021, -1.006, -1.002, -1.005, -1.001, -1.005, -1.001, -0.503, -1.007, -0.504, -1.012, -1.001, -1.0059999999999998, -1.001, -1.001, -1.013, -1.005, -1.001, -1.002, -1.011, -0.504, -1.011, -1.004, -1.003, -1.005, -1.018, -1.0, -1.003, -1.013, 0.941, -1.009, -1.003, -1.002, -1.001], "policy_red_0_v1_reward": [0.873, -1.003, -1.001, -1.006, -1.004, -1.006, -1.0, -1.005, -1.001, 1.264, -1.003, -1.003, -1.003, 0.915, 0.891, -1.007, -1.001, -1.001, -1.002, 0.942, -1.002, -1.002, -1.006], "policy_red_0_v3_reward": [0.967, -1.013, -1.003, 0.9319999999999999, -1.009, -1.002, -1.005, 0.6769999999999999, 0.753, -0.502, 0.816, -1.0, -1.003, 0.914, -0.03200000000000002, 0.929, 0.961], "policy_red_0_v2_reward": [-1.003, 1.432, 0.919, -1.003, -1.042, 0.782, -1.023, -1.0039999999999998, 0.9249999999999999, -1.006, 0.9289999999999999, 0.874, 0.864, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22950798053170487, "mean_inference_ms": 1.49766373403224, "mean_action_processing_ms": 0.06241225622027122, "mean_env_wait_ms": 0.10575248604000784, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0189978297394101, "StateBufferConnector_ms": 0.0014876375103941059, "ViewRequirementAgentConnector_ms": 0.03093492866742729}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.07648656944724, "num_env_steps_trained_throughput_per_sec": 101.07648656944724, "timesteps_total": 212000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 424000, "timers": {"training_iteration_time_ms": 39656.651, "sample_time_ms": 7659.422, "learn_time_ms": 31979.648, "learn_throughput": 125.08, "synch_weights_time_ms": 17.0}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "done": false, "episodes_total": 3166, "training_iteration": 53, "trial_id": "bb874_00000", "date": "2023-09-28_22-05-07", "timestamp": 1695953107, "time_this_iter_s": 39.57697677612305, "time_total_s": 2093.4688115119934, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x352fd1c00>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac405ab0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac405090>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2093.4688115119934, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 34.23859649122807, "ram_util_percent": 28.024561403508773}, "win_rate": 0.7920792079207921, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.182593695446849, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07692691415116618, "policy_loss": -0.025889960158383473, "vf_loss": 0.20219516123955447, "vf_explained_var": 0.1848947071780761, "kl": 0.014381421139648864, "entropy": 1.1569899749010801, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "sampler_results": {"episode_reward_max": 0.46499999999999986, "episode_reward_min": -0.9319999999999999, "episode_reward_mean": -0.07788999999999999, "episode_len_mean": 41.94, "episode_media": {}, "episodes_this_iter": 90, "policy_reward_min": {"blue_0": -1.015, "red_0": -1.031, "red_0_v2": -1.019, "red_0_v3": -1.037, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 1.385, "red_0": 0.974, "red_0_v2": 0.969, "red_0_v3": 1.37, "red_0_v1": 1.466}, "policy_reward_mean": {"blue_0": -0.7973148148148148, "red_0": 0.37634999999999996, "red_0_v2": 0.07352631578947372, "red_0_v3": -0.11106249999999995, "red_0_v1": -0.18081818181818182}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.049000000000000044, -0.134, -0.039000000000000035, -0.20599999999999996, -0.134, -0.17300000000000004, -0.1349999999999999, -0.029000000000000026, -0.03799999999999992, -0.05500000000000005, -0.24299999999999988, -0.3370000000000001, 0.3700000000000001, -0.2829999999999999, -0.123, -0.08099999999999985, -0.031000000000000028, -0.20799999999999996, -0.15200000000000002, -0.119, -0.10599999999999998, -0.29200000000000004, 0.16499999999999992, -0.03700000000000003, -0.257, -0.16500000000000004, -0.06099999999999994, -0.050000000000000044, -0.1459999999999999, -0.029000000000000026, -0.04499999999999993, -0.026000000000000023, -0.07399999999999995, -0.07399999999999995, -0.122, -0.1439999999999999, -0.21199999999999997, -0.03399999999999992, -0.027000000000000024, -0.03799999999999992, -0.09599999999999986, -0.9319999999999999, 0.3639999999999999, -0.42199999999999993, -0.06300000000000006, -0.08299999999999996, 0.32600000000000007, 0.46499999999999986, -0.03200000000000003, -0.16500000000000004, -0.06299999999999994, -0.04899999999999993, -0.09299999999999986, 0.45099999999999996, -0.07599999999999985, -0.05599999999999983, -0.14200000000000002, 0.21799999999999997, -0.10899999999999999, -0.02100000000000002, -0.03599999999999992, -0.13, -0.05699999999999983, -0.15400000000000003, -0.05400000000000005, -0.20899999999999985, -0.07800000000000007, -0.5150000000000001, -0.22999999999999998, -0.05600000000000005, -0.08299999999999996, -0.09499999999999986, -0.03700000000000003, -0.09599999999999997, -0.05400000000000005, -0.11599999999999988, -0.04499999999999993, 0.44199999999999995, -0.08499999999999996, -0.038000000000000034, -0.29400000000000004, -0.051000000000000045, -0.04200000000000004, -0.041999999999999926, -0.03199999999999992, -0.09299999999999997, -0.03399999999999992, -0.06500000000000006, 0.19099999999999995, -0.029000000000000026, -0.128, -0.2559999999999999, -0.051999999999999935, 0.3650000000000001, -0.43700000000000006, -0.263, -0.05800000000000005, -0.07699999999999996, -0.08599999999999997, -0.029000000000000026], "episode_lengths": [19, 38, 11, 64, 40, 53, 42, 12, 11, 17, 74, 100, 36, 90, 35, 26, 12, 63, 38, 37, 36, 92, 102, 15, 81, 49, 18, 16, 41, 9, 14, 12, 26, 23, 36, 45, 65, 11, 9, 11, 29, 287, 42, 128, 20, 25, 50, 11, 10, 51, 20, 16, 28, 16, 23, 18, 43, 84, 31, 10, 11, 42, 17, 46, 14, 64, 24, 287, 68, 15, 22, 26, 14, 30, 20, 35, 14, 19, 23, 14, 252, 16, 15, 14, 9, 27, 11, 22, 93, 9, 38, 77, 15, 44, 121, 79, 18, 23, 26, 9], "policy_blue_0_reward": [0.941, -1.009, -1.003, -1.002, -1.001, -1.009, 1.385, -1.011, -1.009, -1.001, -1.009, -1.002, -1.009, -0.518, -1.001, -1.007, -1.008, -1.002, -1.001, -1.002, -1.002, -1.005, -1.015, -1.001, -1.0, -1.003, -1.0039999999999998, -0.5109999999999999, -1.001, -1.008, -1.001, -1.007, -1.004, -1.0019999999999998, -0.512, -1.002, -1.003, -1.01, -1.002, -1.009, -1.004, -1.002, -1.007, -1.001, -0.501, -0.523, -1.004, -1.0, -1.007, -1.002, -1.015, -0.5069999999999999, 0.927, 0.971], "policy_red_0_v2_reward": [0.874, 0.864, -1.005, -1.005, -1.019, -1.005, 0.951, -1.017, 0.595, 0.9299999999999999, 0.897, 0.969, 0.946, -1.013, 0.954, -1.0099999999999998, -1.005, 0.579, 0.917], "policy_red_0_v3_reward": [0.961, -1.0, 0.885, -1.037, 1.37, -1.002, 0.862, -1.011, -1.008, -0.6080000000000001, -1.017, -1.01, 0.952, 0.949, -1.005, 0.942], "policy_red_0_v1_reward": [-1.006, 0.694, 0.928, -1.0, 1.466, -0.5, -1.004, 0.955, -0.508, -1.002, -1.012]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22945340761169064, "mean_inference_ms": 1.4960775198299512, "mean_action_processing_ms": 0.062390286397215694, "mean_env_wait_ms": 0.10567468755982129, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02019977569580078, "StateBufferConnector_ms": 0.0015298128128051758, "ViewRequirementAgentConnector_ms": 0.031699538230895996}}, "episode_reward_max": 0.46499999999999986, "episode_reward_min": -0.9319999999999999, "episode_reward_mean": -0.07788999999999999, "episode_len_mean": 41.94, "episodes_this_iter": 90, "policy_reward_min": {"blue_0": -1.015, "red_0": -1.031, "red_0_v2": -1.019, "red_0_v3": -1.037, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 1.385, "red_0": 0.974, "red_0_v2": 0.969, "red_0_v3": 1.37, "red_0_v1": 1.466}, "policy_reward_mean": {"blue_0": -0.7973148148148148, "red_0": 0.37634999999999996, "red_0_v2": 0.07352631578947372, "red_0_v3": -0.11106249999999995, "red_0_v1": -0.18081818181818182}, "hist_stats": {"episode_reward": [-0.049000000000000044, -0.134, -0.039000000000000035, -0.20599999999999996, -0.134, -0.17300000000000004, -0.1349999999999999, -0.029000000000000026, -0.03799999999999992, -0.05500000000000005, -0.24299999999999988, -0.3370000000000001, 0.3700000000000001, -0.2829999999999999, -0.123, -0.08099999999999985, -0.031000000000000028, -0.20799999999999996, -0.15200000000000002, -0.119, -0.10599999999999998, -0.29200000000000004, 0.16499999999999992, -0.03700000000000003, -0.257, -0.16500000000000004, -0.06099999999999994, -0.050000000000000044, -0.1459999999999999, -0.029000000000000026, -0.04499999999999993, -0.026000000000000023, -0.07399999999999995, -0.07399999999999995, -0.122, -0.1439999999999999, -0.21199999999999997, -0.03399999999999992, -0.027000000000000024, -0.03799999999999992, -0.09599999999999986, -0.9319999999999999, 0.3639999999999999, -0.42199999999999993, -0.06300000000000006, -0.08299999999999996, 0.32600000000000007, 0.46499999999999986, -0.03200000000000003, -0.16500000000000004, -0.06299999999999994, -0.04899999999999993, -0.09299999999999986, 0.45099999999999996, -0.07599999999999985, -0.05599999999999983, -0.14200000000000002, 0.21799999999999997, -0.10899999999999999, -0.02100000000000002, -0.03599999999999992, -0.13, -0.05699999999999983, -0.15400000000000003, -0.05400000000000005, -0.20899999999999985, -0.07800000000000007, -0.5150000000000001, -0.22999999999999998, -0.05600000000000005, -0.08299999999999996, -0.09499999999999986, -0.03700000000000003, -0.09599999999999997, -0.05400000000000005, -0.11599999999999988, -0.04499999999999993, 0.44199999999999995, -0.08499999999999996, -0.038000000000000034, -0.29400000000000004, -0.051000000000000045, -0.04200000000000004, -0.041999999999999926, -0.03199999999999992, -0.09299999999999997, -0.03399999999999992, -0.06500000000000006, 0.19099999999999995, -0.029000000000000026, -0.128, -0.2559999999999999, -0.051999999999999935, 0.3650000000000001, -0.43700000000000006, -0.263, -0.05800000000000005, -0.07699999999999996, -0.08599999999999997, -0.029000000000000026], "episode_lengths": [19, 38, 11, 64, 40, 53, 42, 12, 11, 17, 74, 100, 36, 90, 35, 26, 12, 63, 38, 37, 36, 92, 102, 15, 81, 49, 18, 16, 41, 9, 14, 12, 26, 23, 36, 45, 65, 11, 9, 11, 29, 287, 42, 128, 20, 25, 50, 11, 10, 51, 20, 16, 28, 16, 23, 18, 43, 84, 31, 10, 11, 42, 17, 46, 14, 64, 24, 287, 68, 15, 22, 26, 14, 30, 20, 35, 14, 19, 23, 14, 252, 16, 15, 14, 9, 27, 11, 22, 93, 9, 38, 77, 15, 44, 121, 79, 18, 23, 26, 9], "policy_blue_0_reward": [0.941, -1.009, -1.003, -1.002, -1.001, -1.009, 1.385, -1.011, -1.009, -1.001, -1.009, -1.002, -1.009, -0.518, -1.001, -1.007, -1.008, -1.002, -1.001, -1.002, -1.002, -1.005, -1.015, -1.001, -1.0, -1.003, -1.0039999999999998, -0.5109999999999999, -1.001, -1.008, -1.001, -1.007, -1.004, -1.0019999999999998, -0.512, -1.002, -1.003, -1.01, -1.002, -1.009, -1.004, -1.002, -1.007, -1.001, -0.501, -0.523, -1.004, -1.0, -1.007, -1.002, -1.015, -0.5069999999999999, 0.927, 0.971], "policy_red_0_v2_reward": [0.874, 0.864, -1.005, -1.005, -1.019, -1.005, 0.951, -1.017, 0.595, 0.9299999999999999, 0.897, 0.969, 0.946, -1.013, 0.954, -1.0099999999999998, -1.005, 0.579, 0.917], "policy_red_0_v3_reward": [0.961, -1.0, 0.885, -1.037, 1.37, -1.002, 0.862, -1.011, -1.008, -0.6080000000000001, -1.017, -1.01, 0.952, 0.949, -1.005, 0.942], "policy_red_0_v1_reward": [-1.006, 0.694, 0.928, -1.0, 1.466, -0.5, -1.004, 0.955, -0.508, -1.002, -1.012]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22945340761169064, "mean_inference_ms": 1.4960775198299512, "mean_action_processing_ms": 0.062390286397215694, "mean_env_wait_ms": 0.10567468755982129, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02019977569580078, "StateBufferConnector_ms": 0.0015298128128051758, "ViewRequirementAgentConnector_ms": 0.031699538230895996}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.51144311072542, "num_env_steps_trained_throughput_per_sec": 100.51144311072542, "timesteps_total": 216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 39666.222, "sample_time_ms": 7656.673, "learn_time_ms": 31991.917, "learn_throughput": 125.032, "synch_weights_time_ms": 17.042}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "episodes_total": 3256, "training_iteration": 54, "trial_id": "bb874_00000", "date": "2023-09-28_22-05-47", "timestamp": 1695953147, "time_this_iter_s": 39.79935002326965, "time_total_s": 2133.268161535263, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d5c7f0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70d240>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70e950>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2133.268161535263, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 39.06964285714285, "ram_util_percent": 27.862500000000004}, "win_rate": 0.74, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1483309381951887, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.054291783758283904, "policy_loss": -0.024565247837745118, "vf_loss": 0.15466372574834775, "vf_explained_var": 0.2966775419190526, "kl": 0.01365605888791131, "entropy": 1.2060428423186142, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "sampler_results": {"episode_reward_max": 0.45199999999999996, "episode_reward_min": -0.9790000000000002, "episode_reward_mean": -0.10509999999999999, "episode_len_mean": 43.56, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"red_0_v3": -1.009, "red_0": -1.045, "red_0_v2": -1.0319999999999998, "blue_0": -1.029, "red_0_v1": -1.017}, "policy_reward_max": {"red_0_v3": 0.971, "red_0": 0.979, "red_0_v2": 1.0379999999999998, "blue_0": 1.238, "red_0_v1": 0.942}, "policy_reward_mean": {"red_0_v3": 0.23366666666666666, "red_0": 0.46707999999999994, "red_0_v2": -0.2627142857142856, "blue_0": -0.8054528301886794, "red_0_v1": -0.7975555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.051000000000000045, -0.04200000000000004, -0.041999999999999926, -0.03199999999999992, -0.09299999999999997, -0.03399999999999992, -0.06500000000000006, 0.19099999999999995, -0.029000000000000026, -0.128, -0.2559999999999999, -0.051999999999999935, 0.3650000000000001, -0.43700000000000006, -0.263, -0.05800000000000005, -0.07699999999999996, -0.08599999999999997, -0.029000000000000026, 0.021999999999999797, -0.08299999999999985, -0.11699999999999988, 0.1260000000000001, -0.041000000000000036, 0.18299999999999994, -0.30800000000000005, -0.08999999999999997, -0.11399999999999988, -0.15800000000000003, -0.029000000000000026, -0.375, -0.07300000000000006, -0.137, -0.03699999999999992, -0.1599999999999998, -0.03200000000000003, -0.604, -0.062000000000000055, -0.040000000000000036, -0.19599999999999984, -0.261, -0.6020000000000001, -0.05300000000000005, -0.03699999999999992, -0.038999999999999924, -0.09599999999999997, -0.07799999999999985, -0.027999999999999914, -0.04999999999999993, -0.038000000000000034, -0.050999999999999934, -0.137, -0.050999999999999934, -0.05399999999999994, -0.06000000000000005, -0.030999999999999917, -0.04400000000000004, -0.03700000000000003, -0.29900000000000004, -0.10899999999999987, -0.029999999999999916, -0.02100000000000002, -0.12399999999999989, -0.049000000000000044, -0.03200000000000003, -0.22799999999999998, -0.05799999999999994, -0.04600000000000004, -0.05700000000000005, -0.06699999999999995, -0.118, -0.17699999999999994, -0.33099999999999974, -0.16999999999999993, -0.3680000000000001, -0.039999999999999925, 0.383, -0.10299999999999976, -0.07000000000000006, -0.19399999999999995, -0.19499999999999984, -0.11599999999999999, -0.052000000000000046, -0.11299999999999977, -0.04300000000000004, -0.05300000000000005, -0.31699999999999995, -0.10199999999999998, 0.22299999999999986, 0.45199999999999996, -0.15800000000000003, -0.7460000000000001, -0.05900000000000005, -0.10599999999999998, -0.9790000000000002, -0.11399999999999988, -0.06499999999999995, -0.040000000000000036, -0.2709999999999999, -0.05800000000000005], "episode_lengths": [16, 15, 14, 9, 27, 11, 22, 93, 9, 38, 77, 15, 44, 121, 79, 18, 23, 26, 9, 147, 26, 36, 118, 15, 100, 90, 28, 35, 44, 9, 111, 21, 45, 15, 40, 10, 175, 20, 14, 60, 79, 148, 17, 12, 12, 30, 23, 9, 15, 12, 16, 41, 16, 15, 22, 10, 14, 12, 91, 32, 9, 7, 37, 15, 10, 72, 17, 14, 16, 22, 36, 54, 103, 53, 108, 13, 37, 31, 20, 58, 62, 36, 16, 29, 13, 19, 96, 30, 84, 14, 46, 227, 17, 32, 286, 31, 20, 12, 84, 19], "policy_red_0_v3_reward": [0.952, 0.949, -1.005, 0.942, 0.911, 0.971, 0.42799999999999994, -1.005, -1.009, 0.945, -1.007, 0.6459999999999999, -1.004, 0.938, 0.853], "policy_red_0_v2_reward": [-1.0099999999999998, -1.005, 0.579, 0.917, 1.0379999999999998, 0.951, -1.0319999999999998, -1.008, -1.007, -1.009, -1.0199999999999998, 0.902, -1.01, 0.035999999999999824], "policy_blue_0_reward": [-1.004, -1.0, -1.007, -1.002, -1.015, -0.5069999999999999, 0.927, 0.971, -1.001, -0.5159999999999999, -0.509, -1.014, -1.006, -1.0019999999999998, -1.002, -1.029, -1.001, -1.0119999999999998, -1.013, -1.002, -1.001, -1.001, -1.003, -1.001, -1.001, -1.011, -1.003, -1.001, -1.001, 0.963, -1.004, -1.002, -1.006, -1.003, -1.004, -1.006, -1.007, -1.0119999999999998, -1.007, -1.001, -0.502, -1.0059999999999998, -1.012, -1.007, -1.006, -1.003, -1.014, 1.238, -0.502, -1.002, -1.0019999999999998, -1.003, -1.012], "policy_red_0_v1_reward": [-0.508, -1.002, -1.012, -1.007, -1.004, -1.016, -1.006, -1.001, -1.001, -1.0019999999999998, -1.002, -1.017, -1.003, -1.0, -1.006, 0.29899999999999993, -1.0099999999999998, 0.942]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22966257277856456, "mean_inference_ms": 1.4969007172382236, "mean_action_processing_ms": 0.06240017771659717, "mean_env_wait_ms": 0.10572664170307239, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019534945487976074, "StateBufferConnector_ms": 0.0015376806259155273, "ViewRequirementAgentConnector_ms": 0.031514763832092285}}, "episode_reward_max": 0.45199999999999996, "episode_reward_min": -0.9790000000000002, "episode_reward_mean": -0.10509999999999999, "episode_len_mean": 43.56, "episodes_this_iter": 81, "policy_reward_min": {"red_0_v3": -1.009, "red_0": -1.045, "red_0_v2": -1.0319999999999998, "blue_0": -1.029, "red_0_v1": -1.017}, "policy_reward_max": {"red_0_v3": 0.971, "red_0": 0.979, "red_0_v2": 1.0379999999999998, "blue_0": 1.238, "red_0_v1": 0.942}, "policy_reward_mean": {"red_0_v3": 0.23366666666666666, "red_0": 0.46707999999999994, "red_0_v2": -0.2627142857142856, "blue_0": -0.8054528301886794, "red_0_v1": -0.7975555555555556}, "hist_stats": {"episode_reward": [-0.051000000000000045, -0.04200000000000004, -0.041999999999999926, -0.03199999999999992, -0.09299999999999997, -0.03399999999999992, -0.06500000000000006, 0.19099999999999995, -0.029000000000000026, -0.128, -0.2559999999999999, -0.051999999999999935, 0.3650000000000001, -0.43700000000000006, -0.263, -0.05800000000000005, -0.07699999999999996, -0.08599999999999997, -0.029000000000000026, 0.021999999999999797, -0.08299999999999985, -0.11699999999999988, 0.1260000000000001, -0.041000000000000036, 0.18299999999999994, -0.30800000000000005, -0.08999999999999997, -0.11399999999999988, -0.15800000000000003, -0.029000000000000026, -0.375, -0.07300000000000006, -0.137, -0.03699999999999992, -0.1599999999999998, -0.03200000000000003, -0.604, -0.062000000000000055, -0.040000000000000036, -0.19599999999999984, -0.261, -0.6020000000000001, -0.05300000000000005, -0.03699999999999992, -0.038999999999999924, -0.09599999999999997, -0.07799999999999985, -0.027999999999999914, -0.04999999999999993, -0.038000000000000034, -0.050999999999999934, -0.137, -0.050999999999999934, -0.05399999999999994, -0.06000000000000005, -0.030999999999999917, -0.04400000000000004, -0.03700000000000003, -0.29900000000000004, -0.10899999999999987, -0.029999999999999916, -0.02100000000000002, -0.12399999999999989, -0.049000000000000044, -0.03200000000000003, -0.22799999999999998, -0.05799999999999994, -0.04600000000000004, -0.05700000000000005, -0.06699999999999995, -0.118, -0.17699999999999994, -0.33099999999999974, -0.16999999999999993, -0.3680000000000001, -0.039999999999999925, 0.383, -0.10299999999999976, -0.07000000000000006, -0.19399999999999995, -0.19499999999999984, -0.11599999999999999, -0.052000000000000046, -0.11299999999999977, -0.04300000000000004, -0.05300000000000005, -0.31699999999999995, -0.10199999999999998, 0.22299999999999986, 0.45199999999999996, -0.15800000000000003, -0.7460000000000001, -0.05900000000000005, -0.10599999999999998, -0.9790000000000002, -0.11399999999999988, -0.06499999999999995, -0.040000000000000036, -0.2709999999999999, -0.05800000000000005], "episode_lengths": [16, 15, 14, 9, 27, 11, 22, 93, 9, 38, 77, 15, 44, 121, 79, 18, 23, 26, 9, 147, 26, 36, 118, 15, 100, 90, 28, 35, 44, 9, 111, 21, 45, 15, 40, 10, 175, 20, 14, 60, 79, 148, 17, 12, 12, 30, 23, 9, 15, 12, 16, 41, 16, 15, 22, 10, 14, 12, 91, 32, 9, 7, 37, 15, 10, 72, 17, 14, 16, 22, 36, 54, 103, 53, 108, 13, 37, 31, 20, 58, 62, 36, 16, 29, 13, 19, 96, 30, 84, 14, 46, 227, 17, 32, 286, 31, 20, 12, 84, 19], "policy_red_0_v3_reward": [0.952, 0.949, -1.005, 0.942, 0.911, 0.971, 0.42799999999999994, -1.005, -1.009, 0.945, -1.007, 0.6459999999999999, -1.004, 0.938, 0.853], "policy_red_0_v2_reward": [-1.0099999999999998, -1.005, 0.579, 0.917, 1.0379999999999998, 0.951, -1.0319999999999998, -1.008, -1.007, -1.009, -1.0199999999999998, 0.902, -1.01, 0.035999999999999824], "policy_blue_0_reward": [-1.004, -1.0, -1.007, -1.002, -1.015, -0.5069999999999999, 0.927, 0.971, -1.001, -0.5159999999999999, -0.509, -1.014, -1.006, -1.0019999999999998, -1.002, -1.029, -1.001, -1.0119999999999998, -1.013, -1.002, -1.001, -1.001, -1.003, -1.001, -1.001, -1.011, -1.003, -1.001, -1.001, 0.963, -1.004, -1.002, -1.006, -1.003, -1.004, -1.006, -1.007, -1.0119999999999998, -1.007, -1.001, -0.502, -1.0059999999999998, -1.012, -1.007, -1.006, -1.003, -1.014, 1.238, -0.502, -1.002, -1.0019999999999998, -1.003, -1.012], "policy_red_0_v1_reward": [-0.508, -1.002, -1.012, -1.007, -1.004, -1.016, -1.006, -1.001, -1.001, -1.0019999999999998, -1.002, -1.017, -1.003, -1.0, -1.006, 0.29899999999999993, -1.0099999999999998, 0.942]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22966257277856456, "mean_inference_ms": 1.4969007172382236, "mean_action_processing_ms": 0.06240017771659717, "mean_env_wait_ms": 0.10572664170307239, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019534945487976074, "StateBufferConnector_ms": 0.0015376806259155273, "ViewRequirementAgentConnector_ms": 0.031514763832092285}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.56298422211248, "num_env_steps_trained_throughput_per_sec": 100.56298422211248, "timesteps_total": 220000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 440000, "timers": {"training_iteration_time_ms": 39679.789, "sample_time_ms": 7664.244, "learn_time_ms": 31997.785, "learn_throughput": 125.009, "synch_weights_time_ms": 17.181}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "done": false, "episodes_total": 3337, "training_iteration": 55, "trial_id": "bb874_00000", "date": "2023-09-28_22-06-27", "timestamp": 1695953187, "time_this_iter_s": 39.779064893722534, "time_total_s": 2173.0472264289856, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d26ec0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac407520>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac406440>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2173.0472264289856, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 37.62105263157895, "ram_util_percent": 27.470175438596495}, "win_rate": 0.78, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3060995509227116, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09205682083029387, "policy_loss": -0.02673472263510727, "vf_loss": 0.2345013598445803, "vf_explained_var": 0.17245967177053292, "kl": 0.01338463373499792, "entropy": 1.1360634231319031, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "sampler_results": {"episode_reward_max": 0.44699999999999995, "episode_reward_min": -0.9790000000000002, "episode_reward_mean": -0.11860999999999997, "episode_len_mean": 44.98, "episode_media": {}, "episodes_this_iter": 94, "policy_reward_min": {"red_0_v2": -1.027, "red_0": -1.023, "red_0_v1": -1.0099999999999998, "blue_0": -1.039, "red_0_v3": -1.0239999999999998}, "policy_reward_max": {"red_0_v2": 0.967, "red_0": 0.973, "red_0_v1": 0.97, "blue_0": 0.964, "red_0_v3": 0.906}, "policy_reward_mean": {"red_0_v2": -0.06236842105263154, "red_0": 0.37776, "red_0_v1": -0.28625, "blue_0": -0.8073999999999999, "red_0_v3": -0.23346666666666654}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.9790000000000002, -0.11399999999999988, -0.06499999999999995, -0.040000000000000036, -0.2709999999999999, -0.05800000000000005, -0.06799999999999995, -0.05399999999999994, -0.128, -0.22599999999999998, -0.051999999999999935, -0.07300000000000006, -0.061999999999999944, -0.21899999999999986, -0.07200000000000006, -0.04999999999999993, -0.2829999999999998, -0.41800000000000004, -0.18900000000000006, -0.19299999999999995, -0.029000000000000026, -0.05399999999999994, -0.05099999999999982, 0.41999999999999993, -0.11399999999999999, -0.050999999999999934, -0.07599999999999996, -0.03300000000000003, -0.06599999999999995, -0.050000000000000044, -0.08699999999999997, -0.132, -0.136, -0.17400000000000004, -0.2330000000000001, 0.32899999999999996, -0.09099999999999997, -0.15600000000000003, -0.030000000000000027, -0.04700000000000004, -0.4039999999999998, -0.522, -0.12299999999999989, -0.14800000000000002, -0.17199999999999982, -0.128, -0.9460000000000001, 0.44699999999999995, -0.03600000000000003, -0.027999999999999914, -0.04999999999999982, -0.09099999999999997, -0.03400000000000003, -0.14, -0.1279999999999999, -0.05900000000000005, -0.09199999999999997, -0.09099999999999997, -0.10099999999999998, -0.09599999999999975, -0.05899999999999994, -0.04700000000000004, -0.16599999999999993, 0.40200000000000014, -0.04700000000000004, -0.04300000000000004, -0.2550000000000001, -0.121, -0.04399999999999993, -0.05400000000000005, -0.16700000000000004, -0.36199999999999977, -0.061000000000000054, -0.10899999999999976, -0.12699999999999978, -0.16700000000000004, -0.29200000000000004, -0.10699999999999998, -0.133, -0.11099999999999999, -0.061999999999999944, -0.10399999999999987, -0.10599999999999998, -0.1349999999999999, -0.715, -0.08899999999999997, -0.030999999999999805, -0.254, -0.14400000000000002, -0.18099999999999994, -0.18500000000000005, 0.40700000000000003, -0.049000000000000044, 0.07699999999999996, -0.10399999999999998, -0.257, -0.06700000000000006, -0.22100000000000009, -0.09599999999999986, -0.05800000000000005], "episode_lengths": [286, 31, 20, 12, 84, 19, 21, 19, 43, 67, 15, 21, 19, 68, 22, 15, 87, 127, 51, 60, 9, 17, 15, 24, 36, 16, 21, 11, 21, 14, 25, 36, 42, 50, 73, 50, 29, 41, 10, 15, 122, 160, 38, 46, 46, 42, 294, 17, 11, 9, 14, 29, 10, 40, 39, 18, 30, 32, 26, 30, 18, 15, 53, 31, 15, 13, 73, 38, 13, 17, 55, 110, 22, 27, 37, 50, 82, 35, 44, 35, 17, 33, 29, 44, 230, 29, 9, 74, 43, 56, 54, 28, 13, 125, 28, 71, 21, 69, 29, 18], "policy_red_0_v2_reward": [0.035999999999999824, -1.016, -1.003, 0.951, 0.902, 0.854, -1.027, -1.007, 0.967, 0.881, -1.005, -1.0219999999999998, 0.862, 0.899, -1.0039999999999998, 0.823, -1.009, 0.738, -1.005], "policy_red_0_v1_reward": [-1.0099999999999998, 0.942, -1.005, -1.006, -1.002, -1.001, 0.841, -1.005, 0.97, -1.006, 0.942, -1.004, -1.009, 0.9289999999999999, 0.847, -1.003], "policy_blue_0_reward": [-1.0019999999999998, -1.003, -1.012, -1.003, -1.0039999999999998, -1.008, -1.005, -1.0039999999999998, -1.005, -1.013, 0.601, -1.009, -0.506, -1.003, -1.001, -1.0, -1.008, -0.506, -1.002, -1.0179999999999998, -1.021, -1.006, -1.004, -1.039, -0.501, 0.964, -1.001, -1.003, -1.005, -1.006, -1.0039999999999998, -1.0039999999999998, -1.001, -1.005, -1.001, -1.002, 0.947, -1.004, -1.009, -1.007, -1.003, -1.003, -1.006, 0.911, -1.007, -0.508, -0.514, -1.003, -1.012, -1.002], "policy_red_0_v3_reward": [-1.003, 0.834, -1.005, -1.01, 0.906, -1.019, 0.852, 0.906, -0.5059999999999999, -1.0239999999999998, -1.009, -1.021, 0.754, 0.858, -1.015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22993381217541345, "mean_inference_ms": 1.4986647211286068, "mean_action_processing_ms": 0.06247440787362237, "mean_env_wait_ms": 0.1059239371321342, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020359158515930176, "StateBufferConnector_ms": 0.001584768295288086, "ViewRequirementAgentConnector_ms": 0.03233611583709717}}, "episode_reward_max": 0.44699999999999995, "episode_reward_min": -0.9790000000000002, "episode_reward_mean": -0.11860999999999997, "episode_len_mean": 44.98, "episodes_this_iter": 94, "policy_reward_min": {"red_0_v2": -1.027, "red_0": -1.023, "red_0_v1": -1.0099999999999998, "blue_0": -1.039, "red_0_v3": -1.0239999999999998}, "policy_reward_max": {"red_0_v2": 0.967, "red_0": 0.973, "red_0_v1": 0.97, "blue_0": 0.964, "red_0_v3": 0.906}, "policy_reward_mean": {"red_0_v2": -0.06236842105263154, "red_0": 0.37776, "red_0_v1": -0.28625, "blue_0": -0.8073999999999999, "red_0_v3": -0.23346666666666654}, "hist_stats": {"episode_reward": [-0.9790000000000002, -0.11399999999999988, -0.06499999999999995, -0.040000000000000036, -0.2709999999999999, -0.05800000000000005, -0.06799999999999995, -0.05399999999999994, -0.128, -0.22599999999999998, -0.051999999999999935, -0.07300000000000006, -0.061999999999999944, -0.21899999999999986, -0.07200000000000006, -0.04999999999999993, -0.2829999999999998, -0.41800000000000004, -0.18900000000000006, -0.19299999999999995, -0.029000000000000026, -0.05399999999999994, -0.05099999999999982, 0.41999999999999993, -0.11399999999999999, -0.050999999999999934, -0.07599999999999996, -0.03300000000000003, -0.06599999999999995, -0.050000000000000044, -0.08699999999999997, -0.132, -0.136, -0.17400000000000004, -0.2330000000000001, 0.32899999999999996, -0.09099999999999997, -0.15600000000000003, -0.030000000000000027, -0.04700000000000004, -0.4039999999999998, -0.522, -0.12299999999999989, -0.14800000000000002, -0.17199999999999982, -0.128, -0.9460000000000001, 0.44699999999999995, -0.03600000000000003, -0.027999999999999914, -0.04999999999999982, -0.09099999999999997, -0.03400000000000003, -0.14, -0.1279999999999999, -0.05900000000000005, -0.09199999999999997, -0.09099999999999997, -0.10099999999999998, -0.09599999999999975, -0.05899999999999994, -0.04700000000000004, -0.16599999999999993, 0.40200000000000014, -0.04700000000000004, -0.04300000000000004, -0.2550000000000001, -0.121, -0.04399999999999993, -0.05400000000000005, -0.16700000000000004, -0.36199999999999977, -0.061000000000000054, -0.10899999999999976, -0.12699999999999978, -0.16700000000000004, -0.29200000000000004, -0.10699999999999998, -0.133, -0.11099999999999999, -0.061999999999999944, -0.10399999999999987, -0.10599999999999998, -0.1349999999999999, -0.715, -0.08899999999999997, -0.030999999999999805, -0.254, -0.14400000000000002, -0.18099999999999994, -0.18500000000000005, 0.40700000000000003, -0.049000000000000044, 0.07699999999999996, -0.10399999999999998, -0.257, -0.06700000000000006, -0.22100000000000009, -0.09599999999999986, -0.05800000000000005], "episode_lengths": [286, 31, 20, 12, 84, 19, 21, 19, 43, 67, 15, 21, 19, 68, 22, 15, 87, 127, 51, 60, 9, 17, 15, 24, 36, 16, 21, 11, 21, 14, 25, 36, 42, 50, 73, 50, 29, 41, 10, 15, 122, 160, 38, 46, 46, 42, 294, 17, 11, 9, 14, 29, 10, 40, 39, 18, 30, 32, 26, 30, 18, 15, 53, 31, 15, 13, 73, 38, 13, 17, 55, 110, 22, 27, 37, 50, 82, 35, 44, 35, 17, 33, 29, 44, 230, 29, 9, 74, 43, 56, 54, 28, 13, 125, 28, 71, 21, 69, 29, 18], "policy_red_0_v2_reward": [0.035999999999999824, -1.016, -1.003, 0.951, 0.902, 0.854, -1.027, -1.007, 0.967, 0.881, -1.005, -1.0219999999999998, 0.862, 0.899, -1.0039999999999998, 0.823, -1.009, 0.738, -1.005], "policy_red_0_v1_reward": [-1.0099999999999998, 0.942, -1.005, -1.006, -1.002, -1.001, 0.841, -1.005, 0.97, -1.006, 0.942, -1.004, -1.009, 0.9289999999999999, 0.847, -1.003], "policy_blue_0_reward": [-1.0019999999999998, -1.003, -1.012, -1.003, -1.0039999999999998, -1.008, -1.005, -1.0039999999999998, -1.005, -1.013, 0.601, -1.009, -0.506, -1.003, -1.001, -1.0, -1.008, -0.506, -1.002, -1.0179999999999998, -1.021, -1.006, -1.004, -1.039, -0.501, 0.964, -1.001, -1.003, -1.005, -1.006, -1.0039999999999998, -1.0039999999999998, -1.001, -1.005, -1.001, -1.002, 0.947, -1.004, -1.009, -1.007, -1.003, -1.003, -1.006, 0.911, -1.007, -0.508, -0.514, -1.003, -1.012, -1.002], "policy_red_0_v3_reward": [-1.003, 0.834, -1.005, -1.01, 0.906, -1.019, 0.852, 0.906, -0.5059999999999999, -1.0239999999999998, -1.009, -1.021, 0.754, 0.858, -1.015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22993381217541345, "mean_inference_ms": 1.4986647211286068, "mean_action_processing_ms": 0.06247440787362237, "mean_env_wait_ms": 0.1059239371321342, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020359158515930176, "StateBufferConnector_ms": 0.001584768295288086, "ViewRequirementAgentConnector_ms": 0.03233611583709717}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.30142111061197, "num_env_steps_trained_throughput_per_sec": 100.30142111061197, "timesteps_total": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 39647.615, "sample_time_ms": 7661.903, "learn_time_ms": 31967.884, "learn_throughput": 125.126, "synch_weights_time_ms": 17.249}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "episodes_total": 3431, "training_iteration": 56, "trial_id": "bb874_00000", "date": "2023-09-28_22-07-07", "timestamp": 1695953227, "time_this_iter_s": 39.88275194168091, "time_total_s": 2212.9299783706665, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d81150>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac406b90>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac406d40>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2212.9299783706665, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 37.37894736842106, "ram_util_percent": 27.50526315789474}, "win_rate": 0.74, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.098600340510408, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0606222596669492, "policy_loss": -0.02595944636426187, "vf_loss": 0.17012835324276238, "vf_explained_var": 0.1483720324933529, "kl": 0.012658677307839613, "entropy": 1.0142057587082187, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "sampler_results": {"episode_reward_max": 0.474, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.06768999999999999, "episode_len_mean": 45.96, "episode_media": {}, "episodes_this_iter": 91, "policy_reward_min": {"blue_0": -1.031, "red_0": -1.0159999999999998, "red_0_v2": -1.018, "red_0_v3": -1.025, "red_0_v1": -1.013}, "policy_reward_max": {"blue_0": 0.967, "red_0": 0.976, "red_0_v2": 1.3279999999999998, "red_0_v3": 1.474, "red_0_v1": 0.918}, "policy_reward_mean": {"blue_0": -0.8428148148148148, "red_0": 0.53134, "red_0_v2": -0.2390588235294117, "red_0_v3": 0.018937499999999996, "red_0_v1": -0.8176923076923076}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.40700000000000003, -0.049000000000000044, 0.07699999999999996, -0.10399999999999998, -0.257, -0.06700000000000006, -0.22100000000000009, -0.09599999999999986, -0.05800000000000005, -0.04200000000000004, -0.10599999999999987, 0.33599999999999997, -0.11199999999999988, -0.028999999999999915, -0.029000000000000026, -0.375, -0.16799999999999993, -0.09199999999999986, 0.45100000000000007, -0.041000000000000036, -0.03200000000000003, 0.3570000000000001, -0.10099999999999998, -0.44100000000000006, -0.025000000000000022, -0.03799999999999992, -0.2649999999999999, 0.474, -0.2799999999999999, -0.026000000000000023, -0.049000000000000044, -0.10999999999999999, -0.4989999999999999, 0.41000000000000003, -0.08000000000000007, -0.026999999999999913, -0.031999999999999806, -0.07800000000000007, -0.135, -0.1369999999999999, -0.08200000000000007, -0.04599999999999982, -0.22199999999999998, -0.06000000000000005, 0.32499999999999996, -0.03400000000000003, -0.04499999999999993, -0.09199999999999997, -0.05899999999999994, -0.17300000000000004, -0.03199999999999992, -0.08699999999999997, -0.9470000000000001, -0.03200000000000003, -0.05399999999999994, -0.09999999999999987, -0.10599999999999976, -0.2769999999999999, -0.052000000000000046, -0.05400000000000005, -0.08600000000000008, -0.18199999999999994, -0.12299999999999989, 0.43899999999999995, 0.43499999999999994, 0.02499999999999991, -0.40200000000000014, -0.129, -0.04700000000000004, -0.118, -0.11899999999999988, -0.09999999999999987, -0.23699999999999988, -0.07399999999999995, -0.07699999999999996, -0.026999999999999913, -0.030000000000000027, -0.051000000000000045, -0.07199999999999984, -0.67, -0.16199999999999992, 0.17600000000000005, -0.061999999999999944, -0.24599999999999989, -0.030999999999999917, -0.09000000000000007, 0.20700000000000007, -0.1409999999999999, -0.31899999999999995, -0.031000000000000028, -0.14, -0.03700000000000003, 0.30299999999999994, -0.08799999999999986, -0.10699999999999987, -0.05700000000000005, -0.06500000000000006, -0.050999999999999934, -0.126, -0.139], "episode_lengths": [28, 13, 125, 28, 71, 21, 69, 29, 18, 14, 35, 51, 35, 8, 9, 115, 47, 23, 18, 13, 10, 44, 27, 131, 8, 11, 76, 8, 89, 8, 15, 36, 156, 28, 24, 8, 10, 24, 39, 42, 24, 14, 61, 18, 53, 11, 14, 30, 18, 47, 9, 25, 287, 162, 17, 29, 32, 88, 16, 17, 24, 57, 36, 18, 19, 146, 120, 39, 15, 38, 36, 31, 76, 27, 26, 8, 10, 19, 23, 202, 47, 102, 21, 75, 10, 300, 89, 46, 95, 9, 37, 11, 59, 25, 34, 17, 18, 16, 36, 43], "policy_blue_0_reward": [-0.508, -0.514, -1.003, -1.012, -1.002, -1.0, -0.507, -1.004, -1.002, -1.012, -1.002, -1.002, -0.5099999999999999, -1.014, -1.008, -1.02, -1.003, -1.0019999999999998, -1.004, -1.011, -1.0019999999999998, 0.967, -1.002, -1.001, -1.002, -1.004, -1.027, -0.522, -1.0079999999999998, -1.0059999999999998, -1.013, 0.946, -1.006, -0.501, -0.502, -0.531, -1.019, -1.005, -1.001, -1.004, -1.002, -1.003, -1.0, -1.031, -1.007, -1.005, -1.011, -0.03800000000000003, -1.005, -1.015, -1.004, -1.002, -1.004, -1.002], "policy_red_0_v2_reward": [-1.009, 0.738, -1.005, -1.005, 0.906, -1.005, -1.013, -0.505, -1.018, 1.3279999999999998, -1.005, -1.01, 0.883, -0.5199999999999999, 1.31, -1.0119999999999998, 0.878], "policy_red_0_v3_reward": [-1.015, 0.848, -1.012, 1.444, 0.975, 1.474, -1.002, 0.9199999999999999, 0.9219999999999999, -1.025, -1.012, -1.001, 0.864, -1.004, 0.94, -1.013], "policy_red_0_v1_reward": [-1.0019999999999998, -1.003, -1.0, -1.013, -1.004, -1.003, -1.001, -1.008, -1.006, 0.918, -1.003, -1.0, -0.5049999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23010176531414156, "mean_inference_ms": 1.4993912609438649, "mean_action_processing_ms": 0.06246766712607112, "mean_env_wait_ms": 0.10599556985578493, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01907944679260254, "StateBufferConnector_ms": 0.0015853643417358398, "ViewRequirementAgentConnector_ms": 0.03169870376586914}}, "episode_reward_max": 0.474, "episode_reward_min": -0.9470000000000001, "episode_reward_mean": -0.06768999999999999, "episode_len_mean": 45.96, "episodes_this_iter": 91, "policy_reward_min": {"blue_0": -1.031, "red_0": -1.0159999999999998, "red_0_v2": -1.018, "red_0_v3": -1.025, "red_0_v1": -1.013}, "policy_reward_max": {"blue_0": 0.967, "red_0": 0.976, "red_0_v2": 1.3279999999999998, "red_0_v3": 1.474, "red_0_v1": 0.918}, "policy_reward_mean": {"blue_0": -0.8428148148148148, "red_0": 0.53134, "red_0_v2": -0.2390588235294117, "red_0_v3": 0.018937499999999996, "red_0_v1": -0.8176923076923076}, "hist_stats": {"episode_reward": [0.40700000000000003, -0.049000000000000044, 0.07699999999999996, -0.10399999999999998, -0.257, -0.06700000000000006, -0.22100000000000009, -0.09599999999999986, -0.05800000000000005, -0.04200000000000004, -0.10599999999999987, 0.33599999999999997, -0.11199999999999988, -0.028999999999999915, -0.029000000000000026, -0.375, -0.16799999999999993, -0.09199999999999986, 0.45100000000000007, -0.041000000000000036, -0.03200000000000003, 0.3570000000000001, -0.10099999999999998, -0.44100000000000006, -0.025000000000000022, -0.03799999999999992, -0.2649999999999999, 0.474, -0.2799999999999999, -0.026000000000000023, -0.049000000000000044, -0.10999999999999999, -0.4989999999999999, 0.41000000000000003, -0.08000000000000007, -0.026999999999999913, -0.031999999999999806, -0.07800000000000007, -0.135, -0.1369999999999999, -0.08200000000000007, -0.04599999999999982, -0.22199999999999998, -0.06000000000000005, 0.32499999999999996, -0.03400000000000003, -0.04499999999999993, -0.09199999999999997, -0.05899999999999994, -0.17300000000000004, -0.03199999999999992, -0.08699999999999997, -0.9470000000000001, -0.03200000000000003, -0.05399999999999994, -0.09999999999999987, -0.10599999999999976, -0.2769999999999999, -0.052000000000000046, -0.05400000000000005, -0.08600000000000008, -0.18199999999999994, -0.12299999999999989, 0.43899999999999995, 0.43499999999999994, 0.02499999999999991, -0.40200000000000014, -0.129, -0.04700000000000004, -0.118, -0.11899999999999988, -0.09999999999999987, -0.23699999999999988, -0.07399999999999995, -0.07699999999999996, -0.026999999999999913, -0.030000000000000027, -0.051000000000000045, -0.07199999999999984, -0.67, -0.16199999999999992, 0.17600000000000005, -0.061999999999999944, -0.24599999999999989, -0.030999999999999917, -0.09000000000000007, 0.20700000000000007, -0.1409999999999999, -0.31899999999999995, -0.031000000000000028, -0.14, -0.03700000000000003, 0.30299999999999994, -0.08799999999999986, -0.10699999999999987, -0.05700000000000005, -0.06500000000000006, -0.050999999999999934, -0.126, -0.139], "episode_lengths": [28, 13, 125, 28, 71, 21, 69, 29, 18, 14, 35, 51, 35, 8, 9, 115, 47, 23, 18, 13, 10, 44, 27, 131, 8, 11, 76, 8, 89, 8, 15, 36, 156, 28, 24, 8, 10, 24, 39, 42, 24, 14, 61, 18, 53, 11, 14, 30, 18, 47, 9, 25, 287, 162, 17, 29, 32, 88, 16, 17, 24, 57, 36, 18, 19, 146, 120, 39, 15, 38, 36, 31, 76, 27, 26, 8, 10, 19, 23, 202, 47, 102, 21, 75, 10, 300, 89, 46, 95, 9, 37, 11, 59, 25, 34, 17, 18, 16, 36, 43], "policy_blue_0_reward": [-0.508, -0.514, -1.003, -1.012, -1.002, -1.0, -0.507, -1.004, -1.002, -1.012, -1.002, -1.002, -0.5099999999999999, -1.014, -1.008, -1.02, -1.003, -1.0019999999999998, -1.004, -1.011, -1.0019999999999998, 0.967, -1.002, -1.001, -1.002, -1.004, -1.027, -0.522, -1.0079999999999998, -1.0059999999999998, -1.013, 0.946, -1.006, -0.501, -0.502, -0.531, -1.019, -1.005, -1.001, -1.004, -1.002, -1.003, -1.0, -1.031, -1.007, -1.005, -1.011, -0.03800000000000003, -1.005, -1.015, -1.004, -1.002, -1.004, -1.002], "policy_red_0_v2_reward": [-1.009, 0.738, -1.005, -1.005, 0.906, -1.005, -1.013, -0.505, -1.018, 1.3279999999999998, -1.005, -1.01, 0.883, -0.5199999999999999, 1.31, -1.0119999999999998, 0.878], "policy_red_0_v3_reward": [-1.015, 0.848, -1.012, 1.444, 0.975, 1.474, -1.002, 0.9199999999999999, 0.9219999999999999, -1.025, -1.012, -1.001, 0.864, -1.004, 0.94, -1.013], "policy_red_0_v1_reward": [-1.0019999999999998, -1.003, -1.0, -1.013, -1.004, -1.003, -1.001, -1.008, -1.006, 0.918, -1.003, -1.0, -0.5049999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23010176531414156, "mean_inference_ms": 1.4993912609438649, "mean_action_processing_ms": 0.06246766712607112, "mean_env_wait_ms": 0.10599556985578493, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01907944679260254, "StateBufferConnector_ms": 0.0015853643417358398, "ViewRequirementAgentConnector_ms": 0.03169870376586914}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.23985942920595, "num_env_steps_trained_throughput_per_sec": 101.23985942920595, "timesteps_total": 228000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 456000, "timers": {"training_iteration_time_ms": 39650.616, "sample_time_ms": 7690.366, "learn_time_ms": 31942.362, "learn_throughput": 125.226, "synch_weights_time_ms": 17.271}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "done": false, "episodes_total": 3522, "training_iteration": 57, "trial_id": "bb874_00000", "date": "2023-09-28_22-07-47", "timestamp": 1695953267, "time_this_iter_s": 39.513030767440796, "time_total_s": 2252.4430091381073, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d82b60>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac755ab0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac756e60>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2252.4430091381073, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 36.65, "ram_util_percent": 27.787499999999998}, "win_rate": 0.83, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1679313025126854, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07576270217565859, "policy_loss": -0.021047424216521903, "vf_loss": 0.1916031111497432, "vf_explained_var": 0.1868250610306859, "kl": 0.01044042499530633, "entropy": 1.0795144431913892, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "sampler_results": {"episode_reward_max": 0.46399999999999997, "episode_reward_min": -0.647, "episode_reward_mean": -0.09099999999999998, "episode_len_mean": 40.04, "episode_media": {}, "episodes_this_iter": 99, "policy_reward_min": {"red_0_v3": -1.0139999999999998, "red_0": -1.032, "red_0_v1": -1.025, "blue_0": -1.023, "red_0_v2": -1.016}, "policy_reward_max": {"red_0_v3": 1.464, "red_0": 0.98, "red_0_v1": 0.952, "blue_0": 1.4529999999999998, "red_0_v2": 0.956}, "policy_reward_mean": {"red_0_v3": -0.05294117647058822, "red_0": 0.49691, "red_0_v1": -0.60595, "blue_0": -0.827531914893617, "red_0_v2": -0.429875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.139, -0.3759999999999999, -0.121, 0.45499999999999996, -0.1339999999999999, -0.07899999999999996, -0.052999999999999936, -0.04299999999999993, -0.05700000000000005, -0.050000000000000044, -0.1379999999999999, -0.06000000000000005, -0.06400000000000006, -0.281, -0.32399999999999995, -0.03500000000000003, -0.21499999999999986, -0.041999999999999815, -0.13700000000000012, -0.05300000000000005, -0.027999999999999914, -0.261, -0.09899999999999998, -0.15799999999999992, -0.363, -0.049000000000000044, -0.11899999999999988, -0.03300000000000003, -0.07400000000000007, -0.11399999999999999, -0.18400000000000005, -0.11699999999999988, 0.45199999999999996, -0.05400000000000005, -0.647, 0.20499999999999996, -0.10299999999999987, 0.18799999999999994, -0.05599999999999983, -0.04400000000000004, -0.16200000000000003, -0.026000000000000023, -0.09299999999999997, -0.16300000000000003, -0.06899999999999995, -0.17600000000000005, -0.03500000000000003, -0.04999999999999993, -0.07300000000000006, -0.038000000000000034, -0.03299999999999992, -0.22499999999999998, -0.15899999999999992, -0.049000000000000044, -0.026000000000000023, -0.028000000000000025, -0.09199999999999986, -0.06699999999999984, -0.040999999999999814, 0.46399999999999997, 0.41700000000000004, -0.07499999999999996, -0.029000000000000026, -0.03200000000000003, -0.08599999999999985, -0.027000000000000024, -0.05500000000000005, -0.07299999999999995, -0.22099999999999997, -0.11399999999999999, -0.04799999999999993, -0.30900000000000005, -0.05500000000000005, -0.07400000000000007, -0.04500000000000004, -0.07899999999999974, -0.3760000000000001, -0.02000000000000013, -0.264, -0.43300000000000005, -0.32500000000000007, -0.09899999999999987, -0.11099999999999999, -0.28600000000000003, -0.21300000000000008, -0.08399999999999996, -0.051000000000000045, -0.11299999999999988, -0.18499999999999994, -0.1339999999999999, -0.03500000000000003, -0.05800000000000005, -0.119, -0.04500000000000004, -0.049000000000000044, -0.07299999999999995, -0.122, -0.10699999999999998, -0.10999999999999999, -0.038000000000000034], "episode_lengths": [43, 117, 38, 14, 43, 25, 16, 14, 21, 16, 45, 18, 20, 85, 97, 11, 66, 12, 183, 17, 9, 85, 31, 47, 104, 15, 36, 11, 22, 36, 56, 32, 15, 18, 187, 94, 30, 92, 14, 16, 52, 8, 29, 53, 22, 54, 11, 15, 21, 12, 10, 66, 48, 18, 10, 8, 25, 19, 13, 12, 26, 22, 9, 10, 24, 9, 19, 22, 71, 37, 15, 96, 17, 24, 15, 25, 114, 159, 84, 118, 99, 33, 31, 90, 65, 26, 15, 36, 54, 43, 11, 18, 37, 12, 15, 26, 38, 33, 37, 12], "policy_red_0_v3_reward": [-1.013, 0.882, -0.503, 0.943, 0.683, -1.0059999999999998, -1.011, 0.9329999999999999, -1.003, 1.464, -1.0139999999999998, 0.886, -1.002, 0.9189999999999999, -1.006, 0.952, -1.004], "policy_red_0_v1_reward": [-1.015, -1.003, -1.001, -1.001, 0.952, 0.946, -1.025, -0.505, -1.004, -1.012, -1.0, 0.702, -1.003, -1.004, -1.006, -1.009, -1.018, -1.004, -1.006, 0.897], "policy_blue_0_reward": [-1.004, -1.007, -1.004, -1.015, -1.007, -0.524, -1.002, -1.001, -1.012, -1.009, -1.018, -1.005, -1.0, -1.004, -1.003, -1.007, 1.4529999999999998, -0.51, -1.002, -1.005, -1.002, -1.004, -1.007, -1.001, -1.006, -1.002, -1.002, 0.964, -1.001, -0.502, -1.001, -1.0039999999999998, -1.006, -1.003, -1.0, -1.015, -0.529, -1.007, -1.023, -1.003, -1.004, -1.002, -1.004, -1.002, 0.965, -1.005, -1.002], "policy_red_0_v2_reward": [-1.002, -1.002, -1.002, 0.902, -1.016, -1.011, 0.794, -1.011, 0.942, -1.006, -1.009, -1.005, -1.002, -1.005, 0.599, 0.956]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302794179762309, "mean_inference_ms": 1.4992447709369134, "mean_action_processing_ms": 0.06248835794388313, "mean_env_wait_ms": 0.1060264965831086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018649697303771973, "StateBufferConnector_ms": 0.0014824867248535156, "ViewRequirementAgentConnector_ms": 0.03119683265686035}}, "episode_reward_max": 0.46399999999999997, "episode_reward_min": -0.647, "episode_reward_mean": -0.09099999999999998, "episode_len_mean": 40.04, "episodes_this_iter": 99, "policy_reward_min": {"red_0_v3": -1.0139999999999998, "red_0": -1.032, "red_0_v1": -1.025, "blue_0": -1.023, "red_0_v2": -1.016}, "policy_reward_max": {"red_0_v3": 1.464, "red_0": 0.98, "red_0_v1": 0.952, "blue_0": 1.4529999999999998, "red_0_v2": 0.956}, "policy_reward_mean": {"red_0_v3": -0.05294117647058822, "red_0": 0.49691, "red_0_v1": -0.60595, "blue_0": -0.827531914893617, "red_0_v2": -0.429875}, "hist_stats": {"episode_reward": [-0.139, -0.3759999999999999, -0.121, 0.45499999999999996, -0.1339999999999999, -0.07899999999999996, -0.052999999999999936, -0.04299999999999993, -0.05700000000000005, -0.050000000000000044, -0.1379999999999999, -0.06000000000000005, -0.06400000000000006, -0.281, -0.32399999999999995, -0.03500000000000003, -0.21499999999999986, -0.041999999999999815, -0.13700000000000012, -0.05300000000000005, -0.027999999999999914, -0.261, -0.09899999999999998, -0.15799999999999992, -0.363, -0.049000000000000044, -0.11899999999999988, -0.03300000000000003, -0.07400000000000007, -0.11399999999999999, -0.18400000000000005, -0.11699999999999988, 0.45199999999999996, -0.05400000000000005, -0.647, 0.20499999999999996, -0.10299999999999987, 0.18799999999999994, -0.05599999999999983, -0.04400000000000004, -0.16200000000000003, -0.026000000000000023, -0.09299999999999997, -0.16300000000000003, -0.06899999999999995, -0.17600000000000005, -0.03500000000000003, -0.04999999999999993, -0.07300000000000006, -0.038000000000000034, -0.03299999999999992, -0.22499999999999998, -0.15899999999999992, -0.049000000000000044, -0.026000000000000023, -0.028000000000000025, -0.09199999999999986, -0.06699999999999984, -0.040999999999999814, 0.46399999999999997, 0.41700000000000004, -0.07499999999999996, -0.029000000000000026, -0.03200000000000003, -0.08599999999999985, -0.027000000000000024, -0.05500000000000005, -0.07299999999999995, -0.22099999999999997, -0.11399999999999999, -0.04799999999999993, -0.30900000000000005, -0.05500000000000005, -0.07400000000000007, -0.04500000000000004, -0.07899999999999974, -0.3760000000000001, -0.02000000000000013, -0.264, -0.43300000000000005, -0.32500000000000007, -0.09899999999999987, -0.11099999999999999, -0.28600000000000003, -0.21300000000000008, -0.08399999999999996, -0.051000000000000045, -0.11299999999999988, -0.18499999999999994, -0.1339999999999999, -0.03500000000000003, -0.05800000000000005, -0.119, -0.04500000000000004, -0.049000000000000044, -0.07299999999999995, -0.122, -0.10699999999999998, -0.10999999999999999, -0.038000000000000034], "episode_lengths": [43, 117, 38, 14, 43, 25, 16, 14, 21, 16, 45, 18, 20, 85, 97, 11, 66, 12, 183, 17, 9, 85, 31, 47, 104, 15, 36, 11, 22, 36, 56, 32, 15, 18, 187, 94, 30, 92, 14, 16, 52, 8, 29, 53, 22, 54, 11, 15, 21, 12, 10, 66, 48, 18, 10, 8, 25, 19, 13, 12, 26, 22, 9, 10, 24, 9, 19, 22, 71, 37, 15, 96, 17, 24, 15, 25, 114, 159, 84, 118, 99, 33, 31, 90, 65, 26, 15, 36, 54, 43, 11, 18, 37, 12, 15, 26, 38, 33, 37, 12], "policy_red_0_v3_reward": [-1.013, 0.882, -0.503, 0.943, 0.683, -1.0059999999999998, -1.011, 0.9329999999999999, -1.003, 1.464, -1.0139999999999998, 0.886, -1.002, 0.9189999999999999, -1.006, 0.952, -1.004], "policy_red_0_v1_reward": [-1.015, -1.003, -1.001, -1.001, 0.952, 0.946, -1.025, -0.505, -1.004, -1.012, -1.0, 0.702, -1.003, -1.004, -1.006, -1.009, -1.018, -1.004, -1.006, 0.897], "policy_blue_0_reward": [-1.004, -1.007, -1.004, -1.015, -1.007, -0.524, -1.002, -1.001, -1.012, -1.009, -1.018, -1.005, -1.0, -1.004, -1.003, -1.007, 1.4529999999999998, -0.51, -1.002, -1.005, -1.002, -1.004, -1.007, -1.001, -1.006, -1.002, -1.002, 0.964, -1.001, -0.502, -1.001, -1.0039999999999998, -1.006, -1.003, -1.0, -1.015, -0.529, -1.007, -1.023, -1.003, -1.004, -1.002, -1.004, -1.002, 0.965, -1.005, -1.002], "policy_red_0_v2_reward": [-1.002, -1.002, -1.002, 0.902, -1.016, -1.011, 0.794, -1.011, 0.942, -1.006, -1.009, -1.005, -1.002, -1.005, 0.599, 0.956]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302794179762309, "mean_inference_ms": 1.4992447709369134, "mean_action_processing_ms": 0.06248835794388313, "mean_env_wait_ms": 0.1060264965831086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018649697303771973, "StateBufferConnector_ms": 0.0014824867248535156, "ViewRequirementAgentConnector_ms": 0.03119683265686035}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.49072458558558, "num_env_steps_trained_throughput_per_sec": 99.49072458558558, "timesteps_total": 232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 39736.553, "sample_time_ms": 7704.166, "learn_time_ms": 32014.533, "learn_throughput": 124.943, "synch_weights_time_ms": 17.228}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "episodes_total": 3621, "training_iteration": 58, "trial_id": "bb874_00000", "date": "2023-09-28_22-08-27", "timestamp": 1695953307, "time_this_iter_s": 40.2076690196991, "time_total_s": 2292.6506781578064, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f4a9e0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355923c70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355920430>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2292.6506781578064, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 36.62280701754386, "ram_util_percent": 27.85964912280702}, "win_rate": 0.8, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0565246362239122, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03657645665877377, "policy_loss": -0.024449924894967504, "vf_loss": 0.11884543037740514, "vf_explained_var": 0.21807985827326776, "kl": 0.013482748913497917, "entropy": 1.0928837246571979, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "sampler_results": {"episode_reward_max": 0.45600000000000007, "episode_reward_min": -0.485, "episode_reward_mean": -0.08366, "episode_len_mean": 45.45, "episode_media": {}, "episodes_this_iter": 78, "policy_reward_min": {"blue_0": -1.023, "red_0": -1.032, "red_0_v2": -1.064, "red_0_v1": -1.018, "red_0_v3": -1.009}, "policy_reward_max": {"blue_0": 0.965, "red_0": 0.972, "red_0_v2": 0.975, "red_0_v1": 0.897, "red_0_v3": 1.428}, "policy_reward_mean": {"blue_0": -0.8795098039215685, "red_0": 0.5812000000000002, "red_0_v2": -0.32945454545454544, "red_0_v1": -0.7991176470588235, "red_0_v3": -0.2105714285714286}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.264, -0.43300000000000005, -0.32500000000000007, -0.09899999999999987, -0.11099999999999999, -0.28600000000000003, -0.21300000000000008, -0.08399999999999996, -0.051000000000000045, -0.11299999999999988, -0.18499999999999994, -0.1339999999999999, -0.03500000000000003, -0.05800000000000005, -0.119, -0.04500000000000004, -0.049000000000000044, -0.07299999999999995, -0.122, -0.10699999999999998, -0.10999999999999999, -0.038000000000000034, 0.04600000000000004, -0.10699999999999998, -0.042999999999999816, -0.485, 0.32999999999999996, -0.09199999999999997, -0.03400000000000014, -0.10799999999999987, -0.14400000000000002, -0.05899999999999994, -0.17000000000000004, -0.04800000000000004, -0.04299999999999993, -0.07600000000000007, -0.04899999999999993, -0.06700000000000006, -0.025000000000000022, -0.42100000000000004, -0.04500000000000004, -0.029000000000000026, -0.1259999999999999, 0.41900000000000004, -0.08899999999999986, -0.03200000000000003, -0.29499999999999993, 0.1459999999999999, 0.401, 0.25, -0.3049999999999998, -0.051999999999999935, -0.253, -0.14400000000000002, -0.04399999999999993, -0.22999999999999976, -0.04499999999999993, -0.20700000000000007, -0.10999999999999999, -0.08200000000000007, -0.11399999999999999, -0.20900000000000007, 0.31600000000000006, -0.11299999999999988, -0.051999999999999935, 0.09699999999999998, -0.1339999999999999, -0.32099999999999995, -0.04799999999999993, -0.09399999999999997, -0.07400000000000007, -0.08599999999999997, -0.08299999999999985, -0.03599999999999992, -0.18999999999999995, -0.08499999999999996, -0.061999999999999944, 0.17899999999999994, -0.10299999999999987, -0.04599999999999993, -0.04500000000000004, -0.17500000000000004, -0.3370000000000001, 0.32199999999999995, -0.06999999999999995, -0.11499999999999999, 0.45600000000000007, -0.08199999999999996, -0.03300000000000003, -0.32300000000000006, -0.32000000000000006, -0.10899999999999987, -0.04600000000000004, -0.1449999999999999, -0.04499999999999993, 0.07600000000000018, -0.06300000000000006, -0.029000000000000026, -0.04400000000000004, -0.4600000000000001], "episode_lengths": [84, 118, 99, 33, 31, 90, 65, 26, 15, 36, 54, 43, 11, 18, 37, 12, 15, 26, 38, 33, 37, 12, 138, 33, 13, 142, 51, 30, 143, 35, 44, 18, 59, 16, 12, 24, 16, 21, 8, 134, 15, 9, 37, 23, 28, 10, 88, 106, 29, 78, 89, 17, 81, 46, 13, 72, 14, 65, 35, 24, 34, 65, 62, 34, 15, 129, 43, 101, 15, 28, 21, 26, 26, 11, 61, 27, 19, 98, 32, 13, 15, 52, 83, 52, 21, 39, 14, 28, 11, 99, 104, 34, 14, 40, 14, 136, 19, 9, 12, 140], "policy_blue_0_reward": [-1.007, -1.023, -1.003, -1.004, -1.002, -1.004, -1.002, 0.965, -1.005, -1.002, -0.5199999999999999, -1.004, -1.0019999999999998, -0.511, -0.522, -1.002, -1.007, -1.0, -1.002, -1.0, -1.003, -1.004, -1.0119999999999998, -0.516, -1.005, -1.002, -1.005, -1.006, -1.007, -0.506, -1.007, -1.002, -1.003, -1.002, -1.003, -1.002, -1.0079999999999998, -1.005, -0.52, -1.004, -0.507, -1.003, -0.5009999999999999, -1.005, -1.0, -1.01, -1.002, -1.011, -1.003, -0.5159999999999999, -1.018], "policy_red_0_v2_reward": [0.599, 0.956, 0.975, -1.001, -1.025, -1.009, -1.006, -1.004, -1.064, -1.017, 0.972], "policy_red_0_v1_reward": [-1.004, -1.006, -1.009, -1.018, -1.004, -1.006, 0.897, -1.003, 0.592, -1.0, -1.007, -1.006, -1.004, -1.002, -1.0, -1.004, -1.001], "policy_red_0_v3_reward": [-1.006, 0.952, -1.004, 0.536, -1.002, 0.822, -1.005, -1.001, 1.428, -1.002, -0.509, 1.255, -1.001, 0.894, -1.009, -0.515, 0.9269999999999999, -1.004, 0.833, -1.004, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031996427476756, "mean_inference_ms": 1.4992964250103455, "mean_action_processing_ms": 0.06251493489930426, "mean_env_wait_ms": 0.10606811253693454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01941096782684326, "StateBufferConnector_ms": 0.0015256404876708984, "ViewRequirementAgentConnector_ms": 0.03179287910461426}}, "episode_reward_max": 0.45600000000000007, "episode_reward_min": -0.485, "episode_reward_mean": -0.08366, "episode_len_mean": 45.45, "episodes_this_iter": 78, "policy_reward_min": {"blue_0": -1.023, "red_0": -1.032, "red_0_v2": -1.064, "red_0_v1": -1.018, "red_0_v3": -1.009}, "policy_reward_max": {"blue_0": 0.965, "red_0": 0.972, "red_0_v2": 0.975, "red_0_v1": 0.897, "red_0_v3": 1.428}, "policy_reward_mean": {"blue_0": -0.8795098039215685, "red_0": 0.5812000000000002, "red_0_v2": -0.32945454545454544, "red_0_v1": -0.7991176470588235, "red_0_v3": -0.2105714285714286}, "hist_stats": {"episode_reward": [-0.264, -0.43300000000000005, -0.32500000000000007, -0.09899999999999987, -0.11099999999999999, -0.28600000000000003, -0.21300000000000008, -0.08399999999999996, -0.051000000000000045, -0.11299999999999988, -0.18499999999999994, -0.1339999999999999, -0.03500000000000003, -0.05800000000000005, -0.119, -0.04500000000000004, -0.049000000000000044, -0.07299999999999995, -0.122, -0.10699999999999998, -0.10999999999999999, -0.038000000000000034, 0.04600000000000004, -0.10699999999999998, -0.042999999999999816, -0.485, 0.32999999999999996, -0.09199999999999997, -0.03400000000000014, -0.10799999999999987, -0.14400000000000002, -0.05899999999999994, -0.17000000000000004, -0.04800000000000004, -0.04299999999999993, -0.07600000000000007, -0.04899999999999993, -0.06700000000000006, -0.025000000000000022, -0.42100000000000004, -0.04500000000000004, -0.029000000000000026, -0.1259999999999999, 0.41900000000000004, -0.08899999999999986, -0.03200000000000003, -0.29499999999999993, 0.1459999999999999, 0.401, 0.25, -0.3049999999999998, -0.051999999999999935, -0.253, -0.14400000000000002, -0.04399999999999993, -0.22999999999999976, -0.04499999999999993, -0.20700000000000007, -0.10999999999999999, -0.08200000000000007, -0.11399999999999999, -0.20900000000000007, 0.31600000000000006, -0.11299999999999988, -0.051999999999999935, 0.09699999999999998, -0.1339999999999999, -0.32099999999999995, -0.04799999999999993, -0.09399999999999997, -0.07400000000000007, -0.08599999999999997, -0.08299999999999985, -0.03599999999999992, -0.18999999999999995, -0.08499999999999996, -0.061999999999999944, 0.17899999999999994, -0.10299999999999987, -0.04599999999999993, -0.04500000000000004, -0.17500000000000004, -0.3370000000000001, 0.32199999999999995, -0.06999999999999995, -0.11499999999999999, 0.45600000000000007, -0.08199999999999996, -0.03300000000000003, -0.32300000000000006, -0.32000000000000006, -0.10899999999999987, -0.04600000000000004, -0.1449999999999999, -0.04499999999999993, 0.07600000000000018, -0.06300000000000006, -0.029000000000000026, -0.04400000000000004, -0.4600000000000001], "episode_lengths": [84, 118, 99, 33, 31, 90, 65, 26, 15, 36, 54, 43, 11, 18, 37, 12, 15, 26, 38, 33, 37, 12, 138, 33, 13, 142, 51, 30, 143, 35, 44, 18, 59, 16, 12, 24, 16, 21, 8, 134, 15, 9, 37, 23, 28, 10, 88, 106, 29, 78, 89, 17, 81, 46, 13, 72, 14, 65, 35, 24, 34, 65, 62, 34, 15, 129, 43, 101, 15, 28, 21, 26, 26, 11, 61, 27, 19, 98, 32, 13, 15, 52, 83, 52, 21, 39, 14, 28, 11, 99, 104, 34, 14, 40, 14, 136, 19, 9, 12, 140], "policy_blue_0_reward": [-1.007, -1.023, -1.003, -1.004, -1.002, -1.004, -1.002, 0.965, -1.005, -1.002, -0.5199999999999999, -1.004, -1.0019999999999998, -0.511, -0.522, -1.002, -1.007, -1.0, -1.002, -1.0, -1.003, -1.004, -1.0119999999999998, -0.516, -1.005, -1.002, -1.005, -1.006, -1.007, -0.506, -1.007, -1.002, -1.003, -1.002, -1.003, -1.002, -1.0079999999999998, -1.005, -0.52, -1.004, -0.507, -1.003, -0.5009999999999999, -1.005, -1.0, -1.01, -1.002, -1.011, -1.003, -0.5159999999999999, -1.018], "policy_red_0_v2_reward": [0.599, 0.956, 0.975, -1.001, -1.025, -1.009, -1.006, -1.004, -1.064, -1.017, 0.972], "policy_red_0_v1_reward": [-1.004, -1.006, -1.009, -1.018, -1.004, -1.006, 0.897, -1.003, 0.592, -1.0, -1.007, -1.006, -1.004, -1.002, -1.0, -1.004, -1.001], "policy_red_0_v3_reward": [-1.006, 0.952, -1.004, 0.536, -1.002, 0.822, -1.005, -1.001, 1.428, -1.002, -0.509, 1.255, -1.001, 0.894, -1.009, -0.515, 0.9269999999999999, -1.004, 0.833, -1.004, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031996427476756, "mean_inference_ms": 1.4992964250103455, "mean_action_processing_ms": 0.06251493489930426, "mean_env_wait_ms": 0.10606811253693454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01941096782684326, "StateBufferConnector_ms": 0.0015256404876708984, "ViewRequirementAgentConnector_ms": 0.03179287910461426}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.87375422311212, "num_env_steps_trained_throughput_per_sec": 99.87375422311212, "timesteps_total": 236000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 472000, "timers": {"training_iteration_time_ms": 39785.41, "sample_time_ms": 7721.655, "learn_time_ms": 32045.962, "learn_throughput": 124.821, "synch_weights_time_ms": 17.159}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "done": false, "episodes_total": 3699, "training_iteration": 59, "trial_id": "bb874_00000", "date": "2023-09-28_22-09-07", "timestamp": 1695953347, "time_this_iter_s": 40.05338191986084, "time_total_s": 2332.7040600776672, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2ab34ff70>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2aaf001f0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2aaf039a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2332.7040600776672, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 37.89824561403508, "ram_util_percent": 28.18771929824561}, "win_rate": 0.85, "league_size": 5}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0106119070202113, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.029075048133866705, "policy_loss": -0.019544423615540533, "vf_loss": 0.09490731316618621, "vf_explained_var": 0.1847917338833213, "kl": 0.011231448327614165, "entropy": 1.0804744517430662, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "sampler_results": {"episode_reward_max": 0.45600000000000007, "episode_reward_min": -0.665, "episode_reward_mean": -0.08043999999999998, "episode_len_mean": 57.12, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"red_0_v1": -1.023, "red_0": -1.014, "blue_0": -1.023, "red_0_v3": -1.026, "red_0_v2": -1.071}, "policy_reward_max": {"red_0_v1": 0.966, "red_0": 0.979, "blue_0": 0.6689999999999999, "red_0_v3": 0.9319999999999999, "red_0_v2": 0.972}, "policy_reward_mean": {"red_0_v1": -0.8261818181818182, "red_0": 0.6301199999999999, "blue_0": -0.8235454545454546, "red_0_v3": -0.2924375, "red_0_v2": -0.6663333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.1339999999999999, -0.32099999999999995, -0.04799999999999993, -0.09399999999999997, -0.07400000000000007, -0.08599999999999997, -0.08299999999999985, -0.03599999999999992, -0.18999999999999995, -0.08499999999999996, -0.061999999999999944, 0.17899999999999994, -0.10299999999999987, -0.04599999999999993, -0.04500000000000004, -0.17500000000000004, -0.3370000000000001, 0.32199999999999995, -0.06999999999999995, -0.11499999999999999, 0.45600000000000007, -0.08199999999999996, -0.03300000000000003, -0.32300000000000006, -0.32000000000000006, -0.10899999999999987, -0.04600000000000004, -0.1449999999999999, -0.04499999999999993, 0.07600000000000018, -0.06300000000000006, -0.029000000000000026, -0.04400000000000004, -0.4600000000000001, -0.3759999999999999, -0.05900000000000005, -0.19100000000000006, -0.1319999999999999, -0.06799999999999995, -0.06900000000000006, -0.11199999999999988, -0.15400000000000003, -0.05900000000000005, 0.19899999999999995, -0.3959999999999999, -0.45200000000000007, -0.029000000000000026, -0.02499999999999991, -0.08099999999999996, -0.02199999999999991, -0.03500000000000003, -0.11499999999999999, 0.27, 0.15400000000000003, 0.25, -0.027999999999999914, -0.05699999999999994, -0.20299999999999985, -0.665, -0.05500000000000004, -0.040000000000000036, -0.030999999999999917, 0.09799999999999998, -0.04999999999999993, -0.039000000000000035, -0.062000000000000055, -0.247, -0.18900000000000006, 0.34099999999999997, -0.03400000000000003, -0.2310000000000001, -0.3450000000000001, -0.041999999999999926, -0.4620000000000001, -0.04699999999999993, 0.44599999999999995, 0.2839999999999999, -0.43600000000000005, -0.126, -0.039999999999999925, -0.053999999999999826, -0.08799999999999997, 0.257, -0.038999999999999924, -0.049000000000000044, 0.42800000000000005, -0.4009999999999999, -0.08799999999999997, -0.11299999999999999, -0.138, -0.052000000000000046, -0.07299999999999995, -0.33699999999999997, -0.249, -0.05899999999999994, -0.11999999999999988, -0.03500000000000003, -0.04299999999999993, -0.15400000000000003, -0.10499999999999987], "episode_lengths": [43, 101, 15, 28, 21, 26, 26, 11, 61, 27, 19, 98, 32, 13, 15, 52, 83, 52, 21, 39, 14, 28, 11, 99, 104, 34, 14, 40, 14, 136, 19, 9, 12, 140, 109, 19, 57, 41, 21, 21, 31, 44, 19, 91, 105, 140, 9, 8, 22, 7, 11, 35, 75, 107, 80, 9, 18, 66, 204, 300, 12, 10, 119, 13, 11, 18, 71, 59, 49, 11, 218, 106, 13, 140, 14, 300, 67, 118, 40, 13, 16, 28, 77, 12, 15, 23, 124, 28, 38, 37, 300, 169, 106, 75, 16, 37, 11, 14, 46, 32], "policy_red_0_v1_reward": [-1.002, -1.0, -1.004, -1.001, -1.023, -1.003, -1.001, -1.004, 0.966, -1.004, -1.012], "policy_blue_0_reward": [-1.007, -1.002, -1.003, -1.002, -1.003, -1.002, -1.0079999999999998, -1.005, -0.52, -1.004, -0.507, -1.003, -0.5009999999999999, -1.005, -1.0, -1.01, -1.002, -1.011, -1.003, -0.5159999999999999, -1.018, -1.0, -1.007, -1.005, -1.005, -1.002, -1.001, -1.002, -0.513, -0.519, -0.508, -1.001, -1.003, -1.007, -1.008, -0.509, -0.531, 0.6689999999999999, -1.003, -1.023, 0.45499999999999996, -0.513, -1.001, -1.005, -0.505, -1.003, -1.002, -0.04400000000000003, -0.5179999999999999, -1.013, -1.018, -1.008, -1.0, -1.008, -1.002], "policy_red_0_v3_reward": [0.9269999999999999, -1.004, 0.833, -1.004, -1.007, 0.9319999999999999, -1.0119999999999998, -1.026, -0.028000000000000018, -0.514, -1.006, -1.003, 0.874, -0.503, 0.866, -1.004], "policy_red_0_v2_reward": [-1.004, -1.064, -1.017, 0.972, -0.511, -1.056, 0.971, -1.01, -1.035, -1.002, -1.001, -1.01, -1.005, -1.028, -1.071, -1.004, 0.882, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23022604722494586, "mean_inference_ms": 1.4996422926130224, "mean_action_processing_ms": 0.06252133102387178, "mean_env_wait_ms": 0.10610512546200315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01945948600769043, "StateBufferConnector_ms": 0.001526474952697754, "ViewRequirementAgentConnector_ms": 0.03179037570953369}}, "episode_reward_max": 0.45600000000000007, "episode_reward_min": -0.665, "episode_reward_mean": -0.08043999999999998, "episode_len_mean": 57.12, "episodes_this_iter": 66, "policy_reward_min": {"red_0_v1": -1.023, "red_0": -1.014, "blue_0": -1.023, "red_0_v3": -1.026, "red_0_v2": -1.071}, "policy_reward_max": {"red_0_v1": 0.966, "red_0": 0.979, "blue_0": 0.6689999999999999, "red_0_v3": 0.9319999999999999, "red_0_v2": 0.972}, "policy_reward_mean": {"red_0_v1": -0.8261818181818182, "red_0": 0.6301199999999999, "blue_0": -0.8235454545454546, "red_0_v3": -0.2924375, "red_0_v2": -0.6663333333333333}, "hist_stats": {"episode_reward": [-0.1339999999999999, -0.32099999999999995, -0.04799999999999993, -0.09399999999999997, -0.07400000000000007, -0.08599999999999997, -0.08299999999999985, -0.03599999999999992, -0.18999999999999995, -0.08499999999999996, -0.061999999999999944, 0.17899999999999994, -0.10299999999999987, -0.04599999999999993, -0.04500000000000004, -0.17500000000000004, -0.3370000000000001, 0.32199999999999995, -0.06999999999999995, -0.11499999999999999, 0.45600000000000007, -0.08199999999999996, -0.03300000000000003, -0.32300000000000006, -0.32000000000000006, -0.10899999999999987, -0.04600000000000004, -0.1449999999999999, -0.04499999999999993, 0.07600000000000018, -0.06300000000000006, -0.029000000000000026, -0.04400000000000004, -0.4600000000000001, -0.3759999999999999, -0.05900000000000005, -0.19100000000000006, -0.1319999999999999, -0.06799999999999995, -0.06900000000000006, -0.11199999999999988, -0.15400000000000003, -0.05900000000000005, 0.19899999999999995, -0.3959999999999999, -0.45200000000000007, -0.029000000000000026, -0.02499999999999991, -0.08099999999999996, -0.02199999999999991, -0.03500000000000003, -0.11499999999999999, 0.27, 0.15400000000000003, 0.25, -0.027999999999999914, -0.05699999999999994, -0.20299999999999985, -0.665, -0.05500000000000004, -0.040000000000000036, -0.030999999999999917, 0.09799999999999998, -0.04999999999999993, -0.039000000000000035, -0.062000000000000055, -0.247, -0.18900000000000006, 0.34099999999999997, -0.03400000000000003, -0.2310000000000001, -0.3450000000000001, -0.041999999999999926, -0.4620000000000001, -0.04699999999999993, 0.44599999999999995, 0.2839999999999999, -0.43600000000000005, -0.126, -0.039999999999999925, -0.053999999999999826, -0.08799999999999997, 0.257, -0.038999999999999924, -0.049000000000000044, 0.42800000000000005, -0.4009999999999999, -0.08799999999999997, -0.11299999999999999, -0.138, -0.052000000000000046, -0.07299999999999995, -0.33699999999999997, -0.249, -0.05899999999999994, -0.11999999999999988, -0.03500000000000003, -0.04299999999999993, -0.15400000000000003, -0.10499999999999987], "episode_lengths": [43, 101, 15, 28, 21, 26, 26, 11, 61, 27, 19, 98, 32, 13, 15, 52, 83, 52, 21, 39, 14, 28, 11, 99, 104, 34, 14, 40, 14, 136, 19, 9, 12, 140, 109, 19, 57, 41, 21, 21, 31, 44, 19, 91, 105, 140, 9, 8, 22, 7, 11, 35, 75, 107, 80, 9, 18, 66, 204, 300, 12, 10, 119, 13, 11, 18, 71, 59, 49, 11, 218, 106, 13, 140, 14, 300, 67, 118, 40, 13, 16, 28, 77, 12, 15, 23, 124, 28, 38, 37, 300, 169, 106, 75, 16, 37, 11, 14, 46, 32], "policy_red_0_v1_reward": [-1.002, -1.0, -1.004, -1.001, -1.023, -1.003, -1.001, -1.004, 0.966, -1.004, -1.012], "policy_blue_0_reward": [-1.007, -1.002, -1.003, -1.002, -1.003, -1.002, -1.0079999999999998, -1.005, -0.52, -1.004, -0.507, -1.003, -0.5009999999999999, -1.005, -1.0, -1.01, -1.002, -1.011, -1.003, -0.5159999999999999, -1.018, -1.0, -1.007, -1.005, -1.005, -1.002, -1.001, -1.002, -0.513, -0.519, -0.508, -1.001, -1.003, -1.007, -1.008, -0.509, -0.531, 0.6689999999999999, -1.003, -1.023, 0.45499999999999996, -0.513, -1.001, -1.005, -0.505, -1.003, -1.002, -0.04400000000000003, -0.5179999999999999, -1.013, -1.018, -1.008, -1.0, -1.008, -1.002], "policy_red_0_v3_reward": [0.9269999999999999, -1.004, 0.833, -1.004, -1.007, 0.9319999999999999, -1.0119999999999998, -1.026, -0.028000000000000018, -0.514, -1.006, -1.003, 0.874, -0.503, 0.866, -1.004], "policy_red_0_v2_reward": [-1.004, -1.064, -1.017, 0.972, -0.511, -1.056, 0.971, -1.01, -1.035, -1.002, -1.001, -1.01, -1.005, -1.028, -1.071, -1.004, 0.882, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23022604722494586, "mean_inference_ms": 1.4996422926130224, "mean_action_processing_ms": 0.06252133102387178, "mean_env_wait_ms": 0.10610512546200315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01945948600769043, "StateBufferConnector_ms": 0.001526474952697754, "ViewRequirementAgentConnector_ms": 0.03179037570953369}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.89068059097688, "num_env_steps_trained_throughput_per_sec": 100.89068059097688, "timesteps_total": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 39816.365, "sample_time_ms": 7732.68, "learn_time_ms": 32065.92, "learn_throughput": 124.743, "synch_weights_time_ms": 17.123}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "episodes_total": 3765, "training_iteration": 60, "trial_id": "bb874_00000", "date": "2023-09-28_22-09-47", "timestamp": 1695953387, "time_this_iter_s": 39.649471044540405, "time_total_s": 2372.3535311222076, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f15ff0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac7541f0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac3243a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2372.3535311222076, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 37.373684210526314, "ram_util_percent": 28.275438596491227}, "win_rate": 0.89, "league_size": 6}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0783415642256537, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04724898786128809, "policy_loss": -0.02395046614158976, "vf_loss": 0.14030940126588878, "vf_explained_var": 0.16996857468038798, "kl": 0.010768799024487886, "entropy": 1.1090062037110329, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "sampler_results": {"episode_reward_max": 0.43600000000000005, "episode_reward_min": -0.929, "episode_reward_mean": -0.10912999999999996, "episode_len_mean": 51.86, "episode_media": {}, "episodes_this_iter": 80, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.012, "red_0_v1": -1.012, "red_0_v3": -1.056, "red_0_v2": -1.019, "red_0_v4": -1.004}, "policy_reward_max": {"blue_0": 0.947, "red_0": 0.983, "red_0_v1": 0.863, "red_0_v3": 1.384, "red_0_v2": 0.967, "red_0_v4": 0.9359999999999999}, "policy_reward_mean": {"blue_0": -0.8791403508771931, "red_0": 0.57386, "red_0_v1": -0.708375, "red_0_v3": -0.45684615384615385, "red_0_v2": -0.37906666666666666, "red_0_v4": -0.12799999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.053999999999999826, -0.08799999999999997, 0.257, -0.038999999999999924, -0.049000000000000044, 0.42800000000000005, -0.4009999999999999, -0.08799999999999997, -0.11299999999999999, -0.138, -0.052000000000000046, -0.07299999999999995, -0.33699999999999997, -0.249, -0.05899999999999994, -0.11999999999999988, -0.03500000000000003, -0.04299999999999993, -0.15400000000000003, -0.10499999999999987, -0.484, 0.239, -0.061999999999999944, -0.09299999999999986, -0.04400000000000004, -0.07100000000000006, -0.03699999999999992, -0.17100000000000004, -0.1489999999999999, -0.15900000000000003, -0.19999999999999973, -0.08899999999999986, -0.04400000000000004, -0.251, -0.10599999999999998, -0.04600000000000004, -0.18700000000000006, -0.859, -0.14200000000000002, -0.029000000000000026, -0.11399999999999999, 0.08799999999999997, -0.661, -0.18399999999999994, -0.07099999999999973, -0.14200000000000002, -0.08899999999999986, -0.07200000000000006, -0.11799999999999988, -0.061000000000000054, -0.08600000000000008, -0.03400000000000003, -0.07599999999999985, -0.04599999999999982, -0.05400000000000005, -0.2539999999999999, -0.040999999999999925, -0.07099999999999995, -0.19600000000000006, -0.16099999999999992, -0.16300000000000003, -0.020000000000000018, -0.04500000000000004, -0.10999999999999988, -0.4810000000000001, 0.43600000000000005, -0.06700000000000006, -0.41800000000000015, -0.02300000000000002, 0.22999999999999998, -0.07999999999999985, -0.19099999999999995, -0.08599999999999997, -0.062000000000000055, -0.929, -0.038999999999999924, -0.03500000000000003, -0.1289999999999999, -0.2599999999999999, -0.18800000000000006, -0.2529999999999999, 0.30499999999999994, -0.05399999999999994, -0.1369999999999999, -0.02499999999999991, -0.11399999999999999, -0.22499999999999987, -0.1429999999999998, -0.07800000000000007, -0.1339999999999999, -0.22699999999999987, -0.031000000000000028, -0.17300000000000004, -0.026999999999999913, 0.40800000000000003, -0.16600000000000004, -0.2899999999999998, 0.3780000000000001, -0.15700000000000003, -0.17100000000000004], "episode_lengths": [16, 28, 77, 12, 15, 23, 124, 28, 38, 37, 300, 169, 106, 75, 16, 37, 11, 14, 46, 32, 137, 79, 19, 30, 14, 21, 12, 56, 46, 49, 64, 26, 14, 75, 34, 14, 53, 256, 47, 9, 36, 130, 209, 61, 23, 44, 28, 22, 37, 19, 24, 10, 23, 14, 17, 79, 12, 22, 60, 48, 45, 9, 13, 33, 147, 23, 21, 121, 10, 84, 25, 60, 28, 20, 293, 12, 11, 40, 81, 56, 82, 63, 17, 44, 8, 35, 70, 43, 22, 43, 70, 10, 50, 8, 28, 52, 95, 38, 47, 52], "policy_blue_0_reward": [-1.005, -0.505, -1.003, -1.002, -0.04400000000000003, -0.5179999999999999, -1.013, -1.018, -1.008, -1.0, -1.008, -1.002, -0.51, -1.004, -1.002, -1.001, -1.001, -1.006, -1.006, -1.013, -1.004, -1.012, -1.048, -1.002, -1.031, -1.007, -1.0019999999999998, -1.001, -1.004, -1.001, 0.9259999999999999, -1.004, 0.947, -1.011, -1.008, -1.011, -1.003, -1.006, -1.023, -0.5, -1.003, -1.009, -1.002, -1.037, -1.002, -1.001, -1.004, -1.016, -0.503, -1.003, -1.003, -1.009, -1.01, -1.01, -1.011, -1.008, -1.006], "policy_red_0_v1_reward": [-1.004, -1.012, -1.0, 0.863, -1.001, -0.511, -1.001, -1.001], "policy_red_0_v3_reward": [-0.503, 0.866, -1.004, -1.0559999999999998, -1.005, -1.005, -1.002, -1.003, -1.056, -1.013, 0.969, -0.511, 1.384], "policy_red_0_v2_reward": [-1.004, 0.882, -1.001, -1.003, -1.005, -1.005, -1.008, -1.003, 0.967, -1.019, 0.877, -1.013, 0.821, -1.003, 0.831], "policy_red_0_v4_reward": [0.828, -1.0039999999999998, 0.857, -0.507, -1.004, 0.9359999999999999, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302220977591106, "mean_inference_ms": 1.4997391838698355, "mean_action_processing_ms": 0.06250940175771355, "mean_env_wait_ms": 0.1060691626782097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019082188606262207, "StateBufferConnector_ms": 0.0015032291412353516, "ViewRequirementAgentConnector_ms": 0.03115987777709961}}, "episode_reward_max": 0.43600000000000005, "episode_reward_min": -0.929, "episode_reward_mean": -0.10912999999999996, "episode_len_mean": 51.86, "episodes_this_iter": 80, "policy_reward_min": {"blue_0": -1.048, "red_0": -1.012, "red_0_v1": -1.012, "red_0_v3": -1.056, "red_0_v2": -1.019, "red_0_v4": -1.004}, "policy_reward_max": {"blue_0": 0.947, "red_0": 0.983, "red_0_v1": 0.863, "red_0_v3": 1.384, "red_0_v2": 0.967, "red_0_v4": 0.9359999999999999}, "policy_reward_mean": {"blue_0": -0.8791403508771931, "red_0": 0.57386, "red_0_v1": -0.708375, "red_0_v3": -0.45684615384615385, "red_0_v2": -0.37906666666666666, "red_0_v4": -0.12799999999999997}, "hist_stats": {"episode_reward": [-0.053999999999999826, -0.08799999999999997, 0.257, -0.038999999999999924, -0.049000000000000044, 0.42800000000000005, -0.4009999999999999, -0.08799999999999997, -0.11299999999999999, -0.138, -0.052000000000000046, -0.07299999999999995, -0.33699999999999997, -0.249, -0.05899999999999994, -0.11999999999999988, -0.03500000000000003, -0.04299999999999993, -0.15400000000000003, -0.10499999999999987, -0.484, 0.239, -0.061999999999999944, -0.09299999999999986, -0.04400000000000004, -0.07100000000000006, -0.03699999999999992, -0.17100000000000004, -0.1489999999999999, -0.15900000000000003, -0.19999999999999973, -0.08899999999999986, -0.04400000000000004, -0.251, -0.10599999999999998, -0.04600000000000004, -0.18700000000000006, -0.859, -0.14200000000000002, -0.029000000000000026, -0.11399999999999999, 0.08799999999999997, -0.661, -0.18399999999999994, -0.07099999999999973, -0.14200000000000002, -0.08899999999999986, -0.07200000000000006, -0.11799999999999988, -0.061000000000000054, -0.08600000000000008, -0.03400000000000003, -0.07599999999999985, -0.04599999999999982, -0.05400000000000005, -0.2539999999999999, -0.040999999999999925, -0.07099999999999995, -0.19600000000000006, -0.16099999999999992, -0.16300000000000003, -0.020000000000000018, -0.04500000000000004, -0.10999999999999988, -0.4810000000000001, 0.43600000000000005, -0.06700000000000006, -0.41800000000000015, -0.02300000000000002, 0.22999999999999998, -0.07999999999999985, -0.19099999999999995, -0.08599999999999997, -0.062000000000000055, -0.929, -0.038999999999999924, -0.03500000000000003, -0.1289999999999999, -0.2599999999999999, -0.18800000000000006, -0.2529999999999999, 0.30499999999999994, -0.05399999999999994, -0.1369999999999999, -0.02499999999999991, -0.11399999999999999, -0.22499999999999987, -0.1429999999999998, -0.07800000000000007, -0.1339999999999999, -0.22699999999999987, -0.031000000000000028, -0.17300000000000004, -0.026999999999999913, 0.40800000000000003, -0.16600000000000004, -0.2899999999999998, 0.3780000000000001, -0.15700000000000003, -0.17100000000000004], "episode_lengths": [16, 28, 77, 12, 15, 23, 124, 28, 38, 37, 300, 169, 106, 75, 16, 37, 11, 14, 46, 32, 137, 79, 19, 30, 14, 21, 12, 56, 46, 49, 64, 26, 14, 75, 34, 14, 53, 256, 47, 9, 36, 130, 209, 61, 23, 44, 28, 22, 37, 19, 24, 10, 23, 14, 17, 79, 12, 22, 60, 48, 45, 9, 13, 33, 147, 23, 21, 121, 10, 84, 25, 60, 28, 20, 293, 12, 11, 40, 81, 56, 82, 63, 17, 44, 8, 35, 70, 43, 22, 43, 70, 10, 50, 8, 28, 52, 95, 38, 47, 52], "policy_blue_0_reward": [-1.005, -0.505, -1.003, -1.002, -0.04400000000000003, -0.5179999999999999, -1.013, -1.018, -1.008, -1.0, -1.008, -1.002, -0.51, -1.004, -1.002, -1.001, -1.001, -1.006, -1.006, -1.013, -1.004, -1.012, -1.048, -1.002, -1.031, -1.007, -1.0019999999999998, -1.001, -1.004, -1.001, 0.9259999999999999, -1.004, 0.947, -1.011, -1.008, -1.011, -1.003, -1.006, -1.023, -0.5, -1.003, -1.009, -1.002, -1.037, -1.002, -1.001, -1.004, -1.016, -0.503, -1.003, -1.003, -1.009, -1.01, -1.01, -1.011, -1.008, -1.006], "policy_red_0_v1_reward": [-1.004, -1.012, -1.0, 0.863, -1.001, -0.511, -1.001, -1.001], "policy_red_0_v3_reward": [-0.503, 0.866, -1.004, -1.0559999999999998, -1.005, -1.005, -1.002, -1.003, -1.056, -1.013, 0.969, -0.511, 1.384], "policy_red_0_v2_reward": [-1.004, 0.882, -1.001, -1.003, -1.005, -1.005, -1.008, -1.003, 0.967, -1.019, 0.877, -1.013, 0.821, -1.003, 0.831], "policy_red_0_v4_reward": [0.828, -1.0039999999999998, 0.857, -0.507, -1.004, 0.9359999999999999, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302220977591106, "mean_inference_ms": 1.4997391838698355, "mean_action_processing_ms": 0.06250940175771355, "mean_env_wait_ms": 0.1060691626782097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019082188606262207, "StateBufferConnector_ms": 0.0015032291412353516, "ViewRequirementAgentConnector_ms": 0.03115987777709961}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.2176323804702, "num_env_steps_trained_throughput_per_sec": 101.2176323804702, "timesteps_total": 244000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 488000, "timers": {"training_iteration_time_ms": 39750.733, "sample_time_ms": 7731.522, "learn_time_ms": 32001.459, "learn_throughput": 124.994, "synch_weights_time_ms": 17.113}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "done": false, "episodes_total": 3845, "training_iteration": 61, "trial_id": "bb874_00000", "date": "2023-09-28_22-10-26", "timestamp": 1695953426, "time_this_iter_s": 39.521552085876465, "time_total_s": 2411.875083208084, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x35622be80>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ad625480>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ad626050>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2411.875083208084, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 33.78035714285714, "ram_util_percent": 28.36964285714286}, "win_rate": 0.86, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.226337735603253, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05616041136502948, "policy_loss": -0.02732462964292305, "vf_loss": 0.1636458375568812, "vf_explained_var": 0.25453504311541714, "kl": 0.013421897678429502, "entropy": 1.022257279480497, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "sampler_results": {"episode_reward_max": 0.44999999999999996, "episode_reward_min": -0.7100000000000002, "episode_reward_mean": -0.08564999999999996, "episode_len_mean": 46.29, "episode_media": {}, "episodes_this_iter": 83, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.012, "red_0_v1": -1.018, "red_0_v2": -1.034, "red_0_v3": -1.029, "red_0_v4": -1.006, "red_0_v5": -1.005}, "policy_reward_max": {"blue_0": 0.9339999999999999, "red_0": 0.979, "red_0_v1": -0.502, "red_0_v2": 1.3980000000000001, "red_0_v3": 1.384, "red_0_v4": 1.221, "red_0_v5": 0.97}, "policy_reward_mean": {"blue_0": -0.8199259259259262, "red_0": 0.47263999999999995, "red_0_v1": -0.9055000000000002, "red_0_v2": -0.04637499999999999, "red_0_v3": -0.06399999999999993, "red_0_v4": 0.025000000000000022, "red_0_v5": -0.2304}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.1369999999999999, -0.02499999999999991, -0.11399999999999999, -0.22499999999999987, -0.1429999999999998, -0.07800000000000007, -0.1339999999999999, -0.22699999999999987, -0.031000000000000028, -0.17300000000000004, -0.026999999999999913, 0.40800000000000003, -0.16600000000000004, -0.2899999999999998, 0.3780000000000001, -0.15700000000000003, -0.17100000000000004, -0.365, 0.21399999999999997, -0.11699999999999999, -0.03399999999999992, -0.06499999999999995, -0.039999999999999925, -0.29600000000000004, -0.08099999999999996, -0.4600000000000001, -0.03200000000000003, 0.124, -0.07800000000000007, -0.09999999999999987, -0.07599999999999996, -0.052000000000000046, -0.236, -0.06000000000000005, -0.624, -0.04300000000000004, -0.05500000000000005, -0.04599999999999993, -0.031000000000000028, -0.10899999999999999, -0.124, -0.031999999999999806, -0.08000000000000007, 0.39400000000000013, -0.15900000000000003, -0.030999999999999917, -0.06999999999999995, -0.09899999999999998, -0.09599999999999986, -0.039000000000000035, -0.1629999999999998, -0.11499999999999977, -0.39400000000000013, -0.04299999999999993, -0.0229999999999998, -0.04799999999999993, -0.08199999999999996, -0.09899999999999987, -0.07900000000000007, 0.30199999999999994, -0.17499999999999993, -0.027000000000000024, -0.07999999999999985, 0.07199999999999995, -0.05500000000000005, -0.03599999999999992, -0.16400000000000003, -0.1339999999999999, 0.242, -0.20200000000000007, -0.15899999999999992, -0.02399999999999991, -0.05700000000000005, -0.1339999999999999, -0.1479999999999998, -0.08099999999999985, -0.09599999999999986, -0.16599999999999993, -0.06599999999999995, -0.29499999999999993, 0.44999999999999996, -0.09299999999999997, -0.19499999999999995, -0.07399999999999984, -0.31800000000000006, -0.10799999999999987, -0.551, -0.03700000000000003, -0.07600000000000007, -0.09199999999999997, -0.7100000000000002, -0.04400000000000004, -0.02499999999999991, 0.43499999999999994, -0.12899999999999978, -0.129, -0.2290000000000001, -0.10999999999999999, -0.14100000000000001, 0.44999999999999996], "episode_lengths": [44, 8, 35, 70, 43, 22, 43, 70, 10, 50, 8, 28, 52, 95, 38, 47, 52, 107, 92, 202, 11, 23, 13, 92, 25, 135, 10, 111, 24, 29, 27, 20, 72, 176, 189, 13, 17, 15, 12, 37, 38, 10, 22, 30, 49, 10, 21, 34, 31, 14, 47, 35, 120, 14, 7, 15, 26, 28, 22, 63, 54, 9, 25, 128, 20, 11, 50, 41, 76, 56, 48, 7, 21, 39, 46, 26, 29, 55, 19, 84, 16, 31, 66, 23, 92, 33, 173, 11, 24, 30, 204, 14, 8, 22, 39, 41, 67, 33, 39, 16], "policy_blue_0_reward": [-1.003, -1.009, -1.01, -1.01, -1.011, -1.008, -1.006, -1.015, -1.0, -1.001, -1.004, -0.512, -1.005, -1.003, -1.002, -1.01, -0.529, -1.003, -1.003, 0.88, -1.0019999999999998, 0.849, -1.001, 0.895, -1.001, -1.007, -1.001, -1.0019999999999998, -1.002, -1.008, -1.0, -1.002, -0.517, -1.002, -1.012, -1.008, -1.01, 0.9339999999999999, -1.007, -1.006, -1.008, -0.502, -1.007, -1.005, -1.007, -1.023, -1.002, -1.002, -1.005, -1.029, -1.002, -1.001, -1.007, -0.502], "policy_red_0_v1_reward": [-1.001, -1.002, -1.018, -1.002, -1.014, -1.003, -0.505, -1.0, -1.008, -0.502], "policy_red_0_v2_reward": [0.877, -1.013, 0.821, -1.003, 0.831, 0.5519999999999999, -1.006, 1.3980000000000001, 0.9369999999999999, 1.2469999999999999, -1.003, -1.0099999999999998, -1.004, -1.034, 0.694, -1.026], "policy_red_0_v3_reward": [0.969, -0.511, 1.384, 0.706, -1.011, 0.9219999999999999, -1.015, -1.029, 0.9229999999999999, -1.023, -1.019], "policy_red_0_v4_reward": [-1.002, 1.221, -1.006, 0.887], "policy_red_0_v5_reward": [0.886, 0.97, -1.001, -1.005, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302871823705671, "mean_inference_ms": 1.4990890922180131, "mean_action_processing_ms": 0.06249636305368265, "mean_env_wait_ms": 0.10604392507288604, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019002437591552734, "StateBufferConnector_ms": 0.0014889240264892578, "ViewRequirementAgentConnector_ms": 0.031014442443847656}}, "episode_reward_max": 0.44999999999999996, "episode_reward_min": -0.7100000000000002, "episode_reward_mean": -0.08564999999999996, "episode_len_mean": 46.29, "episodes_this_iter": 83, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.012, "red_0_v1": -1.018, "red_0_v2": -1.034, "red_0_v3": -1.029, "red_0_v4": -1.006, "red_0_v5": -1.005}, "policy_reward_max": {"blue_0": 0.9339999999999999, "red_0": 0.979, "red_0_v1": -0.502, "red_0_v2": 1.3980000000000001, "red_0_v3": 1.384, "red_0_v4": 1.221, "red_0_v5": 0.97}, "policy_reward_mean": {"blue_0": -0.8199259259259262, "red_0": 0.47263999999999995, "red_0_v1": -0.9055000000000002, "red_0_v2": -0.04637499999999999, "red_0_v3": -0.06399999999999993, "red_0_v4": 0.025000000000000022, "red_0_v5": -0.2304}, "hist_stats": {"episode_reward": [-0.1369999999999999, -0.02499999999999991, -0.11399999999999999, -0.22499999999999987, -0.1429999999999998, -0.07800000000000007, -0.1339999999999999, -0.22699999999999987, -0.031000000000000028, -0.17300000000000004, -0.026999999999999913, 0.40800000000000003, -0.16600000000000004, -0.2899999999999998, 0.3780000000000001, -0.15700000000000003, -0.17100000000000004, -0.365, 0.21399999999999997, -0.11699999999999999, -0.03399999999999992, -0.06499999999999995, -0.039999999999999925, -0.29600000000000004, -0.08099999999999996, -0.4600000000000001, -0.03200000000000003, 0.124, -0.07800000000000007, -0.09999999999999987, -0.07599999999999996, -0.052000000000000046, -0.236, -0.06000000000000005, -0.624, -0.04300000000000004, -0.05500000000000005, -0.04599999999999993, -0.031000000000000028, -0.10899999999999999, -0.124, -0.031999999999999806, -0.08000000000000007, 0.39400000000000013, -0.15900000000000003, -0.030999999999999917, -0.06999999999999995, -0.09899999999999998, -0.09599999999999986, -0.039000000000000035, -0.1629999999999998, -0.11499999999999977, -0.39400000000000013, -0.04299999999999993, -0.0229999999999998, -0.04799999999999993, -0.08199999999999996, -0.09899999999999987, -0.07900000000000007, 0.30199999999999994, -0.17499999999999993, -0.027000000000000024, -0.07999999999999985, 0.07199999999999995, -0.05500000000000005, -0.03599999999999992, -0.16400000000000003, -0.1339999999999999, 0.242, -0.20200000000000007, -0.15899999999999992, -0.02399999999999991, -0.05700000000000005, -0.1339999999999999, -0.1479999999999998, -0.08099999999999985, -0.09599999999999986, -0.16599999999999993, -0.06599999999999995, -0.29499999999999993, 0.44999999999999996, -0.09299999999999997, -0.19499999999999995, -0.07399999999999984, -0.31800000000000006, -0.10799999999999987, -0.551, -0.03700000000000003, -0.07600000000000007, -0.09199999999999997, -0.7100000000000002, -0.04400000000000004, -0.02499999999999991, 0.43499999999999994, -0.12899999999999978, -0.129, -0.2290000000000001, -0.10999999999999999, -0.14100000000000001, 0.44999999999999996], "episode_lengths": [44, 8, 35, 70, 43, 22, 43, 70, 10, 50, 8, 28, 52, 95, 38, 47, 52, 107, 92, 202, 11, 23, 13, 92, 25, 135, 10, 111, 24, 29, 27, 20, 72, 176, 189, 13, 17, 15, 12, 37, 38, 10, 22, 30, 49, 10, 21, 34, 31, 14, 47, 35, 120, 14, 7, 15, 26, 28, 22, 63, 54, 9, 25, 128, 20, 11, 50, 41, 76, 56, 48, 7, 21, 39, 46, 26, 29, 55, 19, 84, 16, 31, 66, 23, 92, 33, 173, 11, 24, 30, 204, 14, 8, 22, 39, 41, 67, 33, 39, 16], "policy_blue_0_reward": [-1.003, -1.009, -1.01, -1.01, -1.011, -1.008, -1.006, -1.015, -1.0, -1.001, -1.004, -0.512, -1.005, -1.003, -1.002, -1.01, -0.529, -1.003, -1.003, 0.88, -1.0019999999999998, 0.849, -1.001, 0.895, -1.001, -1.007, -1.001, -1.0019999999999998, -1.002, -1.008, -1.0, -1.002, -0.517, -1.002, -1.012, -1.008, -1.01, 0.9339999999999999, -1.007, -1.006, -1.008, -0.502, -1.007, -1.005, -1.007, -1.023, -1.002, -1.002, -1.005, -1.029, -1.002, -1.001, -1.007, -0.502], "policy_red_0_v1_reward": [-1.001, -1.002, -1.018, -1.002, -1.014, -1.003, -0.505, -1.0, -1.008, -0.502], "policy_red_0_v2_reward": [0.877, -1.013, 0.821, -1.003, 0.831, 0.5519999999999999, -1.006, 1.3980000000000001, 0.9369999999999999, 1.2469999999999999, -1.003, -1.0099999999999998, -1.004, -1.034, 0.694, -1.026], "policy_red_0_v3_reward": [0.969, -0.511, 1.384, 0.706, -1.011, 0.9219999999999999, -1.015, -1.029, 0.9229999999999999, -1.023, -1.019], "policy_red_0_v4_reward": [-1.002, 1.221, -1.006, 0.887], "policy_red_0_v5_reward": [0.886, 0.97, -1.001, -1.005, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302871823705671, "mean_inference_ms": 1.4990890922180131, "mean_action_processing_ms": 0.06249636305368265, "mean_env_wait_ms": 0.10604392507288604, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019002437591552734, "StateBufferConnector_ms": 0.0014889240264892578, "ViewRequirementAgentConnector_ms": 0.031014442443847656}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.33622018349067, "num_env_steps_trained_throughput_per_sec": 101.33622018349067, "timesteps_total": 248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 39742.986, "sample_time_ms": 7727.454, "learn_time_ms": 31997.649, "learn_throughput": 125.009, "synch_weights_time_ms": 17.241}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "episodes_total": 3928, "training_iteration": 62, "trial_id": "bb874_00000", "date": "2023-09-28_22-11-06", "timestamp": 1695953466, "time_this_iter_s": 39.475658893585205, "time_total_s": 2451.3507421016693, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x3562d1ea0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x3559220e0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355923490>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2451.3507421016693, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 34.13333333333333, "ram_util_percent": 28.312280701754386}, "win_rate": 0.79, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.207227060695489, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0401952938385269, "policy_loss": -0.027626661173417232, "vf_loss": 0.13163068043844153, "vf_explained_var": 0.13886592288812002, "kl": 0.015281738223198827, "entropy": 1.0497323639690876, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "sampler_results": {"episode_reward_max": 0.44999999999999996, "episode_reward_min": -1.02, "episode_reward_mean": -0.11602999999999998, "episode_len_mean": 61.61, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.053, "red_0_v1": -1.008, "red_0_v4": -1.013, "red_0_v3": -1.03, "red_0_v2": -1.034, "red_0_v5": -1.037}, "policy_reward_max": {"blue_0": 0.951, "red_0": 0.979, "red_0_v1": -0.502, "red_0_v4": 0.938, "red_0_v3": 0.9229999999999999, "red_0_v2": 1.4449999999999998, "red_0_v5": 1.436}, "policy_reward_mean": {"blue_0": -0.7476981132075473, "red_0": 0.43911, "red_0_v1": -0.8370000000000001, "red_0_v4": -0.11499999999999998, "red_0_v3": -0.5213, "red_0_v2": -0.20364285714285715, "red_0_v5": -0.20888888888888887}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.04299999999999993, -0.0229999999999998, -0.04799999999999993, -0.08199999999999996, -0.09899999999999987, -0.07900000000000007, 0.30199999999999994, -0.17499999999999993, -0.027000000000000024, -0.07999999999999985, 0.07199999999999995, -0.05500000000000005, -0.03599999999999992, -0.16400000000000003, -0.1339999999999999, 0.242, -0.20200000000000007, -0.15899999999999992, -0.02399999999999991, -0.05700000000000005, -0.1339999999999999, -0.1479999999999998, -0.08099999999999985, -0.09599999999999986, -0.16599999999999993, -0.06599999999999995, -0.29499999999999993, 0.44999999999999996, -0.09299999999999997, -0.19499999999999995, -0.07399999999999984, -0.31800000000000006, -0.10799999999999987, -0.551, -0.03700000000000003, -0.07600000000000007, -0.09199999999999997, -0.7100000000000002, -0.04400000000000004, -0.02499999999999991, 0.43499999999999994, -0.12899999999999978, -0.129, -0.2290000000000001, -0.10999999999999999, -0.14100000000000001, 0.44999999999999996, -0.30499999999999994, -0.06400000000000004, -0.06999999999999995, -0.2469999999999999, -0.03499999999999992, -0.8180000000000001, -0.02100000000000002, 0.44499999999999984, -0.024000000000000014, -0.04299999999999993, -0.581, -0.04700000000000004, -0.18900000000000006, -1.02, -0.07200000000000006, -0.06799999999999995, -0.03399999999999992, -0.04499999999999993, -0.03499999999999992, -0.08099999999999996, -0.6839999999999999, -0.23099999999999987, -0.7819999999999999, 0.364, -0.11599999999999999, -0.15700000000000003, -0.029000000000000026, -0.07899999999999996, -0.062000000000000055, -0.050000000000000044, -0.09400000000000007, -0.15800000000000003, -0.029000000000000026, -0.06699999999999995, -0.1380000000000001, -0.09599999999999986, 0.118, -0.11299999999999999, -0.16100000000000003, -0.5140000000000001, -0.259, -0.127, -0.20100000000000007, -0.5109999999999999, -0.08299999999999996, -0.05799999999999994, -0.07899999999999996, -0.42600000000000005, -0.08100000000000007, -0.050000000000000044, -0.08599999999999985, 0.4289999999999998, -0.05600000000000005], "episode_lengths": [14, 7, 15, 26, 28, 22, 63, 54, 9, 25, 128, 20, 11, 50, 41, 76, 56, 48, 7, 21, 39, 46, 26, 29, 55, 19, 84, 16, 31, 66, 23, 92, 33, 173, 11, 24, 30, 204, 14, 8, 22, 39, 41, 67, 33, 39, 16, 93, 300, 21, 78, 10, 250, 7, 16, 300, 14, 180, 15, 53, 293, 22, 21, 11, 14, 10, 24, 211, 64, 253, 38, 40, 49, 9, 24, 20, 16, 300, 50, 9, 22, 300, 31, 119, 35, 54, 135, 79, 39, 65, 164, 26, 17, 22, 132, 24, 15, 27, 21, 18], "policy_blue_0_reward": [-1.001, -1.0019999999999998, -1.002, -1.008, -1.0, -1.002, -0.517, -1.002, -1.012, -1.008, -1.01, 0.9339999999999999, -1.007, -1.006, -1.008, -0.502, -1.007, -1.005, -1.007, -1.023, -1.002, -1.002, -1.005, -1.029, -1.002, -1.001, -1.007, -0.502, 0.712, -0.03900000000000003, -1.004, -1.008, -1.024, -1.001, -1.004, -1.003, -1.001, -1.002, -1.005, -1.0279999999999998, -1.009, -1.002, -1.004, 0.844, -1.001, -1.003, -1.01, 0.876, -1.014, 0.919, -1.02, 0.951, -1.003], "policy_red_0_v1_reward": [-1.003, -0.505, -1.0, -1.008, -0.502, -1.004], "policy_red_0_v4_reward": [-1.006, 0.887, -1.013, 0.938, -1.001, -0.05500000000000004, -0.504, 0.834], "policy_red_0_v3_reward": [0.9229999999999999, -1.023, -1.019, -1.0, -1.03, -1.005, -1.025, -0.52, -0.05300000000000004, 0.5389999999999999], "policy_red_0_v2_reward": [0.9369999999999999, 1.2469999999999999, -1.003, -1.0099999999999998, -1.004, -1.034, 0.694, -1.026, -1.005, 1.4449999999999998, 0.004999999999999907, -1.007, -1.012, 0.9219999999999999], "policy_red_0_v5_reward": [-1.002, -1.037, -1.0, -0.014000000000000005, -1.001, -1.007, 0.8009999999999999, 1.436, 0.944]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23020136796148344, "mean_inference_ms": 1.4987324144457412, "mean_action_processing_ms": 0.062462870316190175, "mean_env_wait_ms": 0.10598228196420532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018661975860595703, "StateBufferConnector_ms": 0.001490473747253418, "ViewRequirementAgentConnector_ms": 0.030825018882751465}}, "episode_reward_max": 0.44999999999999996, "episode_reward_min": -1.02, "episode_reward_mean": -0.11602999999999998, "episode_len_mean": 61.61, "episodes_this_iter": 53, "policy_reward_min": {"blue_0": -1.029, "red_0": -1.053, "red_0_v1": -1.008, "red_0_v4": -1.013, "red_0_v3": -1.03, "red_0_v2": -1.034, "red_0_v5": -1.037}, "policy_reward_max": {"blue_0": 0.951, "red_0": 0.979, "red_0_v1": -0.502, "red_0_v4": 0.938, "red_0_v3": 0.9229999999999999, "red_0_v2": 1.4449999999999998, "red_0_v5": 1.436}, "policy_reward_mean": {"blue_0": -0.7476981132075473, "red_0": 0.43911, "red_0_v1": -0.8370000000000001, "red_0_v4": -0.11499999999999998, "red_0_v3": -0.5213, "red_0_v2": -0.20364285714285715, "red_0_v5": -0.20888888888888887}, "hist_stats": {"episode_reward": [-0.04299999999999993, -0.0229999999999998, -0.04799999999999993, -0.08199999999999996, -0.09899999999999987, -0.07900000000000007, 0.30199999999999994, -0.17499999999999993, -0.027000000000000024, -0.07999999999999985, 0.07199999999999995, -0.05500000000000005, -0.03599999999999992, -0.16400000000000003, -0.1339999999999999, 0.242, -0.20200000000000007, -0.15899999999999992, -0.02399999999999991, -0.05700000000000005, -0.1339999999999999, -0.1479999999999998, -0.08099999999999985, -0.09599999999999986, -0.16599999999999993, -0.06599999999999995, -0.29499999999999993, 0.44999999999999996, -0.09299999999999997, -0.19499999999999995, -0.07399999999999984, -0.31800000000000006, -0.10799999999999987, -0.551, -0.03700000000000003, -0.07600000000000007, -0.09199999999999997, -0.7100000000000002, -0.04400000000000004, -0.02499999999999991, 0.43499999999999994, -0.12899999999999978, -0.129, -0.2290000000000001, -0.10999999999999999, -0.14100000000000001, 0.44999999999999996, -0.30499999999999994, -0.06400000000000004, -0.06999999999999995, -0.2469999999999999, -0.03499999999999992, -0.8180000000000001, -0.02100000000000002, 0.44499999999999984, -0.024000000000000014, -0.04299999999999993, -0.581, -0.04700000000000004, -0.18900000000000006, -1.02, -0.07200000000000006, -0.06799999999999995, -0.03399999999999992, -0.04499999999999993, -0.03499999999999992, -0.08099999999999996, -0.6839999999999999, -0.23099999999999987, -0.7819999999999999, 0.364, -0.11599999999999999, -0.15700000000000003, -0.029000000000000026, -0.07899999999999996, -0.062000000000000055, -0.050000000000000044, -0.09400000000000007, -0.15800000000000003, -0.029000000000000026, -0.06699999999999995, -0.1380000000000001, -0.09599999999999986, 0.118, -0.11299999999999999, -0.16100000000000003, -0.5140000000000001, -0.259, -0.127, -0.20100000000000007, -0.5109999999999999, -0.08299999999999996, -0.05799999999999994, -0.07899999999999996, -0.42600000000000005, -0.08100000000000007, -0.050000000000000044, -0.08599999999999985, 0.4289999999999998, -0.05600000000000005], "episode_lengths": [14, 7, 15, 26, 28, 22, 63, 54, 9, 25, 128, 20, 11, 50, 41, 76, 56, 48, 7, 21, 39, 46, 26, 29, 55, 19, 84, 16, 31, 66, 23, 92, 33, 173, 11, 24, 30, 204, 14, 8, 22, 39, 41, 67, 33, 39, 16, 93, 300, 21, 78, 10, 250, 7, 16, 300, 14, 180, 15, 53, 293, 22, 21, 11, 14, 10, 24, 211, 64, 253, 38, 40, 49, 9, 24, 20, 16, 300, 50, 9, 22, 300, 31, 119, 35, 54, 135, 79, 39, 65, 164, 26, 17, 22, 132, 24, 15, 27, 21, 18], "policy_blue_0_reward": [-1.001, -1.0019999999999998, -1.002, -1.008, -1.0, -1.002, -0.517, -1.002, -1.012, -1.008, -1.01, 0.9339999999999999, -1.007, -1.006, -1.008, -0.502, -1.007, -1.005, -1.007, -1.023, -1.002, -1.002, -1.005, -1.029, -1.002, -1.001, -1.007, -0.502, 0.712, -0.03900000000000003, -1.004, -1.008, -1.024, -1.001, -1.004, -1.003, -1.001, -1.002, -1.005, -1.0279999999999998, -1.009, -1.002, -1.004, 0.844, -1.001, -1.003, -1.01, 0.876, -1.014, 0.919, -1.02, 0.951, -1.003], "policy_red_0_v1_reward": [-1.003, -0.505, -1.0, -1.008, -0.502, -1.004], "policy_red_0_v4_reward": [-1.006, 0.887, -1.013, 0.938, -1.001, -0.05500000000000004, -0.504, 0.834], "policy_red_0_v3_reward": [0.9229999999999999, -1.023, -1.019, -1.0, -1.03, -1.005, -1.025, -0.52, -0.05300000000000004, 0.5389999999999999], "policy_red_0_v2_reward": [0.9369999999999999, 1.2469999999999999, -1.003, -1.0099999999999998, -1.004, -1.034, 0.694, -1.026, -1.005, 1.4449999999999998, 0.004999999999999907, -1.007, -1.012, 0.9219999999999999], "policy_red_0_v5_reward": [-1.002, -1.037, -1.0, -0.014000000000000005, -1.001, -1.007, 0.8009999999999999, 1.436, 0.944]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23020136796148344, "mean_inference_ms": 1.4987324144457412, "mean_action_processing_ms": 0.062462870316190175, "mean_env_wait_ms": 0.10598228196420532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018661975860595703, "StateBufferConnector_ms": 0.001490473747253418, "ViewRequirementAgentConnector_ms": 0.030825018882751465}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.61750920611769, "num_env_steps_trained_throughput_per_sec": 101.61750920611769, "timesteps_total": 252000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 504000, "timers": {"training_iteration_time_ms": 39721.916, "sample_time_ms": 7730.617, "learn_time_ms": 31973.402, "learn_throughput": 125.104, "synch_weights_time_ms": 17.253}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "done": false, "episodes_total": 3981, "training_iteration": 63, "trial_id": "bb874_00000", "date": "2023-09-28_22-11-46", "timestamp": 1695953506, "time_this_iter_s": 39.36582112312317, "time_total_s": 2490.7165632247925, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d55900>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4dfb50>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dce50>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2490.7165632247925, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 35.56071428571428, "ram_util_percent": 28.473214285714285}, "win_rate": 0.8, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.179454009483258, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.052300190265426254, "policy_loss": -0.024300332534282158, "vf_loss": 0.1499682823739325, "vf_explained_var": 0.20512964067359765, "kl": 0.012907049432783424, "entropy": 0.9650282158826788, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "sampler_results": {"episode_reward_max": 0.4730000000000001, "episode_reward_min": -0.543, "episode_reward_mean": -0.09538999999999997, "episode_len_mean": 58.7, "episode_media": {}, "episodes_this_iter": 75, "policy_reward_min": {"red_0_v4": -1.006, "red_0": -1.053, "blue_0": -1.024, "red_0_v5": -1.0099999999999998, "red_0_v3": -1.025, "red_0_v2": -1.033, "red_0_v1": -1.012}, "policy_reward_max": {"red_0_v4": 0.938, "red_0": 0.979, "blue_0": 0.951, "red_0_v5": 1.436, "red_0_v3": 0.857, "red_0_v2": 0.958, "red_0_v1": 0.95}, "policy_reward_mean": {"red_0_v4": -0.20140000000000002, "red_0": 0.3236200000000001, "blue_0": -0.7595106382978722, "red_0_v5": 0.2826875, "red_0_v3": -0.2927, "red_0_v2": -0.28546153846153843, "red_0_v1": -0.5187499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.062000000000000055, -0.050000000000000044, -0.09400000000000007, -0.15800000000000003, -0.029000000000000026, -0.06699999999999995, -0.1380000000000001, -0.09599999999999986, 0.118, -0.11299999999999999, -0.16100000000000003, -0.5140000000000001, -0.259, -0.127, -0.20100000000000007, -0.5109999999999999, -0.08299999999999996, -0.05799999999999994, -0.07899999999999996, -0.42600000000000005, -0.08100000000000007, -0.050000000000000044, -0.08599999999999985, 0.4289999999999998, -0.05600000000000005, -0.21399999999999997, -0.08899999999999997, -0.126, -0.052000000000000046, -0.4819999999999999, 0.43100000000000005, -0.030000000000000027, -0.18499999999999994, -0.122, -0.11399999999999988, -0.029000000000000026, -0.19900000000000007, -0.10299999999999987, 0.4730000000000001, -0.051000000000000045, -0.07699999999999996, -0.04400000000000004, -0.543, 0.42400000000000015, -0.07899999999999996, -0.46599999999999997, -0.10599999999999998, -0.16799999999999993, -0.3460000000000001, -0.20499999999999985, -0.08099999999999996, -0.18100000000000005, -0.02100000000000001, -0.03199999999999992, -0.20499999999999996, -0.23299999999999987, -0.474, -0.038000000000000034, -0.041999999999999926, -0.14500000000000002, -0.12399999999999989, -0.16399999999999992, 0.42200000000000004, 0.43699999999999994, -0.04200000000000004, -0.2509999999999999, -0.03700000000000003, 0.42499999999999993, 0.42499999999999993, -0.31399999999999995, -0.05699999999999994, -0.04700000000000004, -0.12, -0.09499999999999986, -0.08899999999999986, -0.14600000000000002, -0.02300000000000002, -0.06400000000000006, -0.06399999999999983, -0.06099999999999994, -0.04599999999999993, -0.30899999999999994, -0.10499999999999998, -0.43799999999999994, -0.03500000000000003, -0.03500000000000003, -0.09399999999999986, -0.14100000000000001, -0.17299999999999982, -0.07200000000000005, -0.139, -0.08099999999999996, -0.07799999999999996, -0.02400000000000002, -0.07899999999999996, -0.489, -0.10199999999999987, -0.048000000000000036, -0.18000000000000005, 0.02399999999999991], "episode_lengths": [20, 16, 300, 50, 9, 22, 300, 31, 119, 35, 54, 135, 79, 39, 65, 164, 26, 17, 22, 132, 24, 15, 27, 21, 18, 71, 27, 45, 16, 157, 23, 10, 50, 38, 37, 13, 57, 30, 8, 15, 25, 16, 175, 23, 25, 131, 34, 53, 94, 64, 25, 60, 300, 9, 60, 74, 142, 12, 16, 47, 35, 51, 25, 22, 13, 76, 12, 24, 24, 91, 18, 17, 36, 30, 28, 44, 7, 24, 20, 23, 15, 96, 29, 143, 11, 11, 29, 45, 51, 300, 39, 24, 26, 8, 25, 157, 31, 300, 55, 133], "policy_red_0_v4_reward": [0.938, -1.001, -0.05500000000000004, -0.504, 0.834, 0.787, -0.5, -0.505, -1.006, -1.002], "policy_blue_0_reward": [0.844, -1.001, -1.003, -1.01, 0.876, -1.014, 0.919, -1.02, 0.951, -1.003, -1.002, -1.007, -1.002, -1.0, -0.5019999999999999, -1.001, -0.5019999999999999, -1.003, -1.015, -1.004, -1.006, -1.004, -1.008, -1.007, -1.024, -1.002, -1.009, -0.502, -1.014, -0.503, -0.503, -1.003, -1.005, -1.004, -1.002, -1.003, -1.001, -1.001, -1.002, -1.004, -1.003, -1.009, -0.05100000000000004, -1.0, -1.004, -1.005, -0.519], "policy_red_0_v5_reward": [-1.001, -1.007, 0.8009999999999999, 1.436, 0.944, 0.865, -1.004, 0.97, -1.0099999999999998, 0.949, -1.005, 0.82, -0.008, 0.964, 0.887, 0.922], "policy_red_0_v3_reward": [-0.05300000000000004, 0.5389999999999999, -1.025, 0.857, -1.002, -1.012, -1.006, -1.012, -0.035000000000000024, 0.822], "policy_red_0_v2_reward": [-1.007, -1.012, 0.9219999999999999, 0.912, -1.019, 0.6629999999999999, -1.005, -1.019, 0.958, -1.033, -1.001, 0.944, -1.014], "policy_red_0_v1_reward": [0.95, -1.012, -1.0019999999999998, -1.011]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031544179686084, "mean_inference_ms": 1.5003109314543261, "mean_action_processing_ms": 0.06250293358112083, "mean_env_wait_ms": 0.10611001697552061, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018169164657592773, "StateBufferConnector_ms": 0.0014927387237548828, "ViewRequirementAgentConnector_ms": 0.03060448169708252}}, "episode_reward_max": 0.4730000000000001, "episode_reward_min": -0.543, "episode_reward_mean": -0.09538999999999997, "episode_len_mean": 58.7, "episodes_this_iter": 75, "policy_reward_min": {"red_0_v4": -1.006, "red_0": -1.053, "blue_0": -1.024, "red_0_v5": -1.0099999999999998, "red_0_v3": -1.025, "red_0_v2": -1.033, "red_0_v1": -1.012}, "policy_reward_max": {"red_0_v4": 0.938, "red_0": 0.979, "blue_0": 0.951, "red_0_v5": 1.436, "red_0_v3": 0.857, "red_0_v2": 0.958, "red_0_v1": 0.95}, "policy_reward_mean": {"red_0_v4": -0.20140000000000002, "red_0": 0.3236200000000001, "blue_0": -0.7595106382978722, "red_0_v5": 0.2826875, "red_0_v3": -0.2927, "red_0_v2": -0.28546153846153843, "red_0_v1": -0.5187499999999999}, "hist_stats": {"episode_reward": [-0.062000000000000055, -0.050000000000000044, -0.09400000000000007, -0.15800000000000003, -0.029000000000000026, -0.06699999999999995, -0.1380000000000001, -0.09599999999999986, 0.118, -0.11299999999999999, -0.16100000000000003, -0.5140000000000001, -0.259, -0.127, -0.20100000000000007, -0.5109999999999999, -0.08299999999999996, -0.05799999999999994, -0.07899999999999996, -0.42600000000000005, -0.08100000000000007, -0.050000000000000044, -0.08599999999999985, 0.4289999999999998, -0.05600000000000005, -0.21399999999999997, -0.08899999999999997, -0.126, -0.052000000000000046, -0.4819999999999999, 0.43100000000000005, -0.030000000000000027, -0.18499999999999994, -0.122, -0.11399999999999988, -0.029000000000000026, -0.19900000000000007, -0.10299999999999987, 0.4730000000000001, -0.051000000000000045, -0.07699999999999996, -0.04400000000000004, -0.543, 0.42400000000000015, -0.07899999999999996, -0.46599999999999997, -0.10599999999999998, -0.16799999999999993, -0.3460000000000001, -0.20499999999999985, -0.08099999999999996, -0.18100000000000005, -0.02100000000000001, -0.03199999999999992, -0.20499999999999996, -0.23299999999999987, -0.474, -0.038000000000000034, -0.041999999999999926, -0.14500000000000002, -0.12399999999999989, -0.16399999999999992, 0.42200000000000004, 0.43699999999999994, -0.04200000000000004, -0.2509999999999999, -0.03700000000000003, 0.42499999999999993, 0.42499999999999993, -0.31399999999999995, -0.05699999999999994, -0.04700000000000004, -0.12, -0.09499999999999986, -0.08899999999999986, -0.14600000000000002, -0.02300000000000002, -0.06400000000000006, -0.06399999999999983, -0.06099999999999994, -0.04599999999999993, -0.30899999999999994, -0.10499999999999998, -0.43799999999999994, -0.03500000000000003, -0.03500000000000003, -0.09399999999999986, -0.14100000000000001, -0.17299999999999982, -0.07200000000000005, -0.139, -0.08099999999999996, -0.07799999999999996, -0.02400000000000002, -0.07899999999999996, -0.489, -0.10199999999999987, -0.048000000000000036, -0.18000000000000005, 0.02399999999999991], "episode_lengths": [20, 16, 300, 50, 9, 22, 300, 31, 119, 35, 54, 135, 79, 39, 65, 164, 26, 17, 22, 132, 24, 15, 27, 21, 18, 71, 27, 45, 16, 157, 23, 10, 50, 38, 37, 13, 57, 30, 8, 15, 25, 16, 175, 23, 25, 131, 34, 53, 94, 64, 25, 60, 300, 9, 60, 74, 142, 12, 16, 47, 35, 51, 25, 22, 13, 76, 12, 24, 24, 91, 18, 17, 36, 30, 28, 44, 7, 24, 20, 23, 15, 96, 29, 143, 11, 11, 29, 45, 51, 300, 39, 24, 26, 8, 25, 157, 31, 300, 55, 133], "policy_red_0_v4_reward": [0.938, -1.001, -0.05500000000000004, -0.504, 0.834, 0.787, -0.5, -0.505, -1.006, -1.002], "policy_blue_0_reward": [0.844, -1.001, -1.003, -1.01, 0.876, -1.014, 0.919, -1.02, 0.951, -1.003, -1.002, -1.007, -1.002, -1.0, -0.5019999999999999, -1.001, -0.5019999999999999, -1.003, -1.015, -1.004, -1.006, -1.004, -1.008, -1.007, -1.024, -1.002, -1.009, -0.502, -1.014, -0.503, -0.503, -1.003, -1.005, -1.004, -1.002, -1.003, -1.001, -1.001, -1.002, -1.004, -1.003, -1.009, -0.05100000000000004, -1.0, -1.004, -1.005, -0.519], "policy_red_0_v5_reward": [-1.001, -1.007, 0.8009999999999999, 1.436, 0.944, 0.865, -1.004, 0.97, -1.0099999999999998, 0.949, -1.005, 0.82, -0.008, 0.964, 0.887, 0.922], "policy_red_0_v3_reward": [-0.05300000000000004, 0.5389999999999999, -1.025, 0.857, -1.002, -1.012, -1.006, -1.012, -0.035000000000000024, 0.822], "policy_red_0_v2_reward": [-1.007, -1.012, 0.9219999999999999, 0.912, -1.019, 0.6629999999999999, -1.005, -1.019, 0.958, -1.033, -1.001, 0.944, -1.014], "policy_red_0_v1_reward": [0.95, -1.012, -1.0019999999999998, -1.011]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031544179686084, "mean_inference_ms": 1.5003109314543261, "mean_action_processing_ms": 0.06250293358112083, "mean_env_wait_ms": 0.10611001697552061, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018169164657592773, "StateBufferConnector_ms": 0.0014927387237548828, "ViewRequirementAgentConnector_ms": 0.03060448169708252}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.31750797034672, "num_env_steps_trained_throughput_per_sec": 100.31750797034672, "timesteps_total": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 39729.61, "sample_time_ms": 7734.096, "learn_time_ms": 31977.618, "learn_throughput": 125.087, "synch_weights_time_ms": 17.251}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "episodes_total": 4056, "training_iteration": 64, "trial_id": "bb874_00000", "date": "2023-09-28_22-12-25", "timestamp": 1695953545, "time_this_iter_s": 39.8761031627655, "time_total_s": 2530.592666387558, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x356680190>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ad626dd0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ad626200>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2530.592666387558, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 34.732142857142854, "ram_util_percent": 28.56607142857143}, "win_rate": 0.74, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0589661529908576, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.020747042377721906, "policy_loss": -0.027082128502540097, "vf_loss": 0.09226211482503761, "vf_explained_var": 0.22729244027286769, "kl": 0.013695297756732968, "entropy": 1.040946382905046, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "sampler_results": {"episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.6529999999999999, "episode_reward_mean": -0.1042, "episode_len_mean": 59.04, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"red_0_v2": -1.063, "red_0": -1.015, "blue_0": -1.027, "red_0_v4": -1.029, "red_0_v5": -1.016, "red_0_v3": -1.025, "red_0_v1": -1.011}, "policy_reward_max": {"red_0_v2": 1.428, "red_0": 0.979, "blue_0": 0.955, "red_0_v4": 0.981, "red_0_v5": 0.964, "red_0_v3": 0.845, "red_0_v1": 1.255}, "policy_reward_mean": {"red_0_v2": -0.38149999999999995, "red_0": 0.53183, "blue_0": -0.8668979591836734, "red_0_v4": -0.594, "red_0_v5": -0.10966666666666668, "red_0_v3": -0.43000000000000005, "red_0_v1": -0.4961111111111111}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.12399999999999989, -0.16399999999999992, 0.42200000000000004, 0.43699999999999994, -0.04200000000000004, -0.2509999999999999, -0.03700000000000003, 0.42499999999999993, 0.42499999999999993, -0.31399999999999995, -0.05699999999999994, -0.04700000000000004, -0.12, -0.09499999999999986, -0.08899999999999986, -0.14600000000000002, -0.02300000000000002, -0.06400000000000006, -0.06399999999999983, -0.06099999999999994, -0.04599999999999993, -0.30899999999999994, -0.10499999999999998, -0.43799999999999994, -0.03500000000000003, -0.03500000000000003, -0.09399999999999986, -0.14100000000000001, -0.17299999999999982, -0.07200000000000005, -0.139, -0.08099999999999996, -0.07799999999999996, -0.02400000000000002, -0.07899999999999996, -0.489, -0.10199999999999987, -0.048000000000000036, -0.18000000000000005, 0.02399999999999991, -0.591, -0.05099999999999982, -0.32000000000000006, -0.05400000000000005, -0.09599999999999986, 0.19200000000000006, -0.236, -0.529, -0.16499999999999992, -0.027000000000000024, -0.05300000000000005, -0.07400000000000007, -0.31000000000000005, -0.030000000000000027, -0.03599999999999992, -0.04599999999999993, -0.47099999999999986, -0.05700000000000005, -0.03600000000000003, -0.04400000000000004, -0.05500000000000005, 0.2509999999999999, -0.052999999999999936, 0.43899999999999995, -0.19999999999999996, -0.08099999999999996, 0.3410000000000001, -0.04299999999999993, -0.02100000000000002, -0.03500000000000003, -0.02199999999999991, 0.43699999999999983, -0.236, -0.56, -0.28, -0.10999999999999999, -0.20100000000000007, -0.565, -0.02499999999999991, -0.028999999999999915, -0.42100000000000004, -0.16600000000000004, -0.03300000000000003, -0.44099999999999995, -0.026000000000000023, -0.39, -0.6529999999999999, -0.09800000000000007, 0.14800000000000002, -0.18800000000000006, -0.027000000000000024, -0.44599999999999995, -0.020000000000000018, -0.20499999999999985, -0.05300000000000005, -0.10699999999999998, -0.04500000000000004, -0.2779999999999999, -0.17900000000000005, -0.07699999999999996], "episode_lengths": [35, 51, 25, 22, 13, 76, 12, 24, 24, 91, 18, 17, 36, 30, 28, 44, 7, 24, 20, 23, 15, 96, 29, 143, 11, 11, 29, 45, 51, 300, 39, 24, 26, 8, 25, 157, 31, 300, 55, 133, 172, 15, 92, 18, 31, 97, 73, 163, 50, 9, 15, 24, 80, 10, 11, 15, 156, 18, 15, 14, 17, 79, 16, 19, 55, 25, 50, 14, 7, 11, 7, 22, 78, 172, 82, 36, 60, 176, 8, 8, 131, 49, 11, 134, 8, 124, 200, 300, 107, 60, 9, 139, 6, 66, 20, 33, 13, 87, 215, 24], "policy_red_0_v2_reward": [-1.019, 0.958, -1.033, -1.001, 0.944, -1.014, -1.063, -1.01, 1.428, -1.005], "policy_blue_0_reward": [-1.009, -0.502, -1.014, -0.503, -0.503, -1.003, -1.005, -1.004, -1.002, -1.003, -1.001, -1.001, -1.002, -1.004, -1.003, -1.009, -0.05100000000000004, -1.0, -1.004, -1.005, -0.519, -1.005, -1.023, -1.001, -1.0099999999999998, -1.023, -1.0, -1.0019999999999998, -0.503, -1.004, -1.0, -1.001, -1.02, -1.003, -1.001, -1.018, -1.0, -1.027, -1.001, -1.013, -1.0259999999999998, -0.04400000000000003, -1.0, -1.015, -1.003, 0.955, -1.01, -0.529, -1.004], "policy_red_0_v4_reward": [-0.505, -1.006, -1.002, -0.508, -1.0, -1.0, 0.946, -1.0, -1.029, 0.981, -1.004, -1.001], "policy_red_0_v5_reward": [0.964, 0.887, 0.922, -1.002, -1.002, -1.001, -0.5049999999999999, 0.766, -1.016], "policy_red_0_v3_reward": [-1.002, -1.012, -1.006, -1.012, -0.035000000000000024, 0.822, -1.008, 0.705, -1.025, -1.002, 0.845], "policy_red_0_v1_reward": [-1.011, -1.0, -1.0, -1.0, -1.001, 1.255, 0.8089999999999999, -0.511, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23029444743147606, "mean_inference_ms": 1.49987893584643, "mean_action_processing_ms": 0.0624701569691306, "mean_env_wait_ms": 0.1060530571154781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018198711531502862, "StateBufferConnector_ms": 0.0015434367316109793, "ViewRequirementAgentConnector_ms": 0.030905536242893765}}, "episode_reward_max": 0.43899999999999995, "episode_reward_min": -0.6529999999999999, "episode_reward_mean": -0.1042, "episode_len_mean": 59.04, "episodes_this_iter": 60, "policy_reward_min": {"red_0_v2": -1.063, "red_0": -1.015, "blue_0": -1.027, "red_0_v4": -1.029, "red_0_v5": -1.016, "red_0_v3": -1.025, "red_0_v1": -1.011}, "policy_reward_max": {"red_0_v2": 1.428, "red_0": 0.979, "blue_0": 0.955, "red_0_v4": 0.981, "red_0_v5": 0.964, "red_0_v3": 0.845, "red_0_v1": 1.255}, "policy_reward_mean": {"red_0_v2": -0.38149999999999995, "red_0": 0.53183, "blue_0": -0.8668979591836734, "red_0_v4": -0.594, "red_0_v5": -0.10966666666666668, "red_0_v3": -0.43000000000000005, "red_0_v1": -0.4961111111111111}, "hist_stats": {"episode_reward": [-0.12399999999999989, -0.16399999999999992, 0.42200000000000004, 0.43699999999999994, -0.04200000000000004, -0.2509999999999999, -0.03700000000000003, 0.42499999999999993, 0.42499999999999993, -0.31399999999999995, -0.05699999999999994, -0.04700000000000004, -0.12, -0.09499999999999986, -0.08899999999999986, -0.14600000000000002, -0.02300000000000002, -0.06400000000000006, -0.06399999999999983, -0.06099999999999994, -0.04599999999999993, -0.30899999999999994, -0.10499999999999998, -0.43799999999999994, -0.03500000000000003, -0.03500000000000003, -0.09399999999999986, -0.14100000000000001, -0.17299999999999982, -0.07200000000000005, -0.139, -0.08099999999999996, -0.07799999999999996, -0.02400000000000002, -0.07899999999999996, -0.489, -0.10199999999999987, -0.048000000000000036, -0.18000000000000005, 0.02399999999999991, -0.591, -0.05099999999999982, -0.32000000000000006, -0.05400000000000005, -0.09599999999999986, 0.19200000000000006, -0.236, -0.529, -0.16499999999999992, -0.027000000000000024, -0.05300000000000005, -0.07400000000000007, -0.31000000000000005, -0.030000000000000027, -0.03599999999999992, -0.04599999999999993, -0.47099999999999986, -0.05700000000000005, -0.03600000000000003, -0.04400000000000004, -0.05500000000000005, 0.2509999999999999, -0.052999999999999936, 0.43899999999999995, -0.19999999999999996, -0.08099999999999996, 0.3410000000000001, -0.04299999999999993, -0.02100000000000002, -0.03500000000000003, -0.02199999999999991, 0.43699999999999983, -0.236, -0.56, -0.28, -0.10999999999999999, -0.20100000000000007, -0.565, -0.02499999999999991, -0.028999999999999915, -0.42100000000000004, -0.16600000000000004, -0.03300000000000003, -0.44099999999999995, -0.026000000000000023, -0.39, -0.6529999999999999, -0.09800000000000007, 0.14800000000000002, -0.18800000000000006, -0.027000000000000024, -0.44599999999999995, -0.020000000000000018, -0.20499999999999985, -0.05300000000000005, -0.10699999999999998, -0.04500000000000004, -0.2779999999999999, -0.17900000000000005, -0.07699999999999996], "episode_lengths": [35, 51, 25, 22, 13, 76, 12, 24, 24, 91, 18, 17, 36, 30, 28, 44, 7, 24, 20, 23, 15, 96, 29, 143, 11, 11, 29, 45, 51, 300, 39, 24, 26, 8, 25, 157, 31, 300, 55, 133, 172, 15, 92, 18, 31, 97, 73, 163, 50, 9, 15, 24, 80, 10, 11, 15, 156, 18, 15, 14, 17, 79, 16, 19, 55, 25, 50, 14, 7, 11, 7, 22, 78, 172, 82, 36, 60, 176, 8, 8, 131, 49, 11, 134, 8, 124, 200, 300, 107, 60, 9, 139, 6, 66, 20, 33, 13, 87, 215, 24], "policy_red_0_v2_reward": [-1.019, 0.958, -1.033, -1.001, 0.944, -1.014, -1.063, -1.01, 1.428, -1.005], "policy_blue_0_reward": [-1.009, -0.502, -1.014, -0.503, -0.503, -1.003, -1.005, -1.004, -1.002, -1.003, -1.001, -1.001, -1.002, -1.004, -1.003, -1.009, -0.05100000000000004, -1.0, -1.004, -1.005, -0.519, -1.005, -1.023, -1.001, -1.0099999999999998, -1.023, -1.0, -1.0019999999999998, -0.503, -1.004, -1.0, -1.001, -1.02, -1.003, -1.001, -1.018, -1.0, -1.027, -1.001, -1.013, -1.0259999999999998, -0.04400000000000003, -1.0, -1.015, -1.003, 0.955, -1.01, -0.529, -1.004], "policy_red_0_v4_reward": [-0.505, -1.006, -1.002, -0.508, -1.0, -1.0, 0.946, -1.0, -1.029, 0.981, -1.004, -1.001], "policy_red_0_v5_reward": [0.964, 0.887, 0.922, -1.002, -1.002, -1.001, -0.5049999999999999, 0.766, -1.016], "policy_red_0_v3_reward": [-1.002, -1.012, -1.006, -1.012, -0.035000000000000024, 0.822, -1.008, 0.705, -1.025, -1.002, 0.845], "policy_red_0_v1_reward": [-1.011, -1.0, -1.0, -1.0, -1.001, 1.255, 0.8089999999999999, -0.511, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23029444743147606, "mean_inference_ms": 1.49987893584643, "mean_action_processing_ms": 0.0624701569691306, "mean_env_wait_ms": 0.1060530571154781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018198711531502862, "StateBufferConnector_ms": 0.0015434367316109793, "ViewRequirementAgentConnector_ms": 0.030905536242893765}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.90010916160294, "num_env_steps_trained_throughput_per_sec": 100.90010916160294, "timesteps_total": 260000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 520000, "timers": {"training_iteration_time_ms": 39716.32, "sample_time_ms": 7732.425, "learn_time_ms": 31966.139, "learn_throughput": 125.132, "synch_weights_time_ms": 17.114}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "done": false, "episodes_total": 4116, "training_iteration": 65, "trial_id": "bb874_00000", "date": "2023-09-28_22-13-05", "timestamp": 1695953585, "time_this_iter_s": 39.645761013031006, "time_total_s": 2570.238427400589, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b7d25600>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355921090>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x3559212d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2570.238427400589, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 37.449122807017545, "ram_util_percent": 28.712280701754388}, "win_rate": 0.85, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1303938095768293, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05522773966222303, "policy_loss": -0.022614917128521483, "vf_loss": 0.15369802371133118, "vf_explained_var": 0.22372753086189429, "kl": 0.010008893658099172, "entropy": 1.0081341966986657, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "sampler_results": {"episode_reward_max": 0.45399999999999996, "episode_reward_min": -0.925, "episode_reward_mean": -0.13929999999999998, "episode_len_mean": 63.58, "episode_media": {}, "episodes_this_iter": 72, "policy_reward_min": {"red_0_v5": -1.016, "red_0": -1.011, "blue_0": -1.036, "red_0_v1": -1.019, "red_0_v4": -1.029, "red_0_v2": -1.015, "red_0_v3": -1.0119999999999998}, "policy_reward_max": {"red_0_v5": 1.408, "red_0": 0.98, "blue_0": 0.955, "red_0_v1": 0.974, "red_0_v4": 0.981, "red_0_v2": 0.945, "red_0_v3": 0.845}, "policy_reward_mean": {"red_0_v5": -0.1457, "red_0": 0.38351999999999997, "blue_0": -0.7690370370370367, "red_0_v1": -0.47187499999999993, "red_0_v4": -0.05790909090909093, "red_0_v2": -0.22954545454545452, "red_0_v3": -0.39333333333333326}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.236, -0.56, -0.28, -0.10999999999999999, -0.20100000000000007, -0.565, -0.02499999999999991, -0.028999999999999915, -0.42100000000000004, -0.16600000000000004, -0.03300000000000003, -0.44099999999999995, -0.026000000000000023, -0.39, -0.6529999999999999, -0.09800000000000007, 0.14800000000000002, -0.18800000000000006, -0.027000000000000024, -0.44599999999999995, -0.020000000000000018, -0.20499999999999985, -0.05300000000000005, -0.10699999999999998, -0.04500000000000004, -0.2779999999999999, -0.17900000000000005, -0.07699999999999996, -0.925, -0.09899999999999998, -0.749, -0.08599999999999985, 0.45399999999999996, -0.23699999999999988, -0.29400000000000004, -0.026000000000000023, -0.2819999999999999, -0.050999999999999934, -0.04700000000000004, 0.40700000000000003, -0.04500000000000004, -0.04600000000000004, -0.20999999999999996, -0.09499999999999986, -0.18499999999999983, -0.498, -0.11399999999999977, -0.050000000000000044, -0.132, -0.07199999999999984, -0.09399999999999997, -0.05999999999999994, -0.07999999999999985, -0.04300000000000004, -0.05699999999999994, -0.08799999999999997, -0.09999999999999998, -0.041000000000000036, -0.09899999999999987, -0.07900000000000007, -0.04499999999999993, -0.07200000000000006, -0.06800000000000006, -0.02400000000000002, -0.20200000000000007, -0.08400000000000007, -0.05200000000000004, 0.351, -0.123, -0.15400000000000003, -0.30600000000000005, -0.43999999999999995, -0.31500000000000006, -0.41900000000000004, -0.14, 0.05499999999999994, -0.05800000000000005, -0.1359999999999999, -0.06999999999999995, -0.07200000000000006, -0.34099999999999997, -0.10799999999999987, -0.028999999999999915, -0.17600000000000005, -0.030999999999999917, -0.1279999999999999, -0.22699999999999998, -0.11099999999999999, -0.039000000000000035, -0.07599999999999985, -0.14400000000000002, -0.02400000000000002, -0.363, -0.03700000000000003, -0.17299999999999993, 0.15500000000000003, 0.346, -0.038999999999999924, -0.1459999999999999, -0.030999999999999917], "episode_lengths": [78, 172, 82, 36, 60, 176, 8, 8, 131, 49, 11, 134, 8, 124, 200, 300, 107, 60, 9, 139, 6, 66, 20, 33, 13, 87, 215, 24, 280, 31, 229, 30, 15, 72, 84, 8, 83, 16, 17, 30, 15, 14, 62, 28, 59, 148, 34, 16, 40, 20, 28, 17, 23, 13, 18, 28, 28, 169, 30, 24, 14, 22, 20, 10, 56, 24, 300, 45, 34, 46, 94, 123, 98, 274, 47, 140, 19, 43, 26, 22, 102, 31, 8, 55, 10, 41, 71, 31, 12, 23, 48, 8, 111, 12, 50, 109, 49, 12, 43, 10], "policy_red_0_v5_reward": [0.766, -1.016, -1.009, 1.408, -1.003, -1.003, 0.942, -1.002, 0.963, -0.503], "policy_blue_0_reward": [-1.02, -1.003, -1.001, -1.018, -1.0, -1.027, -1.001, -1.013, -1.0259999999999998, -0.04400000000000003, -1.0, -1.015, -1.003, 0.955, -1.01, -0.529, -1.004, -1.036, -1.0039999999999998, -1.013, -1.007, -1.002, -1.0, -1.0, -1.009, -1.004, -1.021, 0.951, -1.004, -1.005, -1.003, -1.003, -1.005, 0.9239999999999999, -1.002, -1.004, -0.505, -1.007, 0.701, -0.5489999999999999, -1.005, -0.52, -1.005, 0.9279999999999999, -1.0199999999999998, -1.001, -1.005, -1.004, -1.005, -1.0, -1.013, -0.507, -1.004, -1.001], "policy_red_0_v1_reward": [0.8089999999999999, -0.511, -1.006, -1.002, -1.014, 0.974, -1.0059999999999998, -1.019], "policy_red_0_v4_reward": [-1.029, 0.981, -1.004, -1.001, -0.5, -0.518, 0.9309999999999999, -1.004, 0.69, 0.964, 0.853], "policy_red_0_v2_reward": [-1.005, 0.945, -1.009, -1.013, 0.9329999999999999, 0.7939999999999999, -0.03300000000000002, 0.885, -1.005, -1.015, -1.002], "policy_red_0_v3_reward": [0.845, -1.0119999999999998, -1.002, -1.011, 0.827, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2301575136913742, "mean_inference_ms": 1.4995131384276836, "mean_action_processing_ms": 0.06247260218472978, "mean_env_wait_ms": 0.10603731884887445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018789393561226983, "StateBufferConnector_ms": 0.0015775305884225027, "ViewRequirementAgentConnector_ms": 0.03153198105948312}}, "episode_reward_max": 0.45399999999999996, "episode_reward_min": -0.925, "episode_reward_mean": -0.13929999999999998, "episode_len_mean": 63.58, "episodes_this_iter": 72, "policy_reward_min": {"red_0_v5": -1.016, "red_0": -1.011, "blue_0": -1.036, "red_0_v1": -1.019, "red_0_v4": -1.029, "red_0_v2": -1.015, "red_0_v3": -1.0119999999999998}, "policy_reward_max": {"red_0_v5": 1.408, "red_0": 0.98, "blue_0": 0.955, "red_0_v1": 0.974, "red_0_v4": 0.981, "red_0_v2": 0.945, "red_0_v3": 0.845}, "policy_reward_mean": {"red_0_v5": -0.1457, "red_0": 0.38351999999999997, "blue_0": -0.7690370370370367, "red_0_v1": -0.47187499999999993, "red_0_v4": -0.05790909090909093, "red_0_v2": -0.22954545454545452, "red_0_v3": -0.39333333333333326}, "hist_stats": {"episode_reward": [-0.236, -0.56, -0.28, -0.10999999999999999, -0.20100000000000007, -0.565, -0.02499999999999991, -0.028999999999999915, -0.42100000000000004, -0.16600000000000004, -0.03300000000000003, -0.44099999999999995, -0.026000000000000023, -0.39, -0.6529999999999999, -0.09800000000000007, 0.14800000000000002, -0.18800000000000006, -0.027000000000000024, -0.44599999999999995, -0.020000000000000018, -0.20499999999999985, -0.05300000000000005, -0.10699999999999998, -0.04500000000000004, -0.2779999999999999, -0.17900000000000005, -0.07699999999999996, -0.925, -0.09899999999999998, -0.749, -0.08599999999999985, 0.45399999999999996, -0.23699999999999988, -0.29400000000000004, -0.026000000000000023, -0.2819999999999999, -0.050999999999999934, -0.04700000000000004, 0.40700000000000003, -0.04500000000000004, -0.04600000000000004, -0.20999999999999996, -0.09499999999999986, -0.18499999999999983, -0.498, -0.11399999999999977, -0.050000000000000044, -0.132, -0.07199999999999984, -0.09399999999999997, -0.05999999999999994, -0.07999999999999985, -0.04300000000000004, -0.05699999999999994, -0.08799999999999997, -0.09999999999999998, -0.041000000000000036, -0.09899999999999987, -0.07900000000000007, -0.04499999999999993, -0.07200000000000006, -0.06800000000000006, -0.02400000000000002, -0.20200000000000007, -0.08400000000000007, -0.05200000000000004, 0.351, -0.123, -0.15400000000000003, -0.30600000000000005, -0.43999999999999995, -0.31500000000000006, -0.41900000000000004, -0.14, 0.05499999999999994, -0.05800000000000005, -0.1359999999999999, -0.06999999999999995, -0.07200000000000006, -0.34099999999999997, -0.10799999999999987, -0.028999999999999915, -0.17600000000000005, -0.030999999999999917, -0.1279999999999999, -0.22699999999999998, -0.11099999999999999, -0.039000000000000035, -0.07599999999999985, -0.14400000000000002, -0.02400000000000002, -0.363, -0.03700000000000003, -0.17299999999999993, 0.15500000000000003, 0.346, -0.038999999999999924, -0.1459999999999999, -0.030999999999999917], "episode_lengths": [78, 172, 82, 36, 60, 176, 8, 8, 131, 49, 11, 134, 8, 124, 200, 300, 107, 60, 9, 139, 6, 66, 20, 33, 13, 87, 215, 24, 280, 31, 229, 30, 15, 72, 84, 8, 83, 16, 17, 30, 15, 14, 62, 28, 59, 148, 34, 16, 40, 20, 28, 17, 23, 13, 18, 28, 28, 169, 30, 24, 14, 22, 20, 10, 56, 24, 300, 45, 34, 46, 94, 123, 98, 274, 47, 140, 19, 43, 26, 22, 102, 31, 8, 55, 10, 41, 71, 31, 12, 23, 48, 8, 111, 12, 50, 109, 49, 12, 43, 10], "policy_red_0_v5_reward": [0.766, -1.016, -1.009, 1.408, -1.003, -1.003, 0.942, -1.002, 0.963, -0.503], "policy_blue_0_reward": [-1.02, -1.003, -1.001, -1.018, -1.0, -1.027, -1.001, -1.013, -1.0259999999999998, -0.04400000000000003, -1.0, -1.015, -1.003, 0.955, -1.01, -0.529, -1.004, -1.036, -1.0039999999999998, -1.013, -1.007, -1.002, -1.0, -1.0, -1.009, -1.004, -1.021, 0.951, -1.004, -1.005, -1.003, -1.003, -1.005, 0.9239999999999999, -1.002, -1.004, -0.505, -1.007, 0.701, -0.5489999999999999, -1.005, -0.52, -1.005, 0.9279999999999999, -1.0199999999999998, -1.001, -1.005, -1.004, -1.005, -1.0, -1.013, -0.507, -1.004, -1.001], "policy_red_0_v1_reward": [0.8089999999999999, -0.511, -1.006, -1.002, -1.014, 0.974, -1.0059999999999998, -1.019], "policy_red_0_v4_reward": [-1.029, 0.981, -1.004, -1.001, -0.5, -0.518, 0.9309999999999999, -1.004, 0.69, 0.964, 0.853], "policy_red_0_v2_reward": [-1.005, 0.945, -1.009, -1.013, 0.9329999999999999, 0.7939999999999999, -0.03300000000000002, 0.885, -1.005, -1.015, -1.002], "policy_red_0_v3_reward": [0.845, -1.0119999999999998, -1.002, -1.011, 0.827, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2301575136913742, "mean_inference_ms": 1.4995131384276836, "mean_action_processing_ms": 0.06247260218472978, "mean_env_wait_ms": 0.10603731884887445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018789393561226983, "StateBufferConnector_ms": 0.0015775305884225027, "ViewRequirementAgentConnector_ms": 0.03153198105948312}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.98991054775915, "num_env_steps_trained_throughput_per_sec": 99.98991054775915, "timesteps_total": 264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 39728.744, "sample_time_ms": 7728.964, "learn_time_ms": 31981.793, "learn_throughput": 125.071, "synch_weights_time_ms": 17.312}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "episodes_total": 4188, "training_iteration": 66, "trial_id": "bb874_00000", "date": "2023-09-28_22-13-45", "timestamp": 1695953625, "time_this_iter_s": 40.007177114486694, "time_total_s": 2610.2456045150757, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d81120>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac407c70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4063b0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2610.2456045150757, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 37.88245614035088, "ram_util_percent": 28.863157894736847}, "win_rate": 0.78, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2322615281989178, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04285362225067123, "policy_loss": -0.024859287334644858, "vf_loss": 0.13294595190285083, "vf_explained_var": 0.271441394649446, "kl": 0.011524290200663737, "entropy": 1.064923375286162, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "sampler_results": {"episode_reward_max": 0.42000000000000004, "episode_reward_min": -0.7720000000000001, "episode_reward_mean": -0.11841999999999997, "episode_len_mean": 55.8, "episode_media": {}, "episodes_this_iter": 67, "policy_reward_min": {"blue_0": -1.035, "red_0": -1.119, "red_0_v2": -1.022, "red_0_v1": -1.019, "red_0_v4": -1.004, "red_0_v5": -1.009, "red_0_v3": -1.017}, "policy_reward_max": {"blue_0": 0.9279999999999999, "red_0": 0.976, "red_0_v2": 0.91, "red_0_v1": 0.893, "red_0_v4": 0.964, "red_0_v5": 1.307, "red_0_v3": 1.408}, "policy_reward_mean": {"blue_0": -0.8667037037037036, "red_0": 0.47899, "red_0_v2": -0.40674999999999994, "red_0_v1": -0.53675, "red_0_v4": -0.01677777777777778, "red_0_v5": -0.10655555555555554, "red_0_v3": -0.35674999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.351, -0.123, -0.15400000000000003, -0.30600000000000005, -0.43999999999999995, -0.31500000000000006, -0.41900000000000004, -0.14, 0.05499999999999994, -0.05800000000000005, -0.1359999999999999, -0.06999999999999995, -0.07200000000000006, -0.34099999999999997, -0.10799999999999987, -0.028999999999999915, -0.17600000000000005, -0.030999999999999917, -0.1279999999999999, -0.22699999999999998, -0.11099999999999999, -0.039000000000000035, -0.07599999999999985, -0.14400000000000002, -0.02400000000000002, -0.363, -0.03700000000000003, -0.17299999999999993, 0.15500000000000003, 0.346, -0.038999999999999924, -0.1459999999999999, -0.030999999999999917, -0.04600000000000004, -0.11699999999999988, -0.10399999999999987, 0.42000000000000004, -0.383, -0.10699999999999998, -0.030999999999999917, -0.030999999999999917, -0.10999999999999988, -0.3949999999999999, -0.45599999999999996, 0.10399999999999998, -0.15800000000000003, 0.401, -0.3899999999999999, -0.387, -0.06999999999999995, -0.04299999999999993, -0.25, -0.23299999999999987, -0.050999999999999934, -0.1409999999999999, -0.16600000000000004, -0.07099999999999995, -0.18400000000000005, -0.14800000000000002, -0.05499999999999994, -0.027000000000000024, 0.41100000000000003, -0.15600000000000003, -0.21200000000000008, -0.09199999999999997, -0.22199999999999998, -0.05499999999999994, -0.04999999999999993, -0.050000000000000044, -0.14, -0.10899999999999987, -0.050000000000000044, -0.07099999999999995, -0.04899999999999993, -0.07200000000000006, -0.05400000000000005, -0.03300000000000003, -0.10799999999999998, -0.03699999999999992, -0.3460000000000001, -0.03399999999999992, -0.08299999999999996, 0.30400000000000005, -0.07400000000000007, -0.44599999999999995, -0.06400000000000006, -0.10799999999999998, -0.7720000000000001, 0.33399999999999996, -0.674, -0.06699999999999984, -0.16399999999999992, -0.026000000000000023, -0.09499999999999997, -0.1329999999999999, -0.22599999999999998, -0.31500000000000006, -0.3169999999999997, -0.19700000000000006, -0.41200000000000003], "episode_lengths": [45, 34, 46, 94, 123, 98, 274, 47, 140, 19, 43, 26, 22, 102, 31, 8, 55, 10, 41, 71, 31, 12, 23, 48, 8, 111, 12, 50, 109, 49, 12, 43, 10, 300, 36, 33, 25, 114, 36, 10, 10, 33, 130, 141, 124, 53, 26, 129, 117, 21, 14, 79, 76, 16, 46, 52, 22, 56, 41, 18, 9, 29, 44, 60, 28, 65, 18, 15, 16, 46, 34, 16, 22, 18, 22, 21, 11, 34, 12, 106, 11, 25, 62, 24, 143, 20, 34, 209, 48, 206, 21, 51, 8, 26, 42, 68, 83, 97, 49, 122], "policy_blue_0_reward": [-0.505, -1.007, 0.701, -0.5489999999999999, -1.005, -0.52, -1.005, 0.9279999999999999, -1.0199999999999998, -1.001, -1.005, -1.004, -1.005, -1.0, -1.013, -0.507, -1.004, -1.001, -0.04300000000000003, -1.006, -1.017, -1.001, -1.021, -0.512, -1.005, -1.019, -1.001, -1.0, -1.002, -1.005, -1.006, -1.005, -1.006, -1.0, -1.0, -1.004, -1.007, -1.011, -1.0, -1.004, -1.001, -1.005, -1.002, -1.005, -1.006, -1.001, -1.0119999999999998, -1.001, -1.015, -1.002, -0.508, -1.035, -1.003, -1.009], "policy_red_0_v2_reward": [0.885, -1.005, -1.015, -1.002, -0.503, -0.502, 0.91, -1.022], "policy_red_0_v1_reward": [-1.019, -1.001, 0.861, -1.0, -1.007, 0.893, -1.006, -1.015], "policy_red_0_v4_reward": [0.69, 0.964, 0.853, -1.004, -1.001, 0.756, -1.001, -1.001, 0.593], "policy_red_0_v5_reward": [0.942, -1.002, 0.963, -0.503, -1.0, -1.009, -1.0039999999999998, 1.307, 0.347], "policy_red_0_v3_reward": [-1.011, 0.827, -1.007, -1.004, -1.0159999999999998, 1.408, 0.844, -1.017, -1.013, -1.002, -1.006, 0.716]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302769670841618, "mean_inference_ms": 1.5008783250641153, "mean_action_processing_ms": 0.06251652205580273, "mean_env_wait_ms": 0.10613995611210583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018218159675598145, "StateBufferConnector_ms": 0.0015113353729248047, "ViewRequirementAgentConnector_ms": 0.030894160270690918}}, "episode_reward_max": 0.42000000000000004, "episode_reward_min": -0.7720000000000001, "episode_reward_mean": -0.11841999999999997, "episode_len_mean": 55.8, "episodes_this_iter": 67, "policy_reward_min": {"blue_0": -1.035, "red_0": -1.119, "red_0_v2": -1.022, "red_0_v1": -1.019, "red_0_v4": -1.004, "red_0_v5": -1.009, "red_0_v3": -1.017}, "policy_reward_max": {"blue_0": 0.9279999999999999, "red_0": 0.976, "red_0_v2": 0.91, "red_0_v1": 0.893, "red_0_v4": 0.964, "red_0_v5": 1.307, "red_0_v3": 1.408}, "policy_reward_mean": {"blue_0": -0.8667037037037036, "red_0": 0.47899, "red_0_v2": -0.40674999999999994, "red_0_v1": -0.53675, "red_0_v4": -0.01677777777777778, "red_0_v5": -0.10655555555555554, "red_0_v3": -0.35674999999999996}, "hist_stats": {"episode_reward": [0.351, -0.123, -0.15400000000000003, -0.30600000000000005, -0.43999999999999995, -0.31500000000000006, -0.41900000000000004, -0.14, 0.05499999999999994, -0.05800000000000005, -0.1359999999999999, -0.06999999999999995, -0.07200000000000006, -0.34099999999999997, -0.10799999999999987, -0.028999999999999915, -0.17600000000000005, -0.030999999999999917, -0.1279999999999999, -0.22699999999999998, -0.11099999999999999, -0.039000000000000035, -0.07599999999999985, -0.14400000000000002, -0.02400000000000002, -0.363, -0.03700000000000003, -0.17299999999999993, 0.15500000000000003, 0.346, -0.038999999999999924, -0.1459999999999999, -0.030999999999999917, -0.04600000000000004, -0.11699999999999988, -0.10399999999999987, 0.42000000000000004, -0.383, -0.10699999999999998, -0.030999999999999917, -0.030999999999999917, -0.10999999999999988, -0.3949999999999999, -0.45599999999999996, 0.10399999999999998, -0.15800000000000003, 0.401, -0.3899999999999999, -0.387, -0.06999999999999995, -0.04299999999999993, -0.25, -0.23299999999999987, -0.050999999999999934, -0.1409999999999999, -0.16600000000000004, -0.07099999999999995, -0.18400000000000005, -0.14800000000000002, -0.05499999999999994, -0.027000000000000024, 0.41100000000000003, -0.15600000000000003, -0.21200000000000008, -0.09199999999999997, -0.22199999999999998, -0.05499999999999994, -0.04999999999999993, -0.050000000000000044, -0.14, -0.10899999999999987, -0.050000000000000044, -0.07099999999999995, -0.04899999999999993, -0.07200000000000006, -0.05400000000000005, -0.03300000000000003, -0.10799999999999998, -0.03699999999999992, -0.3460000000000001, -0.03399999999999992, -0.08299999999999996, 0.30400000000000005, -0.07400000000000007, -0.44599999999999995, -0.06400000000000006, -0.10799999999999998, -0.7720000000000001, 0.33399999999999996, -0.674, -0.06699999999999984, -0.16399999999999992, -0.026000000000000023, -0.09499999999999997, -0.1329999999999999, -0.22599999999999998, -0.31500000000000006, -0.3169999999999997, -0.19700000000000006, -0.41200000000000003], "episode_lengths": [45, 34, 46, 94, 123, 98, 274, 47, 140, 19, 43, 26, 22, 102, 31, 8, 55, 10, 41, 71, 31, 12, 23, 48, 8, 111, 12, 50, 109, 49, 12, 43, 10, 300, 36, 33, 25, 114, 36, 10, 10, 33, 130, 141, 124, 53, 26, 129, 117, 21, 14, 79, 76, 16, 46, 52, 22, 56, 41, 18, 9, 29, 44, 60, 28, 65, 18, 15, 16, 46, 34, 16, 22, 18, 22, 21, 11, 34, 12, 106, 11, 25, 62, 24, 143, 20, 34, 209, 48, 206, 21, 51, 8, 26, 42, 68, 83, 97, 49, 122], "policy_blue_0_reward": [-0.505, -1.007, 0.701, -0.5489999999999999, -1.005, -0.52, -1.005, 0.9279999999999999, -1.0199999999999998, -1.001, -1.005, -1.004, -1.005, -1.0, -1.013, -0.507, -1.004, -1.001, -0.04300000000000003, -1.006, -1.017, -1.001, -1.021, -0.512, -1.005, -1.019, -1.001, -1.0, -1.002, -1.005, -1.006, -1.005, -1.006, -1.0, -1.0, -1.004, -1.007, -1.011, -1.0, -1.004, -1.001, -1.005, -1.002, -1.005, -1.006, -1.001, -1.0119999999999998, -1.001, -1.015, -1.002, -0.508, -1.035, -1.003, -1.009], "policy_red_0_v2_reward": [0.885, -1.005, -1.015, -1.002, -0.503, -0.502, 0.91, -1.022], "policy_red_0_v1_reward": [-1.019, -1.001, 0.861, -1.0, -1.007, 0.893, -1.006, -1.015], "policy_red_0_v4_reward": [0.69, 0.964, 0.853, -1.004, -1.001, 0.756, -1.001, -1.001, 0.593], "policy_red_0_v5_reward": [0.942, -1.002, 0.963, -0.503, -1.0, -1.009, -1.0039999999999998, 1.307, 0.347], "policy_red_0_v3_reward": [-1.011, 0.827, -1.007, -1.004, -1.0159999999999998, 1.408, 0.844, -1.017, -1.013, -1.002, -1.006, 0.716]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302769670841618, "mean_inference_ms": 1.5008783250641153, "mean_action_processing_ms": 0.06251652205580273, "mean_env_wait_ms": 0.10613995611210583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018218159675598145, "StateBufferConnector_ms": 0.0015113353729248047, "ViewRequirementAgentConnector_ms": 0.030894160270690918}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.98962539236436, "num_env_steps_trained_throughput_per_sec": 100.98962539236436, "timesteps_total": 268000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 536000, "timers": {"training_iteration_time_ms": 39738.534, "sample_time_ms": 7707.616, "learn_time_ms": 32012.954, "learn_throughput": 124.949, "synch_weights_time_ms": 17.316}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "done": false, "episodes_total": 4255, "training_iteration": 67, "trial_id": "bb874_00000", "date": "2023-09-28_22-14-25", "timestamp": 1695953665, "time_this_iter_s": 39.61073017120361, "time_total_s": 2649.8563346862793, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d83ee0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355f252d0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355f25900>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2649.8563346862793, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 33.996428571428574, "ram_util_percent": 28.876785714285717}, "win_rate": 0.81, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.168342806895574, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.049267453188197884, "policy_loss": -0.02622514126051101, "vf_loss": 0.14784868066975226, "vf_explained_var": 0.1826158942654729, "kl": 0.013200646293300148, "entropy": 1.0718751929700374, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "sampler_results": {"episode_reward_max": 0.45500000000000007, "episode_reward_min": -0.9450000000000002, "episode_reward_mean": -0.148, "episode_len_mean": 59.23, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"red_0_v1": -1.029, "red_0": -1.119, "red_0_v5": -1.036, "red_0_v4": -1.003, "blue_0": -1.035, "red_0_v3": -1.024, "red_0_v2": -1.043}, "policy_reward_max": {"red_0_v1": 0.893, "red_0": 0.985, "red_0_v5": 1.307, "red_0_v4": 0.96, "blue_0": 0.954, "red_0_v3": 0.7969999999999999, "red_0_v2": 0.91}, "policy_reward_mean": {"red_0_v1": -0.8115, "red_0": 0.48482999999999987, "red_0_v5": -0.09589999999999999, "red_0_v4": 0.22550000000000003, "blue_0": -0.819851063829787, "red_0_v3": -0.4302999999999999, "red_0_v2": -0.7402}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.08299999999999996, 0.30400000000000005, -0.07400000000000007, -0.44599999999999995, -0.06400000000000006, -0.10799999999999998, -0.7720000000000001, 0.33399999999999996, -0.674, -0.06699999999999984, -0.16399999999999992, -0.026000000000000023, -0.09499999999999997, -0.1329999999999999, -0.22599999999999998, -0.31500000000000006, -0.3169999999999997, -0.19700000000000006, -0.41200000000000003, -0.20500000000000007, -0.029999999999999916, -0.19100000000000006, -0.2859999999999999, -0.10399999999999987, -0.030999999999999805, -0.09999999999999998, -0.06499999999999995, -0.03299999999999992, -0.05600000000000005, -0.03500000000000003, -0.015000000000000013, -0.040999999999999925, -0.18399999999999994, -0.2619999999999999, 0.34299999999999997, -0.07000000000000006, -0.05700000000000005, -0.04299999999999993, -0.027000000000000024, -0.271, -0.353, -0.09499999999999997, -0.42799999999999994, -0.29400000000000004, -0.07999999999999996, -0.040000000000000036, -0.16299999999999992, -0.5409999999999999, -0.02400000000000002, -0.06700000000000006, -0.1460000000000001, -0.5030000000000001, -0.3979999999999999, -0.31999999999999995, -0.24399999999999988, -0.02499999999999991, -0.06000000000000005, -0.9450000000000002, -0.7480000000000001, -0.19900000000000018, -0.06099999999999983, -0.20400000000000007, -0.9250000000000002, -0.08699999999999986, -0.17299999999999982, -0.049000000000000044, -0.03399999999999992, -0.07400000000000007, -0.14100000000000001, -0.050999999999999934, -0.21300000000000008, -0.17099999999999993, -0.492, -0.03600000000000003, -0.16599999999999993, -0.1349999999999999, -0.04700000000000004, -0.18399999999999994, -0.261, -0.19699999999999984, -0.20899999999999985, -0.06699999999999995, -0.08299999999999985, -0.18999999999999995, -0.05499999999999994, -0.07499999999999996, -0.03400000000000003, -0.09799999999999998, 0.21999999999999997, -0.136, 0.45500000000000007, -0.050000000000000044, -0.04700000000000004, -0.18800000000000006, -0.05800000000000005, -0.16099999999999992, 0.43199999999999994, -0.02499999999999991, 0.29899999999999993, -0.05799999999999983], "episode_lengths": [25, 62, 24, 143, 20, 34, 209, 48, 206, 21, 51, 8, 26, 42, 68, 83, 97, 49, 122, 61, 9, 59, 93, 27, 9, 32, 20, 10, 16, 11, 5, 14, 47, 83, 49, 20, 17, 12, 9, 78, 98, 29, 133, 92, 27, 13, 52, 162, 8, 21, 300, 147, 117, 93, 71, 8, 19, 289, 234, 201, 19, 65, 289, 28, 51, 15, 11, 22, 46, 16, 67, 54, 144, 15, 51, 42, 15, 58, 75, 58, 68, 18, 26, 62, 19, 24, 10, 30, 76, 42, 14, 16, 15, 52, 19, 50, 22, 8, 60, 18], "policy_red_0_v1_reward": [-1.007, 0.893, -1.006, -1.015, -1.002, -1.002, -1.005, -1.011, -1.026, -1.029, -1.019, -0.509], "policy_red_0_v5_reward": [1.307, 0.347, -1.0, 0.746, -1.0, -1.036, -1.001, 0.8130000000000001, -1.0, 0.865], "policy_red_0_v4_reward": [-1.001, 0.593, 0.96, 0.861, -1.003, 0.943], "policy_blue_0_reward": [-1.015, -1.002, -0.508, -1.035, -1.003, -1.009, -1.003, -1.003, -1.005, -1.002, -1.009, -0.504, -1.001, -1.004, 0.907, -1.015, -1.006, -1.0, -0.046000000000000034, -1.018, -1.009, -1.001, 0.94, -1.024, -1.0019999999999998, -1.002, -1.007, -1.001, -1.001, -1.003, -1.01, -1.012, -1.0, -1.006, 0.954, -1.016, -1.008, -1.005, -1.0059999999999998, -1.004, -0.508, -1.002, -1.0, -1.01, -1.001, -0.504, -1.0039999999999998], "policy_red_0_v3_reward": [-1.002, -1.006, 0.716, -1.021, -1.0039999999999998, -1.009, 0.7969999999999999, 0.752, -0.5019999999999999, -1.024], "policy_red_0_v2_reward": [0.91, -1.022, -1.003, -1.006, -1.021, -1.0, -1.035, 0.6719999999999999, -1.003, -1.032, -1.007, -1.043, -1.007, -1.004, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303563600941677, "mean_inference_ms": 1.5025227163447779, "mean_action_processing_ms": 0.06255743446249, "mean_env_wait_ms": 0.10624619559399441, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01823747158050537, "StateBufferConnector_ms": 0.0015208721160888672, "ViewRequirementAgentConnector_ms": 0.03081214427947998}}, "episode_reward_max": 0.45500000000000007, "episode_reward_min": -0.9450000000000002, "episode_reward_mean": -0.148, "episode_len_mean": 59.23, "episodes_this_iter": 81, "policy_reward_min": {"red_0_v1": -1.029, "red_0": -1.119, "red_0_v5": -1.036, "red_0_v4": -1.003, "blue_0": -1.035, "red_0_v3": -1.024, "red_0_v2": -1.043}, "policy_reward_max": {"red_0_v1": 0.893, "red_0": 0.985, "red_0_v5": 1.307, "red_0_v4": 0.96, "blue_0": 0.954, "red_0_v3": 0.7969999999999999, "red_0_v2": 0.91}, "policy_reward_mean": {"red_0_v1": -0.8115, "red_0": 0.48482999999999987, "red_0_v5": -0.09589999999999999, "red_0_v4": 0.22550000000000003, "blue_0": -0.819851063829787, "red_0_v3": -0.4302999999999999, "red_0_v2": -0.7402}, "hist_stats": {"episode_reward": [-0.08299999999999996, 0.30400000000000005, -0.07400000000000007, -0.44599999999999995, -0.06400000000000006, -0.10799999999999998, -0.7720000000000001, 0.33399999999999996, -0.674, -0.06699999999999984, -0.16399999999999992, -0.026000000000000023, -0.09499999999999997, -0.1329999999999999, -0.22599999999999998, -0.31500000000000006, -0.3169999999999997, -0.19700000000000006, -0.41200000000000003, -0.20500000000000007, -0.029999999999999916, -0.19100000000000006, -0.2859999999999999, -0.10399999999999987, -0.030999999999999805, -0.09999999999999998, -0.06499999999999995, -0.03299999999999992, -0.05600000000000005, -0.03500000000000003, -0.015000000000000013, -0.040999999999999925, -0.18399999999999994, -0.2619999999999999, 0.34299999999999997, -0.07000000000000006, -0.05700000000000005, -0.04299999999999993, -0.027000000000000024, -0.271, -0.353, -0.09499999999999997, -0.42799999999999994, -0.29400000000000004, -0.07999999999999996, -0.040000000000000036, -0.16299999999999992, -0.5409999999999999, -0.02400000000000002, -0.06700000000000006, -0.1460000000000001, -0.5030000000000001, -0.3979999999999999, -0.31999999999999995, -0.24399999999999988, -0.02499999999999991, -0.06000000000000005, -0.9450000000000002, -0.7480000000000001, -0.19900000000000018, -0.06099999999999983, -0.20400000000000007, -0.9250000000000002, -0.08699999999999986, -0.17299999999999982, -0.049000000000000044, -0.03399999999999992, -0.07400000000000007, -0.14100000000000001, -0.050999999999999934, -0.21300000000000008, -0.17099999999999993, -0.492, -0.03600000000000003, -0.16599999999999993, -0.1349999999999999, -0.04700000000000004, -0.18399999999999994, -0.261, -0.19699999999999984, -0.20899999999999985, -0.06699999999999995, -0.08299999999999985, -0.18999999999999995, -0.05499999999999994, -0.07499999999999996, -0.03400000000000003, -0.09799999999999998, 0.21999999999999997, -0.136, 0.45500000000000007, -0.050000000000000044, -0.04700000000000004, -0.18800000000000006, -0.05800000000000005, -0.16099999999999992, 0.43199999999999994, -0.02499999999999991, 0.29899999999999993, -0.05799999999999983], "episode_lengths": [25, 62, 24, 143, 20, 34, 209, 48, 206, 21, 51, 8, 26, 42, 68, 83, 97, 49, 122, 61, 9, 59, 93, 27, 9, 32, 20, 10, 16, 11, 5, 14, 47, 83, 49, 20, 17, 12, 9, 78, 98, 29, 133, 92, 27, 13, 52, 162, 8, 21, 300, 147, 117, 93, 71, 8, 19, 289, 234, 201, 19, 65, 289, 28, 51, 15, 11, 22, 46, 16, 67, 54, 144, 15, 51, 42, 15, 58, 75, 58, 68, 18, 26, 62, 19, 24, 10, 30, 76, 42, 14, 16, 15, 52, 19, 50, 22, 8, 60, 18], "policy_red_0_v1_reward": [-1.007, 0.893, -1.006, -1.015, -1.002, -1.002, -1.005, -1.011, -1.026, -1.029, -1.019, -0.509], "policy_red_0_v5_reward": [1.307, 0.347, -1.0, 0.746, -1.0, -1.036, -1.001, 0.8130000000000001, -1.0, 0.865], "policy_red_0_v4_reward": [-1.001, 0.593, 0.96, 0.861, -1.003, 0.943], "policy_blue_0_reward": [-1.015, -1.002, -0.508, -1.035, -1.003, -1.009, -1.003, -1.003, -1.005, -1.002, -1.009, -0.504, -1.001, -1.004, 0.907, -1.015, -1.006, -1.0, -0.046000000000000034, -1.018, -1.009, -1.001, 0.94, -1.024, -1.0019999999999998, -1.002, -1.007, -1.001, -1.001, -1.003, -1.01, -1.012, -1.0, -1.006, 0.954, -1.016, -1.008, -1.005, -1.0059999999999998, -1.004, -0.508, -1.002, -1.0, -1.01, -1.001, -0.504, -1.0039999999999998], "policy_red_0_v3_reward": [-1.002, -1.006, 0.716, -1.021, -1.0039999999999998, -1.009, 0.7969999999999999, 0.752, -0.5019999999999999, -1.024], "policy_red_0_v2_reward": [0.91, -1.022, -1.003, -1.006, -1.021, -1.0, -1.035, 0.6719999999999999, -1.003, -1.032, -1.007, -1.043, -1.007, -1.004, -0.502]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303563600941677, "mean_inference_ms": 1.5025227163447779, "mean_action_processing_ms": 0.06255743446249, "mean_env_wait_ms": 0.10624619559399441, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01823747158050537, "StateBufferConnector_ms": 0.0015208721160888672, "ViewRequirementAgentConnector_ms": 0.03081214427947998}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.18128835753582, "num_env_steps_trained_throughput_per_sec": 100.18128835753582, "timesteps_total": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 39710.82, "sample_time_ms": 7707.225, "learn_time_ms": 31985.623, "learn_throughput": 125.056, "synch_weights_time_ms": 17.324}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "episodes_total": 4336, "training_iteration": 68, "trial_id": "bb874_00000", "date": "2023-09-28_22-15-05", "timestamp": 1695953705, "time_this_iter_s": 39.930392026901245, "time_total_s": 2689.7867267131805, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d82f80>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ad626170>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ad626830>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2689.7867267131805, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 34.745614035087726, "ram_util_percent": 28.856140350877197}, "win_rate": 0.82, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2082161287466686, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.037432470475929826, "policy_loss": -0.027499411549554983, "vf_loss": 0.1267306720255874, "vf_explained_var": 0.2947171331072847, "kl": 0.012950004568845385, "entropy": 1.0234545153255263, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "sampler_results": {"episode_reward_max": 0.45799999999999996, "episode_reward_min": -0.572, "episode_reward_mean": -0.06381999999999997, "episode_len_mean": 47.85, "episode_media": {}, "episodes_this_iter": 71, "policy_reward_min": {"blue_0": -1.016, "red_0": -1.037, "red_0_v2": -1.043, "red_0_v4": -1.006, "red_0_v3": -1.0519999999999998, "red_0_v5": -1.009, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 1.168, "red_0": 0.979, "red_0_v2": 0.906, "red_0_v4": 1.3039999999999998, "red_0_v3": 0.808, "red_0_v5": 1.458, "red_0_v1": 0.9349999999999999}, "policy_reward_mean": {"blue_0": -0.81612, "red_0": 0.53181, "red_0_v2": -0.7433333333333333, "red_0_v4": -0.19938461538461538, "red_0_v3": -0.39909090909090905, "red_0_v5": 0.0021111111111111252, "red_0_v1": -0.6379999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.17099999999999993, -0.492, -0.03600000000000003, -0.16599999999999993, -0.1349999999999999, -0.04700000000000004, -0.18399999999999994, -0.261, -0.19699999999999984, -0.20899999999999985, -0.06699999999999995, -0.08299999999999985, -0.18999999999999995, -0.05499999999999994, -0.07499999999999996, -0.03400000000000003, -0.09799999999999998, 0.21999999999999997, -0.136, 0.45500000000000007, -0.050000000000000044, -0.04700000000000004, -0.18800000000000006, -0.05800000000000005, -0.16099999999999992, 0.43199999999999994, -0.02499999999999991, 0.29899999999999993, -0.05799999999999983, -0.24, -0.06400000000000006, -0.10099999999999976, -0.1489999999999999, -0.03500000000000003, -0.14100000000000001, -0.05600000000000005, -0.0229999999999998, -0.09099999999999986, -0.030000000000000027, -0.17000000000000004, -0.05900000000000005, 0.45799999999999996, -0.19599999999999995, -0.040999999999999814, -0.03700000000000003, -0.122, -0.08499999999999996, -0.20199999999999996, -0.06799999999999995, 0.13099999999999978, -0.09499999999999997, -0.135, -0.08200000000000007, -0.08200000000000007, -0.01800000000000001, -0.12299999999999989, -0.28, -0.11399999999999988, 0.45799999999999996, -0.13199999999999978, -0.10699999999999998, 0.29800000000000004, -0.06900000000000006, -0.19399999999999995, -0.10199999999999998, -0.07700000000000005, -0.05399999999999994, -0.1110000000000001, -0.029999999999999916, -0.3420000000000001, 0.42400000000000004, -0.07199999999999984, -0.04700000000000004, -0.2639999999999999, -0.02100000000000002, -0.22099999999999997, 0.050999999999999934, -0.05300000000000005, -0.04600000000000004, 0.33299999999999996, -0.08200000000000007, -0.19100000000000006, -0.09399999999999997, -0.33499999999999996, -0.06799999999999995, -0.06700000000000006, -0.17999999999999994, -0.23499999999999988, -0.22499999999999987, -0.09399999999999997, -0.09899999999999987, 0.355, -0.027999999999999803, -0.19099999999999984, -0.05999999999999994, -0.04600000000000004, 0.372, -0.06600000000000006, -0.030999999999999917, -0.572], "episode_lengths": [54, 144, 15, 51, 42, 15, 58, 75, 58, 68, 18, 26, 62, 19, 24, 10, 30, 76, 42, 14, 16, 15, 52, 19, 50, 22, 8, 60, 18, 79, 18, 27, 46, 11, 45, 18, 7, 28, 10, 54, 18, 14, 57, 11, 14, 38, 31, 66, 21, 106, 29, 40, 22, 24, 300, 36, 85, 33, 12, 40, 33, 61, 21, 58, 30, 300, 17, 300, 9, 101, 25, 26, 15, 83, 7, 71, 139, 17, 14, 51, 24, 61, 32, 92, 21, 21, 53, 70, 69, 31, 30, 45, 8, 58, 22, 14, 41, 20, 10, 184], "policy_blue_0_reward": [-1.012, -1.0, -1.006, 0.954, -1.016, -1.008, -1.005, -1.0059999999999998, -1.004, -0.508, -1.002, -1.0, -1.01, -1.001, -0.504, -1.0039999999999998, -1.0, -1.001, -1.007, -1.0019999999999998, -1.0039999999999998, -1.002, -1.006, -1.007, -1.005, 1.168, -1.005, 0.872, -1.003, -1.006, -1.004, -0.505, -1.007, -1.002, -0.04200000000000003, -1.003, -1.014, -1.003, -1.002, -1.012, -0.525, -1.002, -1.004, -1.007, -1.001, -1.011, -0.509, -1.0039999999999998, -1.004, -1.005], "policy_red_0_v2_reward": [-1.043, -1.007, -1.004, -0.502, -1.009, -1.0199999999999998, -1.007, 0.906, -1.0039999999999998], "policy_red_0_v4_reward": [-1.003, 0.943, 0.763, -1.0, 0.97, 0.941, 1.3039999999999998, -1.001, -1.0, -1.006, -1.0, -0.503, -1.0], "policy_red_0_v3_reward": [0.752, -0.5019999999999999, -1.024, -1.027, -1.011, 0.724, -1.007, 0.808, -0.048000000000000036, -1.003, -1.0519999999999998], "policy_red_0_v5_reward": [-1.001, 0.8130000000000001, -1.0, 0.865, 1.458, -0.010000000000000002, -1.003, 0.906, -1.009], "policy_red_0_v1_reward": [-1.006, 0.9349999999999999, -0.5, -1.006, -0.503, -1.012, -1.005, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303889145035182, "mean_inference_ms": 1.502697974406509, "mean_action_processing_ms": 0.06255288402244716, "mean_env_wait_ms": 0.10625073503414066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019313335418701172, "StateBufferConnector_ms": 0.0015740394592285156, "ViewRequirementAgentConnector_ms": 0.031926631927490234}}, "episode_reward_max": 0.45799999999999996, "episode_reward_min": -0.572, "episode_reward_mean": -0.06381999999999997, "episode_len_mean": 47.85, "episodes_this_iter": 71, "policy_reward_min": {"blue_0": -1.016, "red_0": -1.037, "red_0_v2": -1.043, "red_0_v4": -1.006, "red_0_v3": -1.0519999999999998, "red_0_v5": -1.009, "red_0_v1": -1.012}, "policy_reward_max": {"blue_0": 1.168, "red_0": 0.979, "red_0_v2": 0.906, "red_0_v4": 1.3039999999999998, "red_0_v3": 0.808, "red_0_v5": 1.458, "red_0_v1": 0.9349999999999999}, "policy_reward_mean": {"blue_0": -0.81612, "red_0": 0.53181, "red_0_v2": -0.7433333333333333, "red_0_v4": -0.19938461538461538, "red_0_v3": -0.39909090909090905, "red_0_v5": 0.0021111111111111252, "red_0_v1": -0.6379999999999999}, "hist_stats": {"episode_reward": [-0.17099999999999993, -0.492, -0.03600000000000003, -0.16599999999999993, -0.1349999999999999, -0.04700000000000004, -0.18399999999999994, -0.261, -0.19699999999999984, -0.20899999999999985, -0.06699999999999995, -0.08299999999999985, -0.18999999999999995, -0.05499999999999994, -0.07499999999999996, -0.03400000000000003, -0.09799999999999998, 0.21999999999999997, -0.136, 0.45500000000000007, -0.050000000000000044, -0.04700000000000004, -0.18800000000000006, -0.05800000000000005, -0.16099999999999992, 0.43199999999999994, -0.02499999999999991, 0.29899999999999993, -0.05799999999999983, -0.24, -0.06400000000000006, -0.10099999999999976, -0.1489999999999999, -0.03500000000000003, -0.14100000000000001, -0.05600000000000005, -0.0229999999999998, -0.09099999999999986, -0.030000000000000027, -0.17000000000000004, -0.05900000000000005, 0.45799999999999996, -0.19599999999999995, -0.040999999999999814, -0.03700000000000003, -0.122, -0.08499999999999996, -0.20199999999999996, -0.06799999999999995, 0.13099999999999978, -0.09499999999999997, -0.135, -0.08200000000000007, -0.08200000000000007, -0.01800000000000001, -0.12299999999999989, -0.28, -0.11399999999999988, 0.45799999999999996, -0.13199999999999978, -0.10699999999999998, 0.29800000000000004, -0.06900000000000006, -0.19399999999999995, -0.10199999999999998, -0.07700000000000005, -0.05399999999999994, -0.1110000000000001, -0.029999999999999916, -0.3420000000000001, 0.42400000000000004, -0.07199999999999984, -0.04700000000000004, -0.2639999999999999, -0.02100000000000002, -0.22099999999999997, 0.050999999999999934, -0.05300000000000005, -0.04600000000000004, 0.33299999999999996, -0.08200000000000007, -0.19100000000000006, -0.09399999999999997, -0.33499999999999996, -0.06799999999999995, -0.06700000000000006, -0.17999999999999994, -0.23499999999999988, -0.22499999999999987, -0.09399999999999997, -0.09899999999999987, 0.355, -0.027999999999999803, -0.19099999999999984, -0.05999999999999994, -0.04600000000000004, 0.372, -0.06600000000000006, -0.030999999999999917, -0.572], "episode_lengths": [54, 144, 15, 51, 42, 15, 58, 75, 58, 68, 18, 26, 62, 19, 24, 10, 30, 76, 42, 14, 16, 15, 52, 19, 50, 22, 8, 60, 18, 79, 18, 27, 46, 11, 45, 18, 7, 28, 10, 54, 18, 14, 57, 11, 14, 38, 31, 66, 21, 106, 29, 40, 22, 24, 300, 36, 85, 33, 12, 40, 33, 61, 21, 58, 30, 300, 17, 300, 9, 101, 25, 26, 15, 83, 7, 71, 139, 17, 14, 51, 24, 61, 32, 92, 21, 21, 53, 70, 69, 31, 30, 45, 8, 58, 22, 14, 41, 20, 10, 184], "policy_blue_0_reward": [-1.012, -1.0, -1.006, 0.954, -1.016, -1.008, -1.005, -1.0059999999999998, -1.004, -0.508, -1.002, -1.0, -1.01, -1.001, -0.504, -1.0039999999999998, -1.0, -1.001, -1.007, -1.0019999999999998, -1.0039999999999998, -1.002, -1.006, -1.007, -1.005, 1.168, -1.005, 0.872, -1.003, -1.006, -1.004, -0.505, -1.007, -1.002, -0.04200000000000003, -1.003, -1.014, -1.003, -1.002, -1.012, -0.525, -1.002, -1.004, -1.007, -1.001, -1.011, -0.509, -1.0039999999999998, -1.004, -1.005], "policy_red_0_v2_reward": [-1.043, -1.007, -1.004, -0.502, -1.009, -1.0199999999999998, -1.007, 0.906, -1.0039999999999998], "policy_red_0_v4_reward": [-1.003, 0.943, 0.763, -1.0, 0.97, 0.941, 1.3039999999999998, -1.001, -1.0, -1.006, -1.0, -0.503, -1.0], "policy_red_0_v3_reward": [0.752, -0.5019999999999999, -1.024, -1.027, -1.011, 0.724, -1.007, 0.808, -0.048000000000000036, -1.003, -1.0519999999999998], "policy_red_0_v5_reward": [-1.001, 0.8130000000000001, -1.0, 0.865, 1.458, -0.010000000000000002, -1.003, 0.906, -1.009], "policy_red_0_v1_reward": [-1.006, 0.9349999999999999, -0.5, -1.006, -0.503, -1.012, -1.005, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303889145035182, "mean_inference_ms": 1.502697974406509, "mean_action_processing_ms": 0.06255288402244716, "mean_env_wait_ms": 0.10625073503414066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019313335418701172, "StateBufferConnector_ms": 0.0015740394592285156, "ViewRequirementAgentConnector_ms": 0.031926631927490234}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.65052558605227, "num_env_steps_trained_throughput_per_sec": 99.65052558605227, "timesteps_total": 276000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 552000, "timers": {"training_iteration_time_ms": 39719.792, "sample_time_ms": 7719.987, "learn_time_ms": 31981.85, "learn_throughput": 125.071, "synch_weights_time_ms": 17.307}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "done": false, "episodes_total": 4407, "training_iteration": 69, "trial_id": "bb874_00000", "date": "2023-09-28_22-15-45", "timestamp": 1695953745, "time_this_iter_s": 40.1429340839386, "time_total_s": 2729.929660797119, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355fc3280>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ad624f70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ad625f30>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2729.929660797119, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 38.46491228070175, "ram_util_percent": 28.842105263157897}, "win_rate": 0.83, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4131011914461853, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06511307130652616, "policy_loss": -0.021874606592124715, "vf_loss": 0.170884510075363, "vf_explained_var": 0.2459363636250297, "kl": 0.012908382791331016, "entropy": 1.0362534951418638, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "sampler_results": {"episode_reward_max": 0.47, "episode_reward_min": -1.2030000000000003, "episode_reward_mean": -0.11362999999999998, "episode_len_mean": 52.26, "episode_media": {}, "episodes_this_iter": 76, "policy_reward_min": {"blue_0": -1.041, "red_0": -1.022, "red_0_v3": -1.0519999999999998, "red_0_v1": -1.015, "red_0_v4": -1.195, "red_0_v5": -1.0099999999999998, "red_0_v2": -1.021}, "policy_reward_max": {"blue_0": 0.864, "red_0": 0.976, "red_0_v3": 0.964, "red_0_v1": -0.503, "red_0_v4": 0.973, "red_0_v5": 0.964, "red_0_v2": 0.951}, "policy_reward_mean": {"blue_0": -0.846, "red_0": 0.49979, "red_0_v3": 0.2158888888888889, "red_0_v1": -0.9352857142857143, "red_0_v4": -0.4515833333333334, "red_0_v5": -0.34564285714285703, "red_0_v2": -0.5224999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.050999999999999934, -0.05300000000000005, -0.04600000000000004, 0.33299999999999996, -0.08200000000000007, -0.19100000000000006, -0.09399999999999997, -0.33499999999999996, -0.06799999999999995, -0.06700000000000006, -0.17999999999999994, -0.23499999999999988, -0.22499999999999987, -0.09399999999999997, -0.09899999999999987, 0.355, -0.027999999999999803, -0.19099999999999984, -0.05999999999999994, -0.04600000000000004, 0.372, -0.06600000000000006, -0.030999999999999917, -0.572, -0.04200000000000003, -0.135, -0.08199999999999985, -0.07999999999999985, -0.03700000000000003, -0.135, -0.371, -0.08699999999999986, -0.07000000000000006, -0.06600000000000006, -0.134, -0.35299999999999987, -0.11299999999999999, -0.15599999999999992, -0.2779999999999999, -0.1319999999999999, -0.06299999999999994, -0.04399999999999982, -0.11499999999999999, -0.11899999999999988, -0.038000000000000034, -0.17100000000000004, -0.06299999999999994, -0.07900000000000007, 0.42899999999999994, -0.11699999999999977, -0.126, -0.924, -0.07699999999999996, -0.07400000000000007, -0.07300000000000006, -0.12399999999999989, -0.049000000000000044, -0.04300000000000004, -0.7090000000000001, -0.136, -0.09099999999999997, 0.47, -0.07699999999999996, -0.06300000000000006, -0.28700000000000003, -0.16000000000000014, -0.07699999999999996, -0.03500000000000003, -0.14, -0.10599999999999998, -0.19800000000000006, -0.038999999999999924, 0.10199999999999998, -0.34299999999999997, -0.09999999999999998, -0.118, -0.06900000000000006, -0.10899999999999987, -0.05399999999999994, -0.029000000000000026, -0.30700000000000005, -0.126, -1.2030000000000003, -0.1419999999999999, -0.08799999999999997, -0.09799999999999986, -0.14, -0.030000000000000027, -0.049000000000000044, -0.22499999999999987, -0.03500000000000003, 0.368, -0.06899999999999995, -0.31800000000000006, -0.279, -0.027000000000000024, -0.16699999999999993, -0.1299999999999999, -0.07799999999999985, -0.05899999999999994], "episode_lengths": [139, 17, 14, 51, 24, 61, 32, 92, 21, 21, 53, 70, 69, 31, 30, 45, 8, 58, 22, 14, 41, 20, 10, 184, 300, 43, 25, 24, 12, 41, 121, 26, 22, 20, 40, 116, 33, 47, 79, 41, 20, 14, 35, 38, 12, 53, 20, 22, 300, 31, 38, 288, 24, 24, 24, 39, 15, 14, 218, 43, 27, 13, 25, 19, 93, 53, 23, 11, 46, 34, 60, 12, 124, 106, 30, 34, 21, 32, 17, 9, 82, 39, 294, 45, 28, 31, 42, 13, 15, 66, 11, 38, 22, 94, 85, 9, 54, 39, 25, 16], "policy_blue_0_reward": [-0.525, -1.002, -1.004, -1.007, -1.001, -1.011, -0.509, -1.0039999999999998, -1.004, -1.005, -1.005, -1.005, -1.005, -1.011, -1.003, -1.002, -1.0019999999999998, -1.008, -1.008, -1.003, 0.469, -1.003, -1.041, -1.002, -1.006, -1.003, 0.30599999999999994, 0.864, -1.005, -1.009, -1.004, -1.002, -1.007, -0.517, -1.006, -1.004, -1.003, -1.001, -1.003, -1.002, -1.005, -1.003, 0.861, -1.012, -1.002, -1.011, -1.015, -1.004, -1.003, -1.003], "policy_red_0_v3_reward": [-1.003, -1.0519999999999998, 0.867, 0.964, 0.627, 0.891, 0.9369999999999999, 0.715, -1.003], "policy_red_0_v1_reward": [-0.503, -1.012, -1.005, -1.007, -1.003, -1.002, -1.015], "policy_red_0_v4_reward": [-1.006, -1.0, -0.503, -1.0, 0.892, -1.0019999999999998, 0.9279999999999999, -1.003, -1.195, -1.001, -0.502, 0.973], "policy_red_0_v5_reward": [-1.003, 0.906, -1.009, -0.013000000000000005, -1.001, -1.005, 0.964, 0.957, -0.5, -1.002, -1.002, -1.002, 0.881, -1.0099999999999998], "policy_red_0_v2_reward": [-1.0039999999999998, -1.008, -1.01, -1.013, 0.9259999999999999, -1.021, 0.951, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302595577197083, "mean_inference_ms": 1.5018267148759339, "mean_action_processing_ms": 0.06252509876280661, "mean_env_wait_ms": 0.1061984575543838, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018443584442138672, "StateBufferConnector_ms": 0.0015136003494262695, "ViewRequirementAgentConnector_ms": 0.031028151512145996}}, "episode_reward_max": 0.47, "episode_reward_min": -1.2030000000000003, "episode_reward_mean": -0.11362999999999998, "episode_len_mean": 52.26, "episodes_this_iter": 76, "policy_reward_min": {"blue_0": -1.041, "red_0": -1.022, "red_0_v3": -1.0519999999999998, "red_0_v1": -1.015, "red_0_v4": -1.195, "red_0_v5": -1.0099999999999998, "red_0_v2": -1.021}, "policy_reward_max": {"blue_0": 0.864, "red_0": 0.976, "red_0_v3": 0.964, "red_0_v1": -0.503, "red_0_v4": 0.973, "red_0_v5": 0.964, "red_0_v2": 0.951}, "policy_reward_mean": {"blue_0": -0.846, "red_0": 0.49979, "red_0_v3": 0.2158888888888889, "red_0_v1": -0.9352857142857143, "red_0_v4": -0.4515833333333334, "red_0_v5": -0.34564285714285703, "red_0_v2": -0.5224999999999999}, "hist_stats": {"episode_reward": [0.050999999999999934, -0.05300000000000005, -0.04600000000000004, 0.33299999999999996, -0.08200000000000007, -0.19100000000000006, -0.09399999999999997, -0.33499999999999996, -0.06799999999999995, -0.06700000000000006, -0.17999999999999994, -0.23499999999999988, -0.22499999999999987, -0.09399999999999997, -0.09899999999999987, 0.355, -0.027999999999999803, -0.19099999999999984, -0.05999999999999994, -0.04600000000000004, 0.372, -0.06600000000000006, -0.030999999999999917, -0.572, -0.04200000000000003, -0.135, -0.08199999999999985, -0.07999999999999985, -0.03700000000000003, -0.135, -0.371, -0.08699999999999986, -0.07000000000000006, -0.06600000000000006, -0.134, -0.35299999999999987, -0.11299999999999999, -0.15599999999999992, -0.2779999999999999, -0.1319999999999999, -0.06299999999999994, -0.04399999999999982, -0.11499999999999999, -0.11899999999999988, -0.038000000000000034, -0.17100000000000004, -0.06299999999999994, -0.07900000000000007, 0.42899999999999994, -0.11699999999999977, -0.126, -0.924, -0.07699999999999996, -0.07400000000000007, -0.07300000000000006, -0.12399999999999989, -0.049000000000000044, -0.04300000000000004, -0.7090000000000001, -0.136, -0.09099999999999997, 0.47, -0.07699999999999996, -0.06300000000000006, -0.28700000000000003, -0.16000000000000014, -0.07699999999999996, -0.03500000000000003, -0.14, -0.10599999999999998, -0.19800000000000006, -0.038999999999999924, 0.10199999999999998, -0.34299999999999997, -0.09999999999999998, -0.118, -0.06900000000000006, -0.10899999999999987, -0.05399999999999994, -0.029000000000000026, -0.30700000000000005, -0.126, -1.2030000000000003, -0.1419999999999999, -0.08799999999999997, -0.09799999999999986, -0.14, -0.030000000000000027, -0.049000000000000044, -0.22499999999999987, -0.03500000000000003, 0.368, -0.06899999999999995, -0.31800000000000006, -0.279, -0.027000000000000024, -0.16699999999999993, -0.1299999999999999, -0.07799999999999985, -0.05899999999999994], "episode_lengths": [139, 17, 14, 51, 24, 61, 32, 92, 21, 21, 53, 70, 69, 31, 30, 45, 8, 58, 22, 14, 41, 20, 10, 184, 300, 43, 25, 24, 12, 41, 121, 26, 22, 20, 40, 116, 33, 47, 79, 41, 20, 14, 35, 38, 12, 53, 20, 22, 300, 31, 38, 288, 24, 24, 24, 39, 15, 14, 218, 43, 27, 13, 25, 19, 93, 53, 23, 11, 46, 34, 60, 12, 124, 106, 30, 34, 21, 32, 17, 9, 82, 39, 294, 45, 28, 31, 42, 13, 15, 66, 11, 38, 22, 94, 85, 9, 54, 39, 25, 16], "policy_blue_0_reward": [-0.525, -1.002, -1.004, -1.007, -1.001, -1.011, -0.509, -1.0039999999999998, -1.004, -1.005, -1.005, -1.005, -1.005, -1.011, -1.003, -1.002, -1.0019999999999998, -1.008, -1.008, -1.003, 0.469, -1.003, -1.041, -1.002, -1.006, -1.003, 0.30599999999999994, 0.864, -1.005, -1.009, -1.004, -1.002, -1.007, -0.517, -1.006, -1.004, -1.003, -1.001, -1.003, -1.002, -1.005, -1.003, 0.861, -1.012, -1.002, -1.011, -1.015, -1.004, -1.003, -1.003], "policy_red_0_v3_reward": [-1.003, -1.0519999999999998, 0.867, 0.964, 0.627, 0.891, 0.9369999999999999, 0.715, -1.003], "policy_red_0_v1_reward": [-0.503, -1.012, -1.005, -1.007, -1.003, -1.002, -1.015], "policy_red_0_v4_reward": [-1.006, -1.0, -0.503, -1.0, 0.892, -1.0019999999999998, 0.9279999999999999, -1.003, -1.195, -1.001, -0.502, 0.973], "policy_red_0_v5_reward": [-1.003, 0.906, -1.009, -0.013000000000000005, -1.001, -1.005, 0.964, 0.957, -0.5, -1.002, -1.002, -1.002, 0.881, -1.0099999999999998], "policy_red_0_v2_reward": [-1.0039999999999998, -1.008, -1.01, -1.013, 0.9259999999999999, -1.021, 0.951, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2302595577197083, "mean_inference_ms": 1.5018267148759339, "mean_action_processing_ms": 0.06252509876280661, "mean_env_wait_ms": 0.1061984575543838, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018443584442138672, "StateBufferConnector_ms": 0.0015136003494262695, "ViewRequirementAgentConnector_ms": 0.031028151512145996}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.9794294724253, "num_env_steps_trained_throughput_per_sec": 100.9794294724253, "timesteps_total": 280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 39716.308, "sample_time_ms": 7720.105, "learn_time_ms": 31978.238, "learn_throughput": 125.085, "synch_weights_time_ms": 17.314}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "episodes_total": 4483, "training_iteration": 70, "trial_id": "bb874_00000", "date": "2023-09-28_22-16-25", "timestamp": 1695953785, "time_this_iter_s": 39.614737033843994, "time_total_s": 2769.544397830963, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d83670>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x3559223b0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x3559212d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2769.544397830963, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 34.23508771929824, "ram_util_percent": 28.929824561403503}, "win_rate": 0.81, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.507877683142821, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.059053379493949856, "policy_loss": -0.02366541589702441, "vf_loss": 0.16264120610430838, "vf_explained_var": 0.2202558853973945, "kl": 0.01201439568642108, "entropy": 1.0046868085861207, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "sampler_results": {"episode_reward_max": 0.44799999999999995, "episode_reward_min": -1.2030000000000003, "episode_reward_mean": -0.11776, "episode_len_mean": 54.83, "episode_media": {}, "episodes_this_iter": 71, "policy_reward_min": {"red_0_v4": -1.195, "red_0": -1.06, "blue_0": -1.021, "red_0_v1": -1.015, "red_0_v3": -1.031, "red_0_v5": -1.01, "red_0_v2": -1.007}, "policy_reward_max": {"red_0_v4": 0.973, "red_0": 0.976, "blue_0": 1.023, "red_0_v1": 0.947, "red_0_v3": 0.947, "red_0_v5": 0.881, "red_0_v2": 1.4489999999999998}, "policy_reward_mean": {"red_0_v4": -0.31071428571428567, "red_0": 0.47276, "blue_0": -0.8715744680851063, "red_0_v1": -0.5316666666666666, "red_0_v3": -0.4672727272727272, "red_0_v5": -0.3050999999999999, "red_0_v2": 0.1388333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.038999999999999924, 0.10199999999999998, -0.34299999999999997, -0.09999999999999998, -0.118, -0.06900000000000006, -0.10899999999999987, -0.05399999999999994, -0.029000000000000026, -0.30700000000000005, -0.126, -1.2030000000000003, -0.1419999999999999, -0.08799999999999997, -0.09799999999999986, -0.14, -0.030000000000000027, -0.049000000000000044, -0.22499999999999987, -0.03500000000000003, 0.368, -0.06899999999999995, -0.31800000000000006, -0.279, -0.027000000000000024, -0.16699999999999993, -0.1299999999999999, -0.07799999999999985, -0.05899999999999994, -0.16800000000000004, -0.07800000000000007, -0.026999999999999913, 0.279, -0.2819999999999999, -0.21999999999999997, -0.04600000000000004, -0.07000000000000006, -0.052000000000000046, -0.05600000000000005, -0.3969999999999999, -0.16300000000000003, -0.05899999999999994, -0.2539999999999999, -0.46699999999999986, -0.347, -0.09399999999999986, -0.236, -0.07099999999999995, -0.17100000000000004, -0.17900000000000005, -0.18900000000000006, -0.037000000000000144, -0.14300000000000002, 0.347, -0.10299999999999998, -0.15100000000000002, -0.264, -0.06999999999999995, -0.052000000000000046, -0.16200000000000003, -0.4099999999999999, -0.10999999999999988, -0.21099999999999997, -0.04800000000000004, 0.404, -0.03600000000000003, -0.038000000000000034, -0.18500000000000005, -0.2559999999999999, -0.05999999999999994, -0.10699999999999998, 0.44799999999999995, -0.10099999999999998, -0.08099999999999996, -0.05700000000000005, -0.46599999999999997, -0.14600000000000002, -0.15100000000000002, -0.29999999999999993, -0.08599999999999997, -0.16900000000000004, -0.2270000000000001, -0.06800000000000006, -0.16000000000000003, -0.12000000000000009, -0.34999999999999987, -0.07400000000000007, -0.18000000000000005, -0.05400000000000005, 0.42500000000000004, -0.02400000000000002, -0.16200000000000003, 0.33499999999999996, -0.09299999999999997, -0.138, -0.16299999999999992, -0.20799999999999996, -0.1279999999999999, -0.05500000000000005, -0.2230000000000001], "episode_lengths": [12, 124, 106, 30, 34, 21, 32, 17, 9, 82, 39, 294, 45, 28, 31, 42, 13, 15, 66, 11, 38, 22, 94, 85, 9, 54, 39, 25, 16, 50, 24, 8, 70, 89, 66, 14, 22, 15, 17, 128, 49, 18, 77, 144, 113, 29, 72, 22, 51, 53, 59, 153, 48, 42, 31, 49, 84, 21, 14, 48, 127, 35, 226, 14, 30, 10, 167, 59, 81, 19, 33, 16, 32, 24, 21, 147, 47, 43, 91, 31, 51, 67, 22, 44, 300, 97, 22, 55, 16, 23, 8, 49, 49, 27, 44, 50, 66, 41, 17, 69], "policy_red_0_v4_reward": [-1.003, -1.195, -1.001, -0.502, 0.973, 0.9299999999999999, -1.007, -1.014, -1.004, -1.002, 0.859, 0.7929999999999999, 0.827, -1.004], "policy_blue_0_reward": [-0.517, -1.006, -1.004, -1.003, -1.001, -1.003, -1.002, -1.005, -1.003, 0.861, -1.012, -1.002, -1.011, -1.015, -1.004, -1.003, -1.003, -1.007, -1.004, -0.512, -1.012, -1.002, -1.021, -1.003, -1.012, -1.002, 1.023, -0.507, -1.004, -1.001, -0.534, -1.01, -1.0019999999999998, -1.0059999999999998, -1.004, -1.021, -1.01, -1.019, -1.012, -1.016, -1.003, -0.503, -1.005, -1.009, -1.007, -1.005, -1.001], "policy_red_0_v1_reward": [-1.015, -1.002, 0.947, -1.003, -1.01, -1.008, -1.001, -1.004, 0.817, 0.901, -1.002, -1.0], "policy_red_0_v3_reward": [0.715, -1.003, -1.016, -1.011, -1.004, -0.517, -1.004, -1.001, -1.031, 0.947, 0.7849999999999999], "policy_red_0_v5_reward": [0.881, -1.0099999999999998, -1.005, -1.01, -1.006, 0.843, -1.009, -0.503, -0.08400000000000006, 0.852], "policy_red_0_v2_reward": [0.951, -1.001, 0.948, -1.007, 1.4489999999999998, -0.507]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303417264976543, "mean_inference_ms": 1.5025645405613373, "mean_action_processing_ms": 0.0625436936058923, "mean_env_wait_ms": 0.10621278147811325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018278837203979492, "StateBufferConnector_ms": 0.0014683008193969727, "ViewRequirementAgentConnector_ms": 0.03061366081237793}}, "episode_reward_max": 0.44799999999999995, "episode_reward_min": -1.2030000000000003, "episode_reward_mean": -0.11776, "episode_len_mean": 54.83, "episodes_this_iter": 71, "policy_reward_min": {"red_0_v4": -1.195, "red_0": -1.06, "blue_0": -1.021, "red_0_v1": -1.015, "red_0_v3": -1.031, "red_0_v5": -1.01, "red_0_v2": -1.007}, "policy_reward_max": {"red_0_v4": 0.973, "red_0": 0.976, "blue_0": 1.023, "red_0_v1": 0.947, "red_0_v3": 0.947, "red_0_v5": 0.881, "red_0_v2": 1.4489999999999998}, "policy_reward_mean": {"red_0_v4": -0.31071428571428567, "red_0": 0.47276, "blue_0": -0.8715744680851063, "red_0_v1": -0.5316666666666666, "red_0_v3": -0.4672727272727272, "red_0_v5": -0.3050999999999999, "red_0_v2": 0.1388333333333333}, "hist_stats": {"episode_reward": [-0.038999999999999924, 0.10199999999999998, -0.34299999999999997, -0.09999999999999998, -0.118, -0.06900000000000006, -0.10899999999999987, -0.05399999999999994, -0.029000000000000026, -0.30700000000000005, -0.126, -1.2030000000000003, -0.1419999999999999, -0.08799999999999997, -0.09799999999999986, -0.14, -0.030000000000000027, -0.049000000000000044, -0.22499999999999987, -0.03500000000000003, 0.368, -0.06899999999999995, -0.31800000000000006, -0.279, -0.027000000000000024, -0.16699999999999993, -0.1299999999999999, -0.07799999999999985, -0.05899999999999994, -0.16800000000000004, -0.07800000000000007, -0.026999999999999913, 0.279, -0.2819999999999999, -0.21999999999999997, -0.04600000000000004, -0.07000000000000006, -0.052000000000000046, -0.05600000000000005, -0.3969999999999999, -0.16300000000000003, -0.05899999999999994, -0.2539999999999999, -0.46699999999999986, -0.347, -0.09399999999999986, -0.236, -0.07099999999999995, -0.17100000000000004, -0.17900000000000005, -0.18900000000000006, -0.037000000000000144, -0.14300000000000002, 0.347, -0.10299999999999998, -0.15100000000000002, -0.264, -0.06999999999999995, -0.052000000000000046, -0.16200000000000003, -0.4099999999999999, -0.10999999999999988, -0.21099999999999997, -0.04800000000000004, 0.404, -0.03600000000000003, -0.038000000000000034, -0.18500000000000005, -0.2559999999999999, -0.05999999999999994, -0.10699999999999998, 0.44799999999999995, -0.10099999999999998, -0.08099999999999996, -0.05700000000000005, -0.46599999999999997, -0.14600000000000002, -0.15100000000000002, -0.29999999999999993, -0.08599999999999997, -0.16900000000000004, -0.2270000000000001, -0.06800000000000006, -0.16000000000000003, -0.12000000000000009, -0.34999999999999987, -0.07400000000000007, -0.18000000000000005, -0.05400000000000005, 0.42500000000000004, -0.02400000000000002, -0.16200000000000003, 0.33499999999999996, -0.09299999999999997, -0.138, -0.16299999999999992, -0.20799999999999996, -0.1279999999999999, -0.05500000000000005, -0.2230000000000001], "episode_lengths": [12, 124, 106, 30, 34, 21, 32, 17, 9, 82, 39, 294, 45, 28, 31, 42, 13, 15, 66, 11, 38, 22, 94, 85, 9, 54, 39, 25, 16, 50, 24, 8, 70, 89, 66, 14, 22, 15, 17, 128, 49, 18, 77, 144, 113, 29, 72, 22, 51, 53, 59, 153, 48, 42, 31, 49, 84, 21, 14, 48, 127, 35, 226, 14, 30, 10, 167, 59, 81, 19, 33, 16, 32, 24, 21, 147, 47, 43, 91, 31, 51, 67, 22, 44, 300, 97, 22, 55, 16, 23, 8, 49, 49, 27, 44, 50, 66, 41, 17, 69], "policy_red_0_v4_reward": [-1.003, -1.195, -1.001, -0.502, 0.973, 0.9299999999999999, -1.007, -1.014, -1.004, -1.002, 0.859, 0.7929999999999999, 0.827, -1.004], "policy_blue_0_reward": [-0.517, -1.006, -1.004, -1.003, -1.001, -1.003, -1.002, -1.005, -1.003, 0.861, -1.012, -1.002, -1.011, -1.015, -1.004, -1.003, -1.003, -1.007, -1.004, -0.512, -1.012, -1.002, -1.021, -1.003, -1.012, -1.002, 1.023, -0.507, -1.004, -1.001, -0.534, -1.01, -1.0019999999999998, -1.0059999999999998, -1.004, -1.021, -1.01, -1.019, -1.012, -1.016, -1.003, -0.503, -1.005, -1.009, -1.007, -1.005, -1.001], "policy_red_0_v1_reward": [-1.015, -1.002, 0.947, -1.003, -1.01, -1.008, -1.001, -1.004, 0.817, 0.901, -1.002, -1.0], "policy_red_0_v3_reward": [0.715, -1.003, -1.016, -1.011, -1.004, -0.517, -1.004, -1.001, -1.031, 0.947, 0.7849999999999999], "policy_red_0_v5_reward": [0.881, -1.0099999999999998, -1.005, -1.01, -1.006, 0.843, -1.009, -0.503, -0.08400000000000006, 0.852], "policy_red_0_v2_reward": [0.951, -1.001, 0.948, -1.007, 1.4489999999999998, -0.507]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303417264976543, "mean_inference_ms": 1.5025645405613373, "mean_action_processing_ms": 0.0625436936058923, "mean_env_wait_ms": 0.10621278147811325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018278837203979492, "StateBufferConnector_ms": 0.0014683008193969727, "ViewRequirementAgentConnector_ms": 0.03061366081237793}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.6650135785915, "num_env_steps_trained_throughput_per_sec": 101.6650135785915, "timesteps_total": 284000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 568000, "timers": {"training_iteration_time_ms": 39698.917, "sample_time_ms": 7723.629, "learn_time_ms": 31957.25, "learn_throughput": 125.167, "synch_weights_time_ms": 17.383}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "done": false, "episodes_total": 4554, "training_iteration": 71, "trial_id": "bb874_00000", "date": "2023-09-28_22-17-04", "timestamp": 1695953824, "time_this_iter_s": 39.34756517410278, "time_total_s": 2808.891963005066, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d80a30>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70e440>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70c0d0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2808.891963005066, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 34.880357142857136, "ram_util_percent": 28.850000000000005}, "win_rate": 0.81, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4661492853115003, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.08015286502850358, "policy_loss": -0.022389224881771953, "vf_loss": 0.20234888550670196, "vf_explained_var": 0.2599446831891934, "kl": 0.01168845459781475, "entropy": 0.970043396949768, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 68640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "sampler_results": {"episode_reward_max": 0.48, "episode_reward_min": -0.871, "episode_reward_mean": -0.08832999999999998, "episode_len_mean": 44.57, "episode_media": {}, "episodes_this_iter": 92, "policy_reward_min": {"red_0_v2": -1.0079999999999998, "red_0": -1.037, "blue_0": -1.0219999999999998, "red_0_v4": -1.0079999999999998, "red_0_v3": -1.025, "red_0_v1": -1.055, "red_0_v5": -1.007}, "policy_reward_max": {"red_0_v2": 1.3170000000000002, "red_0": 0.98, "blue_0": 1.31, "red_0_v4": 0.944, "red_0_v3": 0.961, "red_0_v1": 0.854, "red_0_v5": 0.982}, "policy_reward_mean": {"red_0_v2": -0.08699999999999995, "red_0": 0.47094, "blue_0": -0.8830727272727272, "red_0_v4": -0.18071428571428566, "red_0_v3": -0.04599999999999999, "red_0_v1": -0.5041111111111111, "red_0_v5": -0.03787499999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.33499999999999996, -0.09299999999999997, -0.138, -0.16299999999999992, -0.20799999999999996, -0.1279999999999999, -0.05500000000000005, -0.2230000000000001, -0.689, -0.29699999999999993, -0.18700000000000017, -0.06299999999999994, -0.16000000000000003, -0.14, -0.23699999999999988, -0.039999999999999925, -0.030000000000000027, -0.267, -0.18099999999999994, -0.08999999999999997, -0.031000000000000028, -0.16700000000000004, 0.31000000000000005, -0.17099999999999993, -0.02300000000000002, -0.133, -0.050999999999999934, 0.48, -0.051000000000000045, -0.018000000000000016, -0.05800000000000005, -0.12399999999999978, -0.05799999999999994, -0.039000000000000035, 0.41900000000000004, -0.2390000000000001, -0.07999999999999985, -0.3550000000000001, -0.30600000000000005, -0.07200000000000006, -0.31699999999999995, -0.050000000000000044, -0.29300000000000004, -0.1479999999999999, -0.052000000000000046, -0.11199999999999999, -0.049000000000000044, -0.235, -0.871, -0.03200000000000003, -0.11699999999999988, 0.31000000000000005, -0.06599999999999995, -0.07100000000000006, -0.13099999999999978, -0.04500000000000004, -0.050000000000000044, 0.2849999999999998, -0.10999999999999988, 0.3370000000000001, -0.15500000000000003, -0.17900000000000005, -0.06000000000000005, -0.02400000000000002, -0.09699999999999998, -0.09499999999999997, -0.03399999999999992, 0.135, -0.15699999999999992, -0.1299999999999999, -0.28, -0.030999999999999917, -0.09299999999999997, -0.09099999999999986, -0.12299999999999989, -0.11399999999999988, -0.05899999999999994, -0.15200000000000002, -0.06599999999999984, -0.40900000000000003, -0.09099999999999997, -0.06700000000000006, -0.07999999999999985, 0.4, -0.02400000000000002, -0.04799999999999993, -0.3410000000000001, -0.07300000000000006, -0.049000000000000044, 0.396, -0.05499999999999994, -0.1419999999999999, -0.06899999999999995, -0.06700000000000006, -0.08999999999999997, -0.05800000000000005, -0.253, -0.06899999999999995, -0.05700000000000005, -0.14400000000000002], "episode_lengths": [49, 27, 44, 50, 66, 41, 17, 69, 216, 90, 56, 18, 52, 44, 76, 13, 12, 83, 54, 30, 9, 51, 62, 54, 7, 40, 16, 10, 19, 6, 18, 36, 17, 11, 28, 69, 24, 100, 85, 24, 96, 16, 79, 45, 16, 33, 15, 77, 246, 10, 36, 58, 21, 22, 35, 15, 16, 300, 31, 50, 47, 57, 21, 8, 29, 33, 11, 103, 48, 41, 90, 10, 33, 32, 38, 35, 18, 48, 20, 118, 29, 19, 25, 30, 8, 13, 106, 21, 15, 33, 16, 41, 22, 20, 28, 20, 77, 22, 18, 44], "policy_red_0_v2_reward": [-0.507, -1.0079999999999998, -1.004, 0.6699999999999999, 1.3170000000000002, -1.004, 0.9269999999999999], "policy_blue_0_reward": [-1.005, -1.009, -1.007, -1.005, -1.001, -1.0219999999999998, -1.017, -1.004, -1.009, -1.0, -1.012, -1.0059999999999998, -1.003, -1.002, -1.008, 1.31, -1.007, -1.002, -1.004, -1.0079999999999998, -1.004, -1.0039999999999998, -1.015, -1.001, -1.008, -1.002, -1.002, -1.001, 0.9329999999999999, -1.0, -1.002, 0.45899999999999996, -1.003, -1.004, -1.0, -1.007, -1.005, -0.511, -1.004, -1.002, -1.001, -1.001, -1.0039999999999998, -1.0039999999999998, -1.005, -1.005, -0.504, -1.0, -1.008, -1.002, -1.004, -1.002, -1.012, -1.003, -1.01], "policy_red_0_v4_reward": [-1.004, 0.87, -1.0, 0.9359999999999999, -1.0079999999999998, -1.003, 0.944], "policy_red_0_v3_reward": [0.7849999999999999, -1.021, -1.007, 0.961, -1.025, 0.88, -1.002, -1.007, -1.0239999999999998, -0.5079999999999999, 0.85, 0.604, 0.9359999999999999, 0.9339999999999999], "policy_red_0_v1_reward": [-1.002, -0.5, -1.0, -1.055, -1.006, 0.854, -1.002, 0.6739999999999999, -0.5], "policy_red_0_v5_reward": [0.982, -0.501, 0.731, -1.007, 0.767, -1.001, 0.726, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303054657776977, "mean_inference_ms": 1.5021902911924827, "mean_action_processing_ms": 0.06250180067190242, "mean_env_wait_ms": 0.10617705180101562, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018099665641784668, "StateBufferConnector_ms": 0.0014853477478027344, "ViewRequirementAgentConnector_ms": 0.030751824378967285}}, "episode_reward_max": 0.48, "episode_reward_min": -0.871, "episode_reward_mean": -0.08832999999999998, "episode_len_mean": 44.57, "episodes_this_iter": 92, "policy_reward_min": {"red_0_v2": -1.0079999999999998, "red_0": -1.037, "blue_0": -1.0219999999999998, "red_0_v4": -1.0079999999999998, "red_0_v3": -1.025, "red_0_v1": -1.055, "red_0_v5": -1.007}, "policy_reward_max": {"red_0_v2": 1.3170000000000002, "red_0": 0.98, "blue_0": 1.31, "red_0_v4": 0.944, "red_0_v3": 0.961, "red_0_v1": 0.854, "red_0_v5": 0.982}, "policy_reward_mean": {"red_0_v2": -0.08699999999999995, "red_0": 0.47094, "blue_0": -0.8830727272727272, "red_0_v4": -0.18071428571428566, "red_0_v3": -0.04599999999999999, "red_0_v1": -0.5041111111111111, "red_0_v5": -0.03787499999999998}, "hist_stats": {"episode_reward": [0.33499999999999996, -0.09299999999999997, -0.138, -0.16299999999999992, -0.20799999999999996, -0.1279999999999999, -0.05500000000000005, -0.2230000000000001, -0.689, -0.29699999999999993, -0.18700000000000017, -0.06299999999999994, -0.16000000000000003, -0.14, -0.23699999999999988, -0.039999999999999925, -0.030000000000000027, -0.267, -0.18099999999999994, -0.08999999999999997, -0.031000000000000028, -0.16700000000000004, 0.31000000000000005, -0.17099999999999993, -0.02300000000000002, -0.133, -0.050999999999999934, 0.48, -0.051000000000000045, -0.018000000000000016, -0.05800000000000005, -0.12399999999999978, -0.05799999999999994, -0.039000000000000035, 0.41900000000000004, -0.2390000000000001, -0.07999999999999985, -0.3550000000000001, -0.30600000000000005, -0.07200000000000006, -0.31699999999999995, -0.050000000000000044, -0.29300000000000004, -0.1479999999999999, -0.052000000000000046, -0.11199999999999999, -0.049000000000000044, -0.235, -0.871, -0.03200000000000003, -0.11699999999999988, 0.31000000000000005, -0.06599999999999995, -0.07100000000000006, -0.13099999999999978, -0.04500000000000004, -0.050000000000000044, 0.2849999999999998, -0.10999999999999988, 0.3370000000000001, -0.15500000000000003, -0.17900000000000005, -0.06000000000000005, -0.02400000000000002, -0.09699999999999998, -0.09499999999999997, -0.03399999999999992, 0.135, -0.15699999999999992, -0.1299999999999999, -0.28, -0.030999999999999917, -0.09299999999999997, -0.09099999999999986, -0.12299999999999989, -0.11399999999999988, -0.05899999999999994, -0.15200000000000002, -0.06599999999999984, -0.40900000000000003, -0.09099999999999997, -0.06700000000000006, -0.07999999999999985, 0.4, -0.02400000000000002, -0.04799999999999993, -0.3410000000000001, -0.07300000000000006, -0.049000000000000044, 0.396, -0.05499999999999994, -0.1419999999999999, -0.06899999999999995, -0.06700000000000006, -0.08999999999999997, -0.05800000000000005, -0.253, -0.06899999999999995, -0.05700000000000005, -0.14400000000000002], "episode_lengths": [49, 27, 44, 50, 66, 41, 17, 69, 216, 90, 56, 18, 52, 44, 76, 13, 12, 83, 54, 30, 9, 51, 62, 54, 7, 40, 16, 10, 19, 6, 18, 36, 17, 11, 28, 69, 24, 100, 85, 24, 96, 16, 79, 45, 16, 33, 15, 77, 246, 10, 36, 58, 21, 22, 35, 15, 16, 300, 31, 50, 47, 57, 21, 8, 29, 33, 11, 103, 48, 41, 90, 10, 33, 32, 38, 35, 18, 48, 20, 118, 29, 19, 25, 30, 8, 13, 106, 21, 15, 33, 16, 41, 22, 20, 28, 20, 77, 22, 18, 44], "policy_red_0_v2_reward": [-0.507, -1.0079999999999998, -1.004, 0.6699999999999999, 1.3170000000000002, -1.004, 0.9269999999999999], "policy_blue_0_reward": [-1.005, -1.009, -1.007, -1.005, -1.001, -1.0219999999999998, -1.017, -1.004, -1.009, -1.0, -1.012, -1.0059999999999998, -1.003, -1.002, -1.008, 1.31, -1.007, -1.002, -1.004, -1.0079999999999998, -1.004, -1.0039999999999998, -1.015, -1.001, -1.008, -1.002, -1.002, -1.001, 0.9329999999999999, -1.0, -1.002, 0.45899999999999996, -1.003, -1.004, -1.0, -1.007, -1.005, -0.511, -1.004, -1.002, -1.001, -1.001, -1.0039999999999998, -1.0039999999999998, -1.005, -1.005, -0.504, -1.0, -1.008, -1.002, -1.004, -1.002, -1.012, -1.003, -1.01], "policy_red_0_v4_reward": [-1.004, 0.87, -1.0, 0.9359999999999999, -1.0079999999999998, -1.003, 0.944], "policy_red_0_v3_reward": [0.7849999999999999, -1.021, -1.007, 0.961, -1.025, 0.88, -1.002, -1.007, -1.0239999999999998, -0.5079999999999999, 0.85, 0.604, 0.9359999999999999, 0.9339999999999999], "policy_red_0_v1_reward": [-1.002, -0.5, -1.0, -1.055, -1.006, 0.854, -1.002, 0.6739999999999999, -0.5], "policy_red_0_v5_reward": [0.982, -0.501, 0.731, -1.007, 0.767, -1.001, 0.726, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303054657776977, "mean_inference_ms": 1.5021902911924827, "mean_action_processing_ms": 0.06250180067190242, "mean_env_wait_ms": 0.10617705180101562, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018099665641784668, "StateBufferConnector_ms": 0.0014853477478027344, "ViewRequirementAgentConnector_ms": 0.030751824378967285}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.05885146109237, "num_env_steps_trained_throughput_per_sec": 101.05885146109237, "timesteps_total": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 39709.751, "sample_time_ms": 7732.733, "learn_time_ms": 31959.093, "learn_throughput": 125.16, "synch_weights_time_ms": 17.267}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "episodes_total": 4646, "training_iteration": 72, "trial_id": "bb874_00000", "date": "2023-09-28_22-17-44", "timestamp": 1695953864, "time_this_iter_s": 39.58385419845581, "time_total_s": 2848.4758172035217, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d80910>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac7568c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac757910>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2848.4758172035217, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 35.26428571428571, "ram_util_percent": 28.794642857142858}, "win_rate": 0.78, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.299516696482897, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03854545006585492, "policy_loss": -0.024817439502415557, "vf_loss": 0.12380665607828026, "vf_explained_var": 0.3091955319046974, "kl": 0.01218582309198079, "entropy": 0.9776033528149128, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 69600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000}, "sampler_results": {"episode_reward_max": 0.44400000000000006, "episode_reward_min": -0.747, "episode_reward_mean": -0.10081999999999997, "episode_len_mean": 48.53, "episode_media": {}, "episodes_this_iter": 66, "policy_reward_min": {"red_0_v5": -1.008, "red_0": -1.022, "blue_0": -1.025, "red_0_v2": -1.017, "red_0_v1": -1.013, "red_0_v3": -1.0079999999999998, "red_0_v4": -1.012}, "policy_reward_max": {"red_0_v5": 0.976, "red_0": 0.979, "blue_0": 0.969, "red_0_v2": 0.9269999999999999, "red_0_v1": 0.854, "red_0_v3": 0.9359999999999999, "red_0_v4": 0.946}, "policy_reward_mean": {"red_0_v5": 0.02515384615384616, "red_0": 0.47590000000000005, "blue_0": -0.8806530612244898, "red_0_v2": -0.6632857142857143, "red_0_v1": -0.5536923076923077, "red_0_v3": -0.09066666666666656, "red_0_v4": -0.20516666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.03399999999999992, 0.135, -0.15699999999999992, -0.1299999999999999, -0.28, -0.030999999999999917, -0.09299999999999997, -0.09099999999999986, -0.12299999999999989, -0.11399999999999988, -0.05899999999999994, -0.15200000000000002, -0.06599999999999984, -0.40900000000000003, -0.09099999999999997, -0.06700000000000006, -0.07999999999999985, 0.4, -0.02400000000000002, -0.04799999999999993, -0.3410000000000001, -0.07300000000000006, -0.049000000000000044, 0.396, -0.05499999999999994, -0.1419999999999999, -0.06899999999999995, -0.06700000000000006, -0.08999999999999997, -0.05800000000000005, -0.253, -0.06899999999999995, -0.05700000000000005, -0.14400000000000002, -0.062000000000000055, -0.1439999999999999, -0.18299999999999983, -0.10300000000000008, -0.17900000000000005, -0.12700000000000009, -0.07899999999999996, -0.07200000000000006, -0.04999999999999982, -0.10299999999999976, -0.030999999999999917, -0.09999999999999987, -0.02199999999999991, -0.050999999999999934, 0.41500000000000004, -0.131, -0.040000000000000036, -0.03200000000000003, -0.32799999999999985, -0.30600000000000005, -0.05700000000000005, -0.3699999999999999, -0.16400000000000003, -0.09899999999999998, -0.05699999999999994, -0.747, -0.1449999999999999, -0.09999999999999987, -0.09399999999999997, 0.09299999999999997, -0.05400000000000005, -0.19100000000000006, -0.05999999999999994, -0.09999999999999998, -0.11899999999999988, -0.026000000000000023, -0.21900000000000008, -0.22699999999999976, -0.22999999999999998, -0.05799999999999994, -0.03299999999999992, -0.027000000000000024, -0.11799999999999977, -0.19400000000000006, -0.09999999999999998, -0.03400000000000003, -0.29200000000000004, 0.248, -0.031000000000000028, -0.21500000000000008, -0.12099999999999989, -0.039999999999999925, -0.3839999999999999, -0.47, -0.07599999999999985, -0.10899999999999987, -0.18500000000000005, -0.02400000000000002, -0.16599999999999993, -0.28400000000000003, -0.2530000000000001, -0.05400000000000005, -0.06599999999999995, 0.44400000000000006, -0.09199999999999997, -0.06899999999999995], "episode_lengths": [11, 103, 48, 41, 90, 10, 33, 32, 38, 35, 18, 48, 20, 118, 29, 19, 25, 30, 8, 13, 106, 21, 15, 33, 16, 41, 22, 20, 28, 20, 77, 22, 18, 44, 18, 41, 53, 300, 203, 300, 25, 22, 14, 31, 10, 29, 7, 16, 25, 41, 16, 10, 101, 90, 17, 113, 52, 31, 18, 245, 42, 31, 28, 118, 18, 60, 19, 34, 34, 8, 67, 71, 68, 19, 10, 9, 32, 60, 30, 10, 82, 79, 10, 67, 38, 13, 111, 154, 25, 36, 60, 8, 49, 88, 82, 18, 19, 18, 28, 20], "policy_red_0_v5_reward": [-1.001, 0.726, -1.0, -0.014000000000000005, 0.921, -1.008, -0.507, 0.973, 0.818, -1.001, 0.976, 0.946, -0.5019999999999999], "policy_blue_0_reward": [-0.511, -1.004, -1.002, -1.001, -1.001, -1.0039999999999998, -1.0039999999999998, -1.005, -1.005, -0.504, -1.0, -1.008, -1.002, -1.004, -1.002, -1.012, -1.003, -1.01, -1.0099999999999998, -0.04400000000000003, -1.001, -1.002, -0.505, -1.005, -1.001, -1.017, 0.716, -1.005, -1.015, -1.006, -1.0079999999999998, -1.007, -1.004, -1.008, -1.008, -1.01, -1.009, -1.013, -1.001, -1.003, -1.01, 0.969, -1.005, -1.001, -1.025, -1.012, -1.011, -1.004, -1.005], "policy_red_0_v2_reward": [-1.004, 0.9269999999999999, -0.539, -1.001, -1.001, -1.017, -1.008], "policy_red_0_v1_reward": [-1.006, 0.854, -1.002, 0.6739999999999999, -0.5, -1.005, -1.007, -1.013, -1.002, -1.002, -1.004, -1.001, 0.816], "policy_red_0_v3_reward": [0.604, 0.9359999999999999, 0.9339999999999999, -1.0079999999999998, -1.003, -1.007], "policy_red_0_v4_reward": [-1.0079999999999998, -1.003, 0.944, -1.005, -1.001, -1.0, 0.838, 0.946, 0.8089999999999999, -0.504, 0.534, -1.012]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23033394776303684, "mean_inference_ms": 1.5017325706247926, "mean_action_processing_ms": 0.06250199460060513, "mean_env_wait_ms": 0.10615376776954337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018816709518432617, "StateBufferConnector_ms": 0.0014966726303100586, "ViewRequirementAgentConnector_ms": 0.03108382225036621}}, "episode_reward_max": 0.44400000000000006, "episode_reward_min": -0.747, "episode_reward_mean": -0.10081999999999997, "episode_len_mean": 48.53, "episodes_this_iter": 66, "policy_reward_min": {"red_0_v5": -1.008, "red_0": -1.022, "blue_0": -1.025, "red_0_v2": -1.017, "red_0_v1": -1.013, "red_0_v3": -1.0079999999999998, "red_0_v4": -1.012}, "policy_reward_max": {"red_0_v5": 0.976, "red_0": 0.979, "blue_0": 0.969, "red_0_v2": 0.9269999999999999, "red_0_v1": 0.854, "red_0_v3": 0.9359999999999999, "red_0_v4": 0.946}, "policy_reward_mean": {"red_0_v5": 0.02515384615384616, "red_0": 0.47590000000000005, "blue_0": -0.8806530612244898, "red_0_v2": -0.6632857142857143, "red_0_v1": -0.5536923076923077, "red_0_v3": -0.09066666666666656, "red_0_v4": -0.20516666666666664}, "hist_stats": {"episode_reward": [-0.03399999999999992, 0.135, -0.15699999999999992, -0.1299999999999999, -0.28, -0.030999999999999917, -0.09299999999999997, -0.09099999999999986, -0.12299999999999989, -0.11399999999999988, -0.05899999999999994, -0.15200000000000002, -0.06599999999999984, -0.40900000000000003, -0.09099999999999997, -0.06700000000000006, -0.07999999999999985, 0.4, -0.02400000000000002, -0.04799999999999993, -0.3410000000000001, -0.07300000000000006, -0.049000000000000044, 0.396, -0.05499999999999994, -0.1419999999999999, -0.06899999999999995, -0.06700000000000006, -0.08999999999999997, -0.05800000000000005, -0.253, -0.06899999999999995, -0.05700000000000005, -0.14400000000000002, -0.062000000000000055, -0.1439999999999999, -0.18299999999999983, -0.10300000000000008, -0.17900000000000005, -0.12700000000000009, -0.07899999999999996, -0.07200000000000006, -0.04999999999999982, -0.10299999999999976, -0.030999999999999917, -0.09999999999999987, -0.02199999999999991, -0.050999999999999934, 0.41500000000000004, -0.131, -0.040000000000000036, -0.03200000000000003, -0.32799999999999985, -0.30600000000000005, -0.05700000000000005, -0.3699999999999999, -0.16400000000000003, -0.09899999999999998, -0.05699999999999994, -0.747, -0.1449999999999999, -0.09999999999999987, -0.09399999999999997, 0.09299999999999997, -0.05400000000000005, -0.19100000000000006, -0.05999999999999994, -0.09999999999999998, -0.11899999999999988, -0.026000000000000023, -0.21900000000000008, -0.22699999999999976, -0.22999999999999998, -0.05799999999999994, -0.03299999999999992, -0.027000000000000024, -0.11799999999999977, -0.19400000000000006, -0.09999999999999998, -0.03400000000000003, -0.29200000000000004, 0.248, -0.031000000000000028, -0.21500000000000008, -0.12099999999999989, -0.039999999999999925, -0.3839999999999999, -0.47, -0.07599999999999985, -0.10899999999999987, -0.18500000000000005, -0.02400000000000002, -0.16599999999999993, -0.28400000000000003, -0.2530000000000001, -0.05400000000000005, -0.06599999999999995, 0.44400000000000006, -0.09199999999999997, -0.06899999999999995], "episode_lengths": [11, 103, 48, 41, 90, 10, 33, 32, 38, 35, 18, 48, 20, 118, 29, 19, 25, 30, 8, 13, 106, 21, 15, 33, 16, 41, 22, 20, 28, 20, 77, 22, 18, 44, 18, 41, 53, 300, 203, 300, 25, 22, 14, 31, 10, 29, 7, 16, 25, 41, 16, 10, 101, 90, 17, 113, 52, 31, 18, 245, 42, 31, 28, 118, 18, 60, 19, 34, 34, 8, 67, 71, 68, 19, 10, 9, 32, 60, 30, 10, 82, 79, 10, 67, 38, 13, 111, 154, 25, 36, 60, 8, 49, 88, 82, 18, 19, 18, 28, 20], "policy_red_0_v5_reward": [-1.001, 0.726, -1.0, -0.014000000000000005, 0.921, -1.008, -0.507, 0.973, 0.818, -1.001, 0.976, 0.946, -0.5019999999999999], "policy_blue_0_reward": [-0.511, -1.004, -1.002, -1.001, -1.001, -1.0039999999999998, -1.0039999999999998, -1.005, -1.005, -0.504, -1.0, -1.008, -1.002, -1.004, -1.002, -1.012, -1.003, -1.01, -1.0099999999999998, -0.04400000000000003, -1.001, -1.002, -0.505, -1.005, -1.001, -1.017, 0.716, -1.005, -1.015, -1.006, -1.0079999999999998, -1.007, -1.004, -1.008, -1.008, -1.01, -1.009, -1.013, -1.001, -1.003, -1.01, 0.969, -1.005, -1.001, -1.025, -1.012, -1.011, -1.004, -1.005], "policy_red_0_v2_reward": [-1.004, 0.9269999999999999, -0.539, -1.001, -1.001, -1.017, -1.008], "policy_red_0_v1_reward": [-1.006, 0.854, -1.002, 0.6739999999999999, -0.5, -1.005, -1.007, -1.013, -1.002, -1.002, -1.004, -1.001, 0.816], "policy_red_0_v3_reward": [0.604, 0.9359999999999999, 0.9339999999999999, -1.0079999999999998, -1.003, -1.007], "policy_red_0_v4_reward": [-1.0079999999999998, -1.003, 0.944, -1.005, -1.001, -1.0, 0.838, 0.946, 0.8089999999999999, -0.504, 0.534, -1.012]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23033394776303684, "mean_inference_ms": 1.5017325706247926, "mean_action_processing_ms": 0.06250199460060513, "mean_env_wait_ms": 0.10615376776954337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018816709518432617, "StateBufferConnector_ms": 0.0014966726303100586, "ViewRequirementAgentConnector_ms": 0.03108382225036621}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.44965254682091, "num_env_steps_trained_throughput_per_sec": 101.44965254682091, "timesteps_total": 292000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 584000, "timers": {"training_iteration_time_ms": 39716.264, "sample_time_ms": 7725.296, "learn_time_ms": 31972.979, "learn_throughput": 125.106, "synch_weights_time_ms": 17.328}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 584000, "num_agent_steps_trained": 584000}, "done": false, "episodes_total": 4712, "training_iteration": 73, "trial_id": "bb874_00000", "date": "2023-09-28_22-18-23", "timestamp": 1695953903, "time_this_iter_s": 39.431134939193726, "time_total_s": 2887.9069521427155, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d81ff0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac405ab0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac407400>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2887.9069521427155, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 34.324999999999996, "ram_util_percent": 28.900000000000002}, "win_rate": 0.8, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4476842254400255, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.019589518851353203, "policy_loss": -0.02384015203618522, "vf_loss": 0.0836694561119657, "vf_explained_var": 0.46160094620039066, "kl": 0.012650450701297944, "entropy": 0.9351478542511662, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 70560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "sampler_results": {"episode_reward_max": 0.488, "episode_reward_min": -0.747, "episode_reward_mean": -0.13021999999999997, "episode_len_mean": 60.68, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"red_0_v5": -1.011, "red_0": -1.054, "blue_0": -1.031, "red_0_v4": -1.012, "red_0_v1": -1.02, "red_0_v2": -1.022, "red_0_v3": -1.0179999999999998}, "policy_reward_max": {"red_0_v5": 0.976, "red_0": 0.976, "blue_0": 0.969, "red_0_v4": 1.2850000000000001, "red_0_v1": 0.816, "red_0_v2": 0.866, "red_0_v3": 0.923}, "policy_reward_mean": {"red_0_v5": -0.059529411764705886, "red_0": 0.48486000000000007, "blue_0": -0.9177083333333332, "red_0_v4": 0.2622, "red_0_v1": -0.7448571428571428, "red_0_v2": -0.8009999999999999, "red_0_v3": -0.7383333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.747, -0.1449999999999999, -0.09999999999999987, -0.09399999999999997, 0.09299999999999997, -0.05400000000000005, -0.19100000000000006, -0.05999999999999994, -0.09999999999999998, -0.11899999999999988, -0.026000000000000023, -0.21900000000000008, -0.22699999999999976, -0.22999999999999998, -0.05799999999999994, -0.03299999999999992, -0.027000000000000024, -0.11799999999999977, -0.19400000000000006, -0.09999999999999998, -0.03400000000000003, -0.29200000000000004, 0.248, -0.031000000000000028, -0.21500000000000008, -0.12099999999999989, -0.039999999999999925, -0.3839999999999999, -0.47, -0.07599999999999985, -0.10899999999999987, -0.18500000000000005, -0.02400000000000002, -0.16599999999999993, -0.28400000000000003, -0.2530000000000001, -0.05400000000000005, -0.06599999999999995, 0.44400000000000006, -0.09199999999999997, -0.06899999999999995, -0.08599999999999997, -0.03200000000000003, -0.397, -0.19000000000000006, -0.3370000000000001, -0.2330000000000001, -0.04400000000000004, 0.488, -0.5730000000000001, -0.10099999999999987, -0.132, -0.16299999999999992, -0.126, -0.07099999999999995, -0.6729999999999999, -0.03599999999999992, -0.14800000000000002, -0.238, -0.05599999999999994, -0.11899999999999988, 0.43799999999999994, -0.18299999999999994, -0.029999999999999916, -0.551, -0.11200000000000009, -0.04599999999999993, -0.07099999999999984, -0.06700000000000006, -0.07799999999999996, -0.1269999999999999, -0.2470000000000001, -0.052000000000000046, -0.21399999999999997, -0.08899999999999997, -0.17800000000000005, -0.128, -0.2769999999999999, -0.3769999999999999, 0.28, -0.039000000000000035, -0.02499999999999991, -0.10499999999999987, -0.04999999999999993, -0.4109999999999999, -0.11899999999999988, -0.44200000000000006, -0.10999999999999988, -0.19399999999999995, -0.03200000000000003, -0.1429999999999999, -0.129, -0.19799999999999995, -0.07199999999999995, -0.041000000000000036, -0.06499999999999995, -0.03700000000000003, -0.131, -0.10099999999999987, -0.18000000000000013], "episode_lengths": [245, 42, 31, 28, 118, 18, 60, 19, 34, 34, 8, 67, 71, 68, 19, 10, 9, 32, 60, 30, 10, 82, 79, 10, 67, 38, 13, 111, 154, 25, 36, 60, 8, 49, 88, 82, 18, 19, 18, 28, 20, 26, 10, 113, 63, 99, 73, 14, 300, 188, 28, 40, 50, 40, 23, 212, 11, 48, 69, 17, 36, 18, 54, 9, 171, 300, 15, 25, 21, 25, 38, 240, 16, 71, 27, 55, 38, 82, 116, 71, 16, 8, 34, 15, 124, 38, 278, 33, 59, 10, 44, 39, 62, 21, 13, 20, 15, 39, 30, 300], "policy_red_0_v5_reward": [-1.008, -0.507, 0.973, 0.818, -1.001, 0.976, 0.946, -0.5019999999999999, -1.003, 0.657, 0.494, 0.43499999999999994, -1.003, -0.05200000000000004, -1.011, 0.7769999999999999, -1.001], "policy_blue_0_reward": [-1.0079999999999998, -1.007, -1.004, -1.008, -1.008, -1.01, -1.009, -1.013, -1.001, -1.003, -1.01, 0.969, -1.005, -1.001, -1.025, -1.012, -1.011, -1.004, -1.005, -1.002, -1.018, -1.007, -1.001, -1.004, -1.01, -1.002, -1.031, -1.003, -1.01, -1.004, -1.006, -1.0, -1.003, -1.003, -1.002, -1.002, 0.829, -1.005, -1.006, -1.001, -1.003, -1.02, -1.004, -0.537, -1.007, -1.006, -1.005, -1.002], "policy_red_0_v4_reward": [0.946, 0.8089999999999999, -0.504, 0.534, -1.012, 0.8099999999999999, 0.786, 1.2850000000000001, -1.001, -0.03100000000000002], "policy_red_0_v1_reward": [-1.002, -1.004, -1.001, 0.816, -1.02, -1.001, -1.002], "policy_red_0_v2_reward": [-1.001, -1.017, -1.008, -1.008, -1.016, -1.022, -1.001, 0.866, -1.002], "policy_red_0_v3_reward": [-1.003, -1.007, -1.011, -1.0179999999999998, -0.504, 0.923, -1.004, -1.011, -1.01]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031908966279638, "mean_inference_ms": 1.5023947098778594, "mean_action_processing_ms": 0.062499985151577134, "mean_env_wait_ms": 0.10617306638878825, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01848781108856201, "StateBufferConnector_ms": 0.001473546028137207, "ViewRequirementAgentConnector_ms": 0.030823588371276855}}, "episode_reward_max": 0.488, "episode_reward_min": -0.747, "episode_reward_mean": -0.13021999999999997, "episode_len_mean": 60.68, "episodes_this_iter": 59, "policy_reward_min": {"red_0_v5": -1.011, "red_0": -1.054, "blue_0": -1.031, "red_0_v4": -1.012, "red_0_v1": -1.02, "red_0_v2": -1.022, "red_0_v3": -1.0179999999999998}, "policy_reward_max": {"red_0_v5": 0.976, "red_0": 0.976, "blue_0": 0.969, "red_0_v4": 1.2850000000000001, "red_0_v1": 0.816, "red_0_v2": 0.866, "red_0_v3": 0.923}, "policy_reward_mean": {"red_0_v5": -0.059529411764705886, "red_0": 0.48486000000000007, "blue_0": -0.9177083333333332, "red_0_v4": 0.2622, "red_0_v1": -0.7448571428571428, "red_0_v2": -0.8009999999999999, "red_0_v3": -0.7383333333333333}, "hist_stats": {"episode_reward": [-0.747, -0.1449999999999999, -0.09999999999999987, -0.09399999999999997, 0.09299999999999997, -0.05400000000000005, -0.19100000000000006, -0.05999999999999994, -0.09999999999999998, -0.11899999999999988, -0.026000000000000023, -0.21900000000000008, -0.22699999999999976, -0.22999999999999998, -0.05799999999999994, -0.03299999999999992, -0.027000000000000024, -0.11799999999999977, -0.19400000000000006, -0.09999999999999998, -0.03400000000000003, -0.29200000000000004, 0.248, -0.031000000000000028, -0.21500000000000008, -0.12099999999999989, -0.039999999999999925, -0.3839999999999999, -0.47, -0.07599999999999985, -0.10899999999999987, -0.18500000000000005, -0.02400000000000002, -0.16599999999999993, -0.28400000000000003, -0.2530000000000001, -0.05400000000000005, -0.06599999999999995, 0.44400000000000006, -0.09199999999999997, -0.06899999999999995, -0.08599999999999997, -0.03200000000000003, -0.397, -0.19000000000000006, -0.3370000000000001, -0.2330000000000001, -0.04400000000000004, 0.488, -0.5730000000000001, -0.10099999999999987, -0.132, -0.16299999999999992, -0.126, -0.07099999999999995, -0.6729999999999999, -0.03599999999999992, -0.14800000000000002, -0.238, -0.05599999999999994, -0.11899999999999988, 0.43799999999999994, -0.18299999999999994, -0.029999999999999916, -0.551, -0.11200000000000009, -0.04599999999999993, -0.07099999999999984, -0.06700000000000006, -0.07799999999999996, -0.1269999999999999, -0.2470000000000001, -0.052000000000000046, -0.21399999999999997, -0.08899999999999997, -0.17800000000000005, -0.128, -0.2769999999999999, -0.3769999999999999, 0.28, -0.039000000000000035, -0.02499999999999991, -0.10499999999999987, -0.04999999999999993, -0.4109999999999999, -0.11899999999999988, -0.44200000000000006, -0.10999999999999988, -0.19399999999999995, -0.03200000000000003, -0.1429999999999999, -0.129, -0.19799999999999995, -0.07199999999999995, -0.041000000000000036, -0.06499999999999995, -0.03700000000000003, -0.131, -0.10099999999999987, -0.18000000000000013], "episode_lengths": [245, 42, 31, 28, 118, 18, 60, 19, 34, 34, 8, 67, 71, 68, 19, 10, 9, 32, 60, 30, 10, 82, 79, 10, 67, 38, 13, 111, 154, 25, 36, 60, 8, 49, 88, 82, 18, 19, 18, 28, 20, 26, 10, 113, 63, 99, 73, 14, 300, 188, 28, 40, 50, 40, 23, 212, 11, 48, 69, 17, 36, 18, 54, 9, 171, 300, 15, 25, 21, 25, 38, 240, 16, 71, 27, 55, 38, 82, 116, 71, 16, 8, 34, 15, 124, 38, 278, 33, 59, 10, 44, 39, 62, 21, 13, 20, 15, 39, 30, 300], "policy_red_0_v5_reward": [-1.008, -0.507, 0.973, 0.818, -1.001, 0.976, 0.946, -0.5019999999999999, -1.003, 0.657, 0.494, 0.43499999999999994, -1.003, -0.05200000000000004, -1.011, 0.7769999999999999, -1.001], "policy_blue_0_reward": [-1.0079999999999998, -1.007, -1.004, -1.008, -1.008, -1.01, -1.009, -1.013, -1.001, -1.003, -1.01, 0.969, -1.005, -1.001, -1.025, -1.012, -1.011, -1.004, -1.005, -1.002, -1.018, -1.007, -1.001, -1.004, -1.01, -1.002, -1.031, -1.003, -1.01, -1.004, -1.006, -1.0, -1.003, -1.003, -1.002, -1.002, 0.829, -1.005, -1.006, -1.001, -1.003, -1.02, -1.004, -0.537, -1.007, -1.006, -1.005, -1.002], "policy_red_0_v4_reward": [0.946, 0.8089999999999999, -0.504, 0.534, -1.012, 0.8099999999999999, 0.786, 1.2850000000000001, -1.001, -0.03100000000000002], "policy_red_0_v1_reward": [-1.002, -1.004, -1.001, 0.816, -1.02, -1.001, -1.002], "policy_red_0_v2_reward": [-1.001, -1.017, -1.008, -1.008, -1.016, -1.022, -1.001, 0.866, -1.002], "policy_red_0_v3_reward": [-1.003, -1.007, -1.011, -1.0179999999999998, -0.504, 0.923, -1.004, -1.011, -1.01]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031908966279638, "mean_inference_ms": 1.5023947098778594, "mean_action_processing_ms": 0.062499985151577134, "mean_env_wait_ms": 0.10617306638878825, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01848781108856201, "StateBufferConnector_ms": 0.001473546028137207, "ViewRequirementAgentConnector_ms": 0.030823588371276855}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.24116620042643, "num_env_steps_trained_throughput_per_sec": 101.24116620042643, "timesteps_total": 296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 39679.887, "sample_time_ms": 7719.874, "learn_time_ms": 31941.934, "learn_throughput": 125.227, "synch_weights_time_ms": 17.406}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "episodes_total": 4771, "training_iteration": 74, "trial_id": "bb874_00000", "date": "2023-09-28_22-19-03", "timestamp": 1695953943, "time_this_iter_s": 39.512369871139526, "time_total_s": 2927.419322013855, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x3550bbf70>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac4070a0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac4dfb50>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2927.419322013855, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 33.97894736842105, "ram_util_percent": 28.817543859649124}, "win_rate": 0.81, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.299316454678774, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03522259765777562, "policy_loss": -0.02985906659111303, "vf_loss": 0.1253582770974996, "vf_explained_var": 0.1973453301936388, "kl": 0.016970448764582806, "entropy": 0.9915640453497568, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 71520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "sampler_results": {"episode_reward_max": 0.44700000000000006, "episode_reward_min": -0.873, "episode_reward_mean": -0.15374999999999997, "episode_len_mean": 61.44, "episode_media": {}, "episodes_this_iter": 67, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.0539999999999998, "red_0_v3": -1.049, "red_0_v5": -1.011, "red_0_v4": -1.018, "red_0_v1": -1.02, "red_0_v2": -1.016}, "policy_reward_max": {"blue_0": 0.829, "red_0": 0.976, "red_0_v3": 1.447, "red_0_v5": 0.973, "red_0_v4": 1.2850000000000001, "red_0_v1": 0.873, "red_0_v2": 0.956}, "policy_reward_mean": {"blue_0": -0.944933333333333, "red_0": 0.47947, "red_0_v3": -0.3687272727272726, "red_0_v5": -0.5356666666666666, "red_0_v4": 0.03400000000000005, "red_0_v1": -0.8363636363636363, "red_0_v2": -0.16933333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.07099999999999984, -0.06700000000000006, -0.07799999999999996, -0.1269999999999999, -0.2470000000000001, -0.052000000000000046, -0.21399999999999997, -0.08899999999999997, -0.17800000000000005, -0.128, -0.2769999999999999, -0.3769999999999999, 0.28, -0.039000000000000035, -0.02499999999999991, -0.10499999999999987, -0.04999999999999993, -0.4109999999999999, -0.11899999999999988, -0.44200000000000006, -0.10999999999999988, -0.19399999999999995, -0.03200000000000003, -0.1429999999999999, -0.129, -0.19799999999999995, -0.07199999999999995, -0.041000000000000036, -0.06499999999999995, -0.03700000000000003, -0.131, -0.10099999999999987, -0.18000000000000013, 0.44700000000000006, -0.1349999999999999, -0.05399999999999994, -0.12499999999999989, -0.08799999999999997, -0.631, -0.03799999999999992, -0.4119999999999999, -0.372, -0.3400000000000001, -0.10599999999999987, -0.08399999999999974, -0.16300000000000003, -0.04400000000000004, -0.128, -0.06999999999999995, -0.545, 0.20099999999999996, -0.12199999999999989, -0.24500000000000022, -0.10699999999999998, -0.05399999999999994, -0.17700000000000005, -0.14600000000000002, -0.028000000000000025, -0.05800000000000005, 0.11499999999999988, -0.21800000000000008, -0.21199999999999997, -0.137, -0.2569999999999999, -0.04500000000000004, -0.873, -0.17100000000000004, -0.10099999999999987, -0.03599999999999992, -0.03700000000000003, -0.16900000000000004, -0.20799999999999974, -0.2250000000000001, -0.04399999999999993, -0.3599999999999999, -0.04800000000000004, -0.050000000000000044, -0.699, -0.027999999999999914, 0.41900000000000004, -0.2719999999999999, -0.34299999999999997, -0.07399999999999984, -0.03600000000000003, -0.11699999999999999, -0.05599999999999994, -0.688, -0.09699999999999998, -0.030000000000000027, -0.8370000000000001, -0.027999999999999914, -0.4139999999999999, -0.05800000000000005, -0.038999999999999924, -0.06799999999999995, -0.277, -0.21499999999999997, -0.07099999999999995, -0.17099999999999993, -0.2270000000000001], "episode_lengths": [25, 21, 25, 38, 240, 16, 71, 27, 55, 38, 82, 116, 71, 16, 8, 34, 15, 124, 38, 278, 33, 59, 10, 44, 39, 62, 21, 13, 20, 15, 39, 30, 300, 17, 42, 17, 36, 28, 188, 11, 129, 116, 100, 33, 26, 45, 14, 41, 21, 168, 94, 39, 204, 35, 17, 53, 47, 9, 20, 94, 60, 63, 39, 80, 14, 275, 53, 30, 11, 13, 54, 64, 67, 13, 105, 14, 16, 214, 9, 23, 89, 108, 23, 12, 35, 17, 203, 34, 9, 267, 9, 113, 16, 10, 21, 75, 70, 22, 54, 73], "policy_blue_0_reward": [-1.003, -1.003, -1.002, -1.002, 0.829, -1.005, -1.006, -1.001, -1.003, -1.02, -1.004, -0.537, -1.007, -1.006, -1.005, -1.002, -1.005, -1.003, -1.031, -1.004, -1.01, -1.004, -1.0039999999999998, -1.009, -1.025, -0.508, -1.003, -1.003, -1.011, -1.002, -1.004, -1.033, -1.008, -1.003, -1.0099999999999998, -1.001, -1.015, -1.004, -1.003, -1.004, -1.025, -1.001, -1.004, -1.004, -1.0039999999999998], "policy_red_0_v3_reward": [0.923, -1.004, -1.011, -1.01, 1.447, -1.035, -0.5960000000000001, -0.546, 0.834, -1.049, -1.009], "policy_red_0_v5_reward": [-1.011, 0.7769999999999999, -1.001, -1.0, -1.007, -1.002, 0.973, 0.355, -1.0, -0.501, -1.003, -1.008], "policy_red_0_v4_reward": [0.786, 1.2850000000000001, -1.001, -0.03100000000000002, -1.004, 0.857, -1.001, -1.0, 0.97, -1.018, 0.786, 0.7789999999999999], "policy_red_0_v1_reward": [-1.02, -1.001, -1.002, -1.01, 0.873, -1.005, -1.005, -1.008, -1.019, -1.0, -1.003], "policy_red_0_v2_reward": [-1.001, 0.866, -1.002, -1.002, 0.956, 0.953, -1.016, -1.005, 0.727]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23026317755705936, "mean_inference_ms": 1.5026576132153255, "mean_action_processing_ms": 0.06249471247817903, "mean_env_wait_ms": 0.10616312594019138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0186159610748291, "StateBufferConnector_ms": 0.0014685392379760742, "ViewRequirementAgentConnector_ms": 0.03076159954071045}}, "episode_reward_max": 0.44700000000000006, "episode_reward_min": -0.873, "episode_reward_mean": -0.15374999999999997, "episode_len_mean": 61.44, "episodes_this_iter": 67, "policy_reward_min": {"blue_0": -1.033, "red_0": -1.0539999999999998, "red_0_v3": -1.049, "red_0_v5": -1.011, "red_0_v4": -1.018, "red_0_v1": -1.02, "red_0_v2": -1.016}, "policy_reward_max": {"blue_0": 0.829, "red_0": 0.976, "red_0_v3": 1.447, "red_0_v5": 0.973, "red_0_v4": 1.2850000000000001, "red_0_v1": 0.873, "red_0_v2": 0.956}, "policy_reward_mean": {"blue_0": -0.944933333333333, "red_0": 0.47947, "red_0_v3": -0.3687272727272726, "red_0_v5": -0.5356666666666666, "red_0_v4": 0.03400000000000005, "red_0_v1": -0.8363636363636363, "red_0_v2": -0.16933333333333334}, "hist_stats": {"episode_reward": [-0.07099999999999984, -0.06700000000000006, -0.07799999999999996, -0.1269999999999999, -0.2470000000000001, -0.052000000000000046, -0.21399999999999997, -0.08899999999999997, -0.17800000000000005, -0.128, -0.2769999999999999, -0.3769999999999999, 0.28, -0.039000000000000035, -0.02499999999999991, -0.10499999999999987, -0.04999999999999993, -0.4109999999999999, -0.11899999999999988, -0.44200000000000006, -0.10999999999999988, -0.19399999999999995, -0.03200000000000003, -0.1429999999999999, -0.129, -0.19799999999999995, -0.07199999999999995, -0.041000000000000036, -0.06499999999999995, -0.03700000000000003, -0.131, -0.10099999999999987, -0.18000000000000013, 0.44700000000000006, -0.1349999999999999, -0.05399999999999994, -0.12499999999999989, -0.08799999999999997, -0.631, -0.03799999999999992, -0.4119999999999999, -0.372, -0.3400000000000001, -0.10599999999999987, -0.08399999999999974, -0.16300000000000003, -0.04400000000000004, -0.128, -0.06999999999999995, -0.545, 0.20099999999999996, -0.12199999999999989, -0.24500000000000022, -0.10699999999999998, -0.05399999999999994, -0.17700000000000005, -0.14600000000000002, -0.028000000000000025, -0.05800000000000005, 0.11499999999999988, -0.21800000000000008, -0.21199999999999997, -0.137, -0.2569999999999999, -0.04500000000000004, -0.873, -0.17100000000000004, -0.10099999999999987, -0.03599999999999992, -0.03700000000000003, -0.16900000000000004, -0.20799999999999974, -0.2250000000000001, -0.04399999999999993, -0.3599999999999999, -0.04800000000000004, -0.050000000000000044, -0.699, -0.027999999999999914, 0.41900000000000004, -0.2719999999999999, -0.34299999999999997, -0.07399999999999984, -0.03600000000000003, -0.11699999999999999, -0.05599999999999994, -0.688, -0.09699999999999998, -0.030000000000000027, -0.8370000000000001, -0.027999999999999914, -0.4139999999999999, -0.05800000000000005, -0.038999999999999924, -0.06799999999999995, -0.277, -0.21499999999999997, -0.07099999999999995, -0.17099999999999993, -0.2270000000000001], "episode_lengths": [25, 21, 25, 38, 240, 16, 71, 27, 55, 38, 82, 116, 71, 16, 8, 34, 15, 124, 38, 278, 33, 59, 10, 44, 39, 62, 21, 13, 20, 15, 39, 30, 300, 17, 42, 17, 36, 28, 188, 11, 129, 116, 100, 33, 26, 45, 14, 41, 21, 168, 94, 39, 204, 35, 17, 53, 47, 9, 20, 94, 60, 63, 39, 80, 14, 275, 53, 30, 11, 13, 54, 64, 67, 13, 105, 14, 16, 214, 9, 23, 89, 108, 23, 12, 35, 17, 203, 34, 9, 267, 9, 113, 16, 10, 21, 75, 70, 22, 54, 73], "policy_blue_0_reward": [-1.003, -1.003, -1.002, -1.002, 0.829, -1.005, -1.006, -1.001, -1.003, -1.02, -1.004, -0.537, -1.007, -1.006, -1.005, -1.002, -1.005, -1.003, -1.031, -1.004, -1.01, -1.004, -1.0039999999999998, -1.009, -1.025, -0.508, -1.003, -1.003, -1.011, -1.002, -1.004, -1.033, -1.008, -1.003, -1.0099999999999998, -1.001, -1.015, -1.004, -1.003, -1.004, -1.025, -1.001, -1.004, -1.004, -1.0039999999999998], "policy_red_0_v3_reward": [0.923, -1.004, -1.011, -1.01, 1.447, -1.035, -0.5960000000000001, -0.546, 0.834, -1.049, -1.009], "policy_red_0_v5_reward": [-1.011, 0.7769999999999999, -1.001, -1.0, -1.007, -1.002, 0.973, 0.355, -1.0, -0.501, -1.003, -1.008], "policy_red_0_v4_reward": [0.786, 1.2850000000000001, -1.001, -0.03100000000000002, -1.004, 0.857, -1.001, -1.0, 0.97, -1.018, 0.786, 0.7789999999999999], "policy_red_0_v1_reward": [-1.02, -1.001, -1.002, -1.01, 0.873, -1.005, -1.005, -1.008, -1.019, -1.0, -1.003], "policy_red_0_v2_reward": [-1.001, 0.866, -1.002, -1.002, 0.956, 0.953, -1.016, -1.005, 0.727]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23026317755705936, "mean_inference_ms": 1.5026576132153255, "mean_action_processing_ms": 0.06249471247817903, "mean_env_wait_ms": 0.10616312594019138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0186159610748291, "StateBufferConnector_ms": 0.0014685392379760742, "ViewRequirementAgentConnector_ms": 0.03076159954071045}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.57080247716719, "num_env_steps_trained_throughput_per_sec": 101.57080247716719, "timesteps_total": 300000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 600000, "timers": {"training_iteration_time_ms": 39653.709, "sample_time_ms": 7718.92, "learn_time_ms": 31916.646, "learn_throughput": 125.326, "synch_weights_time_ms": 17.465}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 600000, "num_agent_steps_trained": 600000}, "done": false, "episodes_total": 4838, "training_iteration": 75, "trial_id": "bb874_00000", "date": "2023-09-28_22-19-42", "timestamp": 1695953982, "time_this_iter_s": 39.38406205177307, "time_total_s": 2966.803384065628, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x2b4f4bfd0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355922ef0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355920280>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2966.803384065628, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 34.480357142857144, "ram_util_percent": 28.832142857142863}, "win_rate": 0.82, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.240175832125048, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.042891281913762215, "policy_loss": -0.02837037296364239, "vf_loss": 0.13955966745658469, "vf_explained_var": 0.2042924178764224, "kl": 0.012537094376112161, "entropy": 1.0255978772416712, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 72480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "sampler_results": {"episode_reward_max": 0.41900000000000004, "episode_reward_min": -0.8370000000000001, "episode_reward_mean": -0.13335, "episode_len_mean": 57.8, "episode_media": {}, "episodes_this_iter": 72, "policy_reward_min": {"red_0_v2": -1.03, "red_0": -1.0539999999999998, "blue_0": -1.034, "red_0_v1": -1.019, "red_0_v4": -1.025, "red_0_v5": -1.008, "red_0_v3": -1.049}, "policy_reward_max": {"red_0_v2": 0.943, "red_0": 0.978, "blue_0": 0.902, "red_0_v1": 0.84, "red_0_v4": 0.97, "red_0_v5": 0.95, "red_0_v3": 0.9279999999999999}, "policy_reward_mean": {"red_0_v2": -0.5459166666666666, "red_0": 0.48306, "blue_0": -0.8262340425531914, "red_0_v1": -0.7015833333333333, "red_0_v4": -0.2649, "red_0_v5": -0.3456363636363637, "red_0_v3": -0.173375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.2250000000000001, -0.04399999999999993, -0.3599999999999999, -0.04800000000000004, -0.050000000000000044, -0.699, -0.027999999999999914, 0.41900000000000004, -0.2719999999999999, -0.34299999999999997, -0.07399999999999984, -0.03600000000000003, -0.11699999999999999, -0.05599999999999994, -0.688, -0.09699999999999998, -0.030000000000000027, -0.8370000000000001, -0.027999999999999914, -0.4139999999999999, -0.05800000000000005, -0.038999999999999924, -0.06799999999999995, -0.277, -0.21499999999999997, -0.07099999999999995, -0.17099999999999993, -0.2270000000000001, -0.3669999999999999, -0.03699999999999992, -0.16500000000000004, -0.139, -0.22000000000000008, -0.1299999999999999, -0.03799999999999981, -0.07299999999999995, 0.19700000000000006, -0.32899999999999996, -0.04300000000000004, -0.029999999999999916, -0.050000000000000044, -0.3909999999999999, -0.32600000000000007, -0.17500000000000004, 0.30899999999999994, -0.2719999999999999, -0.03699999999999992, -0.09999999999999998, -0.3440000000000001, -0.2619999999999999, -0.21700000000000008, -0.051999999999999935, -0.09599999999999986, -0.19799999999999995, -0.12399999999999978, -0.026000000000000023, -0.09499999999999997, -0.7230000000000001, -0.08499999999999996, -0.10299999999999987, 0.32299999999999995, -0.10099999999999998, -0.062000000000000055, -0.09199999999999997, -0.126, -0.08100000000000006, -0.05999999999999994, -0.16400000000000003, -0.02300000000000002, -0.1220000000000001, -0.21600000000000008, -0.05400000000000005, -0.1390000000000001, 0.28, -0.134, -0.040999999999999814, -0.06499999999999995, -0.027000000000000024, -0.16100000000000003, -0.21400000000000008, -0.049000000000000044, -0.09799999999999998, -0.10199999999999998, -0.15999999999999992, -0.21700000000000008, -0.11199999999999999, -0.05800000000000005, -0.16500000000000004, -0.09299999999999997, -0.09899999999999987, -0.12199999999999989, -0.07999999999999985, -0.07499999999999996, -0.07600000000000007, -0.05700000000000005, -0.051999999999999935, -0.33699999999999997, -0.07200000000000006, -0.04600000000000004, -0.09199999999999997], "episode_lengths": [67, 13, 105, 14, 16, 214, 9, 23, 89, 108, 23, 12, 35, 17, 203, 34, 9, 267, 9, 113, 16, 10, 21, 75, 70, 22, 54, 73, 110, 12, 51, 43, 214, 39, 10, 24, 95, 96, 15, 9, 19, 118, 108, 53, 60, 85, 12, 31, 98, 83, 67, 19, 29, 63, 34, 8, 32, 219, 23, 32, 55, 31, 20, 32, 37, 300, 19, 48, 10, 300, 56, 19, 300, 66, 38, 13, 20, 9, 49, 65, 15, 32, 32, 49, 67, 32, 18, 53, 29, 30, 39, 23, 25, 23, 17, 15, 92, 24, 18, 28], "policy_red_0_v2_reward": [-1.016, -1.005, 0.727, -1.0079999999999998, -1.003, -1.0199999999999998, -1.0239999999999998, 0.901, -1.014, 0.943, -1.002, -1.03], "policy_blue_0_reward": [-1.001, -1.015, -1.004, -1.003, -1.004, -1.025, -1.001, -1.004, -1.004, -1.0039999999999998, -1.009, -0.53, -1.007, -1.015, -1.016, -1.007, -0.508, -1.013, -1.0, 0.902, -1.02, -1.008, 0.7929999999999999, -1.003, -1.034, -1.004, -1.004, -0.511, -1.005, -1.005, -0.03900000000000003, -1.005, -1.001, -1.002, -0.512, -1.0019999999999998, -1.001, -1.0, 0.844, -1.003, -1.004, -1.01, -1.012, -1.004, -1.003, -1.0079999999999998, -1.002], "policy_red_0_v1_reward": [-1.019, -1.0, -1.003, -1.008, -1.001, -1.005, -1.005, -1.001, 0.7889999999999999, -1.002, 0.84, -1.004], "policy_red_0_v4_reward": [-1.0, 0.97, -1.018, 0.786, 0.7789999999999999, 0.869, -1.0, -1.009, -1.001, -1.025], "policy_red_0_v5_reward": [0.355, -1.0, -0.501, -1.003, -1.008, -1.0, -0.504, 0.95, 0.939, -0.024000000000000014, -1.006], "policy_red_0_v3_reward": [-1.049, -1.009, -1.001, 0.881, -0.037000000000000026, 0.903, 0.9279999999999999, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23013663254310487, "mean_inference_ms": 1.5022535992688404, "mean_action_processing_ms": 0.06248046353793102, "mean_env_wait_ms": 0.10613089621246054, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01848006248474121, "StateBufferConnector_ms": 0.0014761686325073242, "ViewRequirementAgentConnector_ms": 0.030674099922180176}}, "episode_reward_max": 0.41900000000000004, "episode_reward_min": -0.8370000000000001, "episode_reward_mean": -0.13335, "episode_len_mean": 57.8, "episodes_this_iter": 72, "policy_reward_min": {"red_0_v2": -1.03, "red_0": -1.0539999999999998, "blue_0": -1.034, "red_0_v1": -1.019, "red_0_v4": -1.025, "red_0_v5": -1.008, "red_0_v3": -1.049}, "policy_reward_max": {"red_0_v2": 0.943, "red_0": 0.978, "blue_0": 0.902, "red_0_v1": 0.84, "red_0_v4": 0.97, "red_0_v5": 0.95, "red_0_v3": 0.9279999999999999}, "policy_reward_mean": {"red_0_v2": -0.5459166666666666, "red_0": 0.48306, "blue_0": -0.8262340425531914, "red_0_v1": -0.7015833333333333, "red_0_v4": -0.2649, "red_0_v5": -0.3456363636363637, "red_0_v3": -0.173375}, "hist_stats": {"episode_reward": [-0.2250000000000001, -0.04399999999999993, -0.3599999999999999, -0.04800000000000004, -0.050000000000000044, -0.699, -0.027999999999999914, 0.41900000000000004, -0.2719999999999999, -0.34299999999999997, -0.07399999999999984, -0.03600000000000003, -0.11699999999999999, -0.05599999999999994, -0.688, -0.09699999999999998, -0.030000000000000027, -0.8370000000000001, -0.027999999999999914, -0.4139999999999999, -0.05800000000000005, -0.038999999999999924, -0.06799999999999995, -0.277, -0.21499999999999997, -0.07099999999999995, -0.17099999999999993, -0.2270000000000001, -0.3669999999999999, -0.03699999999999992, -0.16500000000000004, -0.139, -0.22000000000000008, -0.1299999999999999, -0.03799999999999981, -0.07299999999999995, 0.19700000000000006, -0.32899999999999996, -0.04300000000000004, -0.029999999999999916, -0.050000000000000044, -0.3909999999999999, -0.32600000000000007, -0.17500000000000004, 0.30899999999999994, -0.2719999999999999, -0.03699999999999992, -0.09999999999999998, -0.3440000000000001, -0.2619999999999999, -0.21700000000000008, -0.051999999999999935, -0.09599999999999986, -0.19799999999999995, -0.12399999999999978, -0.026000000000000023, -0.09499999999999997, -0.7230000000000001, -0.08499999999999996, -0.10299999999999987, 0.32299999999999995, -0.10099999999999998, -0.062000000000000055, -0.09199999999999997, -0.126, -0.08100000000000006, -0.05999999999999994, -0.16400000000000003, -0.02300000000000002, -0.1220000000000001, -0.21600000000000008, -0.05400000000000005, -0.1390000000000001, 0.28, -0.134, -0.040999999999999814, -0.06499999999999995, -0.027000000000000024, -0.16100000000000003, -0.21400000000000008, -0.049000000000000044, -0.09799999999999998, -0.10199999999999998, -0.15999999999999992, -0.21700000000000008, -0.11199999999999999, -0.05800000000000005, -0.16500000000000004, -0.09299999999999997, -0.09899999999999987, -0.12199999999999989, -0.07999999999999985, -0.07499999999999996, -0.07600000000000007, -0.05700000000000005, -0.051999999999999935, -0.33699999999999997, -0.07200000000000006, -0.04600000000000004, -0.09199999999999997], "episode_lengths": [67, 13, 105, 14, 16, 214, 9, 23, 89, 108, 23, 12, 35, 17, 203, 34, 9, 267, 9, 113, 16, 10, 21, 75, 70, 22, 54, 73, 110, 12, 51, 43, 214, 39, 10, 24, 95, 96, 15, 9, 19, 118, 108, 53, 60, 85, 12, 31, 98, 83, 67, 19, 29, 63, 34, 8, 32, 219, 23, 32, 55, 31, 20, 32, 37, 300, 19, 48, 10, 300, 56, 19, 300, 66, 38, 13, 20, 9, 49, 65, 15, 32, 32, 49, 67, 32, 18, 53, 29, 30, 39, 23, 25, 23, 17, 15, 92, 24, 18, 28], "policy_red_0_v2_reward": [-1.016, -1.005, 0.727, -1.0079999999999998, -1.003, -1.0199999999999998, -1.0239999999999998, 0.901, -1.014, 0.943, -1.002, -1.03], "policy_blue_0_reward": [-1.001, -1.015, -1.004, -1.003, -1.004, -1.025, -1.001, -1.004, -1.004, -1.0039999999999998, -1.009, -0.53, -1.007, -1.015, -1.016, -1.007, -0.508, -1.013, -1.0, 0.902, -1.02, -1.008, 0.7929999999999999, -1.003, -1.034, -1.004, -1.004, -0.511, -1.005, -1.005, -0.03900000000000003, -1.005, -1.001, -1.002, -0.512, -1.0019999999999998, -1.001, -1.0, 0.844, -1.003, -1.004, -1.01, -1.012, -1.004, -1.003, -1.0079999999999998, -1.002], "policy_red_0_v1_reward": [-1.019, -1.0, -1.003, -1.008, -1.001, -1.005, -1.005, -1.001, 0.7889999999999999, -1.002, 0.84, -1.004], "policy_red_0_v4_reward": [-1.0, 0.97, -1.018, 0.786, 0.7789999999999999, 0.869, -1.0, -1.009, -1.001, -1.025], "policy_red_0_v5_reward": [0.355, -1.0, -0.501, -1.003, -1.008, -1.0, -0.504, 0.95, 0.939, -0.024000000000000014, -1.006], "policy_red_0_v3_reward": [-1.049, -1.009, -1.001, 0.881, -0.037000000000000026, 0.903, 0.9279999999999999, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23013663254310487, "mean_inference_ms": 1.5022535992688404, "mean_action_processing_ms": 0.06248046353793102, "mean_env_wait_ms": 0.10613089621246054, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01848006248474121, "StateBufferConnector_ms": 0.0014761686325073242, "ViewRequirementAgentConnector_ms": 0.030674099922180176}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.88036027119553, "num_env_steps_trained_throughput_per_sec": 100.88036027119553, "timesteps_total": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 39618.399, "sample_time_ms": 7700.909, "learn_time_ms": 31899.664, "learn_throughput": 125.393, "synch_weights_time_ms": 17.177}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "episodes_total": 4910, "training_iteration": 76, "trial_id": "bb874_00000", "date": "2023-09-28_22-20-22", "timestamp": 1695954022, "time_this_iter_s": 39.6536660194397, "time_total_s": 3006.4570500850677, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x356680f40>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac70ee60>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x2ac70dcf0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3006.4570500850677, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 33.591071428571425, "ram_util_percent": 28.914285714285715}, "win_rate": 0.82, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.425761853903532, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.052399075168311056, "policy_loss": -0.023789230358670466, "vf_loss": 0.14974211160636816, "vf_explained_var": 0.2577120928714673, "kl": 0.011427131918953155, "entropy": 0.9681764174252748, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 73440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000}, "sampler_results": {"episode_reward_max": 0.46699999999999997, "episode_reward_min": -0.936, "episode_reward_mean": -0.14031000000000002, "episode_len_mean": 59.76, "episode_media": {}, "episodes_this_iter": 63, "policy_reward_min": {"blue_0": -1.038, "red_0": -1.031, "red_0_v3": -1.053, "red_0_v1": -1.007, "red_0_v5": -1.014, "red_0_v4": -1.025, "red_0_v2": -1.03}, "policy_reward_max": {"blue_0": 0.844, "red_0": 0.989, "red_0_v3": 0.96, "red_0_v1": 0.973, "red_0_v5": 0.904, "red_0_v4": 0.967, "red_0_v2": 1.284}, "policy_reward_mean": {"blue_0": -0.8935531914893617, "red_0": 0.33144000000000007, "red_0_v3": -0.047333333333333324, "red_0_v1": -0.0506, "red_0_v5": -0.17357142857142857, "red_0_v4": -0.015916666666666617, "red_0_v2": -0.18933333333333338}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.09199999999999997, -0.126, -0.08100000000000006, -0.05999999999999994, -0.16400000000000003, -0.02300000000000002, -0.1220000000000001, -0.21600000000000008, -0.05400000000000005, -0.1390000000000001, 0.28, -0.134, -0.040999999999999814, -0.06499999999999995, -0.027000000000000024, -0.16100000000000003, -0.21400000000000008, -0.049000000000000044, -0.09799999999999998, -0.10199999999999998, -0.15999999999999992, -0.21700000000000008, -0.11199999999999999, -0.05800000000000005, -0.16500000000000004, -0.09299999999999997, -0.09899999999999987, -0.12199999999999989, -0.07999999999999985, -0.07499999999999996, -0.07600000000000007, -0.05700000000000005, -0.051999999999999935, -0.33699999999999997, -0.07200000000000006, -0.04600000000000004, -0.09199999999999997, -0.32200000000000006, -0.02200000000000002, -0.19500000000000006, -0.32699999999999996, -0.05799999999999983, -0.10199999999999998, 0.46699999999999997, -0.1499999999999999, -0.09999999999999998, -0.05600000000000005, -0.19600000000000006, -0.936, 0.348, -0.657, -0.03299999999999992, 0.347, -0.3689999999999999, -0.139, -0.07899999999999996, -0.10799999999999976, -0.347, -0.09399999999999997, -0.3640000000000001, -0.08699999999999986, -0.027000000000000024, -0.128, -0.21799999999999997, -0.5469999999999999, -0.06700000000000006, -0.698, -0.07799999999999985, -0.8460000000000001, -0.137, -0.14400000000000002, 0.2669999999999999, -0.08699999999999997, -0.22499999999999987, -0.482, -0.40500000000000014, -0.46399999999999997, -0.041000000000000036, -0.04400000000000004, -0.2270000000000001, -0.06999999999999995, -0.32399999999999984, -0.013000000000000012, -0.07299999999999973, -0.029000000000000026, -0.027000000000000024, -0.1509999999999999, -0.06499999999999995, -0.44499999999999984, -0.07000000000000006, 0.257, -0.2909999999999999, -0.040000000000000036, -0.08099999999999996, -0.18300000000000005, -0.20199999999999996, -0.03400000000000003, -0.05800000000000005, -0.06999999999999995, -0.2839999999999999], "episode_lengths": [32, 37, 300, 19, 48, 10, 300, 56, 19, 300, 66, 38, 13, 20, 9, 49, 65, 15, 32, 32, 49, 67, 32, 18, 53, 29, 30, 39, 23, 25, 23, 17, 15, 92, 24, 18, 28, 94, 10, 57, 96, 18, 32, 11, 43, 32, 16, 55, 291, 44, 213, 10, 47, 118, 45, 24, 34, 104, 32, 108, 26, 9, 40, 67, 162, 24, 193, 25, 250, 43, 44, 70, 27, 70, 144, 118, 147, 11, 15, 73, 21, 97, 7, 23, 9, 11, 46, 20, 136, 24, 71, 88, 12, 25, 57, 58, 11, 18, 23, 85], "policy_blue_0_reward": [-1.005, -0.03900000000000003, -1.005, -1.001, -1.002, -0.512, -1.0019999999999998, -1.001, -1.0, 0.844, -1.003, -1.004, -1.01, -1.012, -1.004, -1.003, -1.0079999999999998, -1.002, -1.008, -1.015, -1.004, -0.503, -1.0099999999999998, -1.002, -1.0059999999999998, -1.016, -1.006, -1.01, -1.003, -1.002, -1.038, -1.008, -1.003, -1.013, 0.549, -1.022, -1.013, -1.0, -1.018, -1.003, -1.009, -1.002, -1.0159999999999998, -1.017, -1.007, -1.013, -1.01], "policy_red_0_v3_reward": [0.881, -0.037000000000000026, 0.903, 0.9279999999999999, -1.003, -1.002, -1.053, 0.96, -1.003], "policy_red_0_v1_reward": [-1.001, 0.7889999999999999, -1.002, 0.84, -1.004, 0.969, -1.007, 0.973, -1.005, 0.942], "policy_red_0_v5_reward": [-0.024000000000000014, -1.006, 0.904, 0.07399999999999995, -0.5, 0.351, -1.014], "policy_red_0_v4_reward": [-1.025, -1.003, 0.819, -1.0, 0.903, 0.947, 0.7739999999999999, -1.002, -1.001, -0.501, 0.967, 0.931], "policy_red_0_v2_reward": [-1.0239999999999998, 0.901, -1.014, 0.943, -1.002, -1.03, -1.019, -0.5, -1.013, -1.006, 0.873, 0.847, 1.284, -1.002, 0.9219999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23023244710091872, "mean_inference_ms": 1.502825464408619, "mean_action_processing_ms": 0.06249771585681771, "mean_env_wait_ms": 0.10617840918769014, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018599987030029297, "StateBufferConnector_ms": 0.0014705657958984375, "ViewRequirementAgentConnector_ms": 0.030770421028137207}}, "episode_reward_max": 0.46699999999999997, "episode_reward_min": -0.936, "episode_reward_mean": -0.14031000000000002, "episode_len_mean": 59.76, "episodes_this_iter": 63, "policy_reward_min": {"blue_0": -1.038, "red_0": -1.031, "red_0_v3": -1.053, "red_0_v1": -1.007, "red_0_v5": -1.014, "red_0_v4": -1.025, "red_0_v2": -1.03}, "policy_reward_max": {"blue_0": 0.844, "red_0": 0.989, "red_0_v3": 0.96, "red_0_v1": 0.973, "red_0_v5": 0.904, "red_0_v4": 0.967, "red_0_v2": 1.284}, "policy_reward_mean": {"blue_0": -0.8935531914893617, "red_0": 0.33144000000000007, "red_0_v3": -0.047333333333333324, "red_0_v1": -0.0506, "red_0_v5": -0.17357142857142857, "red_0_v4": -0.015916666666666617, "red_0_v2": -0.18933333333333338}, "hist_stats": {"episode_reward": [-0.09199999999999997, -0.126, -0.08100000000000006, -0.05999999999999994, -0.16400000000000003, -0.02300000000000002, -0.1220000000000001, -0.21600000000000008, -0.05400000000000005, -0.1390000000000001, 0.28, -0.134, -0.040999999999999814, -0.06499999999999995, -0.027000000000000024, -0.16100000000000003, -0.21400000000000008, -0.049000000000000044, -0.09799999999999998, -0.10199999999999998, -0.15999999999999992, -0.21700000000000008, -0.11199999999999999, -0.05800000000000005, -0.16500000000000004, -0.09299999999999997, -0.09899999999999987, -0.12199999999999989, -0.07999999999999985, -0.07499999999999996, -0.07600000000000007, -0.05700000000000005, -0.051999999999999935, -0.33699999999999997, -0.07200000000000006, -0.04600000000000004, -0.09199999999999997, -0.32200000000000006, -0.02200000000000002, -0.19500000000000006, -0.32699999999999996, -0.05799999999999983, -0.10199999999999998, 0.46699999999999997, -0.1499999999999999, -0.09999999999999998, -0.05600000000000005, -0.19600000000000006, -0.936, 0.348, -0.657, -0.03299999999999992, 0.347, -0.3689999999999999, -0.139, -0.07899999999999996, -0.10799999999999976, -0.347, -0.09399999999999997, -0.3640000000000001, -0.08699999999999986, -0.027000000000000024, -0.128, -0.21799999999999997, -0.5469999999999999, -0.06700000000000006, -0.698, -0.07799999999999985, -0.8460000000000001, -0.137, -0.14400000000000002, 0.2669999999999999, -0.08699999999999997, -0.22499999999999987, -0.482, -0.40500000000000014, -0.46399999999999997, -0.041000000000000036, -0.04400000000000004, -0.2270000000000001, -0.06999999999999995, -0.32399999999999984, -0.013000000000000012, -0.07299999999999973, -0.029000000000000026, -0.027000000000000024, -0.1509999999999999, -0.06499999999999995, -0.44499999999999984, -0.07000000000000006, 0.257, -0.2909999999999999, -0.040000000000000036, -0.08099999999999996, -0.18300000000000005, -0.20199999999999996, -0.03400000000000003, -0.05800000000000005, -0.06999999999999995, -0.2839999999999999], "episode_lengths": [32, 37, 300, 19, 48, 10, 300, 56, 19, 300, 66, 38, 13, 20, 9, 49, 65, 15, 32, 32, 49, 67, 32, 18, 53, 29, 30, 39, 23, 25, 23, 17, 15, 92, 24, 18, 28, 94, 10, 57, 96, 18, 32, 11, 43, 32, 16, 55, 291, 44, 213, 10, 47, 118, 45, 24, 34, 104, 32, 108, 26, 9, 40, 67, 162, 24, 193, 25, 250, 43, 44, 70, 27, 70, 144, 118, 147, 11, 15, 73, 21, 97, 7, 23, 9, 11, 46, 20, 136, 24, 71, 88, 12, 25, 57, 58, 11, 18, 23, 85], "policy_blue_0_reward": [-1.005, -0.03900000000000003, -1.005, -1.001, -1.002, -0.512, -1.0019999999999998, -1.001, -1.0, 0.844, -1.003, -1.004, -1.01, -1.012, -1.004, -1.003, -1.0079999999999998, -1.002, -1.008, -1.015, -1.004, -0.503, -1.0099999999999998, -1.002, -1.0059999999999998, -1.016, -1.006, -1.01, -1.003, -1.002, -1.038, -1.008, -1.003, -1.013, 0.549, -1.022, -1.013, -1.0, -1.018, -1.003, -1.009, -1.002, -1.0159999999999998, -1.017, -1.007, -1.013, -1.01], "policy_red_0_v3_reward": [0.881, -0.037000000000000026, 0.903, 0.9279999999999999, -1.003, -1.002, -1.053, 0.96, -1.003], "policy_red_0_v1_reward": [-1.001, 0.7889999999999999, -1.002, 0.84, -1.004, 0.969, -1.007, 0.973, -1.005, 0.942], "policy_red_0_v5_reward": [-0.024000000000000014, -1.006, 0.904, 0.07399999999999995, -0.5, 0.351, -1.014], "policy_red_0_v4_reward": [-1.025, -1.003, 0.819, -1.0, 0.903, 0.947, 0.7739999999999999, -1.002, -1.001, -0.501, 0.967, 0.931], "policy_red_0_v2_reward": [-1.0239999999999998, 0.901, -1.014, 0.943, -1.002, -1.03, -1.019, -0.5, -1.013, -1.006, 0.873, 0.847, 1.284, -1.002, 0.9219999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23023244710091872, "mean_inference_ms": 1.502825464408619, "mean_action_processing_ms": 0.06249771585681771, "mean_env_wait_ms": 0.10617840918769014, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018599987030029297, "StateBufferConnector_ms": 0.0014705657958984375, "ViewRequirementAgentConnector_ms": 0.030770421028137207}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.41215683205968, "num_env_steps_trained_throughput_per_sec": 101.41215683205968, "timesteps_total": 308000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 616000, "timers": {"training_iteration_time_ms": 39601.896, "sample_time_ms": 7698.237, "learn_time_ms": 31885.884, "learn_throughput": 125.447, "synch_weights_time_ms": 17.128}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 616000, "num_agent_steps_trained": 616000}, "done": false, "episodes_total": 4973, "training_iteration": 77, "trial_id": "bb874_00000", "date": "2023-09-28_22-21-02", "timestamp": 1695954062, "time_this_iter_s": 39.445605993270874, "time_total_s": 3045.9026560783386, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355d825c0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2ac407520>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355920160>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3045.9026560783386, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 34.769642857142856, "ram_util_percent": 29.03928571428571}, "win_rate": 0.74, "league_size": 7}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2769481600572665, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.017981880999226027, "policy_loss": -0.0222583187816781, "vf_loss": 0.07755935014380763, "vf_explained_var": 0.4026528755823771, "kl": 0.012329945598027685, "entropy": 1.005463653927048, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 74400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "sampler_results": {"episode_reward_max": 0.42399999999999993, "episode_reward_min": -0.7829999999999999, "episode_reward_mean": -0.10403999999999998, "episode_len_mean": 50.24, "episode_media": {}, "episodes_this_iter": 75, "policy_reward_min": {"blue_0": -1.03, "red_0": -1.003, "red_0_v1": -1.012, "red_0_v4": -1.003, "red_0_v2": -1.045, "red_0_v3": -1.017, "red_0_v5": -1.011}, "policy_reward_max": {"blue_0": -0.028000000000000018, "red_0": 0.989, "red_0_v1": 0.942, "red_0_v4": 0.967, "red_0_v2": 0.9219999999999999, "red_0_v3": 1.129, "red_0_v5": 0.952}, "policy_reward_mean": {"blue_0": -0.9508846153846152, "red_0": 0.6287, "red_0_v1": -0.7324444444444445, "red_0_v4": -0.21754545454545457, "red_0_v2": -0.7946666666666666, "red_0_v3": -0.3541538461538461, "red_0_v5": -0.5145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.40500000000000014, -0.46399999999999997, -0.041000000000000036, -0.04400000000000004, -0.2270000000000001, -0.06999999999999995, -0.32399999999999984, -0.013000000000000012, -0.07299999999999973, -0.029000000000000026, -0.027000000000000024, -0.1509999999999999, -0.06499999999999995, -0.44499999999999984, -0.07000000000000006, 0.257, -0.2909999999999999, -0.040000000000000036, -0.08099999999999996, -0.18300000000000005, -0.20199999999999996, -0.03400000000000003, -0.05800000000000005, -0.06999999999999995, -0.2839999999999999, -0.1419999999999999, -0.03799999999999992, -0.08000000000000007, -0.07099999999999995, -0.07799999999999985, -0.09599999999999986, -0.08199999999999996, -0.041000000000000036, -0.03400000000000003, -0.11299999999999988, -0.03299999999999992, -0.1589999999999998, -0.31199999999999994, -0.23399999999999999, -0.027999999999999914, -0.051000000000000045, -0.05799999999999983, -0.1389999999999999, -0.11799999999999988, 0.41700000000000004, -0.22199999999999998, -0.08599999999999985, -0.11799999999999988, -0.09800000000000007, -0.09699999999999986, -0.10399999999999987, -0.22899999999999987, -0.048000000000000036, -0.11199999999999999, -0.20500000000000007, -0.1469999999999999, -0.026999999999999913, -0.34899999999999975, -0.09399999999999997, -0.03299999999999992, -0.041999999999999926, -0.02400000000000002, -0.12099999999999989, -0.08899999999999975, 0.401, -0.02100000000000002, -0.05600000000000005, -0.062000000000000055, 0.28200000000000003, 0.127, -0.06800000000000006, -0.08899999999999997, -0.3609999999999999, -0.09199999999999997, -0.040999999999999925, -0.15799999999999992, -0.5080000000000002, -0.07699999999999996, -0.2380000000000002, -0.17299999999999993, -0.039999999999999813, -0.050000000000000044, -0.11599999999999999, -0.031000000000000028, -0.16300000000000012, 0.42399999999999993, -0.04500000000000004, -0.050000000000000044, -0.08499999999999996, -0.029000000000000026, -0.24499999999999988, -0.15000000000000002, -0.052999999999999936, -0.2679999999999999, -0.05899999999999994, -0.06500000000000006, -0.1469999999999999, -0.7829999999999999, -0.06699999999999984, -0.07899999999999985], "episode_lengths": [118, 147, 11, 15, 73, 21, 97, 7, 23, 9, 11, 46, 20, 136, 24, 71, 88, 12, 25, 57, 58, 11, 18, 23, 85, 45, 11, 24, 23, 22, 29, 26, 13, 10, 34, 10, 47, 89, 74, 9, 16, 18, 44, 33, 26, 68, 22, 37, 300, 28, 33, 74, 300, 34, 63, 48, 8, 103, 32, 10, 13, 8, 38, 27, 32, 7, 18, 18, 58, 117, 22, 24, 118, 32, 10, 47, 276, 25, 65, 54, 12, 18, 32, 9, 300, 24, 15, 16, 25, 12, 78, 42, 16, 83, 18, 21, 48, 232, 19, 26], "policy_blue_0_reward": [-1.022, -1.013, -1.0, -1.018, -1.003, -1.009, -1.002, -1.0159999999999998, -1.017, -1.007, -1.013, -1.01, -1.0019999999999998, -1.001, -1.0039999999999998, -1.008, -1.005, -1.003, -1.02, -1.008, -1.007, -1.003, -1.01, -1.005, -0.04200000000000003, -1.004, -1.009, -1.006, -1.002, -1.003, -1.0219999999999998, -1.002, -1.0, -1.004, -1.0059999999999998, -0.501, -1.002, -0.538, -1.001, -1.007, -1.0039999999999998, -1.003, -0.028000000000000018, -1.003, -1.006, -1.004, -1.004, -1.002, -1.001, -1.03, -1.005, -1.001], "policy_red_0_v1_reward": [-1.005, 0.942, -1.005, -1.001, -1.0039999999999998, -1.012, -1.006, -0.501, -1.0], "policy_red_0_v4_reward": [0.947, 0.7739999999999999, -1.002, -1.001, -0.501, 0.967, 0.931, -1.002, -1.003, -0.503, -1.0], "policy_red_0_v2_reward": [-1.002, 0.9219999999999999, -1.004, -1.002, -1.009, -1.045, -1.005, -1.002, -1.005], "policy_red_0_v3_reward": [0.96, -1.003, -1.003, -1.017, -1.003, 0.897, -1.003, -0.511, 1.129, -1.012, -1.005, 0.971, -1.004], "policy_red_0_v5_reward": [-1.001, 0.952, -0.023000000000000013, -1.002, -1.011, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031033368774662, "mean_inference_ms": 1.5038308611055475, "mean_action_processing_ms": 0.062528983875434, "mean_env_wait_ms": 0.10626385192845902, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01932501792907715, "StateBufferConnector_ms": 0.0015246868133544922, "ViewRequirementAgentConnector_ms": 0.03153097629547119}}, "episode_reward_max": 0.42399999999999993, "episode_reward_min": -0.7829999999999999, "episode_reward_mean": -0.10403999999999998, "episode_len_mean": 50.24, "episodes_this_iter": 75, "policy_reward_min": {"blue_0": -1.03, "red_0": -1.003, "red_0_v1": -1.012, "red_0_v4": -1.003, "red_0_v2": -1.045, "red_0_v3": -1.017, "red_0_v5": -1.011}, "policy_reward_max": {"blue_0": -0.028000000000000018, "red_0": 0.989, "red_0_v1": 0.942, "red_0_v4": 0.967, "red_0_v2": 0.9219999999999999, "red_0_v3": 1.129, "red_0_v5": 0.952}, "policy_reward_mean": {"blue_0": -0.9508846153846152, "red_0": 0.6287, "red_0_v1": -0.7324444444444445, "red_0_v4": -0.21754545454545457, "red_0_v2": -0.7946666666666666, "red_0_v3": -0.3541538461538461, "red_0_v5": -0.5145}, "hist_stats": {"episode_reward": [-0.40500000000000014, -0.46399999999999997, -0.041000000000000036, -0.04400000000000004, -0.2270000000000001, -0.06999999999999995, -0.32399999999999984, -0.013000000000000012, -0.07299999999999973, -0.029000000000000026, -0.027000000000000024, -0.1509999999999999, -0.06499999999999995, -0.44499999999999984, -0.07000000000000006, 0.257, -0.2909999999999999, -0.040000000000000036, -0.08099999999999996, -0.18300000000000005, -0.20199999999999996, -0.03400000000000003, -0.05800000000000005, -0.06999999999999995, -0.2839999999999999, -0.1419999999999999, -0.03799999999999992, -0.08000000000000007, -0.07099999999999995, -0.07799999999999985, -0.09599999999999986, -0.08199999999999996, -0.041000000000000036, -0.03400000000000003, -0.11299999999999988, -0.03299999999999992, -0.1589999999999998, -0.31199999999999994, -0.23399999999999999, -0.027999999999999914, -0.051000000000000045, -0.05799999999999983, -0.1389999999999999, -0.11799999999999988, 0.41700000000000004, -0.22199999999999998, -0.08599999999999985, -0.11799999999999988, -0.09800000000000007, -0.09699999999999986, -0.10399999999999987, -0.22899999999999987, -0.048000000000000036, -0.11199999999999999, -0.20500000000000007, -0.1469999999999999, -0.026999999999999913, -0.34899999999999975, -0.09399999999999997, -0.03299999999999992, -0.041999999999999926, -0.02400000000000002, -0.12099999999999989, -0.08899999999999975, 0.401, -0.02100000000000002, -0.05600000000000005, -0.062000000000000055, 0.28200000000000003, 0.127, -0.06800000000000006, -0.08899999999999997, -0.3609999999999999, -0.09199999999999997, -0.040999999999999925, -0.15799999999999992, -0.5080000000000002, -0.07699999999999996, -0.2380000000000002, -0.17299999999999993, -0.039999999999999813, -0.050000000000000044, -0.11599999999999999, -0.031000000000000028, -0.16300000000000012, 0.42399999999999993, -0.04500000000000004, -0.050000000000000044, -0.08499999999999996, -0.029000000000000026, -0.24499999999999988, -0.15000000000000002, -0.052999999999999936, -0.2679999999999999, -0.05899999999999994, -0.06500000000000006, -0.1469999999999999, -0.7829999999999999, -0.06699999999999984, -0.07899999999999985], "episode_lengths": [118, 147, 11, 15, 73, 21, 97, 7, 23, 9, 11, 46, 20, 136, 24, 71, 88, 12, 25, 57, 58, 11, 18, 23, 85, 45, 11, 24, 23, 22, 29, 26, 13, 10, 34, 10, 47, 89, 74, 9, 16, 18, 44, 33, 26, 68, 22, 37, 300, 28, 33, 74, 300, 34, 63, 48, 8, 103, 32, 10, 13, 8, 38, 27, 32, 7, 18, 18, 58, 117, 22, 24, 118, 32, 10, 47, 276, 25, 65, 54, 12, 18, 32, 9, 300, 24, 15, 16, 25, 12, 78, 42, 16, 83, 18, 21, 48, 232, 19, 26], "policy_blue_0_reward": [-1.022, -1.013, -1.0, -1.018, -1.003, -1.009, -1.002, -1.0159999999999998, -1.017, -1.007, -1.013, -1.01, -1.0019999999999998, -1.001, -1.0039999999999998, -1.008, -1.005, -1.003, -1.02, -1.008, -1.007, -1.003, -1.01, -1.005, -0.04200000000000003, -1.004, -1.009, -1.006, -1.002, -1.003, -1.0219999999999998, -1.002, -1.0, -1.004, -1.0059999999999998, -0.501, -1.002, -0.538, -1.001, -1.007, -1.0039999999999998, -1.003, -0.028000000000000018, -1.003, -1.006, -1.004, -1.004, -1.002, -1.001, -1.03, -1.005, -1.001], "policy_red_0_v1_reward": [-1.005, 0.942, -1.005, -1.001, -1.0039999999999998, -1.012, -1.006, -0.501, -1.0], "policy_red_0_v4_reward": [0.947, 0.7739999999999999, -1.002, -1.001, -0.501, 0.967, 0.931, -1.002, -1.003, -0.503, -1.0], "policy_red_0_v2_reward": [-1.002, 0.9219999999999999, -1.004, -1.002, -1.009, -1.045, -1.005, -1.002, -1.005], "policy_red_0_v3_reward": [0.96, -1.003, -1.003, -1.017, -1.003, 0.897, -1.003, -0.511, 1.129, -1.012, -1.005, 0.971, -1.004], "policy_red_0_v5_reward": [-1.001, 0.952, -0.023000000000000013, -1.002, -1.011, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23031033368774662, "mean_inference_ms": 1.5038308611055475, "mean_action_processing_ms": 0.062528983875434, "mean_env_wait_ms": 0.10626385192845902, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01932501792907715, "StateBufferConnector_ms": 0.0015246868133544922, "ViewRequirementAgentConnector_ms": 0.03153097629547119}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.59612869293343, "num_env_steps_trained_throughput_per_sec": 101.59612869293343, "timesteps_total": 312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 39546.293, "sample_time_ms": 7703.726, "learn_time_ms": 31824.83, "learn_throughput": 125.688, "synch_weights_time_ms": 17.086}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "episodes_total": 5048, "training_iteration": 78, "trial_id": "bb874_00000", "date": "2023-09-28_22-21-41", "timestamp": 1695954101, "time_this_iter_s": 39.37427496910095, "time_total_s": 3085.2769310474396, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x35673bdf0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355f25fc0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355f269e0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3085.2769310474396, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 38.64107142857142, "ram_util_percent": 29.114285714285717}, "win_rate": 0.89, "league_size": 8}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3022191901380817, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.035726829835039095, "policy_loss": -0.022705905653371397, "vf_loss": 0.11352106728591024, "vf_explained_var": 0.30025692818065486, "kl": 0.0132090749788207, "entropy": 0.9696127550676465, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 75360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000}, "sampler_results": {"episode_reward_max": 0.46499999999999997, "episode_reward_min": -0.9680000000000001, "episode_reward_mean": -0.12372, "episode_len_mean": 59.95, "episode_media": {}, "episodes_this_iter": 72, "policy_reward_min": {"red_0_v5": -1.015, "red_0": -1.02, "red_0_v3": -1.005, "red_0_v2": -1.045, "blue_0": -1.041, "red_0_v1": -1.009, "red_0_v6": -1.008, "red_0_v4": -1.018}, "policy_reward_max": {"red_0_v5": 0.969, "red_0": 0.976, "red_0_v3": 0.971, "red_0_v2": 0.6699999999999999, "blue_0": 1.3159999999999998, "red_0_v1": 0.842, "red_0_v6": 0.896, "red_0_v4": 0.921}, "policy_reward_mean": {"red_0_v5": -0.3378181818181818, "red_0": 0.5983999999999999, "red_0_v3": -0.5081666666666667, "red_0_v2": -0.7932499999999999, "blue_0": -0.8881041666666666, "red_0_v1": -0.5904, "red_0_v6": -0.38033333333333336, "red_0_v4": -0.7304285714285713}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.3609999999999999, -0.09199999999999997, -0.040999999999999925, -0.15799999999999992, -0.5080000000000002, -0.07699999999999996, -0.2380000000000002, -0.17299999999999993, -0.039999999999999813, -0.050000000000000044, -0.11599999999999999, -0.031000000000000028, -0.16300000000000012, 0.42399999999999993, -0.04500000000000004, -0.050000000000000044, -0.08499999999999996, -0.029000000000000026, -0.24499999999999988, -0.15000000000000002, -0.052999999999999936, -0.2679999999999999, -0.05899999999999994, -0.06500000000000006, -0.1469999999999999, -0.7829999999999999, -0.06699999999999984, -0.07899999999999985, -0.345, -0.43000000000000005, -0.20800000000000007, -0.050999999999999934, -0.07199999999999984, -0.08299999999999996, -0.20799999999999996, -0.07700000000000005, -0.05600000000000005, -0.07299999999999995, -0.03400000000000003, -0.07299999999999995, -0.3989999999999998, -0.17100000000000004, 0.31999999999999984, -0.06300000000000006, -0.06700000000000006, -0.061000000000000054, -0.026000000000000023, -0.3340000000000001, -0.07499999999999996, -0.15599999999999992, -0.031000000000000028, -0.238, -0.06600000000000004, -0.06299999999999994, -0.19999999999999996, -0.131, -0.3979999999999998, 0.19600000000000017, 0.33899999999999997, 0.30899999999999994, -0.10299999999999998, 0.46499999999999997, -0.08200000000000007, -0.1329999999999999, -0.12, -0.09999999999999987, -0.049000000000000044, -0.244, -0.16300000000000003, -0.838, -0.10599999999999998, -0.3059999999999998, -0.07199999999999995, -0.30499999999999994, -0.04400000000000004, -0.11099999999999988, -0.2630000000000002, -0.11999999999999988, -0.07399999999999995, -0.02499999999999991, -0.07599999999999985, -0.2589999999999998, -0.30599999999999994, -0.9680000000000001, -0.04399999999999993, 0.387, -0.17699999999999994, -0.12399999999999989, -0.03600000000000003, -0.264, -0.06799999999999995, -0.050999999999999934, -0.07800000000000007, -0.3250000000000002, -0.05999999999999994, -0.062000000000000055, -0.15600000000000003, -0.03500000000000003, -0.038000000000000034, -0.06499999999999995], "episode_lengths": [118, 32, 10, 47, 276, 25, 65, 54, 12, 18, 32, 9, 300, 24, 15, 16, 25, 12, 78, 42, 16, 83, 18, 21, 48, 232, 19, 26, 113, 130, 60, 16, 22, 26, 66, 300, 16, 23, 10, 23, 121, 48, 60, 19, 21, 19, 8, 99, 25, 45, 10, 72, 300, 20, 62, 39, 124, 95, 44, 51, 27, 10, 24, 40, 40, 29, 16, 70, 47, 263, 34, 92, 27, 90, 14, 36, 300, 35, 21, 8, 23, 75, 91, 290, 13, 35, 54, 37, 12, 86, 19, 16, 24, 104, 17, 18, 48, 14, 13, 23], "policy_red_0_v5_reward": [-1.002, -1.011, -1.002, -1.003, 0.969, -0.507, -1.015, 0.9259999999999999, 0.952, -0.01900000000000001, -1.004], "policy_red_0_v3_reward": [-1.005, 0.971, -1.004, -1.004, -0.506, -0.501], "policy_red_0_v2_reward": [-1.009, -1.045, -1.005, -1.002, -1.005, -1.004, 0.6699999999999999, -0.058000000000000045, -1.013, -1.011, -1.029, -1.008], "policy_blue_0_reward": [-0.538, -1.001, -1.007, -1.0039999999999998, -1.003, -0.028000000000000018, -1.003, -1.006, -1.004, -1.004, -1.002, -1.001, -1.03, -1.005, -1.001, -1.013, -1.0059999999999998, -1.012, -0.046000000000000034, -1.0, -1.002, -1.0219999999999998, 1.3159999999999998, -1.006, -1.01, -1.002, -1.008, -1.017, -0.5099999999999999, -1.005, -1.004, -1.0179999999999998, -1.016, -1.001, -1.0039999999999998, -1.0139999999999998, -1.041, -1.001, -0.504, -1.006, -1.009, -1.0, -1.012, -1.005, -1.001, -1.007, -1.002, -1.004], "policy_red_0_v1_reward": [-0.501, -1.0, -1.004, 0.842, -1.0, -1.007, 0.776, -1.0, -1.001, -1.009], "policy_red_0_v6_reward": [-1.008, -1.002, 0.841, 0.896, -1.002, -1.007], "policy_red_0_v4_reward": [-1.001, 0.921, -1.004, -1.018, -1.004, -1.001, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23027896375913545, "mean_inference_ms": 1.5025102421379677, "mean_action_processing_ms": 0.06251323065191604, "mean_env_wait_ms": 0.10619296567398019, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021197729640536837, "StateBufferConnector_ms": 0.001490473747253418, "ViewRequirementAgentConnector_ms": 0.03211675749884711}}, "episode_reward_max": 0.46499999999999997, "episode_reward_min": -0.9680000000000001, "episode_reward_mean": -0.12372, "episode_len_mean": 59.95, "episodes_this_iter": 72, "policy_reward_min": {"red_0_v5": -1.015, "red_0": -1.02, "red_0_v3": -1.005, "red_0_v2": -1.045, "blue_0": -1.041, "red_0_v1": -1.009, "red_0_v6": -1.008, "red_0_v4": -1.018}, "policy_reward_max": {"red_0_v5": 0.969, "red_0": 0.976, "red_0_v3": 0.971, "red_0_v2": 0.6699999999999999, "blue_0": 1.3159999999999998, "red_0_v1": 0.842, "red_0_v6": 0.896, "red_0_v4": 0.921}, "policy_reward_mean": {"red_0_v5": -0.3378181818181818, "red_0": 0.5983999999999999, "red_0_v3": -0.5081666666666667, "red_0_v2": -0.7932499999999999, "blue_0": -0.8881041666666666, "red_0_v1": -0.5904, "red_0_v6": -0.38033333333333336, "red_0_v4": -0.7304285714285713}, "hist_stats": {"episode_reward": [-0.3609999999999999, -0.09199999999999997, -0.040999999999999925, -0.15799999999999992, -0.5080000000000002, -0.07699999999999996, -0.2380000000000002, -0.17299999999999993, -0.039999999999999813, -0.050000000000000044, -0.11599999999999999, -0.031000000000000028, -0.16300000000000012, 0.42399999999999993, -0.04500000000000004, -0.050000000000000044, -0.08499999999999996, -0.029000000000000026, -0.24499999999999988, -0.15000000000000002, -0.052999999999999936, -0.2679999999999999, -0.05899999999999994, -0.06500000000000006, -0.1469999999999999, -0.7829999999999999, -0.06699999999999984, -0.07899999999999985, -0.345, -0.43000000000000005, -0.20800000000000007, -0.050999999999999934, -0.07199999999999984, -0.08299999999999996, -0.20799999999999996, -0.07700000000000005, -0.05600000000000005, -0.07299999999999995, -0.03400000000000003, -0.07299999999999995, -0.3989999999999998, -0.17100000000000004, 0.31999999999999984, -0.06300000000000006, -0.06700000000000006, -0.061000000000000054, -0.026000000000000023, -0.3340000000000001, -0.07499999999999996, -0.15599999999999992, -0.031000000000000028, -0.238, -0.06600000000000004, -0.06299999999999994, -0.19999999999999996, -0.131, -0.3979999999999998, 0.19600000000000017, 0.33899999999999997, 0.30899999999999994, -0.10299999999999998, 0.46499999999999997, -0.08200000000000007, -0.1329999999999999, -0.12, -0.09999999999999987, -0.049000000000000044, -0.244, -0.16300000000000003, -0.838, -0.10599999999999998, -0.3059999999999998, -0.07199999999999995, -0.30499999999999994, -0.04400000000000004, -0.11099999999999988, -0.2630000000000002, -0.11999999999999988, -0.07399999999999995, -0.02499999999999991, -0.07599999999999985, -0.2589999999999998, -0.30599999999999994, -0.9680000000000001, -0.04399999999999993, 0.387, -0.17699999999999994, -0.12399999999999989, -0.03600000000000003, -0.264, -0.06799999999999995, -0.050999999999999934, -0.07800000000000007, -0.3250000000000002, -0.05999999999999994, -0.062000000000000055, -0.15600000000000003, -0.03500000000000003, -0.038000000000000034, -0.06499999999999995], "episode_lengths": [118, 32, 10, 47, 276, 25, 65, 54, 12, 18, 32, 9, 300, 24, 15, 16, 25, 12, 78, 42, 16, 83, 18, 21, 48, 232, 19, 26, 113, 130, 60, 16, 22, 26, 66, 300, 16, 23, 10, 23, 121, 48, 60, 19, 21, 19, 8, 99, 25, 45, 10, 72, 300, 20, 62, 39, 124, 95, 44, 51, 27, 10, 24, 40, 40, 29, 16, 70, 47, 263, 34, 92, 27, 90, 14, 36, 300, 35, 21, 8, 23, 75, 91, 290, 13, 35, 54, 37, 12, 86, 19, 16, 24, 104, 17, 18, 48, 14, 13, 23], "policy_red_0_v5_reward": [-1.002, -1.011, -1.002, -1.003, 0.969, -0.507, -1.015, 0.9259999999999999, 0.952, -0.01900000000000001, -1.004], "policy_red_0_v3_reward": [-1.005, 0.971, -1.004, -1.004, -0.506, -0.501], "policy_red_0_v2_reward": [-1.009, -1.045, -1.005, -1.002, -1.005, -1.004, 0.6699999999999999, -0.058000000000000045, -1.013, -1.011, -1.029, -1.008], "policy_blue_0_reward": [-0.538, -1.001, -1.007, -1.0039999999999998, -1.003, -0.028000000000000018, -1.003, -1.006, -1.004, -1.004, -1.002, -1.001, -1.03, -1.005, -1.001, -1.013, -1.0059999999999998, -1.012, -0.046000000000000034, -1.0, -1.002, -1.0219999999999998, 1.3159999999999998, -1.006, -1.01, -1.002, -1.008, -1.017, -0.5099999999999999, -1.005, -1.004, -1.0179999999999998, -1.016, -1.001, -1.0039999999999998, -1.0139999999999998, -1.041, -1.001, -0.504, -1.006, -1.009, -1.0, -1.012, -1.005, -1.001, -1.007, -1.002, -1.004], "policy_red_0_v1_reward": [-0.501, -1.0, -1.004, 0.842, -1.0, -1.007, 0.776, -1.0, -1.001, -1.009], "policy_red_0_v6_reward": [-1.008, -1.002, 0.841, 0.896, -1.002, -1.007], "policy_red_0_v4_reward": [-1.001, 0.921, -1.004, -1.018, -1.004, -1.001, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23027896375913545, "mean_inference_ms": 1.5025102421379677, "mean_action_processing_ms": 0.06251323065191604, "mean_env_wait_ms": 0.10619296567398019, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021197729640536837, "StateBufferConnector_ms": 0.001490473747253418, "ViewRequirementAgentConnector_ms": 0.03211675749884711}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.27566178502609, "num_env_steps_trained_throughput_per_sec": 102.27566178502609, "timesteps_total": 316000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 632000, "timers": {"training_iteration_time_ms": 39443.264, "sample_time_ms": 7671.691, "learn_time_ms": 31753.858, "learn_throughput": 125.969, "synch_weights_time_ms": 17.064}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 632000, "num_agent_steps_trained": 632000}, "done": false, "episodes_total": 5120, "training_iteration": 79, "trial_id": "bb874_00000", "date": "2023-09-28_22-22-20", "timestamp": 1695954140, "time_this_iter_s": 39.11274290084839, "time_total_s": 3124.389673948288, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x3567d0460>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x35617a0e0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x35617af80>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3124.389673948288, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 38.80535714285713, "ram_util_percent": 29.208928571428572}, "win_rate": 0.89, "league_size": 9}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.328552082180977, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.031080619231579475, "policy_loss": -0.029978319057894016, "vf_loss": 0.11781888551389177, "vf_explained_var": 0.18544044494628906, "kl": 0.015345546378198642, "entropy": 0.9196140771731734, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 76320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "sampler_results": {"episode_reward_max": 0.43900000000000006, "episode_reward_min": -0.9680000000000001, "episode_reward_mean": -0.10804, "episode_len_mean": 55.56, "episode_media": {}, "episodes_this_iter": 64, "policy_reward_min": {"blue_0": -1.041, "red_0": -1.057, "red_0_v5": -1.006, "red_0_v1": -1.009, "red_0_v6": -1.065, "red_0_v4": -1.018, "red_0_v2": -1.029, "red_0_v3": -1.01, "red_0_v7": 1.241}, "policy_reward_max": {"blue_0": 0.866, "red_0": 0.983, "red_0_v5": 0.976, "red_0_v1": 0.776, "red_0_v6": 0.896, "red_0_v4": 0.921, "red_0_v2": 0.945, "red_0_v3": 0.876, "red_0_v7": 1.241}, "policy_reward_mean": {"blue_0": -0.9055862068965518, "red_0": 0.5773800000000001, "red_0_v5": 0.18325000000000002, "red_0_v1": -0.647, "red_0_v6": -0.5413333333333333, "red_0_v4": -0.46342857142857125, "red_0_v2": -0.7341428571428571, "red_0_v3": -0.44700000000000006, "red_0_v7": 1.241}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.12, -0.09999999999999987, -0.049000000000000044, -0.244, -0.16300000000000003, -0.838, -0.10599999999999998, -0.3059999999999998, -0.07199999999999995, -0.30499999999999994, -0.04400000000000004, -0.11099999999999988, -0.2630000000000002, -0.11999999999999988, -0.07399999999999995, -0.02499999999999991, -0.07599999999999985, -0.2589999999999998, -0.30599999999999994, -0.9680000000000001, -0.04399999999999993, 0.387, -0.17699999999999994, -0.12399999999999989, -0.03600000000000003, -0.264, -0.06799999999999995, -0.050999999999999934, -0.07800000000000007, -0.3250000000000002, -0.05999999999999994, -0.062000000000000055, -0.15600000000000003, -0.03500000000000003, -0.038000000000000034, -0.06499999999999995, -0.15399999999999991, -0.1150000000000001, -0.14, -0.04300000000000004, 0.362, -0.06499999999999995, 0.17999999999999994, -0.19000000000000006, -0.07699999999999996, -0.11299999999999988, -0.1170000000000001, -0.07699999999999996, 0.18399999999999994, -0.17700000000000005, -0.22399999999999998, -0.016000000000000007, -0.05999999999999994, -0.06499999999999995, -0.28200000000000003, -0.2839999999999999, -0.137, -0.5370000000000001, -0.14200000000000002, -0.1439999999999999, -0.1519999999999999, -0.018999999999999906, -0.11599999999999999, -0.04800000000000004, -0.04799999999999993, -0.131, -0.017000000000000015, 0.1329999999999999, -0.19700000000000015, -0.06300000000000006, 0.3400000000000001, -0.04499999999999993, -0.05799999999999983, -0.33599999999999985, -0.04999999999999982, -0.030000000000000027, -0.33399999999999996, -0.123, -0.02400000000000002, -0.133, -0.492, -0.038000000000000034, -0.17899999999999994, -0.07000000000000006, -0.06500000000000006, -0.08199999999999996, -0.19399999999999995, 0.43900000000000006, -0.051000000000000045, -0.15100000000000002, -0.03399999999999992, -0.07199999999999984, -0.15100000000000002, -0.05600000000000005, -0.08000000000000007, -0.040000000000000036, -0.038000000000000034, -0.027999999999999914, -0.09399999999999997, 0.30099999999999993], "episode_lengths": [40, 29, 16, 70, 47, 263, 34, 92, 27, 90, 14, 36, 300, 35, 21, 8, 23, 75, 91, 290, 13, 35, 54, 37, 12, 86, 19, 16, 24, 104, 17, 18, 48, 14, 13, 23, 45, 181, 42, 13, 44, 20, 100, 60, 24, 36, 38, 20, 85, 55, 70, 300, 19, 20, 91, 85, 43, 153, 44, 45, 47, 6, 34, 14, 15, 42, 9, 112, 300, 166, 51, 14, 18, 105, 14, 10, 91, 39, 8, 41, 135, 12, 56, 20, 19, 26, 57, 19, 19, 47, 11, 22, 48, 16, 24, 16, 12, 9, 30, 55], "policy_blue_0_reward": [-1.005, -1.004, -1.0179999999999998, -1.016, -1.001, -1.0039999999999998, -1.0139999999999998, -1.041, -1.001, -0.504, -1.006, -1.009, -1.0, -1.012, -1.005, -1.001, -1.007, -1.002, -1.004, -1.0119999999999998, -0.53, 0.866, -0.505, -1.005, -0.512, -1.006, -1.003, -1.005, -1.003, -1.005, -1.003, -1.006, -1.009, -1.003, -1.003, -1.0, -0.514, -0.5049999999999999, -1.003, -1.0019999999999998, -1.017, -1.0, -1.016, -1.004, -1.021, -1.002, -1.008, -0.5019999999999999, -1.002, -1.007, -1.001, -1.0039999999999998, -1.005, -1.001, -1.001, -1.0, -1.002, -0.509], "policy_red_0_v5_reward": [0.952, -0.01900000000000001, -1.004, -0.011000000000000003, 0.725, 0.976, -1.006, 0.853], "policy_red_0_v1_reward": [0.776, -1.0, -1.001, -1.009, -1.001], "policy_red_0_v6_reward": [0.841, 0.896, -1.002, -1.007, -1.004, -1.065, -1.003, -0.525, -1.003], "policy_red_0_v4_reward": [-1.018, -1.004, -1.001, -1.006, 0.87, -1.0059999999999998, 0.921], "policy_red_0_v2_reward": [-1.029, -1.008, -1.002, -1.015, -1.022, -1.008, 0.945], "policy_red_0_v3_reward": [-1.009, -1.009, -0.08300000000000006, 0.876, -1.01], "policy_red_0_v7_reward": [1.241]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23029732512778486, "mean_inference_ms": 1.5011868327598605, "mean_action_processing_ms": 0.062492172037380576, "mean_env_wait_ms": 0.10611348714566486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021419644355773926, "StateBufferConnector_ms": 0.001540541648864746, "ViewRequirementAgentConnector_ms": 0.032150983810424805}}, "episode_reward_max": 0.43900000000000006, "episode_reward_min": -0.9680000000000001, "episode_reward_mean": -0.10804, "episode_len_mean": 55.56, "episodes_this_iter": 64, "policy_reward_min": {"blue_0": -1.041, "red_0": -1.057, "red_0_v5": -1.006, "red_0_v1": -1.009, "red_0_v6": -1.065, "red_0_v4": -1.018, "red_0_v2": -1.029, "red_0_v3": -1.01, "red_0_v7": 1.241}, "policy_reward_max": {"blue_0": 0.866, "red_0": 0.983, "red_0_v5": 0.976, "red_0_v1": 0.776, "red_0_v6": 0.896, "red_0_v4": 0.921, "red_0_v2": 0.945, "red_0_v3": 0.876, "red_0_v7": 1.241}, "policy_reward_mean": {"blue_0": -0.9055862068965518, "red_0": 0.5773800000000001, "red_0_v5": 0.18325000000000002, "red_0_v1": -0.647, "red_0_v6": -0.5413333333333333, "red_0_v4": -0.46342857142857125, "red_0_v2": -0.7341428571428571, "red_0_v3": -0.44700000000000006, "red_0_v7": 1.241}, "hist_stats": {"episode_reward": [-0.12, -0.09999999999999987, -0.049000000000000044, -0.244, -0.16300000000000003, -0.838, -0.10599999999999998, -0.3059999999999998, -0.07199999999999995, -0.30499999999999994, -0.04400000000000004, -0.11099999999999988, -0.2630000000000002, -0.11999999999999988, -0.07399999999999995, -0.02499999999999991, -0.07599999999999985, -0.2589999999999998, -0.30599999999999994, -0.9680000000000001, -0.04399999999999993, 0.387, -0.17699999999999994, -0.12399999999999989, -0.03600000000000003, -0.264, -0.06799999999999995, -0.050999999999999934, -0.07800000000000007, -0.3250000000000002, -0.05999999999999994, -0.062000000000000055, -0.15600000000000003, -0.03500000000000003, -0.038000000000000034, -0.06499999999999995, -0.15399999999999991, -0.1150000000000001, -0.14, -0.04300000000000004, 0.362, -0.06499999999999995, 0.17999999999999994, -0.19000000000000006, -0.07699999999999996, -0.11299999999999988, -0.1170000000000001, -0.07699999999999996, 0.18399999999999994, -0.17700000000000005, -0.22399999999999998, -0.016000000000000007, -0.05999999999999994, -0.06499999999999995, -0.28200000000000003, -0.2839999999999999, -0.137, -0.5370000000000001, -0.14200000000000002, -0.1439999999999999, -0.1519999999999999, -0.018999999999999906, -0.11599999999999999, -0.04800000000000004, -0.04799999999999993, -0.131, -0.017000000000000015, 0.1329999999999999, -0.19700000000000015, -0.06300000000000006, 0.3400000000000001, -0.04499999999999993, -0.05799999999999983, -0.33599999999999985, -0.04999999999999982, -0.030000000000000027, -0.33399999999999996, -0.123, -0.02400000000000002, -0.133, -0.492, -0.038000000000000034, -0.17899999999999994, -0.07000000000000006, -0.06500000000000006, -0.08199999999999996, -0.19399999999999995, 0.43900000000000006, -0.051000000000000045, -0.15100000000000002, -0.03399999999999992, -0.07199999999999984, -0.15100000000000002, -0.05600000000000005, -0.08000000000000007, -0.040000000000000036, -0.038000000000000034, -0.027999999999999914, -0.09399999999999997, 0.30099999999999993], "episode_lengths": [40, 29, 16, 70, 47, 263, 34, 92, 27, 90, 14, 36, 300, 35, 21, 8, 23, 75, 91, 290, 13, 35, 54, 37, 12, 86, 19, 16, 24, 104, 17, 18, 48, 14, 13, 23, 45, 181, 42, 13, 44, 20, 100, 60, 24, 36, 38, 20, 85, 55, 70, 300, 19, 20, 91, 85, 43, 153, 44, 45, 47, 6, 34, 14, 15, 42, 9, 112, 300, 166, 51, 14, 18, 105, 14, 10, 91, 39, 8, 41, 135, 12, 56, 20, 19, 26, 57, 19, 19, 47, 11, 22, 48, 16, 24, 16, 12, 9, 30, 55], "policy_blue_0_reward": [-1.005, -1.004, -1.0179999999999998, -1.016, -1.001, -1.0039999999999998, -1.0139999999999998, -1.041, -1.001, -0.504, -1.006, -1.009, -1.0, -1.012, -1.005, -1.001, -1.007, -1.002, -1.004, -1.0119999999999998, -0.53, 0.866, -0.505, -1.005, -0.512, -1.006, -1.003, -1.005, -1.003, -1.005, -1.003, -1.006, -1.009, -1.003, -1.003, -1.0, -0.514, -0.5049999999999999, -1.003, -1.0019999999999998, -1.017, -1.0, -1.016, -1.004, -1.021, -1.002, -1.008, -0.5019999999999999, -1.002, -1.007, -1.001, -1.0039999999999998, -1.005, -1.001, -1.001, -1.0, -1.002, -0.509], "policy_red_0_v5_reward": [0.952, -0.01900000000000001, -1.004, -0.011000000000000003, 0.725, 0.976, -1.006, 0.853], "policy_red_0_v1_reward": [0.776, -1.0, -1.001, -1.009, -1.001], "policy_red_0_v6_reward": [0.841, 0.896, -1.002, -1.007, -1.004, -1.065, -1.003, -0.525, -1.003], "policy_red_0_v4_reward": [-1.018, -1.004, -1.001, -1.006, 0.87, -1.0059999999999998, 0.921], "policy_red_0_v2_reward": [-1.029, -1.008, -1.002, -1.015, -1.022, -1.008, 0.945], "policy_red_0_v3_reward": [-1.009, -1.009, -0.08300000000000006, 0.876, -1.01], "policy_red_0_v7_reward": [1.241]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23029732512778486, "mean_inference_ms": 1.5011868327598605, "mean_action_processing_ms": 0.062492172037380576, "mean_env_wait_ms": 0.10611348714566486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021419644355773926, "StateBufferConnector_ms": 0.001540541648864746, "ViewRequirementAgentConnector_ms": 0.032150983810424805}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.59678556918624, "num_env_steps_trained_throughput_per_sec": 102.59678556918624, "timesteps_total": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 39380.818, "sample_time_ms": 7665.994, "learn_time_ms": 31697.063, "learn_throughput": 126.195, "synch_weights_time_ms": 17.116}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "episodes_total": 5184, "training_iteration": 80, "trial_id": "bb874_00000", "date": "2023-09-28_22-23-00", "timestamp": 1695954180, "time_this_iter_s": 38.990236043930054, "time_total_s": 3163.379909992218, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x357a775b0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355f26d40>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355f26830>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3163.379909992218, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 41.425000000000004, "ram_util_percent": 29.167857142857144}, "win_rate": 0.87, "league_size": 10}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4672447188446918, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0455298471460992, "policy_loss": -0.029452306819924463, "vf_loss": 0.1461961726968487, "vf_explained_var": 0.2702333885555466, "kl": 0.014356769739226009, "entropy": 0.9872869847963254, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 77280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000}, "sampler_results": {"episode_reward_max": 0.45699999999999996, "episode_reward_min": -0.9730000000000001, "episode_reward_mean": -0.10257999999999999, "episode_len_mean": 53.44, "episode_media": {}, "episodes_this_iter": 77, "policy_reward_min": {"red_0_v3": -1.01, "red_0": -1.013, "red_0_v5": -1.006, "blue_0": -1.035, "red_0_v6": -1.019, "red_0_v4": -1.004, "red_0_v2": -1.007, "red_0_v8": -1.003, "red_0_v1": -1.004, "red_0_v7": 0.929}, "policy_reward_max": {"red_0_v3": 0.9319999999999999, "red_0": 0.976, "red_0_v5": 1.073, "blue_0": 0.926, "red_0_v6": 0.902, "red_0_v4": 0.921, "red_0_v2": 0.945, "red_0_v8": 0.787, "red_0_v1": -1.001, "red_0_v7": 0.929}, "policy_reward_mean": {"red_0_v3": -0.193, "red_0": 0.48121, "red_0_v5": 0.3602857142857143, "blue_0": -0.9311525423728813, "red_0_v6": -0.09679999999999997, "red_0_v4": -0.418, "red_0_v2": 0.348, "red_0_v8": -0.10799999999999993, "red_0_v1": -1.00175, "red_0_v7": 0.929}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.123, -0.02400000000000002, -0.133, -0.492, -0.038000000000000034, -0.17899999999999994, -0.07000000000000006, -0.06500000000000006, -0.08199999999999996, -0.19399999999999995, 0.43900000000000006, -0.051000000000000045, -0.15100000000000002, -0.03399999999999992, -0.07199999999999984, -0.15100000000000002, -0.05600000000000005, -0.08000000000000007, -0.040000000000000036, -0.038000000000000034, -0.027999999999999914, -0.09399999999999997, 0.30099999999999993, -0.06600000000000004, -0.22299999999999998, -0.03300000000000003, -0.14, 0.374, -0.09399999999999986, -0.09299999999999986, -0.02499999999999991, -0.1339999999999999, -0.569, -0.44900000000000007, -0.027000000000000024, -0.16300000000000003, -0.027999999999999914, -0.07199999999999984, -0.11099999999999999, -0.08399999999999974, -0.06700000000000006, -0.10499999999999987, -0.6719999999999999, -0.05400000000000005, 0.06299999999999994, -0.04499999999999993, -0.15200000000000002, -0.027999999999999914, -0.118, -0.036000000000000025, -0.03300000000000002, -0.2829999999999999, -0.18100000000000005, -0.06499999999999995, -0.07499999999999996, -0.42699999999999994, -0.02499999999999991, -0.07000000000000006, -0.1369999999999999, -0.04400000000000004, 0.241, -0.4490000000000002, -0.08299999999999985, -0.9730000000000001, -0.19599999999999995, -0.05699999999999994, -0.030999999999999917, -0.17300000000000004, -0.14700000000000002, -0.029000000000000026, -0.04300000000000004, -0.04299999999999993, -0.1279999999999999, -0.050999999999999934, -0.05800000000000005, 0.45699999999999996, -0.06900000000000006, -0.2300000000000001, -0.06499999999999995, -0.052999999999999936, -0.05399999999999994, -0.04399999999999993, -0.041000000000000036, -0.04600000000000004, -0.32799999999999996, -0.09999999999999998, -0.07499999999999996, -0.10399999999999998, -0.19299999999999984, -0.30200000000000005, -0.08299999999999996, -0.04399999999999993, -0.05999999999999994, -0.05699999999999994, -0.06000000000000005, -0.31599999999999995, -0.11199999999999999, -0.041000000000000036, -0.038000000000000034, -0.03399999999999992], "episode_lengths": [39, 8, 41, 135, 12, 56, 20, 19, 26, 57, 19, 19, 47, 11, 22, 48, 16, 24, 16, 12, 9, 30, 55, 300, 70, 11, 41, 37, 31, 30, 8, 41, 174, 131, 9, 51, 9, 23, 35, 26, 21, 32, 204, 21, 139, 14, 39, 9, 34, 300, 300, 88, 44, 20, 23, 128, 8, 21, 44, 16, 79, 134, 26, 298, 66, 18, 10, 51, 46, 9, 13, 14, 37, 16, 21, 300, 169, 73, 23, 16, 17, 13, 13, 14, 99, 32, 24, 32, 58, 96, 25, 11, 19, 18, 18, 93, 34, 13, 12, 11], "policy_red_0_v3_reward": [0.876, -1.01, 0.863, -1.001, 0.9319999999999999, -1.002, -1.009], "policy_red_0_v5_reward": [0.976, -1.006, 0.853, 1.073, 0.858, 0.7729999999999999, -1.005], "policy_blue_0_reward": [-1.004, -1.021, -1.002, -1.008, -0.5019999999999999, -1.002, -1.007, -1.001, -1.0039999999999998, -1.005, -1.001, -1.001, -1.0, -1.002, -0.509, -0.505, -1.005, -1.007, -1.03, -1.0, -1.001, -1.003, -1.003, -1.005, -1.006, -1.035, -1.0, -1.002, -1.008, -1.009, 0.926, -1.014, -1.001, -1.003, -1.004, -0.512, -1.017, -1.003, -1.0019999999999998, -1.001, -1.01, -1.001, -1.0079999999999998, -1.003, -0.522, -1.004, -1.003, -1.003, -1.002, -1.001, -1.017, -1.01, -1.009, -1.006, -1.002, -1.004, -1.011, -1.002, -1.001], "policy_red_0_v6_reward": [-1.003, -0.017000000000000008, -1.019, 0.845, 0.848, -1.0, -0.004, -1.003, 0.483, 0.902], "policy_red_0_v4_reward": [0.921, -1.0, -0.006, -1.004, -1.001], "policy_red_0_v2_reward": [0.945, 0.9329999999999999, 0.832, 0.036999999999999936, -1.007], "policy_red_0_v8_reward": [0.787, -1.003], "policy_red_0_v1_reward": [-1.001, -1.001, -1.004, -1.001], "policy_red_0_v7_reward": [0.929]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23066816163726167, "mean_inference_ms": 1.50265920853387, "mean_action_processing_ms": 0.06254803103542185, "mean_env_wait_ms": 0.10630364132368127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019418954849243164, "StateBufferConnector_ms": 0.0015496015548706055, "ViewRequirementAgentConnector_ms": 0.03132152557373047}}, "episode_reward_max": 0.45699999999999996, "episode_reward_min": -0.9730000000000001, "episode_reward_mean": -0.10257999999999999, "episode_len_mean": 53.44, "episodes_this_iter": 77, "policy_reward_min": {"red_0_v3": -1.01, "red_0": -1.013, "red_0_v5": -1.006, "blue_0": -1.035, "red_0_v6": -1.019, "red_0_v4": -1.004, "red_0_v2": -1.007, "red_0_v8": -1.003, "red_0_v1": -1.004, "red_0_v7": 0.929}, "policy_reward_max": {"red_0_v3": 0.9319999999999999, "red_0": 0.976, "red_0_v5": 1.073, "blue_0": 0.926, "red_0_v6": 0.902, "red_0_v4": 0.921, "red_0_v2": 0.945, "red_0_v8": 0.787, "red_0_v1": -1.001, "red_0_v7": 0.929}, "policy_reward_mean": {"red_0_v3": -0.193, "red_0": 0.48121, "red_0_v5": 0.3602857142857143, "blue_0": -0.9311525423728813, "red_0_v6": -0.09679999999999997, "red_0_v4": -0.418, "red_0_v2": 0.348, "red_0_v8": -0.10799999999999993, "red_0_v1": -1.00175, "red_0_v7": 0.929}, "hist_stats": {"episode_reward": [-0.123, -0.02400000000000002, -0.133, -0.492, -0.038000000000000034, -0.17899999999999994, -0.07000000000000006, -0.06500000000000006, -0.08199999999999996, -0.19399999999999995, 0.43900000000000006, -0.051000000000000045, -0.15100000000000002, -0.03399999999999992, -0.07199999999999984, -0.15100000000000002, -0.05600000000000005, -0.08000000000000007, -0.040000000000000036, -0.038000000000000034, -0.027999999999999914, -0.09399999999999997, 0.30099999999999993, -0.06600000000000004, -0.22299999999999998, -0.03300000000000003, -0.14, 0.374, -0.09399999999999986, -0.09299999999999986, -0.02499999999999991, -0.1339999999999999, -0.569, -0.44900000000000007, -0.027000000000000024, -0.16300000000000003, -0.027999999999999914, -0.07199999999999984, -0.11099999999999999, -0.08399999999999974, -0.06700000000000006, -0.10499999999999987, -0.6719999999999999, -0.05400000000000005, 0.06299999999999994, -0.04499999999999993, -0.15200000000000002, -0.027999999999999914, -0.118, -0.036000000000000025, -0.03300000000000002, -0.2829999999999999, -0.18100000000000005, -0.06499999999999995, -0.07499999999999996, -0.42699999999999994, -0.02499999999999991, -0.07000000000000006, -0.1369999999999999, -0.04400000000000004, 0.241, -0.4490000000000002, -0.08299999999999985, -0.9730000000000001, -0.19599999999999995, -0.05699999999999994, -0.030999999999999917, -0.17300000000000004, -0.14700000000000002, -0.029000000000000026, -0.04300000000000004, -0.04299999999999993, -0.1279999999999999, -0.050999999999999934, -0.05800000000000005, 0.45699999999999996, -0.06900000000000006, -0.2300000000000001, -0.06499999999999995, -0.052999999999999936, -0.05399999999999994, -0.04399999999999993, -0.041000000000000036, -0.04600000000000004, -0.32799999999999996, -0.09999999999999998, -0.07499999999999996, -0.10399999999999998, -0.19299999999999984, -0.30200000000000005, -0.08299999999999996, -0.04399999999999993, -0.05999999999999994, -0.05699999999999994, -0.06000000000000005, -0.31599999999999995, -0.11199999999999999, -0.041000000000000036, -0.038000000000000034, -0.03399999999999992], "episode_lengths": [39, 8, 41, 135, 12, 56, 20, 19, 26, 57, 19, 19, 47, 11, 22, 48, 16, 24, 16, 12, 9, 30, 55, 300, 70, 11, 41, 37, 31, 30, 8, 41, 174, 131, 9, 51, 9, 23, 35, 26, 21, 32, 204, 21, 139, 14, 39, 9, 34, 300, 300, 88, 44, 20, 23, 128, 8, 21, 44, 16, 79, 134, 26, 298, 66, 18, 10, 51, 46, 9, 13, 14, 37, 16, 21, 300, 169, 73, 23, 16, 17, 13, 13, 14, 99, 32, 24, 32, 58, 96, 25, 11, 19, 18, 18, 93, 34, 13, 12, 11], "policy_red_0_v3_reward": [0.876, -1.01, 0.863, -1.001, 0.9319999999999999, -1.002, -1.009], "policy_red_0_v5_reward": [0.976, -1.006, 0.853, 1.073, 0.858, 0.7729999999999999, -1.005], "policy_blue_0_reward": [-1.004, -1.021, -1.002, -1.008, -0.5019999999999999, -1.002, -1.007, -1.001, -1.0039999999999998, -1.005, -1.001, -1.001, -1.0, -1.002, -0.509, -0.505, -1.005, -1.007, -1.03, -1.0, -1.001, -1.003, -1.003, -1.005, -1.006, -1.035, -1.0, -1.002, -1.008, -1.009, 0.926, -1.014, -1.001, -1.003, -1.004, -0.512, -1.017, -1.003, -1.0019999999999998, -1.001, -1.01, -1.001, -1.0079999999999998, -1.003, -0.522, -1.004, -1.003, -1.003, -1.002, -1.001, -1.017, -1.01, -1.009, -1.006, -1.002, -1.004, -1.011, -1.002, -1.001], "policy_red_0_v6_reward": [-1.003, -0.017000000000000008, -1.019, 0.845, 0.848, -1.0, -0.004, -1.003, 0.483, 0.902], "policy_red_0_v4_reward": [0.921, -1.0, -0.006, -1.004, -1.001], "policy_red_0_v2_reward": [0.945, 0.9329999999999999, 0.832, 0.036999999999999936, -1.007], "policy_red_0_v8_reward": [0.787, -1.003], "policy_red_0_v1_reward": [-1.001, -1.001, -1.004, -1.001], "policy_red_0_v7_reward": [0.929]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23066816163726167, "mean_inference_ms": 1.50265920853387, "mean_action_processing_ms": 0.06254803103542185, "mean_env_wait_ms": 0.10630364132368127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019418954849243164, "StateBufferConnector_ms": 0.0015496015548706055, "ViewRequirementAgentConnector_ms": 0.03132152557373047}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.27899470811539, "num_env_steps_trained_throughput_per_sec": 101.27899470811539, "timesteps_total": 324000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 648000, "timers": {"training_iteration_time_ms": 39395.814, "sample_time_ms": 7666.549, "learn_time_ms": 31711.506, "learn_throughput": 126.137, "synch_weights_time_ms": 17.114}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 648000, "num_agent_steps_trained": 648000}, "done": false, "episodes_total": 5261, "training_iteration": 81, "trial_id": "bb874_00000", "date": "2023-09-28_22-23-39", "timestamp": 1695954219, "time_this_iter_s": 39.49764919281006, "time_total_s": 3202.877559185028, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x3574abbb0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355920670>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x3559227a0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3202.877559185028, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 34.285714285714285, "ram_util_percent": 29.008928571428573}, "win_rate": 0.8, "league_size": 10}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1924709759652616, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04560204719843265, "policy_loss": -0.020919114986948747, "vf_loss": 0.12952029547886923, "vf_explained_var": 0.20955291197945675, "kl": 0.013420786852378333, "entropy": 0.923143021017313, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 78240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "sampler_results": {"episode_reward_max": 0.46399999999999997, "episode_reward_min": -0.6489999999999999, "episode_reward_mean": -0.10270999999999997, "episode_len_mean": 48.3, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"blue_0": -1.0179999999999998, "red_0": -1.006, "red_0_v5": -1.033, "red_0_v2": -1.0359999999999998, "red_0_v6": -1.091, "red_0_v3": -1.009, "red_0_v8": -1.026, "red_0_v4": -1.004, "red_0_v7": -1.026, "red_0_v1": -1.017}, "policy_reward_max": {"blue_0": 1.3860000000000001, "red_0": 0.983, "red_0_v5": 0.863, "red_0_v2": -0.502, "red_0_v6": 0.9339999999999999, "red_0_v3": -1.008, "red_0_v8": 0.953, "red_0_v4": 0.971, "red_0_v7": 0.966, "red_0_v1": -1.001}, "policy_reward_mean": {"blue_0": -0.864826923076923, "red_0": 0.60306, "red_0_v5": -0.26359999999999995, "red_0_v2": -0.9421428571428571, "red_0_v6": -0.25339999999999996, "red_0_v3": -1.0085, "red_0_v8": -0.302875, "red_0_v4": -0.3013333333333333, "red_0_v7": -0.3041428571428571, "red_0_v1": -1.006125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.04399999999999993, -0.041000000000000036, -0.04600000000000004, -0.32799999999999996, -0.09999999999999998, -0.07499999999999996, -0.10399999999999998, -0.19299999999999984, -0.30200000000000005, -0.08299999999999996, -0.04399999999999993, -0.05999999999999994, -0.05699999999999994, -0.06000000000000005, -0.31599999999999995, -0.11199999999999999, -0.041000000000000036, -0.038000000000000034, -0.03399999999999992, -0.30899999999999994, -0.11299999999999988, -0.06800000000000006, -0.2729999999999999, 0.128, -0.08999999999999997, -0.11199999999999999, -0.21699999999999986, -0.3490000000000001, -0.248, 0.30799999999999994, -0.07499999999999996, -0.10399999999999987, -0.09199999999999997, -0.6489999999999999, -0.07999999999999996, -0.1359999999999998, -0.06599999999999995, -0.42599999999999993, -0.16799999999999993, -0.11699999999999988, -0.349, -0.06400000000000006, -0.03400000000000003, -0.11499999999999988, -0.13, -0.17199999999999993, -0.14100000000000001, -0.16399999999999992, -0.2579999999999999, -0.02499999999999991, -0.09699999999999986, -0.03200000000000003, -0.05999999999999994, -0.04399999999999993, -0.34999999999999987, -0.026999999999999913, -0.24, 0.29399999999999993, -0.11099999999999999, -0.2589999999999999, -0.07100000000000006, -0.03799999999999981, 0.46399999999999997, -0.31299999999999994, -0.030000000000000027, -0.09799999999999998, -0.04800000000000004, -0.07299999999999984, 0.44599999999999995, -0.06400000000000006, 0.3860000000000001, -0.08399999999999985, -0.17300000000000004, -0.08599999999999985, -0.07100000000000006, -0.05999999999999994, -0.15600000000000003, -0.02499999999999991, -0.249, -0.04599999999999982, -0.062000000000000055, -0.017000000000000015, -0.45599999999999996, -0.03599999999999992, -0.09799999999999998, 0.45300000000000007, -0.06099999999999994, -0.21799999999999997, -0.1389999999999999, -0.4930000000000001, -0.16600000000000004, 0.19399999999999995, -0.06699999999999984, -0.03599999999999992, -0.14100000000000001, -0.31199999999999983, -0.3759999999999999, -0.04100000000000003, -0.06299999999999994, -0.03500000000000003], "episode_lengths": [13, 13, 14, 99, 32, 24, 32, 58, 96, 25, 11, 19, 18, 18, 93, 34, 13, 12, 11, 97, 38, 22, 78, 115, 28, 34, 70, 264, 72, 56, 24, 31, 28, 173, 21, 40, 21, 137, 53, 36, 107, 20, 9, 32, 46, 58, 45, 49, 79, 8, 30, 10, 19, 16, 107, 11, 75, 60, 33, 80, 21, 12, 11, 101, 9, 32, 15, 21, 16, 20, 36, 27, 51, 25, 21, 19, 50, 8, 81, 14, 20, 9, 142, 11, 30, 14, 18, 64, 42, 159, 52, 99, 19, 9, 44, 90, 117, 300, 20, 14], "policy_blue_0_reward": [-1.003, -1.002, -1.001, -1.017, -1.01, -1.009, -1.006, -1.002, -1.004, -1.011, -1.002, -1.001, -1.0059999999999998, -1.002, -0.52, -1.006, -1.006, -1.008, -1.014, -0.512, -1.0019999999999998, -1.007, -1.009, -1.0179999999999998, -1.004, -1.0059999999999998, 0.9369999999999999, -1.006, -1.002, -1.0019999999999998, -0.51, -1.0019999999999998, -0.503, -1.006, -1.004, 1.3860000000000001, -1.001, -1.007, -1.002, -1.003, -1.002, -1.0, -1.003, -0.5009999999999999, -1.003, -1.006, -1.008, -1.011, -1.009, -0.508, -1.0039999999999998, -1.003], "policy_red_0_v5_reward": [-1.005, -1.033, -1.003, 0.86, 0.863], "policy_red_0_v2_reward": [-1.007, -1.017, -1.017, -1.0099999999999998, -0.502, -1.006, -1.0359999999999998], "policy_red_0_v6_reward": [0.902, -1.091, -1.003, 0.9339999999999999, -1.009], "policy_red_0_v3_reward": [-1.009, -1.008], "policy_red_0_v8_reward": [-1.003, 0.912, -1.001, -1.0039999999999998, 0.953, 0.755, -1.009, -1.026], "policy_red_0_v4_reward": [-1.004, -1.001, -0.533, 0.76, 0.971, -1.001], "policy_red_0_v7_reward": [-1.009, 0.966, -1.005, -1.026, -1.009, -0.004, 0.958], "policy_red_0_v1_reward": [-1.017, -1.011, -1.01, -1.001, -1.001, -1.003, -1.002, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2305079628125551, "mean_inference_ms": 1.502619933375466, "mean_action_processing_ms": 0.06251644854741706, "mean_env_wait_ms": 0.10624023469235555, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018858671188354492, "StateBufferConnector_ms": 0.001500248908996582, "ViewRequirementAgentConnector_ms": 0.03106367588043213}}, "episode_reward_max": 0.46399999999999997, "episode_reward_min": -0.6489999999999999, "episode_reward_mean": -0.10270999999999997, "episode_len_mean": 48.3, "episodes_this_iter": 81, "policy_reward_min": {"blue_0": -1.0179999999999998, "red_0": -1.006, "red_0_v5": -1.033, "red_0_v2": -1.0359999999999998, "red_0_v6": -1.091, "red_0_v3": -1.009, "red_0_v8": -1.026, "red_0_v4": -1.004, "red_0_v7": -1.026, "red_0_v1": -1.017}, "policy_reward_max": {"blue_0": 1.3860000000000001, "red_0": 0.983, "red_0_v5": 0.863, "red_0_v2": -0.502, "red_0_v6": 0.9339999999999999, "red_0_v3": -1.008, "red_0_v8": 0.953, "red_0_v4": 0.971, "red_0_v7": 0.966, "red_0_v1": -1.001}, "policy_reward_mean": {"blue_0": -0.864826923076923, "red_0": 0.60306, "red_0_v5": -0.26359999999999995, "red_0_v2": -0.9421428571428571, "red_0_v6": -0.25339999999999996, "red_0_v3": -1.0085, "red_0_v8": -0.302875, "red_0_v4": -0.3013333333333333, "red_0_v7": -0.3041428571428571, "red_0_v1": -1.006125}, "hist_stats": {"episode_reward": [-0.04399999999999993, -0.041000000000000036, -0.04600000000000004, -0.32799999999999996, -0.09999999999999998, -0.07499999999999996, -0.10399999999999998, -0.19299999999999984, -0.30200000000000005, -0.08299999999999996, -0.04399999999999993, -0.05999999999999994, -0.05699999999999994, -0.06000000000000005, -0.31599999999999995, -0.11199999999999999, -0.041000000000000036, -0.038000000000000034, -0.03399999999999992, -0.30899999999999994, -0.11299999999999988, -0.06800000000000006, -0.2729999999999999, 0.128, -0.08999999999999997, -0.11199999999999999, -0.21699999999999986, -0.3490000000000001, -0.248, 0.30799999999999994, -0.07499999999999996, -0.10399999999999987, -0.09199999999999997, -0.6489999999999999, -0.07999999999999996, -0.1359999999999998, -0.06599999999999995, -0.42599999999999993, -0.16799999999999993, -0.11699999999999988, -0.349, -0.06400000000000006, -0.03400000000000003, -0.11499999999999988, -0.13, -0.17199999999999993, -0.14100000000000001, -0.16399999999999992, -0.2579999999999999, -0.02499999999999991, -0.09699999999999986, -0.03200000000000003, -0.05999999999999994, -0.04399999999999993, -0.34999999999999987, -0.026999999999999913, -0.24, 0.29399999999999993, -0.11099999999999999, -0.2589999999999999, -0.07100000000000006, -0.03799999999999981, 0.46399999999999997, -0.31299999999999994, -0.030000000000000027, -0.09799999999999998, -0.04800000000000004, -0.07299999999999984, 0.44599999999999995, -0.06400000000000006, 0.3860000000000001, -0.08399999999999985, -0.17300000000000004, -0.08599999999999985, -0.07100000000000006, -0.05999999999999994, -0.15600000000000003, -0.02499999999999991, -0.249, -0.04599999999999982, -0.062000000000000055, -0.017000000000000015, -0.45599999999999996, -0.03599999999999992, -0.09799999999999998, 0.45300000000000007, -0.06099999999999994, -0.21799999999999997, -0.1389999999999999, -0.4930000000000001, -0.16600000000000004, 0.19399999999999995, -0.06699999999999984, -0.03599999999999992, -0.14100000000000001, -0.31199999999999983, -0.3759999999999999, -0.04100000000000003, -0.06299999999999994, -0.03500000000000003], "episode_lengths": [13, 13, 14, 99, 32, 24, 32, 58, 96, 25, 11, 19, 18, 18, 93, 34, 13, 12, 11, 97, 38, 22, 78, 115, 28, 34, 70, 264, 72, 56, 24, 31, 28, 173, 21, 40, 21, 137, 53, 36, 107, 20, 9, 32, 46, 58, 45, 49, 79, 8, 30, 10, 19, 16, 107, 11, 75, 60, 33, 80, 21, 12, 11, 101, 9, 32, 15, 21, 16, 20, 36, 27, 51, 25, 21, 19, 50, 8, 81, 14, 20, 9, 142, 11, 30, 14, 18, 64, 42, 159, 52, 99, 19, 9, 44, 90, 117, 300, 20, 14], "policy_blue_0_reward": [-1.003, -1.002, -1.001, -1.017, -1.01, -1.009, -1.006, -1.002, -1.004, -1.011, -1.002, -1.001, -1.0059999999999998, -1.002, -0.52, -1.006, -1.006, -1.008, -1.014, -0.512, -1.0019999999999998, -1.007, -1.009, -1.0179999999999998, -1.004, -1.0059999999999998, 0.9369999999999999, -1.006, -1.002, -1.0019999999999998, -0.51, -1.0019999999999998, -0.503, -1.006, -1.004, 1.3860000000000001, -1.001, -1.007, -1.002, -1.003, -1.002, -1.0, -1.003, -0.5009999999999999, -1.003, -1.006, -1.008, -1.011, -1.009, -0.508, -1.0039999999999998, -1.003], "policy_red_0_v5_reward": [-1.005, -1.033, -1.003, 0.86, 0.863], "policy_red_0_v2_reward": [-1.007, -1.017, -1.017, -1.0099999999999998, -0.502, -1.006, -1.0359999999999998], "policy_red_0_v6_reward": [0.902, -1.091, -1.003, 0.9339999999999999, -1.009], "policy_red_0_v3_reward": [-1.009, -1.008], "policy_red_0_v8_reward": [-1.003, 0.912, -1.001, -1.0039999999999998, 0.953, 0.755, -1.009, -1.026], "policy_red_0_v4_reward": [-1.004, -1.001, -0.533, 0.76, 0.971, -1.001], "policy_red_0_v7_reward": [-1.009, 0.966, -1.005, -1.026, -1.009, -0.004, 0.958], "policy_red_0_v1_reward": [-1.017, -1.011, -1.01, -1.001, -1.001, -1.003, -1.002, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2305079628125551, "mean_inference_ms": 1.502619933375466, "mean_action_processing_ms": 0.06251644854741706, "mean_env_wait_ms": 0.10624023469235555, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018858671188354492, "StateBufferConnector_ms": 0.001500248908996582, "ViewRequirementAgentConnector_ms": 0.03106367588043213}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.37634333935031, "num_env_steps_trained_throughput_per_sec": 101.37634333935031, "timesteps_total": 328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 39383.418, "sample_time_ms": 7660.293, "learn_time_ms": 31705.396, "learn_throughput": 126.161, "synch_weights_time_ms": 17.08}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "episodes_total": 5342, "training_iteration": 82, "trial_id": "bb874_00000", "date": "2023-09-28_22-24-19", "timestamp": 1695954259, "time_this_iter_s": 39.45979690551758, "time_total_s": 3242.3373560905457, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x355e5bcd0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355f27130>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355f24f70>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3242.3373560905457, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 35.692982456140356, "ram_util_percent": 29.105263157894733}, "win_rate": 0.87, "league_size": 11}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.372746064017216, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.05163432678139846, "policy_loss": -0.025364464189866945, "vf_loss": 0.15086434639912719, "vf_explained_var": 0.30598256420344117, "kl": 0.012012614439555591, "entropy": 0.8359047169486682, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 79200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000}, "sampler_results": {"episode_reward_max": 0.45300000000000007, "episode_reward_min": -0.6840000000000002, "episode_reward_mean": -0.11759999999999997, "episode_len_mean": 52.06, "episode_media": {}, "episodes_this_iter": 72, "policy_reward_min": {"blue_0": -1.024, "red_0": -1.107, "red_0_v1": -1.006, "red_0_v4": -1.004, "red_0_v8": -1.026, "red_0_v2": -1.0359999999999998, "red_0_v6": -1.009, "red_0_v5": -1.004, "red_0_v7": -1.027, "red_0_v3": -1.01, "red_0_v9": -1.0}, "policy_reward_max": {"blue_0": -0.5009999999999999, "red_0": 0.983, "red_0_v1": 0.889, "red_0_v4": 0.95, "red_0_v8": 0.755, "red_0_v2": 0.958, "red_0_v6": 0.9319999999999999, "red_0_v5": 0.863, "red_0_v7": 0.958, "red_0_v3": 0.966, "red_0_v9": 0.91}, "policy_reward_mean": {"blue_0": -0.9503777777777777, "red_0": 0.46890999999999994, "red_0_v1": -0.6712, "red_0_v4": -0.6113999999999999, "red_0_v8": -0.3625999999999999, "red_0_v2": -0.3902857142857142, "red_0_v6": -0.131, "red_0_v5": 0.10659999999999999, "red_0_v7": -0.048714285714285675, "red_0_v3": -0.1078571428571428, "red_0_v9": -0.044999999999999984}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.17300000000000004, -0.08599999999999985, -0.07100000000000006, -0.05999999999999994, -0.15600000000000003, -0.02499999999999991, -0.249, -0.04599999999999982, -0.062000000000000055, -0.017000000000000015, -0.45599999999999996, -0.03599999999999992, -0.09799999999999998, 0.45300000000000007, -0.06099999999999994, -0.21799999999999997, -0.1389999999999999, -0.4930000000000001, -0.16600000000000004, 0.19399999999999995, -0.06699999999999984, -0.03599999999999992, -0.14100000000000001, -0.31199999999999983, -0.3759999999999999, -0.04100000000000003, -0.06299999999999994, -0.03500000000000003, -0.16400000000000003, -0.15100000000000002, -0.532, -0.04400000000000004, -0.09199999999999986, -0.04600000000000004, -0.06800000000000006, -0.04300000000000004, -0.17099999999999993, -0.6840000000000002, -0.06800000000000006, -0.07599999999999985, -0.15899999999999992, 0.261, -0.2749999999999999, -0.119, -0.030999999999999917, -0.15200000000000002, -0.16800000000000004, -0.04999999999999993, -0.029999999999999916, -0.02199999999999991, -0.11099999999999999, -0.08899999999999986, -0.10599999999999998, -0.06799999999999995, -0.17699999999999994, -0.361, 0.09599999999999986, -0.11799999999999988, 0.29500000000000015, -0.04899999999999993, -0.06899999999999995, -0.10999999999999988, -0.10499999999999987, -0.09299999999999997, -0.030000000000000027, -0.08599999999999997, -0.1269999999999999, -0.16000000000000003, -0.126, -0.41400000000000015, -0.11099999999999999, -0.09099999999999986, -0.06799999999999995, -0.06899999999999995, -0.398, 0.42399999999999993, -0.04899999999999982, -0.09399999999999997, -0.20500000000000007, -0.5540000000000002, -0.02199999999999991, -0.07700000000000005, -0.05300000000000005, -0.028999999999999915, -0.11599999999999999, -0.1329999999999999, -0.039999999999999925, -0.1269999999999999, -0.05999999999999994, -0.040000000000000036, -0.5590000000000002, -0.15499999999999992, -0.16200000000000003, -0.09799999999999998, -0.45600000000000007, -0.1399999999999998, -0.04299999999999993, -0.10399999999999998, -0.03400000000000003, -0.16900000000000004], "episode_lengths": [51, 25, 21, 19, 50, 8, 81, 14, 20, 9, 142, 11, 30, 14, 18, 64, 42, 159, 52, 99, 19, 9, 44, 90, 117, 300, 20, 14, 52, 47, 169, 14, 29, 13, 22, 13, 50, 189, 22, 23, 50, 80, 88, 35, 10, 48, 53, 15, 9, 9, 35, 28, 34, 21, 56, 117, 114, 39, 64, 16, 22, 31, 32, 28, 13, 26, 38, 42, 36, 273, 31, 28, 21, 22, 122, 22, 15, 30, 63, 152, 7, 300, 16, 12, 36, 44, 13, 38, 19, 12, 155, 48, 53, 30, 121, 40, 12, 34, 10, 53], "policy_blue_0_reward": [-1.007, -1.002, -1.003, -1.002, -1.0, -1.003, -0.5009999999999999, -1.003, -1.006, -1.008, -1.011, -1.009, -0.508, -1.0039999999999998, -1.003, -1.008, -1.006, -1.013, -1.002, -0.507, -1.009, -1.0, -1.004, -1.001, -1.002, -1.003, -1.0019999999999998, -1.007, -0.5049999999999999, -1.003, -1.006, -1.004, -1.005, -0.547, -1.003, -1.002, -1.008, -1.001, -1.003, -1.005, -1.004, -1.001, -1.024, -1.004, -1.008], "policy_red_0_v1_reward": [-1.003, -1.002, -1.004, -1.0, 0.42299999999999993, -1.006, -1.002, 0.889, -1.001, -1.0059999999999998], "policy_red_0_v4_reward": [-1.001, -1.004, -1.001, 0.95, -1.001], "policy_red_0_v8_reward": [0.755, -1.009, -1.026, 0.485, -1.018], "policy_red_0_v2_reward": [-1.006, -1.0359999999999998, -1.002, 0.958, -0.553, 0.913, -1.006], "policy_red_0_v6_reward": [-1.009, 0.9319999999999999, -1.006, 0.644, -1.001, -0.028000000000000018, 0.5509999999999999], "policy_red_0_v5_reward": [0.863, 0.839, -1.004, -1.004, 0.839], "policy_red_0_v7_reward": [-0.004, 0.958, 0.842, 0.898, -1.002, -1.027, -1.0059999999999998], "policy_red_0_v3_reward": [0.959, -1.005, -1.004, 0.844, -1.01, -0.505, 0.966], "policy_red_0_v9_reward": [-1.0, 0.91]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23032100509040113, "mean_inference_ms": 1.5022346102184725, "mean_action_processing_ms": 0.06249406182031237, "mean_env_wait_ms": 0.10620225399341762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017978429794311523, "StateBufferConnector_ms": 0.0014778375625610352, "ViewRequirementAgentConnector_ms": 0.03080284595489502}}, "episode_reward_max": 0.45300000000000007, "episode_reward_min": -0.6840000000000002, "episode_reward_mean": -0.11759999999999997, "episode_len_mean": 52.06, "episodes_this_iter": 72, "policy_reward_min": {"blue_0": -1.024, "red_0": -1.107, "red_0_v1": -1.006, "red_0_v4": -1.004, "red_0_v8": -1.026, "red_0_v2": -1.0359999999999998, "red_0_v6": -1.009, "red_0_v5": -1.004, "red_0_v7": -1.027, "red_0_v3": -1.01, "red_0_v9": -1.0}, "policy_reward_max": {"blue_0": -0.5009999999999999, "red_0": 0.983, "red_0_v1": 0.889, "red_0_v4": 0.95, "red_0_v8": 0.755, "red_0_v2": 0.958, "red_0_v6": 0.9319999999999999, "red_0_v5": 0.863, "red_0_v7": 0.958, "red_0_v3": 0.966, "red_0_v9": 0.91}, "policy_reward_mean": {"blue_0": -0.9503777777777777, "red_0": 0.46890999999999994, "red_0_v1": -0.6712, "red_0_v4": -0.6113999999999999, "red_0_v8": -0.3625999999999999, "red_0_v2": -0.3902857142857142, "red_0_v6": -0.131, "red_0_v5": 0.10659999999999999, "red_0_v7": -0.048714285714285675, "red_0_v3": -0.1078571428571428, "red_0_v9": -0.044999999999999984}, "hist_stats": {"episode_reward": [-0.17300000000000004, -0.08599999999999985, -0.07100000000000006, -0.05999999999999994, -0.15600000000000003, -0.02499999999999991, -0.249, -0.04599999999999982, -0.062000000000000055, -0.017000000000000015, -0.45599999999999996, -0.03599999999999992, -0.09799999999999998, 0.45300000000000007, -0.06099999999999994, -0.21799999999999997, -0.1389999999999999, -0.4930000000000001, -0.16600000000000004, 0.19399999999999995, -0.06699999999999984, -0.03599999999999992, -0.14100000000000001, -0.31199999999999983, -0.3759999999999999, -0.04100000000000003, -0.06299999999999994, -0.03500000000000003, -0.16400000000000003, -0.15100000000000002, -0.532, -0.04400000000000004, -0.09199999999999986, -0.04600000000000004, -0.06800000000000006, -0.04300000000000004, -0.17099999999999993, -0.6840000000000002, -0.06800000000000006, -0.07599999999999985, -0.15899999999999992, 0.261, -0.2749999999999999, -0.119, -0.030999999999999917, -0.15200000000000002, -0.16800000000000004, -0.04999999999999993, -0.029999999999999916, -0.02199999999999991, -0.11099999999999999, -0.08899999999999986, -0.10599999999999998, -0.06799999999999995, -0.17699999999999994, -0.361, 0.09599999999999986, -0.11799999999999988, 0.29500000000000015, -0.04899999999999993, -0.06899999999999995, -0.10999999999999988, -0.10499999999999987, -0.09299999999999997, -0.030000000000000027, -0.08599999999999997, -0.1269999999999999, -0.16000000000000003, -0.126, -0.41400000000000015, -0.11099999999999999, -0.09099999999999986, -0.06799999999999995, -0.06899999999999995, -0.398, 0.42399999999999993, -0.04899999999999982, -0.09399999999999997, -0.20500000000000007, -0.5540000000000002, -0.02199999999999991, -0.07700000000000005, -0.05300000000000005, -0.028999999999999915, -0.11599999999999999, -0.1329999999999999, -0.039999999999999925, -0.1269999999999999, -0.05999999999999994, -0.040000000000000036, -0.5590000000000002, -0.15499999999999992, -0.16200000000000003, -0.09799999999999998, -0.45600000000000007, -0.1399999999999998, -0.04299999999999993, -0.10399999999999998, -0.03400000000000003, -0.16900000000000004], "episode_lengths": [51, 25, 21, 19, 50, 8, 81, 14, 20, 9, 142, 11, 30, 14, 18, 64, 42, 159, 52, 99, 19, 9, 44, 90, 117, 300, 20, 14, 52, 47, 169, 14, 29, 13, 22, 13, 50, 189, 22, 23, 50, 80, 88, 35, 10, 48, 53, 15, 9, 9, 35, 28, 34, 21, 56, 117, 114, 39, 64, 16, 22, 31, 32, 28, 13, 26, 38, 42, 36, 273, 31, 28, 21, 22, 122, 22, 15, 30, 63, 152, 7, 300, 16, 12, 36, 44, 13, 38, 19, 12, 155, 48, 53, 30, 121, 40, 12, 34, 10, 53], "policy_blue_0_reward": [-1.007, -1.002, -1.003, -1.002, -1.0, -1.003, -0.5009999999999999, -1.003, -1.006, -1.008, -1.011, -1.009, -0.508, -1.0039999999999998, -1.003, -1.008, -1.006, -1.013, -1.002, -0.507, -1.009, -1.0, -1.004, -1.001, -1.002, -1.003, -1.0019999999999998, -1.007, -0.5049999999999999, -1.003, -1.006, -1.004, -1.005, -0.547, -1.003, -1.002, -1.008, -1.001, -1.003, -1.005, -1.004, -1.001, -1.024, -1.004, -1.008], "policy_red_0_v1_reward": [-1.003, -1.002, -1.004, -1.0, 0.42299999999999993, -1.006, -1.002, 0.889, -1.001, -1.0059999999999998], "policy_red_0_v4_reward": [-1.001, -1.004, -1.001, 0.95, -1.001], "policy_red_0_v8_reward": [0.755, -1.009, -1.026, 0.485, -1.018], "policy_red_0_v2_reward": [-1.006, -1.0359999999999998, -1.002, 0.958, -0.553, 0.913, -1.006], "policy_red_0_v6_reward": [-1.009, 0.9319999999999999, -1.006, 0.644, -1.001, -0.028000000000000018, 0.5509999999999999], "policy_red_0_v5_reward": [0.863, 0.839, -1.004, -1.004, 0.839], "policy_red_0_v7_reward": [-0.004, 0.958, 0.842, 0.898, -1.002, -1.027, -1.0059999999999998], "policy_red_0_v3_reward": [0.959, -1.005, -1.004, 0.844, -1.01, -0.505, 0.966], "policy_red_0_v9_reward": [-1.0, 0.91]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23032100509040113, "mean_inference_ms": 1.5022346102184725, "mean_action_processing_ms": 0.06249406182031237, "mean_env_wait_ms": 0.10620225399341762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017978429794311523, "StateBufferConnector_ms": 0.0014778375625610352, "ViewRequirementAgentConnector_ms": 0.03080284595489502}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.37275627598014, "num_env_steps_trained_throughput_per_sec": 101.37275627598014, "timesteps_total": 332000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 664000, "timers": {"training_iteration_time_ms": 39386.409, "sample_time_ms": 7665.541, "learn_time_ms": 31703.024, "learn_throughput": 126.171, "synch_weights_time_ms": 17.189}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 664000, "num_agent_steps_trained": 664000}, "done": false, "episodes_total": 5414, "training_iteration": 83, "trial_id": "bb874_00000", "date": "2023-09-28_22-24-59", "timestamp": 1695954299, "time_this_iter_s": 39.46142387390137, "time_total_s": 3281.798779964447, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x357a04fd0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355921b40>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355921c60>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3281.798779964447, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 34.94285714285714, "ram_util_percent": 29.166071428571428}, "win_rate": 0.8, "league_size": 11}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1823300156742333, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.037804230134740165, "policy_loss": -0.019080341345397756, "vf_loss": 0.11167592873098328, "vf_explained_var": 0.3009269008412957, "kl": 0.008994339761595726, "entropy": 0.752260067872703, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 80160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "sampler_results": {"episode_reward_max": 0.42399999999999993, "episode_reward_min": -0.5590000000000002, "episode_reward_mean": -0.11596999999999999, "episode_len_mean": 61.59, "episode_media": {}, "episodes_this_iter": 55, "policy_reward_min": {"red_0_v6": -1.009, "red_0": -1.022, "red_0_v2": -1.011, "red_0_v1": -1.006, "blue_0": -1.024, "red_0_v9": -1.0, "red_0_v4": -1.001, "red_0_v3": -1.016, "red_0_v5": -1.005, "red_0_v7": -1.027, "red_0_v8": -1.018}, "policy_reward_max": {"red_0_v6": 0.644, "red_0": 0.979, "red_0_v2": 0.913, "red_0_v1": 0.979, "blue_0": -0.5049999999999999, "red_0_v9": 1.2149999999999999, "red_0_v4": 1.109, "red_0_v3": 0.966, "red_0_v5": 0.941, "red_0_v7": 0.9249999999999999, "red_0_v8": 0.638}, "policy_reward_mean": {"red_0_v6": -0.3565, "red_0": 0.38356999999999997, "red_0_v2": -0.41425, "red_0_v1": -0.2965, "blue_0": -0.967820512820513, "red_0_v9": 0.514, "red_0_v4": 0.14583333333333337, "red_0_v3": -0.11114285714285714, "red_0_v5": -0.38536363636363635, "red_0_v7": -0.09074999999999994, "red_0_v8": -0.5032000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.361, 0.09599999999999986, -0.11799999999999988, 0.29500000000000015, -0.04899999999999993, -0.06899999999999995, -0.10999999999999988, -0.10499999999999987, -0.09299999999999997, -0.030000000000000027, -0.08599999999999997, -0.1269999999999999, -0.16000000000000003, -0.126, -0.41400000000000015, -0.11099999999999999, -0.09099999999999986, -0.06799999999999995, -0.06899999999999995, -0.398, 0.42399999999999993, -0.04899999999999982, -0.09399999999999997, -0.20500000000000007, -0.5540000000000002, -0.02199999999999991, -0.07700000000000005, -0.05300000000000005, -0.028999999999999915, -0.11599999999999999, -0.1329999999999999, -0.039999999999999925, -0.1269999999999999, -0.05999999999999994, -0.040000000000000036, -0.5590000000000002, -0.15499999999999992, -0.16200000000000003, -0.09799999999999998, -0.45600000000000007, -0.1399999999999998, -0.04299999999999993, -0.10399999999999998, -0.03400000000000003, -0.16900000000000004, -0.503, -0.14600000000000002, -0.10899999999999987, -0.29399999999999993, -0.049000000000000044, -0.06399999999999995, 0.19300000000000006, -0.17100000000000004, -0.004, -0.22799999999999998, -0.31000000000000005, -0.030999999999999805, -0.19599999999999995, -0.15999999999999992, -0.3760000000000001, -0.3619999999999999, -0.06899999999999995, -0.030999999999999917, 0.377, -0.11499999999999999, -0.02499999999999991, -0.051999999999999935, -0.07899999999999996, -0.030000000000000027, 0.10599999999999987, -0.14100000000000001, -0.133, -0.038999999999999924, -0.09999999999999998, -0.05900000000000005, -0.19699999999999995, -0.02100000000000001, -0.14500000000000002, -0.08999999999999997, -0.393, -0.1460000000000001, -0.05699999999999983, 0.31799999999999995, -0.008, -0.052000000000000046, -0.06800000000000006, -0.265, -0.025000000000000022, -0.515, -0.2569999999999999, -0.02100000000000002, -0.06800000000000006, -0.364, -0.18599999999999994, -0.030000000000000027, -0.2929999999999999, -0.040000000000000036, -0.05300000000000005, -0.08000000000000007, -0.051999999999999935], "episode_lengths": [117, 114, 39, 64, 16, 22, 31, 32, 28, 13, 26, 38, 42, 36, 273, 31, 28, 21, 22, 122, 22, 15, 30, 63, 152, 7, 300, 16, 12, 36, 44, 13, 38, 19, 12, 155, 48, 53, 30, 121, 40, 12, 34, 10, 53, 161, 46, 34, 93, 19, 21, 93, 51, 300, 70, 91, 9, 57, 47, 104, 113, 23, 8, 33, 35, 8, 13, 27, 13, 125, 45, 41, 12, 30, 16, 60, 300, 47, 26, 114, 300, 17, 57, 300, 16, 20, 83, 11, 169, 80, 7, 20, 118, 58, 10, 90, 12, 17, 24, 15], "policy_red_0_v6_reward": [0.644, -1.001, -0.028000000000000018, 0.5509999999999999, -1.001, -1.009, -1.005, -0.003], "policy_red_0_v2_reward": [-0.553, 0.913, -1.006, -1.011], "policy_red_0_v1_reward": [-1.006, -1.002, 0.889, -1.001, -1.0059999999999998, 0.78, 0.979, -1.005], "policy_blue_0_reward": [-0.5049999999999999, -1.003, -1.006, -1.004, -1.005, -0.547, -1.003, -1.002, -1.008, -1.001, -1.003, -1.005, -1.004, -1.001, -1.024, -1.004, -1.008, -1.002, -1.006, -1.0, -1.001, -1.0039999999999998, -1.005, -1.012, -1.008, -1.0, -1.003, -1.005, -1.007, -1.021, -1.0039999999999998, -0.51, -1.012, -1.002, -1.002, -1.0, -1.004, -1.002, -1.002], "policy_red_0_v9_reward": [-1.0, 0.91, 1.2149999999999999, 0.931], "policy_red_0_v4_reward": [-1.001, 0.95, -1.001, -0.004, 1.109, 0.8220000000000001], "policy_red_0_v3_reward": [0.844, -1.01, -0.505, 0.966, -1.016, -1.007, 0.95], "policy_red_0_v5_reward": [-1.004, -1.004, 0.839, 0.512, -0.508, -1.005, 0.941, -0.002, -1.004, -1.0, -1.004], "policy_red_0_v7_reward": [-1.002, -1.027, -1.0059999999999998, 0.702, 0.821, 0.872, -1.011, 0.9249999999999999], "policy_red_0_v8_reward": [-1.018, -1.001, -1.012, -0.1230000000000001, 0.638]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23033051951600667, "mean_inference_ms": 1.502599535168643, "mean_action_processing_ms": 0.062493758119114666, "mean_env_wait_ms": 0.10622450166503893, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017623424530029297, "StateBufferConnector_ms": 0.0014801952573988172, "ViewRequirementAgentConnector_ms": 0.03060060077243381}}, "episode_reward_max": 0.42399999999999993, "episode_reward_min": -0.5590000000000002, "episode_reward_mean": -0.11596999999999999, "episode_len_mean": 61.59, "episodes_this_iter": 55, "policy_reward_min": {"red_0_v6": -1.009, "red_0": -1.022, "red_0_v2": -1.011, "red_0_v1": -1.006, "blue_0": -1.024, "red_0_v9": -1.0, "red_0_v4": -1.001, "red_0_v3": -1.016, "red_0_v5": -1.005, "red_0_v7": -1.027, "red_0_v8": -1.018}, "policy_reward_max": {"red_0_v6": 0.644, "red_0": 0.979, "red_0_v2": 0.913, "red_0_v1": 0.979, "blue_0": -0.5049999999999999, "red_0_v9": 1.2149999999999999, "red_0_v4": 1.109, "red_0_v3": 0.966, "red_0_v5": 0.941, "red_0_v7": 0.9249999999999999, "red_0_v8": 0.638}, "policy_reward_mean": {"red_0_v6": -0.3565, "red_0": 0.38356999999999997, "red_0_v2": -0.41425, "red_0_v1": -0.2965, "blue_0": -0.967820512820513, "red_0_v9": 0.514, "red_0_v4": 0.14583333333333337, "red_0_v3": -0.11114285714285714, "red_0_v5": -0.38536363636363635, "red_0_v7": -0.09074999999999994, "red_0_v8": -0.5032000000000001}, "hist_stats": {"episode_reward": [-0.361, 0.09599999999999986, -0.11799999999999988, 0.29500000000000015, -0.04899999999999993, -0.06899999999999995, -0.10999999999999988, -0.10499999999999987, -0.09299999999999997, -0.030000000000000027, -0.08599999999999997, -0.1269999999999999, -0.16000000000000003, -0.126, -0.41400000000000015, -0.11099999999999999, -0.09099999999999986, -0.06799999999999995, -0.06899999999999995, -0.398, 0.42399999999999993, -0.04899999999999982, -0.09399999999999997, -0.20500000000000007, -0.5540000000000002, -0.02199999999999991, -0.07700000000000005, -0.05300000000000005, -0.028999999999999915, -0.11599999999999999, -0.1329999999999999, -0.039999999999999925, -0.1269999999999999, -0.05999999999999994, -0.040000000000000036, -0.5590000000000002, -0.15499999999999992, -0.16200000000000003, -0.09799999999999998, -0.45600000000000007, -0.1399999999999998, -0.04299999999999993, -0.10399999999999998, -0.03400000000000003, -0.16900000000000004, -0.503, -0.14600000000000002, -0.10899999999999987, -0.29399999999999993, -0.049000000000000044, -0.06399999999999995, 0.19300000000000006, -0.17100000000000004, -0.004, -0.22799999999999998, -0.31000000000000005, -0.030999999999999805, -0.19599999999999995, -0.15999999999999992, -0.3760000000000001, -0.3619999999999999, -0.06899999999999995, -0.030999999999999917, 0.377, -0.11499999999999999, -0.02499999999999991, -0.051999999999999935, -0.07899999999999996, -0.030000000000000027, 0.10599999999999987, -0.14100000000000001, -0.133, -0.038999999999999924, -0.09999999999999998, -0.05900000000000005, -0.19699999999999995, -0.02100000000000001, -0.14500000000000002, -0.08999999999999997, -0.393, -0.1460000000000001, -0.05699999999999983, 0.31799999999999995, -0.008, -0.052000000000000046, -0.06800000000000006, -0.265, -0.025000000000000022, -0.515, -0.2569999999999999, -0.02100000000000002, -0.06800000000000006, -0.364, -0.18599999999999994, -0.030000000000000027, -0.2929999999999999, -0.040000000000000036, -0.05300000000000005, -0.08000000000000007, -0.051999999999999935], "episode_lengths": [117, 114, 39, 64, 16, 22, 31, 32, 28, 13, 26, 38, 42, 36, 273, 31, 28, 21, 22, 122, 22, 15, 30, 63, 152, 7, 300, 16, 12, 36, 44, 13, 38, 19, 12, 155, 48, 53, 30, 121, 40, 12, 34, 10, 53, 161, 46, 34, 93, 19, 21, 93, 51, 300, 70, 91, 9, 57, 47, 104, 113, 23, 8, 33, 35, 8, 13, 27, 13, 125, 45, 41, 12, 30, 16, 60, 300, 47, 26, 114, 300, 17, 57, 300, 16, 20, 83, 11, 169, 80, 7, 20, 118, 58, 10, 90, 12, 17, 24, 15], "policy_red_0_v6_reward": [0.644, -1.001, -0.028000000000000018, 0.5509999999999999, -1.001, -1.009, -1.005, -0.003], "policy_red_0_v2_reward": [-0.553, 0.913, -1.006, -1.011], "policy_red_0_v1_reward": [-1.006, -1.002, 0.889, -1.001, -1.0059999999999998, 0.78, 0.979, -1.005], "policy_blue_0_reward": [-0.5049999999999999, -1.003, -1.006, -1.004, -1.005, -0.547, -1.003, -1.002, -1.008, -1.001, -1.003, -1.005, -1.004, -1.001, -1.024, -1.004, -1.008, -1.002, -1.006, -1.0, -1.001, -1.0039999999999998, -1.005, -1.012, -1.008, -1.0, -1.003, -1.005, -1.007, -1.021, -1.0039999999999998, -0.51, -1.012, -1.002, -1.002, -1.0, -1.004, -1.002, -1.002], "policy_red_0_v9_reward": [-1.0, 0.91, 1.2149999999999999, 0.931], "policy_red_0_v4_reward": [-1.001, 0.95, -1.001, -0.004, 1.109, 0.8220000000000001], "policy_red_0_v3_reward": [0.844, -1.01, -0.505, 0.966, -1.016, -1.007, 0.95], "policy_red_0_v5_reward": [-1.004, -1.004, 0.839, 0.512, -0.508, -1.005, 0.941, -0.002, -1.004, -1.0, -1.004], "policy_red_0_v7_reward": [-1.002, -1.027, -1.0059999999999998, 0.702, 0.821, 0.872, -1.011, 0.9249999999999999], "policy_red_0_v8_reward": [-1.018, -1.001, -1.012, -0.1230000000000001, 0.638]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23033051951600667, "mean_inference_ms": 1.502599535168643, "mean_action_processing_ms": 0.062493758119114666, "mean_env_wait_ms": 0.10622450166503893, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017623424530029297, "StateBufferConnector_ms": 0.0014801952573988172, "ViewRequirementAgentConnector_ms": 0.03060060077243381}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.30907556454966, "num_env_steps_trained_throughput_per_sec": 100.30907556454966, "timesteps_total": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 39423.122, "sample_time_ms": 7669.127, "learn_time_ms": 31736.267, "learn_throughput": 126.039, "synch_weights_time_ms": 17.078}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "episodes_total": 5469, "training_iteration": 84, "trial_id": "bb874_00000", "date": "2023-09-28_22-25-39", "timestamp": 1695954339, "time_this_iter_s": 39.87929177284241, "time_total_s": 3321.6780717372894, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x3574fb5b0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x357ef6b90>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x357ef6dd0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3321.6780717372894, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 35.65964912280702, "ram_util_percent": 29.236842105263154}, "win_rate": 0.77, "league_size": 11}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.386829682315389, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04857353122448937, "policy_loss": -0.026396244130349564, "vf_loss": 0.1467394458750884, "vf_explained_var": 0.26601383530845246, "kl": 0.012124410806523662, "entropy": 0.8248289917285244, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 81120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "sampler_results": {"episode_reward_max": 0.9359999999999999, "episode_reward_min": -0.5760000000000001, "episode_reward_mean": -0.1009, "episode_len_mean": 67.75, "episode_media": {}, "episodes_this_iter": 68, "policy_reward_min": {"blue_0": -1.024, "red_0": -1.037, "red_0_v4": -1.014, "red_0_v6": -1.015, "red_0_v7": -1.011, "red_0_v5": -1.004, "red_0_v8": -1.012, "red_0_v3": -1.006, "red_0_v1": -1.005, "red_0_v9": -1.007, "red_0_v2": -1.004}, "policy_reward_max": {"blue_0": 0.958, "red_0": 0.977, "red_0_v4": 1.109, "red_0_v6": 0.877, "red_0_v7": 0.9319999999999999, "red_0_v5": 0.941, "red_0_v8": 0.638, "red_0_v3": 0.95, "red_0_v1": 0.979, "red_0_v9": 0.904, "red_0_v2": 1.4220000000000002}, "policy_reward_mean": {"blue_0": -0.8708421052631579, "red_0": 0.33505, "red_0_v4": -0.03562500000000002, "red_0_v6": -0.18944444444444442, "red_0_v7": 0.15255555555555564, "red_0_v5": -0.633875, "red_0_v8": -0.3622857142857142, "red_0_v3": -0.16860000000000003, "red_0_v1": -0.589, "red_0_v9": -0.3141999999999999, "red_0_v2": 0.7338000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.030000000000000027, 0.10599999999999987, -0.14100000000000001, -0.133, -0.038999999999999924, -0.09999999999999998, -0.05900000000000005, -0.19699999999999995, -0.02100000000000001, -0.14500000000000002, -0.08999999999999997, -0.393, -0.1460000000000001, -0.05699999999999983, 0.31799999999999995, -0.008, -0.052000000000000046, -0.06800000000000006, -0.265, -0.025000000000000022, -0.515, -0.2569999999999999, -0.02100000000000002, -0.06800000000000006, -0.364, -0.18599999999999994, -0.030000000000000027, -0.2929999999999999, -0.040000000000000036, -0.05300000000000005, -0.08000000000000007, -0.051999999999999935, -0.18800000000000006, -0.18500000000000005, -0.33299999999999996, -0.07999999999999996, -0.08599999999999997, -0.3440000000000001, -0.06599999999999995, -0.04499999999999993, -0.5029999999999999, -0.16300000000000003, 0.9359999999999999, -0.121, 0.4119999999999999, -0.052000000000000046, -0.15400000000000003, -0.07399999999999984, -0.40700000000000003, -0.03399999999999992, -0.2670000000000001, -0.2729999999999999, -0.03599999999999992, -0.06300000000000006, 0.386, -0.08899999999999997, -0.07899999999999985, -0.255, -0.10699999999999998, -0.039999999999999925, -0.03200000000000003, 0.371, -0.041000000000000036, -0.19400000000000006, -0.04399999999999993, -0.128, -0.08099999999999996, -0.09199999999999997, -0.31700000000000006, -0.02900000000000002, -0.09899999999999987, -0.050000000000000044, -0.18999999999999995, -0.1260000000000001, -0.051999999999999935, -0.06700000000000006, -0.039999999999999925, -0.16700000000000004, -0.20899999999999985, 0.41900000000000004, -0.04600000000000004, -0.15700000000000003, -0.15600000000000003, -0.1439999999999999, -0.028000000000000025, -0.09799999999999998, 0.396, -0.09899999999999998, -0.14100000000000001, -0.10799999999999998, -0.07699999999999974, -0.1399999999999999, -0.011000000000000003, -0.17900000000000005, -0.05399999999999994, -0.5760000000000001, -0.07400000000000005, -0.40200000000000014, -0.504, -0.5099999999999999], "episode_lengths": [13, 125, 45, 41, 12, 30, 16, 60, 300, 47, 26, 114, 300, 17, 57, 300, 16, 20, 83, 11, 169, 80, 7, 20, 118, 58, 10, 90, 12, 17, 24, 15, 60, 59, 100, 25, 30, 104, 21, 14, 151, 47, 171, 35, 25, 16, 50, 23, 112, 11, 69, 78, 11, 20, 31, 29, 26, 75, 32, 13, 10, 40, 13, 65, 13, 36, 23, 30, 89, 300, 32, 16, 62, 169, 15, 24, 11, 45, 63, 25, 14, 50, 52, 45, 300, 28, 32, 31, 50, 32, 25, 43, 300, 63, 17, 166, 300, 129, 159, 167], "policy_blue_0_reward": [-1.0, -1.003, -1.005, -1.007, -1.021, -1.0039999999999998, -0.51, -1.012, -1.002, -1.002, -1.0, -1.004, -1.002, -1.002, -1.02, -1.003, 0.958, -1.003, -1.004, -1.017, -1.01, -1.003, -1.004, -1.002, -0.505, -1.001, -1.0039999999999998, 0.72, -1.002, -1.011, -0.522, -1.007, -1.0119999999999998, -1.006, -1.0079999999999998, -1.0099999999999998, -1.024, -1.018], "policy_red_0_v4_reward": [1.109, 0.8220000000000001, -1.001, -1.002, 0.958, 0.845, -1.002, -1.014], "policy_red_0_v6_reward": [-1.005, -0.003, -1.015, 0.6729999999999999, 0.8019999999999999, 0.877, -0.028000000000000018, -1.006, -1.0], "policy_red_0_v7_reward": [0.872, -1.011, 0.9249999999999999, 0.921, 0.9319999999999999, 0.755, -1.007, -1.005, -0.009000000000000001], "policy_red_0_v5_reward": [0.941, -0.002, -1.004, -1.0, -1.004, -1.001, -1.001, -1.0], "policy_red_0_v8_reward": [-1.012, -0.1230000000000001, 0.638, -1.004, -0.003, -0.02900000000000002, -1.003], "policy_red_0_v3_reward": [0.95, -1.006, -1.003, 0.7349999999999999, -0.519], "policy_red_0_v1_reward": [0.979, -1.005, -1.005, -1.0, -0.5, -1.003], "policy_red_0_v9_reward": [0.533, -1.007, 0.904, -1.001, -1.0], "policy_red_0_v2_reward": [1.415, -1.004, 0.926, 1.4220000000000002, 0.91]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23028114259633842, "mean_inference_ms": 1.5033662380321773, "mean_action_processing_ms": 0.06250887273360507, "mean_env_wait_ms": 0.10628740821393352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018325209617614746, "StateBufferConnector_ms": 0.001478433609008789, "ViewRequirementAgentConnector_ms": 0.030855655670166016}}, "episode_reward_max": 0.9359999999999999, "episode_reward_min": -0.5760000000000001, "episode_reward_mean": -0.1009, "episode_len_mean": 67.75, "episodes_this_iter": 68, "policy_reward_min": {"blue_0": -1.024, "red_0": -1.037, "red_0_v4": -1.014, "red_0_v6": -1.015, "red_0_v7": -1.011, "red_0_v5": -1.004, "red_0_v8": -1.012, "red_0_v3": -1.006, "red_0_v1": -1.005, "red_0_v9": -1.007, "red_0_v2": -1.004}, "policy_reward_max": {"blue_0": 0.958, "red_0": 0.977, "red_0_v4": 1.109, "red_0_v6": 0.877, "red_0_v7": 0.9319999999999999, "red_0_v5": 0.941, "red_0_v8": 0.638, "red_0_v3": 0.95, "red_0_v1": 0.979, "red_0_v9": 0.904, "red_0_v2": 1.4220000000000002}, "policy_reward_mean": {"blue_0": -0.8708421052631579, "red_0": 0.33505, "red_0_v4": -0.03562500000000002, "red_0_v6": -0.18944444444444442, "red_0_v7": 0.15255555555555564, "red_0_v5": -0.633875, "red_0_v8": -0.3622857142857142, "red_0_v3": -0.16860000000000003, "red_0_v1": -0.589, "red_0_v9": -0.3141999999999999, "red_0_v2": 0.7338000000000001}, "hist_stats": {"episode_reward": [-0.030000000000000027, 0.10599999999999987, -0.14100000000000001, -0.133, -0.038999999999999924, -0.09999999999999998, -0.05900000000000005, -0.19699999999999995, -0.02100000000000001, -0.14500000000000002, -0.08999999999999997, -0.393, -0.1460000000000001, -0.05699999999999983, 0.31799999999999995, -0.008, -0.052000000000000046, -0.06800000000000006, -0.265, -0.025000000000000022, -0.515, -0.2569999999999999, -0.02100000000000002, -0.06800000000000006, -0.364, -0.18599999999999994, -0.030000000000000027, -0.2929999999999999, -0.040000000000000036, -0.05300000000000005, -0.08000000000000007, -0.051999999999999935, -0.18800000000000006, -0.18500000000000005, -0.33299999999999996, -0.07999999999999996, -0.08599999999999997, -0.3440000000000001, -0.06599999999999995, -0.04499999999999993, -0.5029999999999999, -0.16300000000000003, 0.9359999999999999, -0.121, 0.4119999999999999, -0.052000000000000046, -0.15400000000000003, -0.07399999999999984, -0.40700000000000003, -0.03399999999999992, -0.2670000000000001, -0.2729999999999999, -0.03599999999999992, -0.06300000000000006, 0.386, -0.08899999999999997, -0.07899999999999985, -0.255, -0.10699999999999998, -0.039999999999999925, -0.03200000000000003, 0.371, -0.041000000000000036, -0.19400000000000006, -0.04399999999999993, -0.128, -0.08099999999999996, -0.09199999999999997, -0.31700000000000006, -0.02900000000000002, -0.09899999999999987, -0.050000000000000044, -0.18999999999999995, -0.1260000000000001, -0.051999999999999935, -0.06700000000000006, -0.039999999999999925, -0.16700000000000004, -0.20899999999999985, 0.41900000000000004, -0.04600000000000004, -0.15700000000000003, -0.15600000000000003, -0.1439999999999999, -0.028000000000000025, -0.09799999999999998, 0.396, -0.09899999999999998, -0.14100000000000001, -0.10799999999999998, -0.07699999999999974, -0.1399999999999999, -0.011000000000000003, -0.17900000000000005, -0.05399999999999994, -0.5760000000000001, -0.07400000000000005, -0.40200000000000014, -0.504, -0.5099999999999999], "episode_lengths": [13, 125, 45, 41, 12, 30, 16, 60, 300, 47, 26, 114, 300, 17, 57, 300, 16, 20, 83, 11, 169, 80, 7, 20, 118, 58, 10, 90, 12, 17, 24, 15, 60, 59, 100, 25, 30, 104, 21, 14, 151, 47, 171, 35, 25, 16, 50, 23, 112, 11, 69, 78, 11, 20, 31, 29, 26, 75, 32, 13, 10, 40, 13, 65, 13, 36, 23, 30, 89, 300, 32, 16, 62, 169, 15, 24, 11, 45, 63, 25, 14, 50, 52, 45, 300, 28, 32, 31, 50, 32, 25, 43, 300, 63, 17, 166, 300, 129, 159, 167], "policy_blue_0_reward": [-1.0, -1.003, -1.005, -1.007, -1.021, -1.0039999999999998, -0.51, -1.012, -1.002, -1.002, -1.0, -1.004, -1.002, -1.002, -1.02, -1.003, 0.958, -1.003, -1.004, -1.017, -1.01, -1.003, -1.004, -1.002, -0.505, -1.001, -1.0039999999999998, 0.72, -1.002, -1.011, -0.522, -1.007, -1.0119999999999998, -1.006, -1.0079999999999998, -1.0099999999999998, -1.024, -1.018], "policy_red_0_v4_reward": [1.109, 0.8220000000000001, -1.001, -1.002, 0.958, 0.845, -1.002, -1.014], "policy_red_0_v6_reward": [-1.005, -0.003, -1.015, 0.6729999999999999, 0.8019999999999999, 0.877, -0.028000000000000018, -1.006, -1.0], "policy_red_0_v7_reward": [0.872, -1.011, 0.9249999999999999, 0.921, 0.9319999999999999, 0.755, -1.007, -1.005, -0.009000000000000001], "policy_red_0_v5_reward": [0.941, -0.002, -1.004, -1.0, -1.004, -1.001, -1.001, -1.0], "policy_red_0_v8_reward": [-1.012, -0.1230000000000001, 0.638, -1.004, -0.003, -0.02900000000000002, -1.003], "policy_red_0_v3_reward": [0.95, -1.006, -1.003, 0.7349999999999999, -0.519], "policy_red_0_v1_reward": [0.979, -1.005, -1.005, -1.0, -0.5, -1.003], "policy_red_0_v9_reward": [0.533, -1.007, 0.904, -1.001, -1.0], "policy_red_0_v2_reward": [1.415, -1.004, 0.926, 1.4220000000000002, 0.91]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23028114259633842, "mean_inference_ms": 1.5033662380321773, "mean_action_processing_ms": 0.06250887273360507, "mean_env_wait_ms": 0.10628740821393352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018325209617614746, "StateBufferConnector_ms": 0.001478433609008789, "ViewRequirementAgentConnector_ms": 0.030855655670166016}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.55806881892967, "num_env_steps_trained_throughput_per_sec": 100.55806881892967, "timesteps_total": 340000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 680000, "timers": {"training_iteration_time_ms": 39462.783, "sample_time_ms": 7674.485, "learn_time_ms": 31770.603, "learn_throughput": 125.903, "synch_weights_time_ms": 17.038}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 680000, "num_agent_steps_trained": 680000}, "done": false, "episodes_total": 5537, "training_iteration": 85, "trial_id": "bb874_00000", "date": "2023-09-28_22-26-19", "timestamp": 1695954379, "time_this_iter_s": 39.78080105781555, "time_total_s": 3361.458872795105, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x357ea6470>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x3559235b0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355922680>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3361.458872795105, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 35.68771929824561, "ram_util_percent": 29.433333333333337}, "win_rate": 0.75, "league_size": 11}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.182359012713035, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03379147380849948, "policy_loss": -0.024204001812904608, "vf_loss": 0.11316623099846765, "vf_explained_var": 0.2381363886098067, "kl": 0.011001273257971416, "entropy": 0.7878948509693146, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 82080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "sampler_results": {"episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.5760000000000001, "episode_reward_mean": -0.09423, "episode_len_mean": 65.52, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"red_0_v7": -1.007, "red_0": -1.037, "red_0_v9": -1.001, "red_0_v1": -1.009, "blue_0": -1.024, "red_0_v6": -1.008, "red_0_v2": -1.005, "red_0_v5": -1.001, "red_0_v4": -1.014, "red_0_v8": -1.006, "red_0_v3": -1.008}, "policy_reward_max": {"red_0_v7": 0.755, "red_0": 0.981, "red_0_v9": 0.904, "red_0_v1": -0.5, "blue_0": 0.72, "red_0_v6": 0.877, "red_0_v2": 1.4220000000000002, "red_0_v5": -1.0, "red_0_v4": 0.958, "red_0_v8": 0.904, "red_0_v3": 0.938}, "policy_reward_mean": {"red_0_v7": -0.2583999999999999, "red_0": 0.45129000000000014, "red_0_v9": -0.296, "red_0_v1": -0.8026, "blue_0": -0.9075714285714286, "red_0_v6": -0.4854444444444444, "red_0_v2": 0.2506000000000001, "red_0_v5": -1.0005, "red_0_v4": -0.15489999999999998, "red_0_v8": -0.16153846153846152, "red_0_v3": -0.19566666666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.255, -0.10699999999999998, -0.039999999999999925, -0.03200000000000003, 0.371, -0.041000000000000036, -0.19400000000000006, -0.04399999999999993, -0.128, -0.08099999999999996, -0.09199999999999997, -0.31700000000000006, -0.02900000000000002, -0.09899999999999987, -0.050000000000000044, -0.18999999999999995, -0.1260000000000001, -0.051999999999999935, -0.06700000000000006, -0.039999999999999925, -0.16700000000000004, -0.20899999999999985, 0.41900000000000004, -0.04600000000000004, -0.15700000000000003, -0.15600000000000003, -0.1439999999999999, -0.028000000000000025, -0.09799999999999998, 0.396, -0.09899999999999998, -0.14100000000000001, -0.10799999999999998, -0.07699999999999974, -0.1399999999999999, -0.011000000000000003, -0.17900000000000005, -0.05399999999999994, -0.5760000000000001, -0.07400000000000005, -0.40200000000000014, -0.504, -0.5099999999999999, 0.20999999999999996, -0.06500000000000006, -0.3009999999999998, -0.052000000000000046, -0.07599999999999996, -0.061000000000000054, -0.062000000000000055, -0.17600000000000005, -0.2410000000000001, -0.12299999999999989, 0.11699999999999999, -0.049000000000000044, -0.1190000000000001, -0.09599999999999997, -0.1269999999999999, -0.027000000000000024, -0.08200000000000007, -0.04700000000000004, -0.03700000000000003, -0.07800000000000007, -0.15800000000000003, 0.15200000000000002, -0.243, -0.09399999999999986, -0.42600000000000005, -0.08799999999999986, -0.18700000000000006, -0.19400000000000006, -0.05400000000000005, -0.020000000000000018, 0.43799999999999994, -0.02400000000000002, -0.05999999999999994, -0.08800000000000006, -0.2709999999999999, 0.262, -0.17900000000000005, -0.02300000000000002, -0.030999999999999917, -0.028000000000000025, -0.038000000000000034, -0.15700000000000003, -0.11599999999999999, 0.405, -0.04600000000000004, -0.122, -0.027999999999999914, -0.061000000000000054, -0.11899999999999988, -0.06300000000000006, -0.04700000000000004, -0.17199999999999993, -0.25, -0.09199999999999986, -0.4929999999999999, -0.42300000000000004, -0.11499999999999999], "episode_lengths": [75, 32, 13, 10, 40, 13, 65, 13, 36, 23, 30, 89, 300, 32, 16, 62, 169, 15, 24, 11, 45, 63, 25, 14, 50, 52, 45, 300, 28, 32, 31, 50, 32, 25, 43, 300, 63, 17, 166, 300, 129, 159, 167, 89, 19, 89, 16, 27, 21, 22, 45, 69, 36, 122, 13, 178, 30, 40, 9, 24, 15, 11, 24, 48, 101, 75, 29, 134, 27, 57, 54, 16, 6, 300, 8, 19, 300, 88, 68, 57, 7, 10, 8, 12, 51, 35, 32, 151, 36, 9, 182, 36, 19, 15, 51, 80, 27, 148, 120, 33], "policy_red_0_v7_reward": [0.755, -1.007, -1.005, -0.009000000000000001, -0.026000000000000016], "policy_red_0_v9_reward": [0.904, -1.001, -1.0, 0.824, -0.503, -1.0], "policy_red_0_v1_reward": [-1.0, -0.5, -1.003, -1.009, -0.501], "policy_blue_0_reward": [-1.002, -0.505, -1.001, -1.0039999999999998, 0.72, -1.002, -1.011, -0.522, -1.007, -1.0119999999999998, -1.006, -1.0079999999999998, -1.0099999999999998, -1.024, -1.018, -0.514, -1.0159999999999998, -1.002, -1.004, -1.003, -1.01, -0.526, -1.002, -1.006, -1.001, -1.002, -0.516, -1.005, -1.024, -1.003, -1.001, -1.0, -1.001, -1.001, -1.006, -1.001, -1.009, -1.011, -1.011, -1.003, -1.016, -1.012], "policy_red_0_v6_reward": [0.8019999999999999, 0.877, -0.028000000000000018, -1.006, -1.0, -1.008, -1.001, -1.003, -1.002], "policy_red_0_v2_reward": [0.926, 1.4220000000000002, 0.91, -1.005, -1.0], "policy_red_0_v5_reward": [-1.001, -1.0], "policy_red_0_v4_reward": [-1.002, 0.958, 0.845, -1.002, -1.014, 0.919, -0.507, 0.765, -1.01, -0.501], "policy_red_0_v8_reward": [-0.003, -0.02900000000000002, -1.003, 0.904, -1.003, 0.849, 0.826, -1.006, 0.48, -1.001, -1.003, -1.0, 0.889], "policy_red_0_v3_reward": [-0.517, 0.938, -1.008]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2301043068840288, "mean_inference_ms": 1.5031835548500836, "mean_action_processing_ms": 0.062481809779209065, "mean_env_wait_ms": 0.10622728351493457, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018858671188354492, "StateBufferConnector_ms": 0.0015177726745605469, "ViewRequirementAgentConnector_ms": 0.0312654972076416}}, "episode_reward_max": 0.43799999999999994, "episode_reward_min": -0.5760000000000001, "episode_reward_mean": -0.09423, "episode_len_mean": 65.52, "episodes_this_iter": 57, "policy_reward_min": {"red_0_v7": -1.007, "red_0": -1.037, "red_0_v9": -1.001, "red_0_v1": -1.009, "blue_0": -1.024, "red_0_v6": -1.008, "red_0_v2": -1.005, "red_0_v5": -1.001, "red_0_v4": -1.014, "red_0_v8": -1.006, "red_0_v3": -1.008}, "policy_reward_max": {"red_0_v7": 0.755, "red_0": 0.981, "red_0_v9": 0.904, "red_0_v1": -0.5, "blue_0": 0.72, "red_0_v6": 0.877, "red_0_v2": 1.4220000000000002, "red_0_v5": -1.0, "red_0_v4": 0.958, "red_0_v8": 0.904, "red_0_v3": 0.938}, "policy_reward_mean": {"red_0_v7": -0.2583999999999999, "red_0": 0.45129000000000014, "red_0_v9": -0.296, "red_0_v1": -0.8026, "blue_0": -0.9075714285714286, "red_0_v6": -0.4854444444444444, "red_0_v2": 0.2506000000000001, "red_0_v5": -1.0005, "red_0_v4": -0.15489999999999998, "red_0_v8": -0.16153846153846152, "red_0_v3": -0.19566666666666668}, "hist_stats": {"episode_reward": [-0.255, -0.10699999999999998, -0.039999999999999925, -0.03200000000000003, 0.371, -0.041000000000000036, -0.19400000000000006, -0.04399999999999993, -0.128, -0.08099999999999996, -0.09199999999999997, -0.31700000000000006, -0.02900000000000002, -0.09899999999999987, -0.050000000000000044, -0.18999999999999995, -0.1260000000000001, -0.051999999999999935, -0.06700000000000006, -0.039999999999999925, -0.16700000000000004, -0.20899999999999985, 0.41900000000000004, -0.04600000000000004, -0.15700000000000003, -0.15600000000000003, -0.1439999999999999, -0.028000000000000025, -0.09799999999999998, 0.396, -0.09899999999999998, -0.14100000000000001, -0.10799999999999998, -0.07699999999999974, -0.1399999999999999, -0.011000000000000003, -0.17900000000000005, -0.05399999999999994, -0.5760000000000001, -0.07400000000000005, -0.40200000000000014, -0.504, -0.5099999999999999, 0.20999999999999996, -0.06500000000000006, -0.3009999999999998, -0.052000000000000046, -0.07599999999999996, -0.061000000000000054, -0.062000000000000055, -0.17600000000000005, -0.2410000000000001, -0.12299999999999989, 0.11699999999999999, -0.049000000000000044, -0.1190000000000001, -0.09599999999999997, -0.1269999999999999, -0.027000000000000024, -0.08200000000000007, -0.04700000000000004, -0.03700000000000003, -0.07800000000000007, -0.15800000000000003, 0.15200000000000002, -0.243, -0.09399999999999986, -0.42600000000000005, -0.08799999999999986, -0.18700000000000006, -0.19400000000000006, -0.05400000000000005, -0.020000000000000018, 0.43799999999999994, -0.02400000000000002, -0.05999999999999994, -0.08800000000000006, -0.2709999999999999, 0.262, -0.17900000000000005, -0.02300000000000002, -0.030999999999999917, -0.028000000000000025, -0.038000000000000034, -0.15700000000000003, -0.11599999999999999, 0.405, -0.04600000000000004, -0.122, -0.027999999999999914, -0.061000000000000054, -0.11899999999999988, -0.06300000000000006, -0.04700000000000004, -0.17199999999999993, -0.25, -0.09199999999999986, -0.4929999999999999, -0.42300000000000004, -0.11499999999999999], "episode_lengths": [75, 32, 13, 10, 40, 13, 65, 13, 36, 23, 30, 89, 300, 32, 16, 62, 169, 15, 24, 11, 45, 63, 25, 14, 50, 52, 45, 300, 28, 32, 31, 50, 32, 25, 43, 300, 63, 17, 166, 300, 129, 159, 167, 89, 19, 89, 16, 27, 21, 22, 45, 69, 36, 122, 13, 178, 30, 40, 9, 24, 15, 11, 24, 48, 101, 75, 29, 134, 27, 57, 54, 16, 6, 300, 8, 19, 300, 88, 68, 57, 7, 10, 8, 12, 51, 35, 32, 151, 36, 9, 182, 36, 19, 15, 51, 80, 27, 148, 120, 33], "policy_red_0_v7_reward": [0.755, -1.007, -1.005, -0.009000000000000001, -0.026000000000000016], "policy_red_0_v9_reward": [0.904, -1.001, -1.0, 0.824, -0.503, -1.0], "policy_red_0_v1_reward": [-1.0, -0.5, -1.003, -1.009, -0.501], "policy_blue_0_reward": [-1.002, -0.505, -1.001, -1.0039999999999998, 0.72, -1.002, -1.011, -0.522, -1.007, -1.0119999999999998, -1.006, -1.0079999999999998, -1.0099999999999998, -1.024, -1.018, -0.514, -1.0159999999999998, -1.002, -1.004, -1.003, -1.01, -0.526, -1.002, -1.006, -1.001, -1.002, -0.516, -1.005, -1.024, -1.003, -1.001, -1.0, -1.001, -1.001, -1.006, -1.001, -1.009, -1.011, -1.011, -1.003, -1.016, -1.012], "policy_red_0_v6_reward": [0.8019999999999999, 0.877, -0.028000000000000018, -1.006, -1.0, -1.008, -1.001, -1.003, -1.002], "policy_red_0_v2_reward": [0.926, 1.4220000000000002, 0.91, -1.005, -1.0], "policy_red_0_v5_reward": [-1.001, -1.0], "policy_red_0_v4_reward": [-1.002, 0.958, 0.845, -1.002, -1.014, 0.919, -0.507, 0.765, -1.01, -0.501], "policy_red_0_v8_reward": [-0.003, -0.02900000000000002, -1.003, 0.904, -1.003, 0.849, 0.826, -1.006, 0.48, -1.001, -1.003, -1.0, 0.889], "policy_red_0_v3_reward": [-0.517, 0.938, -1.008]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2301043068840288, "mean_inference_ms": 1.5031835548500836, "mean_action_processing_ms": 0.062481809779209065, "mean_env_wait_ms": 0.10622728351493457, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018858671188354492, "StateBufferConnector_ms": 0.0015177726745605469, "ViewRequirementAgentConnector_ms": 0.0312654972076416}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.52375696248524, "num_env_steps_trained_throughput_per_sec": 100.52375696248524, "timesteps_total": 344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 39476.849, "sample_time_ms": 7682.047, "learn_time_ms": 31777.091, "learn_throughput": 125.877, "synch_weights_time_ms": 17.049}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "episodes_total": 5594, "training_iteration": 86, "trial_id": "bb874_00000", "date": "2023-09-28_22-26-59", "timestamp": 1695954419, "time_this_iter_s": 39.79434418678284, "time_total_s": 3401.253216981888, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x357ea49a0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355f27eb0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355f25cf0>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3401.253216981888, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 36.18214285714286, "ram_util_percent": 29.40892857142857}, "win_rate": 0.81, "league_size": 11}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.167254198839267, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.02724124168647298, "policy_loss": -0.026749843319218296, "vf_loss": 0.10553560501818235, "vf_explained_var": 0.3996486860016982, "kl": 0.009906446483402458, "entropy": 0.7580065727854769, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 83040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000}, "sampler_results": {"episode_reward_max": 0.44699999999999995, "episode_reward_min": -0.4929999999999999, "episode_reward_mean": -0.08911999999999995, "episode_len_mean": 69.3, "episode_media": {}, "episodes_this_iter": 63, "policy_reward_min": {"red_0_v8": -1.006, "red_0": -1.036, "blue_0": -1.024, "red_0_v4": -1.01, "red_0_v6": -1.0059999999999998, "red_0_v7": -1.013, "red_0_v9": -1.002, "red_0_v1": -1.003, "red_0_v3": -1.008, "red_0_v2": -1.011, "red_0_v5": -1.005}, "policy_reward_max": {"red_0_v8": 0.889, "red_0": 0.983, "blue_0": 0.7979999999999999, "red_0_v4": 0.765, "red_0_v6": 0.923, "red_0_v7": 0.9239999999999999, "red_0_v9": 0.951, "red_0_v1": -0.501, "red_0_v3": 0.938, "red_0_v2": -1.002, "red_0_v5": 0.964}, "policy_reward_mean": {"red_0_v8": -0.29729999999999995, "red_0": 0.5186999999999999, "blue_0": -0.8653043478260871, "red_0_v4": -0.24866666666666667, "red_0_v6": -0.43249999999999994, "red_0_v7": -0.2264, "red_0_v9": -0.375, "red_0_v1": -0.752, "red_0_v3": -0.27375000000000005, "red_0_v2": -1.0065, "red_0_v5": -0.3808333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.15800000000000003, 0.15200000000000002, -0.243, -0.09399999999999986, -0.42600000000000005, -0.08799999999999986, -0.18700000000000006, -0.19400000000000006, -0.05400000000000005, -0.020000000000000018, 0.43799999999999994, -0.02400000000000002, -0.05999999999999994, -0.08800000000000006, -0.2709999999999999, 0.262, -0.17900000000000005, -0.02300000000000002, -0.030999999999999917, -0.028000000000000025, -0.038000000000000034, -0.15700000000000003, -0.11599999999999999, 0.405, -0.04600000000000004, -0.122, -0.027999999999999914, -0.061000000000000054, -0.11899999999999988, -0.06300000000000006, -0.04700000000000004, -0.17199999999999993, -0.25, -0.09199999999999986, -0.4929999999999999, -0.42300000000000004, -0.11499999999999999, -0.11000000000000008, -0.06800000000000005, -0.17700000000000005, -0.277, 0.43299999999999994, -0.278, -0.3530000000000001, -0.139, -0.15999999999999992, -0.08699999999999997, -0.007, -0.20999999999999996, -0.04799999999999993, -0.3779999999999999, -0.09999999999999987, -0.4069999999999999, -0.04799999999999993, -0.10499999999999987, -0.10199999999999998, -0.02400000000000002, -0.017000000000000015, -0.1439999999999999, -0.09799999999999998, -0.09499999999999975, 0.44299999999999995, 0.44699999999999995, -0.040999999999999925, -0.06699999999999995, -0.47499999999999987, -0.07899999999999996, -0.07599999999999985, -0.025000000000000015, -0.06200000000000005, -0.07899999999999996, -0.08099999999999985, -0.10699999999999998, -0.137, -0.04700000000000004, -0.041999999999999815, -0.12999999999999978, -0.20000000000000007, -0.2729999999999999, -0.026000000000000023, -0.051000000000000045, -0.2479999999999999, -0.06900000000000005, -0.16399999999999992, -0.16899999999999993, -0.18600000000000005, -0.08800000000000006, -0.03600000000000003, -0.09099999999999997, -0.11799999999999988, -0.1369999999999999, 0.2859999999999999, -0.03600000000000003, -0.05899999999999994, -0.026000000000000023, -0.08100000000000007, -0.18000000000000005, -0.029999999999999805, -0.07399999999999995, -0.04600000000000004], "episode_lengths": [48, 101, 75, 29, 134, 27, 57, 54, 16, 6, 300, 8, 19, 300, 88, 68, 57, 7, 10, 8, 12, 51, 35, 32, 151, 36, 9, 182, 36, 19, 15, 51, 80, 27, 148, 120, 33, 300, 300, 55, 83, 22, 78, 112, 43, 45, 27, 300, 61, 15, 119, 29, 130, 15, 34, 190, 8, 9, 43, 30, 27, 16, 17, 12, 22, 142, 25, 23, 300, 300, 24, 26, 36, 39, 15, 12, 40, 65, 86, 8, 16, 77, 300, 53, 50, 60, 300, 12, 31, 35, 40, 67, 12, 18, 8, 24, 56, 8, 19, 12], "policy_red_0_v8_reward": [0.849, 0.826, -1.006, 0.48, -1.001, -1.003, -1.0, 0.889, -1.003, -1.004], "policy_blue_0_reward": [-0.516, -1.005, -1.024, -1.003, -1.001, -1.0, -1.001, -1.001, -1.006, -1.001, -1.009, -1.011, -1.011, -1.003, -1.016, -1.012, 0.734, -0.5, -1.007, -1.004, -1.01, -1.003, -1.023, -1.0, -1.006, -1.005, -0.502, -1.021, -1.002, -1.004, -1.004, -1.005, -1.005, -1.001, -1.007, 0.7979999999999999, -1.007, -1.012, -1.003, -1.007, -0.047000000000000035, -1.005, -0.511, -1.005, -1.002, -1.008], "policy_red_0_v4_reward": [0.765, -1.01, -0.501], "policy_red_0_v6_reward": [-1.001, -1.003, -1.002, -0.01800000000000001, 0.6509999999999999, 0.923, -1.0039999999999998, -1.0059999999999998], "policy_red_0_v7_reward": [-0.026000000000000016, -0.006, -1.0, -0.011000000000000003, -0.02100000000000001, 0.904, -1.005, 0.9239999999999999, -1.013, -1.01], "policy_red_0_v9_reward": [-0.503, -1.0, -0.046000000000000034, -1.002, 0.951, -0.025000000000000015, -1.0], "policy_red_0_v1_reward": [-0.501, -1.003], "policy_red_0_v3_reward": [-0.517, 0.938, -1.008, -0.508], "policy_red_0_v2_reward": [-1.008, -1.011, -1.005, -1.002], "policy_red_0_v5_reward": [0.758, -1.0, -1.0, -1.002, -1.005, 0.964]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23003222408597046, "mean_inference_ms": 1.502472693532919, "mean_action_processing_ms": 0.062460020371929444, "mean_env_wait_ms": 0.1061705503181909, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018390655517578125, "StateBufferConnector_ms": 0.0015462636947631836, "ViewRequirementAgentConnector_ms": 0.030947566032409668}}, "episode_reward_max": 0.44699999999999995, "episode_reward_min": -0.4929999999999999, "episode_reward_mean": -0.08911999999999995, "episode_len_mean": 69.3, "episodes_this_iter": 63, "policy_reward_min": {"red_0_v8": -1.006, "red_0": -1.036, "blue_0": -1.024, "red_0_v4": -1.01, "red_0_v6": -1.0059999999999998, "red_0_v7": -1.013, "red_0_v9": -1.002, "red_0_v1": -1.003, "red_0_v3": -1.008, "red_0_v2": -1.011, "red_0_v5": -1.005}, "policy_reward_max": {"red_0_v8": 0.889, "red_0": 0.983, "blue_0": 0.7979999999999999, "red_0_v4": 0.765, "red_0_v6": 0.923, "red_0_v7": 0.9239999999999999, "red_0_v9": 0.951, "red_0_v1": -0.501, "red_0_v3": 0.938, "red_0_v2": -1.002, "red_0_v5": 0.964}, "policy_reward_mean": {"red_0_v8": -0.29729999999999995, "red_0": 0.5186999999999999, "blue_0": -0.8653043478260871, "red_0_v4": -0.24866666666666667, "red_0_v6": -0.43249999999999994, "red_0_v7": -0.2264, "red_0_v9": -0.375, "red_0_v1": -0.752, "red_0_v3": -0.27375000000000005, "red_0_v2": -1.0065, "red_0_v5": -0.3808333333333333}, "hist_stats": {"episode_reward": [-0.15800000000000003, 0.15200000000000002, -0.243, -0.09399999999999986, -0.42600000000000005, -0.08799999999999986, -0.18700000000000006, -0.19400000000000006, -0.05400000000000005, -0.020000000000000018, 0.43799999999999994, -0.02400000000000002, -0.05999999999999994, -0.08800000000000006, -0.2709999999999999, 0.262, -0.17900000000000005, -0.02300000000000002, -0.030999999999999917, -0.028000000000000025, -0.038000000000000034, -0.15700000000000003, -0.11599999999999999, 0.405, -0.04600000000000004, -0.122, -0.027999999999999914, -0.061000000000000054, -0.11899999999999988, -0.06300000000000006, -0.04700000000000004, -0.17199999999999993, -0.25, -0.09199999999999986, -0.4929999999999999, -0.42300000000000004, -0.11499999999999999, -0.11000000000000008, -0.06800000000000005, -0.17700000000000005, -0.277, 0.43299999999999994, -0.278, -0.3530000000000001, -0.139, -0.15999999999999992, -0.08699999999999997, -0.007, -0.20999999999999996, -0.04799999999999993, -0.3779999999999999, -0.09999999999999987, -0.4069999999999999, -0.04799999999999993, -0.10499999999999987, -0.10199999999999998, -0.02400000000000002, -0.017000000000000015, -0.1439999999999999, -0.09799999999999998, -0.09499999999999975, 0.44299999999999995, 0.44699999999999995, -0.040999999999999925, -0.06699999999999995, -0.47499999999999987, -0.07899999999999996, -0.07599999999999985, -0.025000000000000015, -0.06200000000000005, -0.07899999999999996, -0.08099999999999985, -0.10699999999999998, -0.137, -0.04700000000000004, -0.041999999999999815, -0.12999999999999978, -0.20000000000000007, -0.2729999999999999, -0.026000000000000023, -0.051000000000000045, -0.2479999999999999, -0.06900000000000005, -0.16399999999999992, -0.16899999999999993, -0.18600000000000005, -0.08800000000000006, -0.03600000000000003, -0.09099999999999997, -0.11799999999999988, -0.1369999999999999, 0.2859999999999999, -0.03600000000000003, -0.05899999999999994, -0.026000000000000023, -0.08100000000000007, -0.18000000000000005, -0.029999999999999805, -0.07399999999999995, -0.04600000000000004], "episode_lengths": [48, 101, 75, 29, 134, 27, 57, 54, 16, 6, 300, 8, 19, 300, 88, 68, 57, 7, 10, 8, 12, 51, 35, 32, 151, 36, 9, 182, 36, 19, 15, 51, 80, 27, 148, 120, 33, 300, 300, 55, 83, 22, 78, 112, 43, 45, 27, 300, 61, 15, 119, 29, 130, 15, 34, 190, 8, 9, 43, 30, 27, 16, 17, 12, 22, 142, 25, 23, 300, 300, 24, 26, 36, 39, 15, 12, 40, 65, 86, 8, 16, 77, 300, 53, 50, 60, 300, 12, 31, 35, 40, 67, 12, 18, 8, 24, 56, 8, 19, 12], "policy_red_0_v8_reward": [0.849, 0.826, -1.006, 0.48, -1.001, -1.003, -1.0, 0.889, -1.003, -1.004], "policy_blue_0_reward": [-0.516, -1.005, -1.024, -1.003, -1.001, -1.0, -1.001, -1.001, -1.006, -1.001, -1.009, -1.011, -1.011, -1.003, -1.016, -1.012, 0.734, -0.5, -1.007, -1.004, -1.01, -1.003, -1.023, -1.0, -1.006, -1.005, -0.502, -1.021, -1.002, -1.004, -1.004, -1.005, -1.005, -1.001, -1.007, 0.7979999999999999, -1.007, -1.012, -1.003, -1.007, -0.047000000000000035, -1.005, -0.511, -1.005, -1.002, -1.008], "policy_red_0_v4_reward": [0.765, -1.01, -0.501], "policy_red_0_v6_reward": [-1.001, -1.003, -1.002, -0.01800000000000001, 0.6509999999999999, 0.923, -1.0039999999999998, -1.0059999999999998], "policy_red_0_v7_reward": [-0.026000000000000016, -0.006, -1.0, -0.011000000000000003, -0.02100000000000001, 0.904, -1.005, 0.9239999999999999, -1.013, -1.01], "policy_red_0_v9_reward": [-0.503, -1.0, -0.046000000000000034, -1.002, 0.951, -0.025000000000000015, -1.0], "policy_red_0_v1_reward": [-0.501, -1.003], "policy_red_0_v3_reward": [-0.517, 0.938, -1.008, -0.508], "policy_red_0_v2_reward": [-1.008, -1.011, -1.005, -1.002], "policy_red_0_v5_reward": [0.758, -1.0, -1.0, -1.002, -1.005, 0.964]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23003222408597046, "mean_inference_ms": 1.502472693532919, "mean_action_processing_ms": 0.062460020371929444, "mean_env_wait_ms": 0.1061705503181909, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018390655517578125, "StateBufferConnector_ms": 0.0015462636947631836, "ViewRequirementAgentConnector_ms": 0.030947566032409668}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 100.27604515556806, "num_env_steps_trained_throughput_per_sec": 100.27604515556806, "timesteps_total": 348000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 696000, "timers": {"training_iteration_time_ms": 39521.537, "sample_time_ms": 7688.097, "learn_time_ms": 31815.647, "learn_throughput": 125.724, "synch_weights_time_ms": 17.124}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 696000, "num_agent_steps_trained": 696000}, "done": false, "episodes_total": 5657, "training_iteration": 87, "trial_id": "bb874_00000", "date": "2023-09-28_22-27-39", "timestamp": 1695954459, "time_this_iter_s": 39.89255428314209, "time_total_s": 3441.14577126503, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x357a04af0>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x355f26440>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x355f26b90>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3441.14577126503, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 35.81578947368421, "ram_util_percent": 29.663157894736838}, "win_rate": 0.85, "league_size": 11}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1188020344202716, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.03984082555155813, "policy_loss": -0.02599383941172467, "vf_loss": 0.12878776170546188, "vf_explained_var": 0.3047318548584978, "kl": 0.011033217763530315, "entropy": 0.765859856766959, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "sampler_results": {"episode_reward_max": 0.45599999999999996, "episode_reward_min": -0.6700000000000002, "episode_reward_mean": -0.07633999999999996, "episode_len_mean": 51.49, "episode_media": {}, "episodes_this_iter": 76, "policy_reward_min": {"blue_0": -1.022, "red_0": -1.054, "red_0_v2": -1.019, "red_0_v9": -1.0, "red_0_v5": -1.005, "red_0_v7": -1.013, "red_0_v6": -1.0059999999999998, "red_0_v8": -1.005, "red_0_v1": -1.01, "red_0_v4": -1.002, "red_0_v3": -1.03}, "policy_reward_max": {"blue_0": 0.9359999999999999, "red_0": 0.979, "red_0_v2": 0.9259999999999999, "red_0_v9": 1.4409999999999998, "red_0_v5": 0.964, "red_0_v7": 0.9239999999999999, "red_0_v6": 0.9209999999999999, "red_0_v8": 1.363, "red_0_v1": -1.0, "red_0_v4": 0.976, "red_0_v3": -1.016}, "policy_reward_mean": {"blue_0": -0.8524038461538461, "red_0": 0.5469299999999999, "red_0_v2": -0.6216, "red_0_v9": 0.27933333333333327, "red_0_v5": -0.017499999999999988, "red_0_v7": -0.5399090909090908, "red_0_v6": -0.04249999999999993, "red_0_v8": -0.3257142857142856, "red_0_v1": -1.0036666666666665, "red_0_v4": -0.025599999999999977, "red_0_v3": -1.0230000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.12999999999999978, -0.20000000000000007, -0.2729999999999999, -0.026000000000000023, -0.051000000000000045, -0.2479999999999999, -0.06900000000000005, -0.16399999999999992, -0.16899999999999993, -0.18600000000000005, -0.08800000000000006, -0.03600000000000003, -0.09099999999999997, -0.11799999999999988, -0.1369999999999999, 0.2859999999999999, -0.03600000000000003, -0.05899999999999994, -0.026000000000000023, -0.08100000000000007, -0.18000000000000005, -0.029999999999999805, -0.07399999999999995, -0.04600000000000004, -0.08399999999999985, -0.03200000000000003, -0.11899999999999977, -0.07200000000000006, -0.08999999999999997, -0.1609999999999998, -0.4119999999999999, 0.43999999999999995, -0.04699999999999993, 0.346, -0.027000000000000024, -0.038000000000000034, -0.061999999999999944, -0.05800000000000005, -0.17700000000000005, -0.04400000000000004, 0.42000000000000004, -0.053999999999999826, -0.11699999999999988, -0.29000000000000004, -0.07799999999999985, -0.12199999999999989, -0.19899999999999995, -0.1570000000000001, -0.07799999999999985, -0.04399999999999982, -0.17500000000000004, -0.132, -0.05999999999999983, -0.04899999999999993, -0.06799999999999995, -0.3420000000000001, -0.09899999999999998, 0.3599999999999999, -0.08999999999999997, -0.05599999999999994, 0.2609999999999998, -0.09699999999999998, -0.02400000000000002, -0.03699999999999992, -0.05800000000000005, -0.14900000000000002, -0.06800000000000006, 0.397, -0.05000000000000004, -0.027999999999999914, -0.03499999999999992, -0.08299999999999996, -0.18399999999999983, -0.136, -0.05400000000000005, -0.05800000000000005, -0.04799999999999993, -0.01800000000000001, -0.15399999999999991, -0.2519999999999999, -0.06299999999999994, -0.07400000000000007, -0.04899999999999982, -0.119, -0.09199999999999986, -0.2559999999999999, -0.5619999999999999, -0.03400000000000003, -0.03799999999999992, -0.02199999999999991, -0.31200000000000006, -0.029000000000000026, -0.029000000000000026, -0.2599999999999999, -0.04400000000000004, -0.030000000000000027, -0.07599999999999985, -0.6700000000000002, 0.45599999999999996, -0.15699999999999992], "episode_lengths": [40, 65, 86, 8, 16, 77, 300, 53, 50, 60, 300, 12, 31, 35, 40, 67, 12, 18, 8, 24, 56, 8, 19, 12, 27, 10, 37, 24, 28, 49, 129, 19, 14, 45, 9, 12, 19, 18, 53, 14, 26, 16, 36, 76, 24, 37, 62, 300, 25, 12, 53, 42, 18, 14, 21, 96, 31, 45, 26, 17, 300, 31, 8, 14, 18, 45, 20, 30, 300, 9, 10, 30, 60, 44, 21, 18, 15, 300, 45, 71, 20, 22, 13, 37, 27, 75, 171, 10, 11, 7, 82, 9, 9, 81, 12, 10, 23, 198, 14, 48], "policy_blue_0_reward": [-1.007, 0.7979999999999999, -1.007, -1.012, -1.003, -1.007, -0.047000000000000035, -1.005, -0.511, -1.005, -1.002, -1.008, -1.002, -1.002, -1.004, -1.007, -1.005, -0.508, -1.0, -1.001, -1.001, -1.012, -1.0019999999999998, 0.764, -1.003, -1.006, -1.011, -1.005, -1.004, -1.005, -1.013, -1.006, -1.002, -1.003, -1.004, -1.006, -1.002, -0.5, -1.0099999999999998, 0.9359999999999999, -1.002, -1.013, -1.002, -1.005, -1.009, -1.019, -1.001, -1.001, -1.002, -1.003, -1.0059999999999998, -1.022], "policy_red_0_v2_reward": [-1.002, -1.019, 0.9259999999999999, -1.009, -1.004], "policy_red_0_v9_reward": [0.951, -0.025000000000000015, -1.0, 1.4409999999999998, 0.81, -0.501], "policy_red_0_v5_reward": [-1.005, 0.964, -0.025000000000000015, -0.004], "policy_red_0_v7_reward": [0.904, -1.005, 0.9239999999999999, -1.013, -1.01, -1.004, -1.005, 0.2819999999999998, -1.005, -1.003, -1.0039999999999998], "policy_red_0_v6_reward": [-1.0059999999999998, 0.9209999999999999], "policy_red_0_v8_reward": [-1.005, -0.501, -1.001, 1.363, -1.0, 0.866, -1.002], "policy_red_0_v1_reward": [-1.0, -1.004, -1.003, -1.003, -1.002, -1.01], "policy_red_0_v4_reward": [0.976, -0.012000000000000004, 0.91, -1.002, -1.0], "policy_red_0_v3_reward": [-1.03, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23042376606040327, "mean_inference_ms": 1.5041044517435445, "mean_action_processing_ms": 0.06256054793656766, "mean_env_wait_ms": 0.1064012757078407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01868152618408203, "StateBufferConnector_ms": 0.0015388727188110352, "ViewRequirementAgentConnector_ms": 0.03116893768310547}}, "episode_reward_max": 0.45599999999999996, "episode_reward_min": -0.6700000000000002, "episode_reward_mean": -0.07633999999999996, "episode_len_mean": 51.49, "episodes_this_iter": 76, "policy_reward_min": {"blue_0": -1.022, "red_0": -1.054, "red_0_v2": -1.019, "red_0_v9": -1.0, "red_0_v5": -1.005, "red_0_v7": -1.013, "red_0_v6": -1.0059999999999998, "red_0_v8": -1.005, "red_0_v1": -1.01, "red_0_v4": -1.002, "red_0_v3": -1.03}, "policy_reward_max": {"blue_0": 0.9359999999999999, "red_0": 0.979, "red_0_v2": 0.9259999999999999, "red_0_v9": 1.4409999999999998, "red_0_v5": 0.964, "red_0_v7": 0.9239999999999999, "red_0_v6": 0.9209999999999999, "red_0_v8": 1.363, "red_0_v1": -1.0, "red_0_v4": 0.976, "red_0_v3": -1.016}, "policy_reward_mean": {"blue_0": -0.8524038461538461, "red_0": 0.5469299999999999, "red_0_v2": -0.6216, "red_0_v9": 0.27933333333333327, "red_0_v5": -0.017499999999999988, "red_0_v7": -0.5399090909090908, "red_0_v6": -0.04249999999999993, "red_0_v8": -0.3257142857142856, "red_0_v1": -1.0036666666666665, "red_0_v4": -0.025599999999999977, "red_0_v3": -1.0230000000000001}, "hist_stats": {"episode_reward": [-0.12999999999999978, -0.20000000000000007, -0.2729999999999999, -0.026000000000000023, -0.051000000000000045, -0.2479999999999999, -0.06900000000000005, -0.16399999999999992, -0.16899999999999993, -0.18600000000000005, -0.08800000000000006, -0.03600000000000003, -0.09099999999999997, -0.11799999999999988, -0.1369999999999999, 0.2859999999999999, -0.03600000000000003, -0.05899999999999994, -0.026000000000000023, -0.08100000000000007, -0.18000000000000005, -0.029999999999999805, -0.07399999999999995, -0.04600000000000004, -0.08399999999999985, -0.03200000000000003, -0.11899999999999977, -0.07200000000000006, -0.08999999999999997, -0.1609999999999998, -0.4119999999999999, 0.43999999999999995, -0.04699999999999993, 0.346, -0.027000000000000024, -0.038000000000000034, -0.061999999999999944, -0.05800000000000005, -0.17700000000000005, -0.04400000000000004, 0.42000000000000004, -0.053999999999999826, -0.11699999999999988, -0.29000000000000004, -0.07799999999999985, -0.12199999999999989, -0.19899999999999995, -0.1570000000000001, -0.07799999999999985, -0.04399999999999982, -0.17500000000000004, -0.132, -0.05999999999999983, -0.04899999999999993, -0.06799999999999995, -0.3420000000000001, -0.09899999999999998, 0.3599999999999999, -0.08999999999999997, -0.05599999999999994, 0.2609999999999998, -0.09699999999999998, -0.02400000000000002, -0.03699999999999992, -0.05800000000000005, -0.14900000000000002, -0.06800000000000006, 0.397, -0.05000000000000004, -0.027999999999999914, -0.03499999999999992, -0.08299999999999996, -0.18399999999999983, -0.136, -0.05400000000000005, -0.05800000000000005, -0.04799999999999993, -0.01800000000000001, -0.15399999999999991, -0.2519999999999999, -0.06299999999999994, -0.07400000000000007, -0.04899999999999982, -0.119, -0.09199999999999986, -0.2559999999999999, -0.5619999999999999, -0.03400000000000003, -0.03799999999999992, -0.02199999999999991, -0.31200000000000006, -0.029000000000000026, -0.029000000000000026, -0.2599999999999999, -0.04400000000000004, -0.030000000000000027, -0.07599999999999985, -0.6700000000000002, 0.45599999999999996, -0.15699999999999992], "episode_lengths": [40, 65, 86, 8, 16, 77, 300, 53, 50, 60, 300, 12, 31, 35, 40, 67, 12, 18, 8, 24, 56, 8, 19, 12, 27, 10, 37, 24, 28, 49, 129, 19, 14, 45, 9, 12, 19, 18, 53, 14, 26, 16, 36, 76, 24, 37, 62, 300, 25, 12, 53, 42, 18, 14, 21, 96, 31, 45, 26, 17, 300, 31, 8, 14, 18, 45, 20, 30, 300, 9, 10, 30, 60, 44, 21, 18, 15, 300, 45, 71, 20, 22, 13, 37, 27, 75, 171, 10, 11, 7, 82, 9, 9, 81, 12, 10, 23, 198, 14, 48], "policy_blue_0_reward": [-1.007, 0.7979999999999999, -1.007, -1.012, -1.003, -1.007, -0.047000000000000035, -1.005, -0.511, -1.005, -1.002, -1.008, -1.002, -1.002, -1.004, -1.007, -1.005, -0.508, -1.0, -1.001, -1.001, -1.012, -1.0019999999999998, 0.764, -1.003, -1.006, -1.011, -1.005, -1.004, -1.005, -1.013, -1.006, -1.002, -1.003, -1.004, -1.006, -1.002, -0.5, -1.0099999999999998, 0.9359999999999999, -1.002, -1.013, -1.002, -1.005, -1.009, -1.019, -1.001, -1.001, -1.002, -1.003, -1.0059999999999998, -1.022], "policy_red_0_v2_reward": [-1.002, -1.019, 0.9259999999999999, -1.009, -1.004], "policy_red_0_v9_reward": [0.951, -0.025000000000000015, -1.0, 1.4409999999999998, 0.81, -0.501], "policy_red_0_v5_reward": [-1.005, 0.964, -0.025000000000000015, -0.004], "policy_red_0_v7_reward": [0.904, -1.005, 0.9239999999999999, -1.013, -1.01, -1.004, -1.005, 0.2819999999999998, -1.005, -1.003, -1.0039999999999998], "policy_red_0_v6_reward": [-1.0059999999999998, 0.9209999999999999], "policy_red_0_v8_reward": [-1.005, -0.501, -1.001, 1.363, -1.0, 0.866, -1.002], "policy_red_0_v1_reward": [-1.0, -1.004, -1.003, -1.003, -1.002, -1.01], "policy_red_0_v4_reward": [0.976, -0.012000000000000004, 0.91, -1.002, -1.0], "policy_red_0_v3_reward": [-1.03, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23042376606040327, "mean_inference_ms": 1.5041044517435445, "mean_action_processing_ms": 0.06256054793656766, "mean_env_wait_ms": 0.1064012757078407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01868152618408203, "StateBufferConnector_ms": 0.0015388727188110352, "ViewRequirementAgentConnector_ms": 0.03116893768310547}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 99.91160048313547, "num_env_steps_trained_throughput_per_sec": 99.91160048313547, "timesteps_total": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 39587.918, "sample_time_ms": 7680.75, "learn_time_ms": 31889.3, "learn_throughput": 125.434, "synch_weights_time_ms": 17.198}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "episodes_total": 5733, "training_iteration": 88, "trial_id": "bb874_00000", "date": "2023-09-28_22-28-19", "timestamp": 1695954499, "time_this_iter_s": 40.038208961486816, "time_total_s": 3481.1839802265167, "pid": 23546, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"blue": 1, "red": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.9, "key_pickup_sparse_reward": 0.01, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300, "policies_map": {"red_0": "<multigrid.agents_pool.JaiAslam_policies.JaiAslam_Policy.JaiAslam_Policy object at 0x357944280>"}, "team_policies_mapping": {"red_0": "JaiAslam_Policy"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"blue": 1, "red": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"blue_0": [null, null, null, null], "red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x35617be20>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<function train.<locals>.<lambda> at 0x35617bd00>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3481.1839802265167, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 36.56140350877193, "ram_util_percent": 29.75087719298245}, "win_rate": 0.84, "league_size": 11}
