{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5994225210820635, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.024107205669376224, "policy_loss": -0.01689604377267339, "vf_loss": 0.019916269087116235, "vf_explained_var": -0.08884449992328883, "kl": 0.010905488120303432, "entropy": 1.9350395135581493, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.657182829392453, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.005168620662516332, "policy_loss": -0.020338378948993825, "vf_loss": 0.029110671509018478, "vf_explained_var": 0.19380681564410526, "kl": 0.012738806611733936, "entropy": 1.9333380407343308, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.4462685523935, "num_env_steps_trained_throughput_per_sec": 51.4462685523935, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 8000, "timers": {"training_iteration_time_ms": 77750.976, "sample_time_ms": 8518.907, "learn_time_ms": 69199.337, "learn_throughput": 57.804, "synch_weights_time_ms": 32.065}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "b02c7_00000", "date": "2023-09-27_22-01-00", "timestamp": 1695866460, "time_this_iter_s": 77.75246381759644, "time_total_s": 77.75246381759644, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a411d2d0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a411cd00>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea2b00>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 77.75246381759644, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 36.1981981981982, "ram_util_percent": 31.37927927927929}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7360896365717053, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03127961565818017, "policy_loss": -0.01665839026827598, "vf_loss": 0.0038414581273779427, "vf_explained_var": 0.06744158770889044, "kl": 0.01309607289887893, "entropy": 1.916116946314772, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7983574274927377, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010141014336538016, "policy_loss": -0.015409247124625835, "vf_loss": 0.01050812423612418, "vf_explained_var": -0.03377519994974136, "kl": 0.009654200515642825, "entropy": 1.9166697586576145, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 50.809489810058906, "num_env_steps_trained_throughput_per_sec": 50.809489810058906, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 78238.204, "sample_time_ms": 8798.012, "learn_time_ms": 69407.665, "learn_throughput": 57.631, "synch_weights_time_ms": 31.878}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 0, "training_iteration": 2, "trial_id": "b02c7_00000", "date": "2023-09-27_22-02-19", "timestamp": 1695866539, "time_this_iter_s": 78.72670888900757, "time_total_s": 156.479172706604, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a4194160>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a4196ad0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428acb0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 156.479172706604, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 34.02035398230089, "ram_util_percent": 31.409734513274337}}
{"custom_metrics": {"red_0/door_open_done_mean": 1.0, "red_0/door_open_done_min": 1, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8208330197570225, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.030823704565106406, "policy_loss": -0.013716868504949768, "vf_loss": 0.0008173671037790579, "vf_explained_var": -0.43565865444640317, "kl": 0.00751270382626501, "entropy": 1.901806133116285, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9605749680660665, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008575617117094226, "policy_loss": -0.015141332237059638, "vf_loss": 0.012407095544525267, "vf_explained_var": 0.34431341184924047, "kl": 0.011247090665355815, "entropy": 1.8872509632259606, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "sampler_results": {"episode_reward_max": 1.6718625000000007, "episode_reward_min": 1.6718625000000007, "episode_reward_mean": 1.6718625000000007, "episode_len_mean": 956.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"red_0": 1.866862500000001, "red_1": -0.19500000000000015}, "policy_reward_max": {"red_0": 1.866862500000001, "red_1": -0.19500000000000015}, "policy_reward_mean": {"red_0": 1.866862500000001, "red_1": -0.19500000000000015}, "custom_metrics": {"red_0/door_open_done_mean": 1.0, "red_0/door_open_done_min": 1, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007], "episode_lengths": [956], "policy_red_0_reward": [1.866862500000001], "policy_red_1_reward": [-0.19500000000000015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2386431015103584, "mean_inference_ms": 1.759838204300473, "mean_action_processing_ms": 0.07434411410189587, "mean_env_wait_ms": 0.13093864987235979, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021946430206298828, "StateBufferConnector_ms": 0.0016808509826660156, "ViewRequirementAgentConnector_ms": 0.03731250762939453}}, "episode_reward_max": 1.6718625000000007, "episode_reward_min": 1.6718625000000007, "episode_reward_mean": 1.6718625000000007, "episode_len_mean": 956.0, "episodes_this_iter": 1, "policy_reward_min": {"red_0": 1.866862500000001, "red_1": -0.19500000000000015}, "policy_reward_max": {"red_0": 1.866862500000001, "red_1": -0.19500000000000015}, "policy_reward_mean": {"red_0": 1.866862500000001, "red_1": -0.19500000000000015}, "hist_stats": {"episode_reward": [1.6718625000000007], "episode_lengths": [956], "policy_red_0_reward": [1.866862500000001], "policy_red_1_reward": [-0.19500000000000015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2386431015103584, "mean_inference_ms": 1.759838204300473, "mean_action_processing_ms": 0.07434411410189587, "mean_env_wait_ms": 0.13093864987235979, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021946430206298828, "StateBufferConnector_ms": 0.0016808509826660156, "ViewRequirementAgentConnector_ms": 0.03731250762939453}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 50.98044972479405, "num_env_steps_trained_throughput_per_sec": 50.98044972479405, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 24000, "timers": {"training_iteration_time_ms": 78312.613, "sample_time_ms": 8886.065, "learn_time_ms": 69394.073, "learn_throughput": 57.642, "synch_weights_time_ms": 31.845}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 1, "training_iteration": 3, "trial_id": "b02c7_00000", "date": "2023-09-27_22-03-37", "timestamp": 1695866617, "time_this_iter_s": 78.46301007270813, "time_total_s": 234.94218277931213, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42c0730>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42c0a60>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea2d40>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 234.94218277931213, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 37.215315315315316, "ram_util_percent": 31.507207207207216}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.1, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9076446230833729, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03355954076796479, "policy_loss": -0.0195868381037144, "vf_loss": 0.004109128743584734, "vf_explained_var": 0.4265672481308381, "kl": 0.013081600400923795, "entropy": 1.8643587602923313, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1563990967348219, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0017578306296248533, "policy_loss": -0.01627899425341942, "vf_loss": 0.02815216415425918, "vf_explained_var": 0.43768107537180184, "kl": 0.011492007591281586, "entropy": 1.853319231669108, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "sampler_results": {"episode_reward_max": 1.6718625000000007, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.0589172252772987, "episode_len_mean": 1247.6, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 1.866862500000001, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 0.799512225277297, "red_1": 0.2594049999999983}, "custom_metrics": {"red_0/door_open_done_mean": 0.1, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23935577835305372, "mean_inference_ms": 1.7736989742641835, "mean_action_processing_ms": 0.07517726068511023, "mean_env_wait_ms": 0.1319456309123414, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02010941505432129, "StateBufferConnector_ms": 0.0016367435455322266, "ViewRequirementAgentConnector_ms": 0.036379098892211914}}, "episode_reward_max": 1.6718625000000007, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.0589172252772987, "episode_len_mean": 1247.6, "episodes_this_iter": 9, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 1.866862500000001, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 0.799512225277297, "red_1": 0.2594049999999983}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23935577835305372, "mean_inference_ms": 1.7736989742641835, "mean_action_processing_ms": 0.07517726068511023, "mean_env_wait_ms": 0.1319456309123414, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02010941505432129, "StateBufferConnector_ms": 0.0016367435455322266, "ViewRequirementAgentConnector_ms": 0.036379098892211914}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.308605354613576, "num_env_steps_trained_throughput_per_sec": 51.308605354613576, "timesteps_total": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 78224.364, "sample_time_ms": 8932.896, "learn_time_ms": 69259.288, "learn_throughput": 57.754, "synch_weights_time_ms": 31.549}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 10, "training_iteration": 4, "trial_id": "b02c7_00000", "date": "2023-09-27_22-04-55", "timestamp": 1695866695, "time_this_iter_s": 77.96146726608276, "time_total_s": 312.9036500453949, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a6660a30>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a6660b80>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9f9a0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 312.9036500453949, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 35.48482142857143, "ram_util_percent": 31.32767857142857}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.18181818181818182, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9254697481480737, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.034517923083906984, "policy_loss": -0.018978408232699924, "vf_loss": 0.001436158239539509, "vf_explained_var": 0.18778257711480062, "kl": 0.011505454229955744, "entropy": 1.8558685299009086, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.231906680824856, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008907437363995995, "policy_loss": -0.017007816624997455, "vf_loss": 0.01557575277305053, "vf_explained_var": 0.3575290406743685, "kl": 0.010761442640537501, "entropy": 1.8397849220782518, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "sampler_results": {"episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.172140943433908, "episode_len_mean": 1165.3636363636363, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 0.9446363979793613, "red_1": 0.2275045454545439}, "custom_metrics": {"red_0/door_open_done_mean": 0.18181818181818182, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23967275203535932, "mean_inference_ms": 1.776717504061277, "mean_action_processing_ms": 0.07533925136552143, "mean_env_wait_ms": 0.13233240610356306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020257993177934128, "StateBufferConnector_ms": 0.001625581221147017, "ViewRequirementAgentConnector_ms": 0.03636208447543057}}, "episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.172140943433908, "episode_len_mean": 1165.3636363636363, "episodes_this_iter": 1, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 0.9446363979793613, "red_1": 0.2275045454545439}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23967275203535932, "mean_inference_ms": 1.776717504061277, "mean_action_processing_ms": 0.07533925136552143, "mean_env_wait_ms": 0.13233240610356306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020257993177934128, "StateBufferConnector_ms": 0.001625581221147017, "ViewRequirementAgentConnector_ms": 0.03636208447543057}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.34460947270111, "num_env_steps_trained_throughput_per_sec": 51.34460947270111, "timesteps_total": 20000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 40000, "timers": {"training_iteration_time_ms": 78160.481, "sample_time_ms": 8954.998, "learn_time_ms": 69173.364, "learn_throughput": 57.826, "synch_weights_time_ms": 31.484}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 11, "training_iteration": 5, "trial_id": "b02c7_00000", "date": "2023-09-27_22-06-14", "timestamp": 1695866774, "time_this_iter_s": 77.9066309928894, "time_total_s": 390.8102810382843, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x3574fd810>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x3574fd600>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428ea70>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 390.8102810382843, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 35.309909909909905, "ram_util_percent": 31.39189189189188}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.23076923076923078, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9810294376375774, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03451948821123854, "policy_loss": -0.019188270573795307, "vf_loss": 0.002029747339050421, "vf_explained_var": 0.25775861653188864, "kl": 0.010706317909402888, "entropy": 1.8487355745087066, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2524111425504088, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.014074193913135484, "policy_loss": -0.01755949495272944, "vf_loss": 0.005974544690858844, "vf_explained_var": 0.6313912662367026, "kl": 0.011573329424638188, "entropy": 1.8166368582596382, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "sampler_results": {"episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2129387494011996, "episode_len_mean": 1160.3846153846155, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.0188964417088906, "red_1": 0.19404230769230635}, "custom_metrics": {"red_0/door_open_done_mean": 0.23076923076923078, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23958670993767608, "mean_inference_ms": 1.7763958632393937, "mean_action_processing_ms": 0.07532460493806202, "mean_env_wait_ms": 0.13231313953370816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02020872556246244, "StateBufferConnector_ms": 0.0016038234417255109, "ViewRequirementAgentConnector_ms": 0.036525726318359375}}, "episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2129387494011996, "episode_len_mean": 1160.3846153846155, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.0188964417088906, "red_1": 0.19404230769230635}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23958670993767608, "mean_inference_ms": 1.7763958632393937, "mean_action_processing_ms": 0.07532460493806202, "mean_env_wait_ms": 0.13231313953370816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02020872556246244, "StateBufferConnector_ms": 0.0016038234417255109, "ViewRequirementAgentConnector_ms": 0.036525726318359375}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.14054599391086, "num_env_steps_trained_throughput_per_sec": 51.14054599391086, "timesteps_total": 24000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 78169.703, "sample_time_ms": 8971.546, "learn_time_ms": 69166.095, "learn_throughput": 57.832, "synch_weights_time_ms": 31.427}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 13, "training_iteration": 6, "trial_id": "b02c7_00000", "date": "2023-09-27_22-07-32", "timestamp": 1695866852, "time_this_iter_s": 78.21755003929138, "time_total_s": 469.0278310775757, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354d93bb0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354d91cc0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9edd0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 469.0278310775757, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 37.26607142857143, "ram_util_percent": 31.623214285714287}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.15, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0752143014843265, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03564017571934528, "policy_loss": -0.020438528781717955, "vf_loss": 0.0009274930645612282, "vf_explained_var": 0.5347442629436652, "kl": 0.012855716388281153, "entropy": 1.8236538196603458, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3701670206462344, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.005118849361557902, "policy_loss": -0.023343639905215242, "vf_loss": 0.034199894832757614, "vf_explained_var": 0.48611524781833093, "kl": 0.01438245382384438, "entropy": 1.751647040868799, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "sampler_results": {"episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2733826342274668, "episode_len_mean": 1202.25, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.0883276342274664, "red_1": 0.18505499999999966}, "custom_metrics": {"red_0/door_open_done_mean": 0.15, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23979305813272916, "mean_inference_ms": 1.7799428865133429, "mean_action_processing_ms": 0.07551425598364023, "mean_env_wait_ms": 0.1325284324191594, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020227432250976562, "StateBufferConnector_ms": 0.001640915870666504, "ViewRequirementAgentConnector_ms": 0.036487579345703125}}, "episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2733826342274668, "episode_len_mean": 1202.25, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.0883276342274664, "red_1": 0.18505499999999966}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23979305813272916, "mean_inference_ms": 1.7799428865133429, "mean_action_processing_ms": 0.07551425598364023, "mean_env_wait_ms": 0.1325284324191594, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020227432250976562, "StateBufferConnector_ms": 0.001640915870666504, "ViewRequirementAgentConnector_ms": 0.036487579345703125}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 50.932687016775255, "num_env_steps_trained_throughput_per_sec": 50.932687016775255, "timesteps_total": 28000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 56000, "timers": {"training_iteration_time_ms": 78221.89, "sample_time_ms": 8995.596, "learn_time_ms": 69193.925, "learn_throughput": 57.809, "synch_weights_time_ms": 31.724}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "done": false, "episodes_total": 20, "training_iteration": 7, "trial_id": "b02c7_00000", "date": "2023-09-27_22-08-51", "timestamp": 1695866931, "time_this_iter_s": 78.53725790977478, "time_total_s": 547.5650889873505, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354d928f0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354d91720>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428f6d0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 547.5650889873505, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 35.60982142857143, "ram_util_percent": 31.695535714285718}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.18181818181818182, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1334800424054265, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.034277890280645804, "policy_loss": -0.01938732551158561, "vf_loss": 0.0017706690838470726, "vf_explained_var": 0.6383062667523821, "kl": 0.011604263337060654, "entropy": 1.8096752577771744, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5165447177365423, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.018040172868738106, "policy_loss": -0.021467617486875194, "vf_loss": 0.005560667808701207, "vf_explained_var": 0.3314516645545761, "kl": 0.011949292067822626, "entropy": 1.742747042576472, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "sampler_results": {"episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2501212867976974, "episode_len_mean": 1171.2727272727273, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.0498667413431513, "red_1": 0.20025454545454513}, "custom_metrics": {"red_0/door_open_done_mean": 0.18181818181818182, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2400434703610757, "mean_inference_ms": 1.7819983968695838, "mean_action_processing_ms": 0.07562229345756882, "mean_env_wait_ms": 0.13276541975547407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02113905819979581, "StateBufferConnector_ms": 0.0016391277313232422, "ViewRequirementAgentConnector_ms": 0.03646991469643333}}, "episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2501212867976974, "episode_len_mean": 1171.2727272727273, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.2790000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.0498667413431513, "red_1": 0.20025454545454513}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2400434703610757, "mean_inference_ms": 1.7819983968695838, "mean_action_processing_ms": 0.07562229345756882, "mean_env_wait_ms": 0.13276541975547407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02113905819979581, "StateBufferConnector_ms": 0.0016391277313232422, "ViewRequirementAgentConnector_ms": 0.03646991469643333}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 50.89007574248861, "num_env_steps_trained_throughput_per_sec": 50.89007574248861, "timesteps_total": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 78269.25, "sample_time_ms": 9019.448, "learn_time_ms": 69216.86, "learn_throughput": 57.789, "synch_weights_time_ms": 32.286}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "episodes_total": 22, "training_iteration": 8, "trial_id": "b02c7_00000", "date": "2023-09-27_22-10-10", "timestamp": 1695867010, "time_this_iter_s": 78.60313296318054, "time_total_s": 626.168221950531, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42ca5c0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42ca410>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9d480>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 626.168221950531, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 36.36785714285714, "ram_util_percent": 31.74285714285715}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2692307692307692, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1105158069481453, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.028227797025222875, "policy_loss": -0.015091246393179365, "vf_loss": 0.00609105064055863, "vf_explained_var": 0.4938863324622313, "kl": 0.010245830434629491, "entropy": 1.8231242518872022, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.500642660818994, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.006846270856597888, "policy_loss": -0.014693993256272127, "vf_loss": 0.014512235963047715, "vf_explained_var": 0.3498185219243169, "kl": 0.011387253021713188, "entropy": 1.6858458828181029, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "sampler_results": {"episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2988658280381526, "episode_len_mean": 1131.076923076923, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.1363812126535373, "red_1": 0.16248461538461506}, "custom_metrics": {"red_0/door_open_done_mean": 0.2692307692307692, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2402712664534663, "mean_inference_ms": 1.7843850649136697, "mean_action_processing_ms": 0.07575612393884888, "mean_env_wait_ms": 0.13305956776052175, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021431537774892952, "StateBufferConnector_ms": 0.0016239973214956431, "ViewRequirementAgentConnector_ms": 0.0363927621107835}}, "episode_reward_max": 2.304378125000001, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.2988658280381526, "episode_len_mean": 1131.076923076923, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.1363812126535373, "red_1": 0.16248461538461506}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2402712664534663, "mean_inference_ms": 1.7843850649136697, "mean_action_processing_ms": 0.07575612393884888, "mean_env_wait_ms": 0.13305956776052175, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021431537774892952, "StateBufferConnector_ms": 0.0016239973214956431, "ViewRequirementAgentConnector_ms": 0.0363927621107835}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.12078509228746, "num_env_steps_trained_throughput_per_sec": 51.12078509228746, "timesteps_total": 36000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 72000, "timers": {"training_iteration_time_ms": 78266.672, "sample_time_ms": 9036.169, "learn_time_ms": 69197.689, "learn_throughput": 57.805, "synch_weights_time_ms": 32.156}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 26, "training_iteration": 9, "trial_id": "b02c7_00000", "date": "2023-09-27_22-11-28", "timestamp": 1695867088, "time_this_iter_s": 78.24822402000427, "time_total_s": 704.4164459705353, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a401f670>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a401faf0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66eb7f0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 704.4164459705353, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 35.296396396396396, "ram_util_percent": 31.841441441441454}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.25, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.208628855397304, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0364787911493598, "policy_loss": -0.022608294693539695, "vf_loss": 0.0034571523027504252, "vf_explained_var": 0.6849628589426477, "kl": 0.0124405216201321, "entropy": 1.8087177178512017, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.475954149539272, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010708406477321356, "policy_loss": -0.02133178216754459, "vf_loss": 0.019400596379030806, "vf_explained_var": 0.7197326449056466, "kl": 0.01273972532725306, "entropy": 1.6248674030105272, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "sampler_results": {"episode_reward_max": 2.305658605000008, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.365887568310668, "episode_len_mean": 1136.25, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.1952321584910162, "red_1": 0.17065540981965238}, "custom_metrics": {"red_0/door_open_done_mean": 0.25, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2404071920829533, "mean_inference_ms": 1.7867084961865816, "mean_action_processing_ms": 0.07585847753624719, "mean_env_wait_ms": 0.13327211096524788, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02123601734638214, "StateBufferConnector_ms": 0.0016041100025177002, "ViewRequirementAgentConnector_ms": 0.03643445670604706}}, "episode_reward_max": 2.305658605000008, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.365887568310668, "episode_len_mean": 1136.25, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.1952321584910162, "red_1": 0.17065540981965238}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2404071920829533, "mean_inference_ms": 1.7867084961865816, "mean_action_processing_ms": 0.07585847753624719, "mean_env_wait_ms": 0.13327211096524788, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02123601734638214, "StateBufferConnector_ms": 0.0016041100025177002, "ViewRequirementAgentConnector_ms": 0.03643445670604706}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 50.87151359509976, "num_env_steps_trained_throughput_per_sec": 50.87151359509976, "timesteps_total": 40000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 78302.95, "sample_time_ms": 9046.773, "learn_time_ms": 69223.392, "learn_throughput": 57.784, "synch_weights_time_ms": 32.125}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 32, "training_iteration": 10, "trial_id": "b02c7_00000", "date": "2023-09-27_22-12-47", "timestamp": 1695867167, "time_this_iter_s": 78.63199424743652, "time_total_s": 783.0484402179718, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x29d5b51e0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x29d5b5ab0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66e8c10>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 783.0484402179718, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 34.39026548672567, "ram_util_percent": 31.855752212389387}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2857142857142857, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.276544576138258, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.035572424856218275, "policy_loss": -0.021362095786510812, "vf_loss": 0.0021529455936009374, "vf_explained_var": 0.44147570841014383, "kl": 0.013950542526175084, "entropy": 1.8076911579817534, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4224469073116779, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01875870702363803, "policy_loss": -0.023531484170719826, "vf_loss": 0.006502092475178263, "vf_explained_var": 0.5474746440226833, "kl": 0.015860379496366952, "entropy": 1.650344635422031, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "sampler_results": {"episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.4087211939021067, "episode_len_mean": 1104.2, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.233593390638425, "red_1": 0.17512780326368219}, "custom_metrics": {"red_0/door_open_done_mean": 0.2857142857142857, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24052750232508438, "mean_inference_ms": 1.7876417061211685, "mean_action_processing_ms": 0.07591358161551116, "mean_env_wait_ms": 0.13339351982225595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021224362509591237, "StateBufferConnector_ms": 0.0016164779663085938, "ViewRequirementAgentConnector_ms": 0.036444664001464844}}, "episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.4087211939021067, "episode_len_mean": 1104.2, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.233593390638425, "red_1": 0.17512780326368219}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24052750232508438, "mean_inference_ms": 1.7876417061211685, "mean_action_processing_ms": 0.07591358161551116, "mean_env_wait_ms": 0.13339351982225595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021224362509591237, "StateBufferConnector_ms": 0.0016164779663085938, "ViewRequirementAgentConnector_ms": 0.036444664001464844}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.02841260228682, "num_env_steps_trained_throughput_per_sec": 51.02841260228682, "timesteps_total": 44000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 88000, "timers": {"training_iteration_time_ms": 78366.621, "sample_time_ms": 9106.141, "learn_time_ms": 69227.773, "learn_throughput": 57.78, "synch_weights_time_ms": 32.047}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "done": false, "episodes_total": 35, "training_iteration": 11, "trial_id": "b02c7_00000", "date": "2023-09-27_22-14-06", "timestamp": 1695867246, "time_this_iter_s": 78.39000391960144, "time_total_s": 861.4384441375732, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42c0070>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42c0ac0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428dea0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 861.4384441375732, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 35.12792792792793, "ram_util_percent": 31.885585585585584}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2777777777777778, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3098516687750816, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03276403678507146, "policy_loss": -0.018131257820641622, "vf_loss": 0.0016749358280018594, "vf_explained_var": 0.6930883219465613, "kl": 0.011696057237127659, "entropy": 1.7809458327790102, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3851608928292989, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.012201948460763863, "policy_loss": -0.01635277931103095, "vf_loss": 0.007653166200058573, "vf_explained_var": 0.6788874261081219, "kl": 0.00954801452649967, "entropy": 1.5853551062444846, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "sampler_results": {"episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.4153315284552754, "episode_len_mean": 1109.0833333333333, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2360128308378076, "red_1": 0.17931869761746877}, "custom_metrics": {"red_0/door_open_done_mean": 0.2777777777777778, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24054527366876938, "mean_inference_ms": 1.787976610101725, "mean_action_processing_ms": 0.07593922603911159, "mean_env_wait_ms": 0.1334339987174298, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02122289604610867, "StateBufferConnector_ms": 0.0016328361299302843, "ViewRequirementAgentConnector_ms": 0.03648632102542453}}, "episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.4153315284552754, "episode_len_mean": 1109.0833333333333, "episodes_this_iter": 1, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2360128308378076, "red_1": 0.17931869761746877}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24054527366876938, "mean_inference_ms": 1.787976610101725, "mean_action_processing_ms": 0.07593922603911159, "mean_env_wait_ms": 0.1334339987174298, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02122289604610867, "StateBufferConnector_ms": 0.0016328361299302843, "ViewRequirementAgentConnector_ms": 0.03648632102542453}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.2466530962886, "num_env_steps_trained_throughput_per_sec": 51.2466530962886, "timesteps_total": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 78299.464, "sample_time_ms": 9111.298, "learn_time_ms": 69155.493, "learn_throughput": 57.841, "synch_weights_time_ms": 32.009}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 36, "training_iteration": 12, "trial_id": "b02c7_00000", "date": "2023-09-27_22-15-24", "timestamp": 1695867324, "time_this_iter_s": 78.05615091323853, "time_total_s": 939.4945950508118, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42c1ba0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42c16c0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428f130>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 939.4945950508118, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 35.65446428571429, "ram_util_percent": 31.797321428571426}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.28888888888888886, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3317369868357976, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03422502948797046, "policy_loss": -0.020325054812807743, "vf_loss": 0.0024716153257031692, "vf_explained_var": 0.7875033302232624, "kl": 0.011457556829790405, "entropy": 1.7427293731520572, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.515667281113565, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008723551715835736, "policy_loss": -0.021069924666759714, "vf_loss": 0.022865681410379087, "vf_explained_var": 0.651336393567423, "kl": 0.012296086657102023, "entropy": 1.5456855467210213, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "sampler_results": {"episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.4595791388586963, "episode_len_mean": 1095.1555555555556, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2124119585425002, "red_1": 0.24716718031619742}, "custom_metrics": {"red_0/door_open_done_mean": 0.28888888888888886, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2407556086334323, "mean_inference_ms": 1.7909829666608355, "mean_action_processing_ms": 0.07609920618625103, "mean_env_wait_ms": 0.1337727764183006, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021524959140353732, "StateBufferConnector_ms": 0.0016506512959798176, "ViewRequirementAgentConnector_ms": 0.036706659528944224}}, "episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.4595791388586963, "episode_len_mean": 1095.1555555555556, "episodes_this_iter": 9, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2124119585425002, "red_1": 0.24716718031619742}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2407556086334323, "mean_inference_ms": 1.7909829666608355, "mean_action_processing_ms": 0.07609920618625103, "mean_env_wait_ms": 0.1337727764183006, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021524959140353732, "StateBufferConnector_ms": 0.0016506512959798176, "ViewRequirementAgentConnector_ms": 0.036706659528944224}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 54.32685484728368, "num_env_steps_trained_throughput_per_sec": 54.32685484728368, "timesteps_total": 52000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 104000, "timers": {"training_iteration_time_ms": 77816.16, "sample_time_ms": 9122.728, "learn_time_ms": 68660.765, "learn_throughput": 58.257, "synch_weights_time_ms": 31.999}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "done": false, "episodes_total": 45, "training_iteration": 13, "trial_id": "b02c7_00000", "date": "2023-09-27_22-16-38", "timestamp": 1695867398, "time_this_iter_s": 73.63106298446655, "time_total_s": 1013.1256580352783, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3c35ed0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3c35cc0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66e9f30>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1013.1256580352783, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 36.46666666666667, "ram_util_percent": 31.8552380952381}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.30434782608695654, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3068532297387718, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.033135145264532186, "policy_loss": -0.01847545031851041, "vf_loss": 0.0008976875729634534, "vf_explained_var": 0.6643988284592827, "kl": 0.012403207085921493, "entropy": 1.7589180391281842, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5244509464129805, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.016912672082010735, "policy_loss": -0.021622773750762766, "vf_loss": 0.006540552033523757, "vf_explained_var": 0.5410661593700449, "kl": 0.014916234448045258, "entropy": 1.543420938650767, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "sampler_results": {"episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.48077964916212, "episode_len_mean": 1083.804347826087, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2297465379832324, "red_1": 0.25103311117888877}, "custom_metrics": {"red_0/door_open_done_mean": 0.30434782608695654, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24073927747881643, "mean_inference_ms": 1.790876334810905, "mean_action_processing_ms": 0.07609431176903464, "mean_env_wait_ms": 0.13378338604364873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021444455437038257, "StateBufferConnector_ms": 0.0016489754552426546, "ViewRequirementAgentConnector_ms": 0.036596733590830925}}, "episode_reward_max": 2.473130737816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.48077964916212, "episode_len_mean": 1083.804347826087, "episodes_this_iter": 1, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2297465379832324, "red_1": 0.25103311117888877}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24073927747881643, "mean_inference_ms": 1.790876334810905, "mean_action_processing_ms": 0.07609431176903464, "mean_env_wait_ms": 0.13378338604364873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021444455437038257, "StateBufferConnector_ms": 0.0016489754552426546, "ViewRequirementAgentConnector_ms": 0.036596733590830925}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.40348294628316, "num_env_steps_trained_throughput_per_sec": 55.40348294628316, "timesteps_total": 56000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 77239.96, "sample_time_ms": 9004.455, "learn_time_ms": 68202.752, "learn_throughput": 58.649, "synch_weights_time_ms": 32.081}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "episodes_total": 46, "training_iteration": 14, "trial_id": "b02c7_00000", "date": "2023-09-27_22-17-51", "timestamp": 1695867471, "time_this_iter_s": 72.20017409324646, "time_total_s": 1085.3258321285248, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x29c88ab90>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3ac9a20>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9e290>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1085.3258321285248, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 36.80776699029126, "ram_util_percent": 31.824271844660196}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3333333333333333, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2982001806919774, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0349243142032113, "policy_loss": -0.020600895253786198, "vf_loss": 0.000986503784300415, "vf_explained_var": 0.837405555571119, "kl": 0.012178898921207404, "entropy": 1.7252451325456302, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5618085785458484, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.013625054190439793, "policy_loss": -0.024048482220920656, "vf_loss": 0.018096887556021103, "vf_explained_var": 0.7081717209269603, "kl": 0.014163130349328234, "entropy": 1.4576416455209256, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "sampler_results": {"episode_reward_max": 2.474552612816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5322193868724354, "episode_len_mean": 1071.921568627451, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2711306983581452, "red_1": 0.26108868851429184}, "custom_metrics": {"red_0/door_open_done_mean": 0.3333333333333333, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24045527626506882, "mean_inference_ms": 1.789047256520143, "mean_action_processing_ms": 0.07598469013890212, "mean_env_wait_ms": 0.13369171973386673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02100350810032265, "StateBufferConnector_ms": 0.0016214800815956265, "ViewRequirementAgentConnector_ms": 0.035981337229410805}}, "episode_reward_max": 2.474552612816173, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5322193868724354, "episode_len_mean": 1071.921568627451, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.18100000000000013, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2711306983581452, "red_1": 0.26108868851429184}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24045527626506882, "mean_inference_ms": 1.789047256520143, "mean_action_processing_ms": 0.07598469013890212, "mean_env_wait_ms": 0.13369171973386673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02100350810032265, "StateBufferConnector_ms": 0.0016214800815956265, "ViewRequirementAgentConnector_ms": 0.035981337229410805}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.411726484369616, "num_env_steps_trained_throughput_per_sec": 55.411726484369616, "timesteps_total": 60000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 120000, "timers": {"training_iteration_time_ms": 76668.152, "sample_time_ms": 8888.228, "learn_time_ms": 67747.148, "learn_throughput": 59.043, "synch_weights_time_ms": 32.104}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 51, "training_iteration": 15, "trial_id": "b02c7_00000", "date": "2023-09-27_22-19-03", "timestamp": 1695867543, "time_this_iter_s": 72.18953609466553, "time_total_s": 1157.5153682231903, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a66623b0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a66618a0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea1cf0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1157.5153682231903, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 37.193203883495144, "ram_util_percent": 31.809708737864074}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3392857142857143, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2602186451355617, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03374848217257143, "policy_loss": -0.019154696997914774, "vf_loss": 0.0005671896030889911, "vf_explained_var": 0.8276356614505251, "kl": 0.011781801331813823, "entropy": 1.7233740732073783, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.42476270844539, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010666673241818596, "policy_loss": -0.017688095353272124, "vf_loss": 0.01291558665931613, "vf_explained_var": 0.5635470991333326, "kl": 0.010101302952304735, "entropy": 1.456632175669074, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "sampler_results": {"episode_reward_max": 2.521286987816174, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5373201396239782, "episode_len_mean": 1072.1607142857142, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2595875840127495, "red_1": 0.27773255561123017}, "custom_metrics": {"red_0/door_open_done_mean": 0.3392857142857143, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24000923474341537, "mean_inference_ms": 1.7863147312885848, "mean_action_processing_ms": 0.07579579954653363, "mean_env_wait_ms": 0.13342532420971387, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020888234887804304, "StateBufferConnector_ms": 0.0016048550605773926, "ViewRequirementAgentConnector_ms": 0.0355258584022522}}, "episode_reward_max": 2.521286987816174, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5373201396239782, "episode_len_mean": 1072.1607142857142, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2595875840127495, "red_1": 0.27773255561123017}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24000923474341537, "mean_inference_ms": 1.7863147312885848, "mean_action_processing_ms": 0.07579579954653363, "mean_env_wait_ms": 0.13342532420971387, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020888234887804304, "StateBufferConnector_ms": 0.0016048550605773926, "ViewRequirementAgentConnector_ms": 0.0355258584022522}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.343701203570305, "num_env_steps_trained_throughput_per_sec": 55.343701203570305, "timesteps_total": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 76074.131, "sample_time_ms": 8773.464, "learn_time_ms": 67267.857, "learn_throughput": 59.464, "synch_weights_time_ms": 32.137}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "episodes_total": 56, "training_iteration": 16, "trial_id": "b02c7_00000", "date": "2023-09-27_22-20-16", "timestamp": 1695867616, "time_this_iter_s": 72.27836990356445, "time_total_s": 1229.7937381267548, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42cbca0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42c9300>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66ea200>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1229.7937381267548, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 36.72330097087379, "ram_util_percent": 31.76601941747573}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3620689655172414, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4298513881241282, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.031033438424735018, "policy_loss": -0.01866861902963137, "vf_loss": 0.004373253770851685, "vf_explained_var": 0.6505606169501941, "kl": 0.012333208030203876, "entropy": 1.7018088174362977, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.518776779435575, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.005033072982769227, "policy_loss": -0.018522565688666268, "vf_loss": 0.024489312113534348, "vf_explained_var": 0.38243046489854654, "kl": 0.012986270163858837, "entropy": 1.3524165281405052, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "sampler_results": {"episode_reward_max": 2.521286987816174, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5597744470992927, "episode_len_mean": 1052.8620689655172, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2613430140953477, "red_1": 0.29843143300394637}, "custom_metrics": {"red_0/door_open_done_mean": 0.3620689655172414, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23985923845608717, "mean_inference_ms": 1.7851521974646622, "mean_action_processing_ms": 0.07572285906973203, "mean_env_wait_ms": 0.13337016181601127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02073316738523286, "StateBufferConnector_ms": 0.0015994598125589304, "ViewRequirementAgentConnector_ms": 0.03535768081401956}}, "episode_reward_max": 2.521286987816174, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5597744470992927, "episode_len_mean": 1052.8620689655172, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.395878125000004, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2613430140953477, "red_1": 0.29843143300394637}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23985923845608717, "mean_inference_ms": 1.7851521974646622, "mean_action_processing_ms": 0.07572285906973203, "mean_env_wait_ms": 0.13337016181601127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02073316738523286, "StateBufferConnector_ms": 0.0015994598125589304, "ViewRequirementAgentConnector_ms": 0.03535768081401956}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.469482404216976, "num_env_steps_trained_throughput_per_sec": 55.469482404216976, "timesteps_total": 68000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 136000, "timers": {"training_iteration_time_ms": 75431.801, "sample_time_ms": 8648.063, "learn_time_ms": 66751.143, "learn_throughput": 59.924, "synch_weights_time_ms": 31.932}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "done": false, "episodes_total": 58, "training_iteration": 17, "trial_id": "b02c7_00000", "date": "2023-09-27_22-21-28", "timestamp": 1695867688, "time_this_iter_s": 72.11439418792725, "time_total_s": 1301.908132314682, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3b5f550>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3b5d1e0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428da20>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1301.908132314682, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 37.012621359223296, "ram_util_percent": 31.785436893203876}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.375, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3934827202931046, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03419750971503769, "policy_loss": -0.020404778308875392, "vf_loss": 0.001588977620182656, "vf_explained_var": 0.8549643296127518, "kl": 0.011432970346184755, "entropy": 1.6873814675956964, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4438463230617344, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008497297919681538, "policy_loss": -0.019064394525291087, "vf_loss": 0.019992396748178484, "vf_explained_var": 0.636980897312363, "kl": 0.009513730615570723, "entropy": 1.3318487143764892, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5987777304037478, "episode_len_mean": 1033.203125, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.283347681743923, "red_1": 0.3154300486598264}, "custom_metrics": {"red_0/door_open_done_mean": 0.375, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23919394951885461, "mean_inference_ms": 1.780653238643597, "mean_action_processing_ms": 0.07544707518959565, "mean_env_wait_ms": 0.13300323520289142, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020487233996391296, "StateBufferConnector_ms": 0.0015756115317344666, "ViewRequirementAgentConnector_ms": 0.0349532812833786}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.5987777304037478, "episode_len_mean": 1033.203125, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.283347681743923, "red_1": 0.3154300486598264}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23919394951885461, "mean_inference_ms": 1.780653238643597, "mean_action_processing_ms": 0.07544707518959565, "mean_env_wait_ms": 0.13300323520289142, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020487233996391296, "StateBufferConnector_ms": 0.0015756115317344666, "ViewRequirementAgentConnector_ms": 0.0349532812833786}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.404241322524385, "num_env_steps_trained_throughput_per_sec": 55.404241322524385, "timesteps_total": 72000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 74791.386, "sample_time_ms": 8517.162, "learn_time_ms": 66242.173, "learn_throughput": 60.384, "synch_weights_time_ms": 31.399}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 64, "training_iteration": 18, "trial_id": "b02c7_00000", "date": "2023-09-27_22-22-41", "timestamp": 1695867761, "time_this_iter_s": 72.19951605796814, "time_total_s": 1374.1076483726501, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a39f33d0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a39f1090>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428cd30>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1374.1076483726501, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 37.064077669902915, "ram_util_percent": 31.886407766990303}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.38235294117647056, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4196108302101493, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03246536565226658, "policy_loss": -0.01832980839632607, "vf_loss": 0.0007226779704978981, "vf_explained_var": 0.7598460853099823, "kl": 0.011360440322371542, "entropy": 1.6768984561165174, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4393037475024661, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009483838699452463, "policy_loss": -0.015353720257310972, "vf_loss": 0.01034118463624812, "vf_explained_var": 0.6819857565686107, "kl": 0.010238499011658556, "entropy": 1.3484094332903624, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.61907300509518, "episode_len_mean": 1024.1764705882354, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2988594298859333, "red_1": 0.32021357520924837}, "custom_metrics": {"red_0/door_open_done_mean": 0.38235294117647056, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2387000654416853, "mean_inference_ms": 1.7775975048902237, "mean_action_processing_ms": 0.07524257371515308, "mean_env_wait_ms": 0.13271150430021383, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020241737365722656, "StateBufferConnector_ms": 0.001568128080929027, "ViewRequirementAgentConnector_ms": 0.03465133554795209}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.61907300509518, "episode_len_mean": 1024.1764705882354, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.19200000000000014, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.4580499999999925}, "policy_reward_mean": {"red_0": 1.2988594298859333, "red_1": 0.32021357520924837}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2387000654416853, "mean_inference_ms": 1.7775975048902237, "mean_action_processing_ms": 0.07524257371515308, "mean_env_wait_ms": 0.13271150430021383, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020241737365722656, "StateBufferConnector_ms": 0.001568128080929027, "ViewRequirementAgentConnector_ms": 0.03465133554795209}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.38578528668965, "num_env_steps_trained_throughput_per_sec": 55.38578528668965, "timesteps_total": 76000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 152000, "timers": {"training_iteration_time_ms": 74188.85, "sample_time_ms": 8390.291, "learn_time_ms": 65766.395, "learn_throughput": 60.821, "synch_weights_time_ms": 31.506}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "done": false, "episodes_total": 68, "training_iteration": 19, "trial_id": "b02c7_00000", "date": "2023-09-27_22-23-53", "timestamp": 1695867833, "time_this_iter_s": 72.22400212287903, "time_total_s": 1446.3316504955292, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3a4fa30>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3a4f790>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66eb370>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1446.3316504955292, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 37.78446601941747, "ram_util_percent": 32.11067961165049}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3783783783783784, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.322613919340074, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03548146851632434, "policy_loss": -0.023023619778784147, "vf_loss": 0.0031641483558208466, "vf_explained_var": 0.4916794078424573, "kl": 0.01258740910744004, "entropy": 1.6557404726743699, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4866746977282068, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009546947792781186, "policy_loss": -0.018845422716306834, "vf_loss": 0.017005405921130052, "vf_explained_var": 0.6707376171524326, "kl": 0.010572133520831507, "entropy": 1.3186547987163066, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6321284919288792, "episode_len_mean": 1027.4594594594594, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2754824551825439, "red_1": 0.3566460367463362}, "custom_metrics": {"red_0/door_open_done_mean": 0.3783783783783784, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2380699472092684, "mean_inference_ms": 1.7732495100515668, "mean_action_processing_ms": 0.07496362723904146, "mean_env_wait_ms": 0.1323605893008361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019950963355399465, "StateBufferConnector_ms": 0.0015576143522520324, "ViewRequirementAgentConnector_ms": 0.03429361291833826}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6321284919288792, "episode_len_mean": 1027.4594594594594, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2754824551825439, "red_1": 0.3566460367463362}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2380699472092684, "mean_inference_ms": 1.7732495100515668, "mean_action_processing_ms": 0.07496362723904146, "mean_env_wait_ms": 0.1323605893008361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019950963355399465, "StateBufferConnector_ms": 0.0015576143522520324, "ViewRequirementAgentConnector_ms": 0.03429361291833826}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.524292493533984, "num_env_steps_trained_throughput_per_sec": 55.524292493533984, "timesteps_total": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 73529.956, "sample_time_ms": 8261.131, "learn_time_ms": 65236.738, "learn_throughput": 61.315, "synch_weights_time_ms": 31.434}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 74, "training_iteration": 20, "trial_id": "b02c7_00000", "date": "2023-09-27_22-25-05", "timestamp": 1695867905, "time_this_iter_s": 72.04366111755371, "time_total_s": 1518.3753116130829, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3e28790>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3e2ba00>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9c700>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1518.3753116130829, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 36.080582524271854, "ram_util_percent": 32.17766990291262}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3783783783783784, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.452245172051092, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03142369666412984, "policy_loss": -0.018205492890653357, "vf_loss": 0.0014229471905309766, "vf_explained_var": 0.5947879562775295, "kl": 0.013879557069785577, "entropy": 1.6705589776237806, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5298165182893475, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01897008467149135, "policy_loss": -0.021125799430834983, "vf_loss": 0.0029114859255059853, "vf_explained_var": 0.17194958856950204, "kl": 0.009843020317472905, "entropy": 1.268633271753788, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6321284919288792, "episode_len_mean": 1027.4594594594594, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2754824551825439, "red_1": 0.3566460367463362}, "custom_metrics": {"red_0/door_open_done_mean": 0.3783783783783784, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2380699472092684, "mean_inference_ms": 1.7732495100515668, "mean_action_processing_ms": 0.07496362723904146, "mean_env_wait_ms": 0.1323605893008361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019950963355399465, "StateBufferConnector_ms": 0.0015576143522520324, "ViewRequirementAgentConnector_ms": 0.03429361291833826}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6321284919288792, "episode_len_mean": 1027.4594594594594, "episodes_this_iter": 0, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2754824551825439, "red_1": 0.3566460367463362}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2380699472092684, "mean_inference_ms": 1.7732495100515668, "mean_action_processing_ms": 0.07496362723904146, "mean_env_wait_ms": 0.1323605893008361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019950963355399465, "StateBufferConnector_ms": 0.0015576143522520324, "ViewRequirementAgentConnector_ms": 0.03429361291833826}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.27601556790041, "num_env_steps_trained_throughput_per_sec": 55.27601556790041, "timesteps_total": 84000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 168000, "timers": {"training_iteration_time_ms": 72927.598, "sample_time_ms": 8141.636, "learn_time_ms": 64753.777, "learn_throughput": 61.772, "synch_weights_time_ms": 31.532}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "done": false, "episodes_total": 74, "training_iteration": 21, "trial_id": "b02c7_00000", "date": "2023-09-27_22-26-18", "timestamp": 1695867978, "time_this_iter_s": 72.36719083786011, "time_total_s": 1590.742502450943, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a6662500>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a6662530>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66e85e0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1590.742502450943, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 37.591262135922335, "ram_util_percent": 32.31553398058253}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3717948717948718, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5264439943556984, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03162299380965124, "policy_loss": -0.01951012331119273, "vf_loss": 0.0037170670280223324, "vf_explained_var": 0.6345212748274207, "kl": 0.0129841189997467, "entropy": 1.6568228335430224, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3302521128517886, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011686636865366988, "policy_loss": -0.015047019948542583, "vf_loss": 0.00587389420082521, "vf_explained_var": 0.7040200227871537, "kl": 0.008378453217081491, "entropy": 1.2522547110915183, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6368776055000231, "episode_len_mean": 1036.8333333333333, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2734109782756526, "red_1": 0.3634666272243717}, "custom_metrics": {"red_0/door_open_done_mean": 0.3717948717948718, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23754718485021342, "mean_inference_ms": 1.7699342187665281, "mean_action_processing_ms": 0.07474590947912695, "mean_env_wait_ms": 0.13206006252449093, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019926749742948092, "StateBufferConnector_ms": 0.0015512490883851664, "ViewRequirementAgentConnector_ms": 0.03407597541809082}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6368776055000231, "episode_len_mean": 1036.8333333333333, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2734109782756526, "red_1": 0.3634666272243717}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23754718485021342, "mean_inference_ms": 1.7699342187665281, "mean_action_processing_ms": 0.07474590947912695, "mean_env_wait_ms": 0.13206006252449093, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019926749742948092, "StateBufferConnector_ms": 0.0015512490883851664, "ViewRequirementAgentConnector_ms": 0.03407597541809082}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.53960264983094, "num_env_steps_trained_throughput_per_sec": 55.53960264983094, "timesteps_total": 88000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 72324.279, "sample_time_ms": 8013.102, "learn_time_ms": 64278.969, "learn_throughput": 62.229, "synch_weights_time_ms": 31.557}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "episodes_total": 78, "training_iteration": 22, "trial_id": "b02c7_00000", "date": "2023-09-27_22-27-30", "timestamp": 1695868050, "time_this_iter_s": 72.02379202842712, "time_total_s": 1662.7662944793701, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a4267a60>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42655d0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea3d00>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1662.7662944793701, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 37.478640776699024, "ram_util_percent": 32.47184466019417}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.38636363636363635, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5673549165949225, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.034881867001846936, "policy_loss": -0.023023247081922212, "vf_loss": 0.002755604007021854, "vf_explained_var": 0.707132566658159, "kl": 0.014138816980982996, "entropy": 1.6064185995608569, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6140532563750942, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.002340751890005777, "policy_loss": -0.014462135693368813, "vf_loss": 0.032720543849184956, "vf_explained_var": 0.6470967873930931, "kl": 0.008321022450237978, "entropy": 1.2215890636046727, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.656575413337672, "episode_len_mean": 1022.4772727272727, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2740609731925245, "red_1": 0.382514440145149}, "custom_metrics": {"red_0/door_open_done_mean": 0.38636363636363635, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23642883221550173, "mean_inference_ms": 1.762309051351683, "mean_action_processing_ms": 0.07426163131167184, "mean_env_wait_ms": 0.13141383982033972, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02001930366862904, "StateBufferConnector_ms": 0.0015413219278508966, "ViewRequirementAgentConnector_ms": 0.03373771905899048}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.656575413337672, "episode_len_mean": 1022.4772727272727, "episodes_this_iter": 10, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.4234276128161696, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.2740609731925245, "red_1": 0.382514440145149}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23642883221550173, "mean_inference_ms": 1.762309051351683, "mean_action_processing_ms": 0.07426163131167184, "mean_env_wait_ms": 0.13141383982033972, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02001930366862904, "StateBufferConnector_ms": 0.0015413219278508966, "ViewRequirementAgentConnector_ms": 0.03373771905899048}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.60183163736232, "num_env_steps_trained_throughput_per_sec": 55.60183163736232, "timesteps_total": 92000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 184000, "timers": {"training_iteration_time_ms": 72155.445, "sample_time_ms": 7880.668, "learn_time_ms": 64242.183, "learn_throughput": 62.264, "synch_weights_time_ms": 31.939}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "done": false, "episodes_total": 88, "training_iteration": 23, "trial_id": "b02c7_00000", "date": "2023-09-27_22-28-43", "timestamp": 1695868123, "time_this_iter_s": 71.94395017623901, "time_total_s": 1734.7102446556091, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a4266b30>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a4267820>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428eb90>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1734.7102446556091, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 40.977669902912616, "ram_util_percent": 32.45145631067963}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.4065934065934066, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5042320870483914, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03172521552714898, "policy_loss": -0.018566367698804244, "vf_loss": 0.001414400104734644, "vf_explained_var": 0.6181936144828797, "kl": 0.010657817416197805, "entropy": 1.5997611397256455, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5652130332464973, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0072435496718147386, "policy_loss": -0.01389206731740463, "vf_loss": 0.011997754249265805, "vf_explained_var": 0.6278219436605771, "kl": 0.008954241927926775, "entropy": 1.1412080386653543, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.686027271562238, "episode_len_mean": 1004.010989010989, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3067495712020956, "red_1": 0.379277700360144}, "custom_metrics": {"red_0/door_open_done_mean": 0.4065934065934066, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23610747613888827, "mean_inference_ms": 1.7602084541890992, "mean_action_processing_ms": 0.07412213409851152, "mean_env_wait_ms": 0.13121555007029326, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019915025312821945, "StateBufferConnector_ms": 0.0015328218648721884, "ViewRequirementAgentConnector_ms": 0.03362448660881965}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.686027271562238, "episode_len_mean": 1004.010989010989, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3067495712020956, "red_1": 0.379277700360144}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23610747613888827, "mean_inference_ms": 1.7602084541890992, "mean_action_processing_ms": 0.07412213409851152, "mean_env_wait_ms": 0.13121555007029326, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019915025312821945, "StateBufferConnector_ms": 0.0015328218648721884, "ViewRequirementAgentConnector_ms": 0.03362448660881965}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.62030841884466, "num_env_steps_trained_throughput_per_sec": 55.62030841884466, "timesteps_total": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 72127.3, "sample_time_ms": 7881.907, "learn_time_ms": 64212.772, "learn_throughput": 62.293, "synch_weights_time_ms": 31.966}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "episodes_total": 91, "training_iteration": 24, "trial_id": "b02c7_00000", "date": "2023-09-27_22-29-55", "timestamp": 1695868195, "time_this_iter_s": 71.91963982582092, "time_total_s": 1806.62988448143, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354ccf040>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42c9c00>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428cdc0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1806.62988448143, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 36.59320388349515, "ram_util_percent": 32.39029126213592}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.40860215053763443, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5461232343067726, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03247311287547442, "policy_loss": -0.01912540766594854, "vf_loss": 0.0005802118293862198, "vf_explained_var": 0.4207766187066833, "kl": 0.011567516804303169, "entropy": 1.595131552964449, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4666137195502718, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011453600168382157, "policy_loss": -0.018785283529238465, "vf_loss": 0.012409589682404961, "vf_explained_var": 0.41393166047831376, "kl": 0.012040434620716862, "entropy": 1.2811983705808718, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.693764543685979, "episode_len_mean": 1000.5376344086021, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3138261487099256, "red_1": 0.3799383949760549}, "custom_metrics": {"red_0/door_open_done_mean": 0.40860215053763443, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23589046611360528, "mean_inference_ms": 1.7586902862751566, "mean_action_processing_ms": 0.07402775078796744, "mean_env_wait_ms": 0.13108942365579715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01985911400087418, "StateBufferConnector_ms": 0.0015344671023789272, "ViewRequirementAgentConnector_ms": 0.03356805411718225}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.693764543685979, "episode_len_mean": 1000.5376344086021, "episodes_this_iter": 2, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3138261487099256, "red_1": 0.3799383949760549}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23589046611360528, "mean_inference_ms": 1.7586902862751566, "mean_action_processing_ms": 0.07402775078796744, "mean_env_wait_ms": 0.13108942365579715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01985911400087418, "StateBufferConnector_ms": 0.0015344671023789272, "ViewRequirementAgentConnector_ms": 0.03356805411718225}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.69816219578723, "num_env_steps_trained_throughput_per_sec": 55.69816219578723, "timesteps_total": 100000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 200000, "timers": {"training_iteration_time_ms": 72090.177, "sample_time_ms": 7880.758, "learn_time_ms": 64176.76, "learn_throughput": 62.328, "synch_weights_time_ms": 32.004}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 93, "training_iteration": 25, "trial_id": "b02c7_00000", "date": "2023-09-27_22-31-07", "timestamp": 1695868267, "time_this_iter_s": 71.81908297538757, "time_total_s": 1878.4489674568176, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3face50>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3facee0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428d120>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1878.4489674568176, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 37.770588235294106, "ram_util_percent": 32.51078431372549}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.41, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.48004446287329, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.030589282262008057, "policy_loss": -0.016911108659405726, "vf_loss": 0.0006228788432963483, "vf_explained_var": 0.706877393523852, "kl": 0.009924408378421398, "entropy": 1.5974494890620312, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5104327171109617, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011917165211343672, "policy_loss": -0.01855948594917815, "vf_loss": 0.010863676402853647, "vf_explained_var": 0.6751577785238624, "kl": 0.012585817555890772, "entropy": 1.3066806580871344, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6928758022750943, "episode_len_mean": 1013.62, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3032520646119239, "red_1": 0.38962373766317165}, "custom_metrics": {"red_0/door_open_done_mean": 0.41, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23517615587257779, "mean_inference_ms": 1.7538319133843125, "mean_action_processing_ms": 0.07371745831465, "mean_env_wait_ms": 0.13067172620545145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019753336906433105, "StateBufferConnector_ms": 0.0015395879745483398, "ViewRequirementAgentConnector_ms": 0.033394813537597656}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.10149999999999965, "episode_reward_mean": 1.6928758022750943, "episode_len_mean": 1013.62, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3032520646119239, "red_1": 0.38962373766317165}, "hist_stats": {"episode_reward": [1.6718625000000007, 0.10149999999999965, 1.5951925427729485, 1.5047836050000079, 0.920500000000006, 1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891], "episode_lengths": [956, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280], "policy_red_0_reward": [1.866862500000001, 0.33399999999999985, 1.3426925427729566, 1.2432836050000027, 0.7269999999999999, -0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944], "policy_red_1_reward": [-0.19500000000000015, -0.23250000000000018, 0.2524999999999998, 0.2614999999999998, 0.19349999999999978, 1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23517615587257779, "mean_inference_ms": 1.7538319133843125, "mean_action_processing_ms": 0.07371745831465, "mean_env_wait_ms": 0.13067172620545145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019753336906433105, "StateBufferConnector_ms": 0.0015395879745483398, "ViewRequirementAgentConnector_ms": 0.033394813537597656}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.50163574880728, "num_env_steps_trained_throughput_per_sec": 55.50163574880728, "timesteps_total": 104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 72069.611, "sample_time_ms": 7879.989, "learn_time_ms": 64157.01, "learn_throughput": 62.347, "synch_weights_time_ms": 31.951}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "episodes_total": 100, "training_iteration": 26, "trial_id": "b02c7_00000", "date": "2023-09-27_22-32-19", "timestamp": 1695868339, "time_this_iter_s": 72.07357907295227, "time_total_s": 1950.52254652977, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a41be440>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a41be560>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea3130>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1950.52254652977, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 36.636893203883496, "ram_util_percent": 32.571844660194174}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.45, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.478543758454422, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.037508812133940715, "policy_loss": -0.0247178635004578, "vf_loss": 0.0004705418836692843, "vf_explained_var": 0.8638119611268242, "kl": 0.014485235705911951, "entropy": 1.592326755076647, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5639839039494594, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.006169501543263322, "policy_loss": -0.014163037874095608, "vf_loss": 0.01513970638407045, "vf_explained_var": 0.7602773785591126, "kl": 0.008238648889566965, "entropy": 1.2240469194948673, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.7560458276881739, "episode_len_mean": 983.02, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.346802090025003, "red_1": 0.4092437376631717}, "custom_metrics": {"red_0/door_open_done_mean": 0.45, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449], "policy_red_0_reward": [-0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817], "policy_red_1_reward": [1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23440442061136563, "mean_inference_ms": 1.7489356107647722, "mean_action_processing_ms": 0.07339930389619892, "mean_env_wait_ms": 0.13026174324688997, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01957833766937256, "StateBufferConnector_ms": 0.0015305280685424805, "ViewRequirementAgentConnector_ms": 0.03306281566619873}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.7560458276881739, "episode_len_mean": 983.02, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.346802090025003, "red_1": 0.4092437376631717}, "hist_stats": {"episode_reward": [1.2770500000000107, 1.4742836050000034, 0.9365000000000052, 0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449], "policy_red_0_reward": [-0.18100000000000013, 1.7532836050000105, -0.16200000000000012, 0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817], "policy_red_1_reward": [1.4580499999999925, -0.2790000000000002, 1.098499999999992, -0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23440442061136563, "mean_inference_ms": 1.7489356107647722, "mean_action_processing_ms": 0.07339930389619892, "mean_env_wait_ms": 0.13026174324688997, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01957833766937256, "StateBufferConnector_ms": 0.0015305280685424805, "ViewRequirementAgentConnector_ms": 0.03306281566619873}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.57926164055578, "num_env_steps_trained_throughput_per_sec": 55.57926164055578, "timesteps_total": 108000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 216000, "timers": {"training_iteration_time_ms": 72055.367, "sample_time_ms": 7880.445, "learn_time_ms": 64142.26, "learn_throughput": 62.361, "synch_weights_time_ms": 31.997}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "done": false, "episodes_total": 105, "training_iteration": 27, "trial_id": "b02c7_00000", "date": "2023-09-27_22-33-31", "timestamp": 1695868411, "time_this_iter_s": 71.9730076789856, "time_total_s": 2022.4955542087555, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x3574fdc00>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x3574fd060>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9ff40>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2022.4955542087555, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 36.570873786407766, "ram_util_percent": 32.50679611650485}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.48, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5419446530441443, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.029411278426656886, "policy_loss": -0.016246753321320286, "vf_loss": 0.0002233935060000173, "vf_explained_var": 0.277102065893511, "kl": 0.011929820844102174, "entropy": 1.5662186740587154, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6520290605723857, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010317950373791972, "policy_loss": -0.017359806615907778, "vf_loss": 0.011747016663624285, "vf_explained_var": 0.7747686131546895, "kl": 0.011792063485824662, "entropy": 1.190065015355746, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.7815723293517758, "episode_len_mean": 962.26, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3814924074975912, "red_1": 0.40007992185418645}, "custom_metrics": {"red_0/door_open_done_mean": 0.48, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187], "episode_lengths": [1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783], "policy_red_0_reward": [0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902], "policy_red_1_reward": [-0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23399775618181376, "mean_inference_ms": 1.746388546930891, "mean_action_processing_ms": 0.07322856112991404, "mean_env_wait_ms": 0.13006554009024549, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019581198692321777, "StateBufferConnector_ms": 0.0015320777893066406, "ViewRequirementAgentConnector_ms": 0.032962679862976074}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.7815723293517758, "episode_len_mean": 962.26, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.3814924074975912, "red_1": 0.40007992185418645}, "hist_stats": {"episode_reward": [0.5625000000000033, 0.545000000000003, 2.304378125000001, 0.9310000000000093, 1.9436533644425968, 1.0080000000000058, 1.6789346144426023, 0.6060000000000052, 1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187], "episode_lengths": [1280, 1280, 343, 1280, 986, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783], "policy_red_0_reward": [0.7739999999999999, 0.2969999999999999, 2.395878125000004, 0.6829999999999999, 2.171653364442604, 1.20000000000001, 1.3319346144426076, 0.7889999999999998, 0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902], "policy_red_1_reward": [-0.21150000000000016, 0.24799999999999983, -0.09150000000000005, 0.24799999999999983, -0.22800000000000017, -0.19200000000000014, 0.34699999999999986, -0.18300000000000013, 0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23399775618181376, "mean_inference_ms": 1.746388546930891, "mean_action_processing_ms": 0.07322856112991404, "mean_env_wait_ms": 0.13006554009024549, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019581198692321777, "StateBufferConnector_ms": 0.0015320777893066406, "ViewRequirementAgentConnector_ms": 0.032962679862976074}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.637287440947574, "num_env_steps_trained_throughput_per_sec": 55.637287440947574, "timesteps_total": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 72025.126, "sample_time_ms": 7874.283, "learn_time_ms": 64118.162, "learn_throughput": 62.385, "synch_weights_time_ms": 32.015}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "episodes_total": 108, "training_iteration": 28, "trial_id": "b02c7_00000", "date": "2023-09-27_22-34-44", "timestamp": 1695868484, "time_this_iter_s": 71.89778590202332, "time_total_s": 2094.393340110779, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x3574fd450>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x3574fd990>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428eef0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2094.393340110779, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 35.97156862745098, "ram_util_percent": 32.45784313725491}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.52, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4711716897785663, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0320649340631159, "policy_loss": -0.01883227382932091, "vf_loss": 0.00024705129820479975, "vf_explained_var": 0.7953443344061574, "kl": 0.009910977101549178, "entropy": 1.5338381982098024, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.676036216504872, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009359149574083857, "policy_loss": -0.01826264505943982, "vf_loss": 0.01584327689439912, "vf_explained_var": 0.8253271758556366, "kl": 0.011220434448485623, "entropy": 1.2622300626089176, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.8623982835882193, "episode_len_mean": 932.92, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.4261883617340338, "red_1": 0.4362099218541863}, "custom_metrics": {"red_0/door_open_done_mean": 0.52, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001], "policy_red_0_reward": [0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918], "policy_red_1_reward": [0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23268168980889015, "mean_inference_ms": 1.7377255763952497, "mean_action_processing_ms": 0.07266878271049725, "mean_env_wait_ms": 0.12933846779105307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01949012279510498, "StateBufferConnector_ms": 0.00151824951171875, "ViewRequirementAgentConnector_ms": 0.03254055976867676}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.8623982835882193, "episode_len_mean": 932.92, "episodes_this_iter": 8, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.4261883617340338, "red_1": 0.4362099218541863}, "hist_stats": {"episode_reward": [1.601193237816176, 1.589193237816172, 1.5769346144425997, 1.6391932378161793, 0.5800000000000052, 1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001], "policy_red_0_reward": [0.9016932378161696, 1.8576932378161781, 1.0988846144426003, 1.3416932378161865, 0.28399999999999986, 1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918], "policy_red_1_reward": [0.6995000000000043, -0.2685000000000002, 0.47805000000000647, 0.2974999999999998, 0.2959999999999998, 0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23268168980889015, "mean_inference_ms": 1.7377255763952497, "mean_action_processing_ms": 0.07266878271049725, "mean_env_wait_ms": 0.12933846779105307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01949012279510498, "StateBufferConnector_ms": 0.00151824951171875, "ViewRequirementAgentConnector_ms": 0.03254055976867676}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.54031272358851, "num_env_steps_trained_throughput_per_sec": 55.54031272358851, "timesteps_total": 116000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 232000, "timers": {"training_iteration_time_ms": 72005.033, "sample_time_ms": 7866.912, "learn_time_ms": 64105.56, "learn_throughput": 62.397, "synch_weights_time_ms": 31.901}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "done": false, "episodes_total": 116, "training_iteration": 29, "trial_id": "b02c7_00000", "date": "2023-09-27_22-35-56", "timestamp": 1695868556, "time_this_iter_s": 72.02346515655518, "time_total_s": 2166.416805267334, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x355041ab0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x355043280>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66eb640>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2166.416805267334, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 36.32135922330097, "ram_util_percent": 32.4990291262136}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.56, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.362993217135469, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03650201985874446, "policy_loss": -0.02390451869747873, "vf_loss": 0.00021303641892700398, "vf_explained_var": 0.21949344215293726, "kl": 0.012420812756665988, "entropy": 1.5188181787729262, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6753928801665703, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011909962314166477, "policy_loss": -0.017291931737660585, "vf_loss": 0.008679651216759036, "vf_explained_var": 0.8166511656095584, "kl": 0.011041798816114907, "entropy": 1.166216087465485, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.912686239700117, "episode_len_mean": 896.62, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.468796817845932, "red_1": 0.44388942185418634}, "custom_metrics": {"red_0/door_open_done_mean": 0.56, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176], "episode_lengths": [443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353], "policy_red_0_reward": [1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177], "policy_red_1_reward": [0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23180844671774573, "mean_inference_ms": 1.7317613480402434, "mean_action_processing_ms": 0.07228644122980653, "mean_env_wait_ms": 0.12881818961539163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0192415714263916, "StateBufferConnector_ms": 0.0015090703964233398, "ViewRequirementAgentConnector_ms": 0.032272934913635254}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.912686239700117, "episode_len_mean": 896.62, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.3135000000000002}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.468796817845932, "red_1": 0.44388942185418634}, "hist_stats": {"episode_reward": [1.4550156250000015, 1.2957812500000034, 1.8012523550000108, 1.4694346144426034, 1.7013750000000056, 1.5376925427729542, 1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176], "episode_lengths": [443, 646, 1066, 1280, 648, 1280, 1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353], "policy_red_0_reward": [1.0465156249999998, 0.8947812500000001, 1.9737523550000156, 1.7829346144426144, 1.7973750000000086, 1.2861030335440753, 1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177], "policy_red_1_reward": [0.4084999999999999, 0.4009999999999999, -0.17250000000000013, -0.3135000000000002, -0.09600000000000006, 0.2515895092288868, -0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23180844671774573, "mean_inference_ms": 1.7317613480402434, "mean_action_processing_ms": 0.07228644122980653, "mean_env_wait_ms": 0.12881818961539163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0192415714263916, "StateBufferConnector_ms": 0.0015090703964233398, "ViewRequirementAgentConnector_ms": 0.032272934913635254}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.56755431708184, "num_env_steps_trained_throughput_per_sec": 55.56755431708184, "timesteps_total": 120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 71999.424, "sample_time_ms": 7869.933, "learn_time_ms": 64096.937, "learn_throughput": 62.405, "synch_weights_time_ms": 31.895}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 121, "training_iteration": 30, "trial_id": "b02c7_00000", "date": "2023-09-27_22-37-08", "timestamp": 1695868628, "time_this_iter_s": 71.98806571960449, "time_total_s": 2238.4048709869385, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354d90b50>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354d91d50>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428d990>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2238.4048709869385, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 37.53495145631068, "ram_util_percent": 32.493203883495156}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.57, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3530934299652775, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02631405870245847, "policy_loss": -0.013097833965851654, "vf_loss": 0.00020536508618154887, "vf_explained_var": 0.622147970336179, "kl": 0.007841417590628393, "entropy": 1.4887190443774065, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5330908327673873, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0077444917775816675, "policy_loss": -0.013170684061090772, "vf_loss": 0.00976309423179676, "vf_explained_var": 0.8004082564264536, "kl": 0.008559434978785274, "entropy": 1.1672417155777415, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.9531417305542111, "episode_len_mean": 890.25, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.22950000000000018}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.487478203792315, "red_1": 0.46566352676189743}, "custom_metrics": {"red_0/door_open_done_mean": 0.57, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173], "episode_lengths": [1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310], "policy_red_0_reward": [1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174], "policy_red_1_reward": [-0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23068687917745861, "mean_inference_ms": 1.7241546349164478, "mean_action_processing_ms": 0.07180257874300754, "mean_env_wait_ms": 0.12816709004614898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018902301788330078, "StateBufferConnector_ms": 0.0015054941177368164, "ViewRequirementAgentConnector_ms": 0.031974077224731445}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.9531417305542111, "episode_len_mean": 890.25, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.22950000000000018}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.487478203792315, "red_1": 0.46566352676189743}, "hist_stats": {"episode_reward": [1.2555500000000126, 1.6186932378161818, 1.6126932378161851, 1.6076030335440676, 2.305658605000008, 1.6446932378161847, 1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173], "episode_lengths": [1280, 1280, 1280, 1280, 552, 1280, 475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310], "policy_red_0_reward": [1.485050000000022, 1.8136932378161883, 1.301693237816191, 1.8191030335440743, 0.9958749999999998, 1.8036932378161898, 1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174], "policy_red_1_reward": [-0.22950000000000018, -0.19500000000000015, 0.3109999999999999, -0.21150000000000016, 1.3097836049999978, -0.1590000000000001, 0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23068687917745861, "mean_inference_ms": 1.7241546349164478, "mean_action_processing_ms": 0.07180257874300754, "mean_env_wait_ms": 0.12816709004614898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018902301788330078, "StateBufferConnector_ms": 0.0015054941177368164, "ViewRequirementAgentConnector_ms": 0.031974077224731445}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.23153894188492, "num_env_steps_trained_throughput_per_sec": 55.23153894188492, "timesteps_total": 124000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 248000, "timers": {"training_iteration_time_ms": 72005.252, "sample_time_ms": 7864.32, "learn_time_ms": 64108.51, "learn_throughput": 62.394, "synch_weights_time_ms": 31.763}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "done": false, "episodes_total": 127, "training_iteration": 31, "trial_id": "b02c7_00000", "date": "2023-09-27_22-38-21", "timestamp": 1695868701, "time_this_iter_s": 72.42607522010803, "time_total_s": 2310.8309462070465, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a66608e0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a66609a0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9cd30>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2310.8309462070465, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 36.60485436893204, "ram_util_percent": 32.59805825242718}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.61, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4575572825036942, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.033285144315110905, "policy_loss": -0.02079731331541552, "vf_loss": 0.0009073136324180571, "vf_explained_var": 0.7718768599753578, "kl": 0.011034096680222002, "entropy": 1.5148307450115681, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3287568025601406, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.012785699080268387, "policy_loss": -0.01930621021783736, "vf_loss": 0.01162130121423009, "vf_explained_var": 0.6374342350910107, "kl": 0.008859693720652005, "entropy": 1.0620780428871512, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.9739546090469324, "episode_len_mean": 864.55, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.4858239183350357, "red_1": 0.48813069071189735}, "custom_metrics": {"red_0/door_open_done_mean": 0.61, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817], "episode_lengths": [475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876], "policy_red_0_reward": [1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833], "policy_red_1_reward": [0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22956549739156482, "mean_inference_ms": 1.716311218199107, "mean_action_processing_ms": 0.07130528237698276, "mean_env_wait_ms": 0.1274680932486862, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018835783004760742, "StateBufferConnector_ms": 0.0014934539794921875, "ViewRequirementAgentConnector_ms": 0.03168201446533203}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.9739546090469324, "episode_len_mean": 864.55, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.4858239183350357, "red_1": 0.48813069071189735}, "hist_stats": {"episode_reward": [1.4790156250000022, 2.473130737816173, 1.6466932378161843, 1.6181030335440743, 1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817], "episode_lengths": [475, 532, 1280, 1280, 822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876], "policy_red_0_reward": [1.051015625, 2.073630737816176, 1.3206932378161902, 1.2741030335440797, 0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833], "policy_red_1_reward": [0.42799999999999994, 0.3994999999999999, 0.32599999999999985, 0.34399999999999986, 1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22956549739156482, "mean_inference_ms": 1.716311218199107, "mean_action_processing_ms": 0.07130528237698276, "mean_env_wait_ms": 0.1274680932486862, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018835783004760742, "StateBufferConnector_ms": 0.0014934539794921875, "ViewRequirementAgentConnector_ms": 0.03168201446533203}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.51580490825268, "num_env_steps_trained_throughput_per_sec": 55.51580490825268, "timesteps_total": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 72008.339, "sample_time_ms": 7864.014, "learn_time_ms": 64111.941, "learn_throughput": 62.391, "synch_weights_time_ms": 31.726}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "episodes_total": 133, "training_iteration": 32, "trial_id": "b02c7_00000", "date": "2023-09-27_22-39-33", "timestamp": 1695868773, "time_this_iter_s": 72.05521297454834, "time_total_s": 2382.886159181595, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354ccc7f0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354ccfd00>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea1f30>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2382.886159181595, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 36.62912621359224, "ram_util_percent": 32.630097087378644}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.63, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5716972699388863, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03688226168354352, "policy_loss": -0.02525679243456883, "vf_loss": 0.0004020767267472062, "vf_explained_var": 0.8408922053252658, "kl": 0.01417920644575285, "entropy": 1.4662349954247476, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.530919228369991, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011505529351476676, "policy_loss": -0.016377610980756192, "vf_loss": 0.008202291418274398, "vf_explained_var": 0.838840147604545, "kl": 0.009250593060160678, "entropy": 1.079182121405999, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.9957525423396532, "episode_len_mean": 845.34, "episode_media": {}, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.503226851627757, "red_1": 0.49252569071189745}, "custom_metrics": {"red_0/door_open_done_mean": 0.63, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814], "episode_lengths": [822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589], "policy_red_0_reward": [0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823], "policy_red_1_reward": [1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22874940007501438, "mean_inference_ms": 1.710646151065571, "mean_action_processing_ms": 0.07093884942054107, "mean_env_wait_ms": 0.1269535596889585, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018739819526672363, "StateBufferConnector_ms": 0.0014802217483520508, "ViewRequirementAgentConnector_ms": 0.031493544578552246}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 1.9957525423396532, "episode_len_mean": 845.34, "episodes_this_iter": 4, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.503226851627757, "red_1": 0.49252569071189745}, "hist_stats": {"episode_reward": [1.7855812500000066, 1.646193237816182, 1.6296932378161801, 0.6020000000000069, 2.408755737816169, 1.6831932378161818, 1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814], "episode_lengths": [822, 1280, 1280, 1280, 652, 1280, 1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589], "policy_red_0_reward": [0.7690312499999998, 1.330693237816189, 1.3396932378161877, -0.1350000000000001, 1.562255737816172, 1.3406932378161875, 1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823], "policy_red_1_reward": [1.0165499999999987, 0.31549999999999984, 0.2899999999999998, 0.737000000000007, 0.8465000000000036, 0.34249999999999986, 0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22874940007501438, "mean_inference_ms": 1.710646151065571, "mean_action_processing_ms": 0.07093884942054107, "mean_env_wait_ms": 0.1269535596889585, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018739819526672363, "StateBufferConnector_ms": 0.0014802217483520508, "ViewRequirementAgentConnector_ms": 0.031493544578552246}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.48729672945971, "num_env_steps_trained_throughput_per_sec": 55.48729672945971, "timesteps_total": 132000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 264000, "timers": {"training_iteration_time_ms": 72023.189, "sample_time_ms": 7869.297, "learn_time_ms": 64121.98, "learn_throughput": 62.381, "synch_weights_time_ms": 31.259}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "done": false, "episodes_total": 137, "training_iteration": 33, "trial_id": "b02c7_00000", "date": "2023-09-27_22-40-46", "timestamp": 1695868846, "time_this_iter_s": 72.09220099449158, "time_total_s": 2454.9783601760864, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42cbaf0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42caa40>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9ec20>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2454.9783601760864, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 36.59126213592233, "ram_util_percent": 32.689320388349515}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.64, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5500824213648836, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02568720585598688, "policy_loss": -0.013621285210441177, "vf_loss": 0.00028429049816243907, "vf_explained_var": 0.7998624809086323, "kl": 0.011258777494855543, "entropy": 1.445982217291991, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6465392957131069, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01087748609522047, "policy_loss": -0.01493006206243687, "vf_loss": 0.00721490822082463, "vf_explained_var": 0.8606038673470418, "kl": 0.007971199782528875, "entropy": 1.149117670332392, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.028300750845977, "episode_len_mean": 828.43, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.5437905601340807, "red_1": 0.4845101907118973}, "custom_metrics": {"red_0/door_open_done_mean": 0.64, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177], "episode_lengths": [1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407], "policy_red_0_reward": [1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178], "policy_red_1_reward": [0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22756202163764722, "mean_inference_ms": 1.7023418276767557, "mean_action_processing_ms": 0.07041109167990654, "mean_env_wait_ms": 0.12621315204567202, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018389105796813965, "StateBufferConnector_ms": 0.001462697982788086, "ViewRequirementAgentConnector_ms": 0.031130552291870117}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.028300750845977, "episode_len_mean": 828.43, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.5437905601340807, "red_1": 0.4845101907118973}, "hist_stats": {"episode_reward": [1.605434614442604, 1.7501718750000004, 2.4348026128161777, 1.8784744878152244, 2.3529119878161757, 2.474552612816173, 1.689693237816178, 1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177], "episode_lengths": [1280, 201, 573, 1030, 666, 557, 1280, 1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407], "policy_red_0_reward": [1.3079346144426112, 1.272671875, 2.00980261281618, 1.54647448781523, 1.953411987816179, 2.0570526128161757, 1.3726932378161845, 1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178], "policy_red_1_reward": [0.2974999999999998, 0.4775, 0.42499999999999993, 0.33199999999999985, 0.3994999999999999, 0.4174999999999999, 0.31699999999999984, 0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22756202163764722, "mean_inference_ms": 1.7023418276767557, "mean_action_processing_ms": 0.07041109167990654, "mean_env_wait_ms": 0.12621315204567202, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018389105796813965, "StateBufferConnector_ms": 0.001462697982788086, "ViewRequirementAgentConnector_ms": 0.031130552291870117}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.755570963145, "num_env_steps_trained_throughput_per_sec": 55.755570963145, "timesteps_total": 136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 72005.742, "sample_time_ms": 7865.885, "learn_time_ms": 64108.028, "learn_throughput": 62.395, "synch_weights_time_ms": 31.179}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "episodes_total": 143, "training_iteration": 34, "trial_id": "b02c7_00000", "date": "2023-09-27_22-41-58", "timestamp": 1695868918, "time_this_iter_s": 71.74532127380371, "time_total_s": 2526.72368144989, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42672e0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a4266fb0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428ee60>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2526.72368144989, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 36.02352941176471, "ram_util_percent": 32.75490196078431}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.65, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6231666223456462, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03256500401451679, "policy_loss": -0.020982698185252956, "vf_loss": 0.0002572251819894215, "vf_explained_var": 0.7864108577370643, "kl": 0.013598614721079125, "entropy": 1.4430640800545613, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6325072435662151, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0094502337019397, "policy_loss": -0.018421078126023834, "vf_loss": 0.015012537590033995, "vf_explained_var": 0.7391695721074939, "kl": 0.013374982176617783, "entropy": 1.2104208124180635, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.045341624931429, "episode_len_mean": 816.32, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.5534999241251057, "red_1": 0.49184170080632333}, "custom_metrics": {"red_0/door_open_done_mean": 0.65, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737], "episode_lengths": [1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251], "policy_red_0_reward": [1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174], "policy_red_1_reward": [0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22629291352841488, "mean_inference_ms": 1.6934444763977805, "mean_action_processing_ms": 0.06985246766575799, "mean_env_wait_ms": 0.1253924788056168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018433094024658203, "StateBufferConnector_ms": 0.0014630556106567383, "ViewRequirementAgentConnector_ms": 0.03103315830230713}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.045341624931429, "episode_len_mean": 816.32, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.5534999241251057, "red_1": 0.49184170080632333}, "hist_stats": {"episode_reward": [1.6316925427729545, 1.67019323781618, 0.5690000000000061, 1.9322088628161922, 2.521286987816174, 1.254050000000023, 2.3012244878161825, 2.0757656250000003, 2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737], "episode_lengths": [1280, 1280, 1280, 1019, 514, 1280, 726, 299, 1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251], "policy_red_0_reward": [1.3296925427729593, 1.3456932378161817, -0.19200000000000014, 1.5492088628161966, 2.084286987816176, 0.9220500000000202, 1.861224487816185, 0.759765625, 1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174], "policy_red_1_reward": [0.3019999999999998, 0.32449999999999984, 0.7610000000000063, 0.3829999999999999, 0.43699999999999994, 0.33199999999999985, 0.43999999999999995, 1.3159999999999998, 0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22629291352841488, "mean_inference_ms": 1.6934444763977805, "mean_action_processing_ms": 0.06985246766575799, "mean_env_wait_ms": 0.1253924788056168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018433094024658203, "StateBufferConnector_ms": 0.0014630556106567383, "ViewRequirementAgentConnector_ms": 0.03103315830230713}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.527720710009994, "num_env_steps_trained_throughput_per_sec": 55.527720710009994, "timesteps_total": 140000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 280000, "timers": {"training_iteration_time_ms": 72027.785, "sample_time_ms": 7864.251, "learn_time_ms": 64131.589, "learn_throughput": 62.372, "synch_weights_time_ms": 31.294}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 150, "training_iteration": 35, "trial_id": "b02c7_00000", "date": "2023-09-27_22-43-10", "timestamp": 1695868990, "time_this_iter_s": 72.04027605056763, "time_total_s": 2598.7639575004578, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a6661840>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a6661960>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea3520>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2598.7639575004578, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 36.877669902912615, "ram_util_percent": 32.737864077669904}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.67, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.796014169914027, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03548729888195036, "policy_loss": -0.02433172699966235, "vf_loss": 0.000205970763587023, "vf_explained_var": 0.7747333178917567, "kl": 0.012840332272815136, "entropy": 1.3826623187710843, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.605126653673748, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.006710074593017149, "policy_loss": -0.01522469832270872, "vf_loss": 0.0151952410757076, "vf_explained_var": 0.7617401753241817, "kl": 0.009626521213942852, "entropy": 1.0083011743302146, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.1024930227663456, "episode_len_mean": 785.25, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.6157663219600227, "red_1": 0.48672670080632324}, "custom_metrics": {"red_0/door_open_done_mean": 0.67, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737], "episode_lengths": [1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277], "policy_red_0_reward": [1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744], "policy_red_1_reward": [0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2250847262530667, "mean_inference_ms": 1.6851667660679892, "mean_action_processing_ms": 0.06932306136473093, "mean_env_wait_ms": 0.12463737126533525, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01831662654876709, "StateBufferConnector_ms": 0.0014629364013671875, "ViewRequirementAgentConnector_ms": 0.031033635139465332}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.1024930227663456, "episode_len_mean": 785.25, "episodes_this_iter": 8, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.6157663219600227, "red_1": 0.48672670080632324}, "hist_stats": {"episode_reward": [2.0022713628161837, 1.884578125, 1.6876932378161822, 1.5931932378161924, 1.7756932378161725, 2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737], "episode_lengths": [1031, 71, 1280, 1280, 1280, 117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277], "policy_red_0_reward": [1.6177713628161878, 0.939078125, 1.3436932378161877, 1.253693237816198, 1.3986932378161736, 2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744], "policy_red_1_reward": [0.3844999999999999, 0.9455000000000001, 0.34399999999999986, 0.33949999999999986, 0.3769999999999999, 0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2250847262530667, "mean_inference_ms": 1.6851667660679892, "mean_action_processing_ms": 0.06932306136473093, "mean_env_wait_ms": 0.12463737126533525, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01831662654876709, "StateBufferConnector_ms": 0.0014629364013671875, "ViewRequirementAgentConnector_ms": 0.031033635139465332}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.70593618314885, "num_env_steps_trained_throughput_per_sec": 55.70593618314885, "timesteps_total": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 72001.354, "sample_time_ms": 7855.739, "learn_time_ms": 64113.66, "learn_throughput": 62.389, "synch_weights_time_ms": 31.308}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "episodes_total": 158, "training_iteration": 36, "trial_id": "b02c7_00000", "date": "2023-09-27_22-44-22", "timestamp": 1695869062, "time_this_iter_s": 71.80932211875916, "time_total_s": 2670.573279619217, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3fafee0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3fafc40>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea24d0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2670.573279619217, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 36.616504854368934, "ram_util_percent": 32.7990291262136}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.68, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3362003137047092, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03281432802298999, "policy_loss": -0.021407625248199717, "vf_loss": 0.0001667373540679288, "vf_explained_var": 0.8774412616466483, "kl": 0.01037878314961149, "entropy": 1.3565828399111828, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3417167969668904, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01118477589043323, "policy_loss": -0.01598012401809683, "vf_loss": 0.008066428463401583, "vf_explained_var": 0.8528054697439075, "kl": 0.007613419991658551, "entropy": 0.7605500023191174, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "sampler_results": {"episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.120501804016346, "episode_len_mean": 770.76, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.6344051032100233, "red_1": 0.4860967008063233}, "custom_metrics": {"red_0/door_open_done_mean": 0.68, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004], "episode_lengths": [117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143], "policy_red_0_reward": [2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046], "policy_red_1_reward": [0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22448696038550728, "mean_inference_ms": 1.6810252998269746, "mean_action_processing_ms": 0.06905016414237618, "mean_env_wait_ms": 0.1242698393759221, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018265247344970703, "StateBufferConnector_ms": 0.001462697982788086, "ViewRequirementAgentConnector_ms": 0.031001925468444824}}, "episode_reward_max": 2.911427612816169, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.120501804016346, "episode_len_mean": 770.76, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.6344051032100233, "red_1": 0.4860967008063233}, "hist_stats": {"episode_reward": [2.911427612816169, 1.9977531250000098, 2.7651932378161725, 1.6836932378161822, 1.3285500000000208, 1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004], "episode_lengths": [117, 703, 256, 1280, 1280, 1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143], "policy_red_0_reward": [2.4234276128161696, 1.5757531250000127, 2.2966932378161733, 1.3626932378161847, 0.9530500000000192, -0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046], "policy_red_1_reward": [0.488, 0.42199999999999993, 0.46849999999999997, 0.3209999999999999, 0.3754999999999999, 1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22448696038550728, "mean_inference_ms": 1.6810252998269746, "mean_action_processing_ms": 0.06905016414237618, "mean_env_wait_ms": 0.1242698393759221, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018265247344970703, "StateBufferConnector_ms": 0.001462697982788086, "ViewRequirementAgentConnector_ms": 0.031001925468444824}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.59537201145834, "num_env_steps_trained_throughput_per_sec": 55.59537201145834, "timesteps_total": 148000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 296000, "timers": {"training_iteration_time_ms": 71999.268, "sample_time_ms": 7856.742, "learn_time_ms": 64110.676, "learn_throughput": 62.392, "synch_weights_time_ms": 31.205}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "done": false, "episodes_total": 163, "training_iteration": 37, "trial_id": "b02c7_00000", "date": "2023-09-27_22-45-34", "timestamp": 1695869134, "time_this_iter_s": 71.95207190513611, "time_total_s": 2742.525351524353, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a6660760>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a6662c20>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428d6c0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2742.525351524353, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 38.356310679611646, "ram_util_percent": 32.960194174757284}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.7, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6993865946618218, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02626432443636683, "policy_loss": -0.015098788707594698, "vf_loss": 0.000991752960536966, "vf_explained_var": 0.7976952953264117, "kl": 0.010373480928289306, "entropy": 1.3736108222355445, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6110260638718803, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008353575897611638, "policy_loss": -0.01714362014948468, "vf_loss": 0.016409287063773568, "vf_explained_var": 0.702968048180143, "kl": 0.007435646136506132, "entropy": 0.9017283499240876, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "sampler_results": {"episode_reward_max": 2.9097557378161714, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.131441231272671, "episode_len_mean": 763.22, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.6422795304663473, "red_1": 0.4891617008063233}, "custom_metrics": {"red_0/door_open_done_mean": 0.7, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787], "episode_lengths": [1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562], "policy_red_0_reward": [-0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793], "policy_red_1_reward": [1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2239944744466195, "mean_inference_ms": 1.6772314293921595, "mean_action_processing_ms": 0.06881790833610103, "mean_env_wait_ms": 0.12396476312861987, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01833951473236084, "StateBufferConnector_ms": 0.0014653205871582031, "ViewRequirementAgentConnector_ms": 0.03102719783782959}}, "episode_reward_max": 2.9097557378161714, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.131441231272671, "episode_len_mean": 763.22, "episodes_this_iter": 5, "policy_reward_min": {"red_0": -0.35600000000000026, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.796283605}, "policy_reward_mean": {"red_0": 1.6422795304663473, "red_1": 0.4891617008063233}, "hist_stats": {"episode_reward": [1.4402836050000183, 1.6476932378161888, 1.5856932378161974, 1.8886463628161954, 1.684693237816186, 2.4335343750000065, 1.7988651128162052, 1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787], "episode_lengths": [1280, 1280, 1280, 1039, 1280, 229, 1001, 1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562], "policy_red_0_reward": [-0.35600000000000026, 0.43369323781616953, 1.208693237816202, 1.5071463628161998, 1.3166932378161906, 1.9530343750000068, 1.4368651128162104, 1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793], "policy_red_1_reward": [1.796283605, 1.2139999999999946, 0.3769999999999999, 0.3814999999999999, 0.3679999999999999, 0.4805, 0.3619999999999999, 0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2239944744466195, "mean_inference_ms": 1.6772314293921595, "mean_action_processing_ms": 0.06881790833610103, "mean_env_wait_ms": 0.12396476312861987, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01833951473236084, "StateBufferConnector_ms": 0.0014653205871582031, "ViewRequirementAgentConnector_ms": 0.03102719783782959}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.44925870514226, "num_env_steps_trained_throughput_per_sec": 55.44925870514226, "timesteps_total": 152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 72023.648, "sample_time_ms": 7857.628, "learn_time_ms": 64134.086, "learn_throughput": 62.369, "synch_weights_time_ms": 31.287}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "episodes_total": 168, "training_iteration": 38, "trial_id": "b02c7_00000", "date": "2023-09-27_22-46-47", "timestamp": 1695869207, "time_this_iter_s": 72.14161920547485, "time_total_s": 2814.666970729828, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3f60d00>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3f61120>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428e8c0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2814.666970729828, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 37.18932038834952, "ram_util_percent": 32.919417475728174}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.71, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7034393406783541, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.031460742830313394, "policy_loss": -0.0208534387362306, "vf_loss": 0.00013067769913466994, "vf_explained_var": 0.6653351463377476, "kl": 0.014933662389147078, "entropy": 1.3659375416735808, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5480131545414528, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010370968621767436, "policy_loss": -0.016045348481081117, "vf_loss": 0.009766169599970453, "vf_explained_var": 0.8414629281808933, "kl": 0.007992391767568786, "entropy": 0.8071836605047186, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "sampler_results": {"episode_reward_max": 2.9097557378161714, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.146214764186274, "episode_len_mean": 745.01, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.2891406250000004, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.4501030335440523}, "policy_reward_mean": {"red_0": 1.67432089942995, "red_1": 0.47189386475632333}, "custom_metrics": {"red_0/door_open_done_mean": 0.71, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280], "policy_red_0_reward": [1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254], "policy_red_1_reward": [0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22327625919788371, "mean_inference_ms": 1.6721779591931138, "mean_action_processing_ms": 0.06849934724306883, "mean_env_wait_ms": 0.12347941429395509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018338680267333984, "StateBufferConnector_ms": 0.0014611482620239258, "ViewRequirementAgentConnector_ms": 0.031055212020874023}}, "episode_reward_max": 2.9097557378161714, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.146214764186274, "episode_len_mean": 745.01, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.2891406250000004, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.4501030335440523}, "policy_reward_mean": {"red_0": 1.67432089942995, "red_1": 0.47189386475632333}, "hist_stats": {"episode_reward": [1.7736932378161776, 1.563193237816199, 1.7631932378161825, 1.4341932378161957, 1.6371932378161902, 2.877771362816171, 1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223], "episode_lengths": [1280, 1280, 1280, 1280, 1280, 135, 1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280], "policy_red_0_reward": [1.399693237816182, 1.1961030335440888, 0.9076932378161756, 1.1876932378162053, 1.2766932378161955, 2.3987713628161718, 1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254], "policy_red_1_reward": [0.3739999999999999, 0.3670902042721149, 0.8555000000000033, 0.24649999999999977, 0.3604999999999999, 0.479, -0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22327625919788371, "mean_inference_ms": 1.6721779591931138, "mean_action_processing_ms": 0.06849934724306883, "mean_env_wait_ms": 0.12347941429395509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018338680267333984, "StateBufferConnector_ms": 0.0014611482620239258, "ViewRequirementAgentConnector_ms": 0.031055212020874023}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.71000601950537, "num_env_steps_trained_throughput_per_sec": 55.71000601950537, "timesteps_total": 156000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 312000, "timers": {"training_iteration_time_ms": 72001.71, "sample_time_ms": 7858.454, "learn_time_ms": 64111.333, "learn_throughput": 62.391, "synch_weights_time_ms": 31.281}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "done": false, "episodes_total": 175, "training_iteration": 39, "trial_id": "b02c7_00000", "date": "2023-09-27_22-47-59", "timestamp": 1695869279, "time_this_iter_s": 71.80407691001892, "time_total_s": 2886.471047639847, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42c9f60>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42ca230>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9de10>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2886.471047639847, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 36.36078431372549, "ram_util_percent": 32.91176470588234}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.75, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6931233111768962, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03004124271149825, "policy_loss": -0.018776629751664588, "vf_loss": 7.629299194983711e-05, "vf_explained_var": 0.39576120482136806, "kl": 0.011299250487744909, "entropy": 1.356260914603869, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8632682265713811, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.016817163121352983, "policy_loss": -0.022180005809059367, "vf_loss": 0.007984095219580923, "vf_explained_var": 0.8476950567836563, "kl": 0.011319968535522532, "entropy": 0.8931981530040503, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "sampler_results": {"episode_reward_max": 2.91202136281617, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.175870701686274, "episode_len_mean": 719.43, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.2891406250000004, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.4501030335440523}, "policy_reward_mean": {"red_0": 1.7022727389726713, "red_1": 0.4735979627136021}, "custom_metrics": {"red_0/door_open_done_mean": 0.75, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065], "episode_lengths": [1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280], "policy_red_0_reward": [1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083], "policy_red_1_reward": [-0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2227884373433104, "mean_inference_ms": 1.6687064838390586, "mean_action_processing_ms": 0.06827432220170385, "mean_env_wait_ms": 0.12314762761129758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018187880516052246, "StateBufferConnector_ms": 0.0014563798904418945, "ViewRequirementAgentConnector_ms": 0.031061649322509766}}, "episode_reward_max": 2.91202136281617, "episode_reward_min": 0.5348593749999995, "episode_reward_mean": 2.175870701686274, "episode_len_mean": 719.43, "episodes_this_iter": 6, "policy_reward_min": {"red_0": -0.2891406250000004, "red_1": -0.09840979572788508}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.4501030335440523}, "policy_reward_mean": {"red_0": 1.7022727389726713, "red_1": 0.4735979627136021}, "hist_stats": {"episode_reward": [1.6236932378161977, 2.263611730000011, 0.5348593749999995, 2.1633750000000003, 1.7466932378161841, 1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065], "episode_lengths": [1280, 599, 1101, 200, 1280, 1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280], "policy_red_0_reward": [1.7221030335440863, 0.873828125, -0.2891406250000004, 1.234375, 1.3456932378161879, 1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083], "policy_red_1_reward": [-0.09840979572788508, 1.3897836049999985, 0.8239999999999998, 0.9290000000000007, 0.4009999999999999, 0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2227884373433104, "mean_inference_ms": 1.6687064838390586, "mean_action_processing_ms": 0.06827432220170385, "mean_env_wait_ms": 0.12314762761129758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018187880516052246, "StateBufferConnector_ms": 0.0014563798904418945, "ViewRequirementAgentConnector_ms": 0.031061649322509766}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.59783304792464, "num_env_steps_trained_throughput_per_sec": 55.59783304792464, "timesteps_total": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 71997.79, "sample_time_ms": 7858.553, "learn_time_ms": 64107.343, "learn_throughput": 62.395, "synch_weights_time_ms": 31.248}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 181, "training_iteration": 40, "trial_id": "b02c7_00000", "date": "2023-09-27_22-49-11", "timestamp": 1695869351, "time_this_iter_s": 71.94885277748108, "time_total_s": 2958.419900417328, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x3574fdf90>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x3574ff0d0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66ea4d0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2958.419900417328, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 37.02135922330097, "ram_util_percent": 32.92330097087378}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.76, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6134601911529898, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02726211912055684, "policy_loss": -0.01580081386055099, "vf_loss": 6.579977606596306e-05, "vf_explained_var": 0.18914347731818756, "kl": 0.009339487485298588, "entropy": 1.3362103171646595, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.458009127403299, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011627661761910229, "policy_loss": -0.01729625997832045, "vf_loss": 0.00962964639911661, "vf_explained_var": 0.7428175802032153, "kl": 0.008395889327751623, "entropy": 0.8254029411201675, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "sampler_results": {"episode_reward_max": 2.91202136281617, "episode_reward_min": 0.8336932378162785, "episode_reward_mean": 2.1862395359421662, "episode_len_mean": 713.41, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": 0.3290589542721147, "red_1": -0.03600000000000001}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.4501030335440523}, "policy_reward_mean": {"red_0": 1.722935311321284, "red_1": 0.463304224620881}, "custom_metrics": {"red_0/door_open_done_mean": 0.76, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162], "episode_lengths": [1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618], "policy_red_0_reward": [1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006], "policy_red_1_reward": [0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22237381831601905, "mean_inference_ms": 1.6657995405397363, "mean_action_processing_ms": 0.06809383902544328, "mean_env_wait_ms": 0.12288494338975758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01811361312866211, "StateBufferConnector_ms": 0.0014622211456298828, "ViewRequirementAgentConnector_ms": 0.031152725219726562}}, "episode_reward_max": 2.91202136281617, "episode_reward_min": 0.8336932378162785, "episode_reward_mean": 2.1862395359421662, "episode_len_mean": 713.41, "episodes_this_iter": 5, "policy_reward_min": {"red_0": 0.3290589542721147, "red_1": -0.03600000000000001}, "policy_reward_max": {"red_0": 2.609443237816183, "red_1": 1.4501030335440523}, "policy_reward_mean": {"red_0": 1.722935311321284, "red_1": 0.463304224620881}, "hist_stats": {"episode_reward": [1.5356932378162016, 2.285099487816186, 2.5734432378161816, 2.70108386281617, 2.37531823781618, 1.4191932378162124, 2.672427612816172, 1.7791619878162015, 1.738599487816193, 1.157693237816246, 2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162], "episode_lengths": [1280, 670, 400, 355, 632, 1280, 405, 1130, 1214, 1280, 848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618], "policy_red_0_reward": [1.1736932378162068, 1.8675994878161886, 2.609443237816183, 2.240083862816172, 1.9473182378161824, 1.0736932378162178, 2.197927612816173, 0.3290589542721147, 1.3930994878161989, 0.7746932378162252, 1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006], "policy_red_1_reward": [0.3619999999999999, 0.4174999999999999, -0.03600000000000001, 0.46099999999999997, 0.42799999999999994, 0.34549999999999986, 0.4745, 1.4501030335440523, 0.34549999999999986, 0.3829999999999999, 0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22237381831601905, "mean_inference_ms": 1.6657995405397363, "mean_action_processing_ms": 0.06809383902544328, "mean_env_wait_ms": 0.12288494338975758, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01811361312866211, "StateBufferConnector_ms": 0.0014622211456298828, "ViewRequirementAgentConnector_ms": 0.031152725219726562}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.4690046634328, "num_env_steps_trained_throughput_per_sec": 55.4690046634328, "timesteps_total": 164000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 328000, "timers": {"training_iteration_time_ms": 71966.786, "sample_time_ms": 7854.668, "learn_time_ms": 64080.202, "learn_throughput": 62.422, "synch_weights_time_ms": 31.274}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "done": false, "episodes_total": 186, "training_iteration": 41, "trial_id": "b02c7_00000", "date": "2023-09-27_22-50-23", "timestamp": 1695869423, "time_this_iter_s": 72.1159348487854, "time_total_s": 3030.5358352661133, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3e9f970>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3e9f430>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428edd0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3030.5358352661133, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 36.708737864077676, "ram_util_percent": 32.9990291262136}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.78, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4491799745708704, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.028378493430742915, "policy_loss": -0.01759202659595758, "vf_loss": 9.88624950442348e-05, "vf_explained_var": 0.7333383242910106, "kl": 0.011312641346103706, "entropy": 1.309842624515295, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.496172618524482, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0059531582846526964, "policy_loss": -0.014131343856085247, "vf_loss": 0.01407364801755951, "vf_explained_var": 0.8212516795222958, "kl": 0.009642773567159405, "entropy": 0.7871931783854962, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "sampler_results": {"episode_reward_max": 2.91202136281617, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.219468870163562, "episode_len_mean": 685.43, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.34399999999999986}, "policy_reward_max": {"red_0": 2.4187557378161717, "red_1": 0.843}, "policy_reward_mean": {"red_0": 1.7548156758781202, "red_1": 0.4646531942854405}, "custom_metrics": {"red_0/door_open_done_mean": 0.78, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693], "episode_lengths": [848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280], "policy_red_0_reward": [1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487], "policy_red_1_reward": [0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2216311394796578, "mean_inference_ms": 1.6606050771370522, "mean_action_processing_ms": 0.06776007345398864, "mean_env_wait_ms": 0.12241886257167155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017990469932556152, "StateBufferConnector_ms": 0.0014488697052001953, "ViewRequirementAgentConnector_ms": 0.03107750415802002}}, "episode_reward_max": 2.91202136281617, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.219468870163562, "episode_len_mean": 685.43, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.34399999999999986}, "policy_reward_max": {"red_0": 2.4187557378161717, "red_1": 0.843}, "policy_reward_mean": {"red_0": 1.7548156758781202, "red_1": 0.4646531942854405}, "hist_stats": {"episode_reward": [2.208443237816178, 1.661693237816185, 1.5851932378161944, 1.6366932378161891, 2.767286987816174, 2.7904588628161706, 1.8136307378161955, 2.19647448781618, 2.54299011281618, 1.5055156250000006, 2.553821783544066, 2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693], "episode_lengths": [848, 1280, 1280, 1280, 258, 267, 1172, 870, 449, 539, 442, 783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280], "policy_red_0_reward": [1.8074432378161815, 1.3176932378161905, 1.2306932378162, 1.2866932378161944, 2.2822869878161747, 2.3099588628161714, 1.4156307378161994, 1.772974487816183, 2.0879901128161817, 1.040015625, 2.065153364442605, 1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487], "policy_red_1_reward": [0.4009999999999999, 0.34399999999999986, 0.35449999999999987, 0.34999999999999987, 0.485, 0.4805, 0.3979999999999999, 0.42349999999999993, 0.45499999999999996, 0.46549999999999997, 0.48866841910146297, 0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2216311394796578, "mean_inference_ms": 1.6606050771370522, "mean_action_processing_ms": 0.06776007345398864, "mean_env_wait_ms": 0.12241886257167155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017990469932556152, "StateBufferConnector_ms": 0.0014488697052001953, "ViewRequirementAgentConnector_ms": 0.03107750415802002}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.618311503043124, "num_env_steps_trained_throughput_per_sec": 55.618311503043124, "timesteps_total": 168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 71953.506, "sample_time_ms": 7855.578, "learn_time_ms": 64066.048, "learn_throughput": 62.436, "synch_weights_time_ms": 31.238}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "episodes_total": 196, "training_iteration": 42, "trial_id": "b02c7_00000", "date": "2023-09-27_22-51-36", "timestamp": 1695869496, "time_this_iter_s": 71.92248392105103, "time_total_s": 3102.4583191871643, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3eb89d0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3ebb520>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66eb520>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3102.4583191871643, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 36.866019417475734, "ram_util_percent": 33.02427184466019}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.81, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4881633100410303, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02547649380103394, "policy_loss": -0.014552817475729778, "vf_loss": 0.0008735083222821534, "vf_explained_var": 0.7436535524825255, "kl": 0.009521709993518358, "entropy": 1.3264772700766723, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3834757023801407, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.019709660149480137, "policy_loss": -0.034743683788838096, "vf_loss": 0.019907696598481076, "vf_explained_var": 0.8188008654862642, "kl": 0.02975787617696981, "entropy": 0.8713992478946845, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "sampler_results": {"episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.2885366538079874, "episode_len_mean": 629.29, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3814999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.843}, "policy_reward_mean": {"red_0": 1.8161501437135603, "red_1": 0.4723865100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.81, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716], "episode_lengths": [783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336], "policy_red_0_reward": [1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172], "policy_red_1_reward": [0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22096801461348076, "mean_inference_ms": 1.6558950299493147, "mean_action_processing_ms": 0.06746395491624022, "mean_env_wait_ms": 0.12197462737294408, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018003463745117188, "StateBufferConnector_ms": 0.0014361143112182617, "ViewRequirementAgentConnector_ms": 0.031035661697387695}}, "episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.2885366538079874, "episode_len_mean": 629.29, "episodes_this_iter": 11, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3814999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.843}, "policy_reward_mean": {"red_0": 1.8161501437135603, "red_1": 0.4723865100944259}, "hist_stats": {"episode_reward": [2.181146362816187, 2.267568237816186, 2.2640526128161844, 1.4871932378162098, 2.8259588628161723, 2.889458862816171, 1.5621932378162058, 2.3152713628161865, 2.0503651128161895, 2.6334744878161764, 2.534568237816184, 1.5181932378162064, 2.6805838628161807, 2.648490112816176, 1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716], "episode_lengths": [783, 712, 749, 1280, 203, 139, 1280, 711, 1001, 390, 456, 1280, 291, 353, 1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336], "policy_red_0_reward": [1.7741463628161902, 1.8380682378161883, 1.8270526128161868, 1.1056932378162143, 2.3379588628161727, 2.3999588628161708, 1.1506932378162091, 1.8467713628161877, 1.6058651128161918, 2.169474487816177, 2.0570682378161846, 1.136693237816211, 2.2000838628161814, 2.181490112816177, 1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172], "policy_red_1_reward": [0.4069999999999999, 0.42949999999999994, 0.43699999999999994, 0.3814999999999999, 0.488, 0.4895, 0.4114999999999999, 0.46849999999999997, 0.44449999999999995, 0.46399999999999997, 0.4775, 0.3814999999999999, 0.4805, 0.46699999999999997, 0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22096801461348076, "mean_inference_ms": 1.6558950299493147, "mean_action_processing_ms": 0.06746395491624022, "mean_env_wait_ms": 0.12197462737294408, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018003463745117188, "StateBufferConnector_ms": 0.0014361143112182617, "ViewRequirementAgentConnector_ms": 0.031035661697387695}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.45242949626048, "num_env_steps_trained_throughput_per_sec": 55.45242949626048, "timesteps_total": 172000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 344000, "timers": {"training_iteration_time_ms": 71958.039, "sample_time_ms": 7849.118, "learn_time_ms": 64077.026, "learn_throughput": 62.425, "synch_weights_time_ms": 31.254}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "done": false, "episodes_total": 207, "training_iteration": 43, "trial_id": "b02c7_00000", "date": "2023-09-27_22-52-48", "timestamp": 1695869568, "time_this_iter_s": 72.13767504692078, "time_total_s": 3174.595994234085, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3ebac20>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3eb8760>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428dab0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3174.595994234085, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 35.98627450980391, "ram_util_percent": 33.03823529411765}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.83, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4227105115850767, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02956972535503155, "policy_loss": -0.018738457298119706, "vf_loss": 0.00012085849592532819, "vf_explained_var": 0.9256523587430517, "kl": 0.01140910031454155, "entropy": 1.317351753388842, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7783892033621669, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009494963288792254, "policy_loss": -0.019230798028002028, "vf_loss": 0.016511886218601526, "vf_explained_var": 0.8473550028478106, "kl": 0.008178221518110717, "entropy": 0.9735745128244162, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "sampler_results": {"episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.3320415825289507, "episode_len_mean": 589.01, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3964999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.8488550724345223, "red_1": 0.4831865100944258}, "custom_metrics": {"red_0/door_open_done_mean": 0.83, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867], "episode_lengths": [1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627], "policy_red_0_reward": [1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872], "policy_red_1_reward": [0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028572698288135, "mean_inference_ms": 1.6508483152046112, "mean_action_processing_ms": 0.06715526022807798, "mean_env_wait_ms": 0.12152112029436628, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01782548427581787, "StateBufferConnector_ms": 0.001427292823791504, "ViewRequirementAgentConnector_ms": 0.03098464012145996}}, "episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.3320415825289507, "episode_len_mean": 589.01, "episodes_this_iter": 14, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3964999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.8488550724345223, "red_1": 0.4831865100944258}, "hist_stats": {"episode_reward": [1.6531932378161938, 2.241896362816185, 2.15497448781619, 2.2804467835440843, 2.2503651128161732, 2.725224487816173, 1.4955625000000001, 2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867], "episode_lengths": [1280, 799, 838, 594, 905, 310, 588, 464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627], "policy_red_0_reward": [1.2566932378161977, 1.7928963628161867, 1.7164744878161922, 1.8134467835440853, 1.8193651128161759, 2.250724487816174, 1.0725625, 1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872], "policy_red_1_reward": [0.3964999999999999, 0.44899999999999995, 0.43849999999999995, 0.46699999999999997, 0.43099999999999994, 0.4745, 0.423, 0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028572698288135, "mean_inference_ms": 1.6508483152046112, "mean_action_processing_ms": 0.06715526022807798, "mean_env_wait_ms": 0.12152112029436628, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01782548427581787, "StateBufferConnector_ms": 0.001427292823791504, "ViewRequirementAgentConnector_ms": 0.03098464012145996}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.55360118064966, "num_env_steps_trained_throughput_per_sec": 55.55360118064966, "timesteps_total": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 71984.121, "sample_time_ms": 7846.382, "learn_time_ms": 64105.727, "learn_throughput": 62.397, "synch_weights_time_ms": 31.372}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "episodes_total": 221, "training_iteration": 44, "trial_id": "b02c7_00000", "date": "2023-09-27_22-54-00", "timestamp": 1695869640, "time_this_iter_s": 72.00642204284668, "time_total_s": 3246.6024162769318, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3a4f0a0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3a4f2b0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9ce50>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3246.6024162769318, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 36.900970873786406, "ram_util_percent": 33.05242718446602}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.84, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2859514217823744, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.024289899496579892, "policy_loss": -0.012843691665815034, "vf_loss": 0.0005502879064958204, "vf_explained_var": 0.7545789731666446, "kl": 0.007614476290268612, "entropy": 1.324424695596099, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5136992377539475, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0076434359598351875, "policy_loss": -0.018017688396503216, "vf_loss": 0.016126414980196083, "vf_explained_var": 0.7989092747991283, "kl": 0.010278373563347164, "entropy": 0.7724675238753359, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "sampler_results": {"episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.3747436356998133, "episode_len_mean": 556.62, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.4009999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.8880121256053852, "red_1": 0.48673151009442583}, "custom_metrics": {"red_0/door_open_done_mean": 0.84, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716], "episode_lengths": [464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139], "policy_red_0_reward": [1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172], "policy_red_1_reward": [0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2199735078468197, "mean_inference_ms": 1.648718545154329, "mean_action_processing_ms": 0.06701348842026679, "mean_env_wait_ms": 0.12130484058715561, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017824292182922363, "StateBufferConnector_ms": 0.0014259815216064453, "ViewRequirementAgentConnector_ms": 0.030942559242248535}}, "episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.3747436356998133, "episode_len_mean": 556.62, "episodes_this_iter": 7, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.4009999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.8880121256053852, "red_1": 0.48673151009442583}, "hist_stats": {"episode_reward": [2.4319432378161947, 1.7041932378161904, 2.327161987816175, 1.9340625000000005, 2.2332557378161817, 1.6573125000000006, 2.5601776128161817, 2.720693237816176, 2.4585526128161814, 1.7946932378161873, 1.381193237816226, 1.7821932378161858, 2.802708862816173, 2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716], "episode_lengths": [464, 1280, 810, 364, 876, 284, 453, 320, 589, 1280, 1280, 1280, 219, 437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139], "policy_red_0_reward": [1.9514432378161954, 1.2926932378161933, 1.8751619878161765, 1.0910625, 1.7707557378161833, 1.1723124999999999, 2.0781776128161824, 2.226693237816176, 1.9825526128161823, 1.3366932378161889, 0.9696932378162259, 1.343693237816188, 2.3177088628161737, 2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172], "policy_red_1_reward": [0.4805, 0.4114999999999999, 0.45199999999999996, 0.843, 0.46249999999999997, 0.485, 0.482, 0.494, 0.476, 0.45799999999999996, 0.4114999999999999, 0.43849999999999995, 0.485, 0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2199735078468197, "mean_inference_ms": 1.648718545154329, "mean_action_processing_ms": 0.06701348842026679, "mean_env_wait_ms": 0.12130484058715561, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017824292182922363, "StateBufferConnector_ms": 0.0014259815216064453, "ViewRequirementAgentConnector_ms": 0.030942559242248535}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.604434963504545, "num_env_steps_trained_throughput_per_sec": 55.604434963504545, "timesteps_total": 180000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 360000, "timers": {"training_iteration_time_ms": 71974.184, "sample_time_ms": 7842.419, "learn_time_ms": 64099.951, "learn_throughput": 62.403, "synch_weights_time_ms": 31.173}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 228, "training_iteration": 45, "trial_id": "b02c7_00000", "date": "2023-09-27_22-55-13", "timestamp": 1695869713, "time_this_iter_s": 71.94038915634155, "time_total_s": 3318.5428054332733, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3f613f0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3f61510>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea35b0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3318.5428054332733, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 36.57961165048544, "ram_util_percent": 33.08349514563107}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5894813728829225, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02890246384619483, "policy_loss": -0.017800921671247732, "vf_loss": 0.00019331326960051834, "vf_explained_var": 0.8673640344291925, "kl": 0.009998601146044924, "entropy": 1.3197918978830179, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6550519178931913, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0034024023598855516, "policy_loss": -0.016852978984146224, "vf_loss": 0.024078663301770574, "vf_explained_var": 0.7746203853438298, "kl": 0.0073939133272195555, "entropy": 0.8069288575400909, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "sampler_results": {"episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.431811450594239, "episode_len_mean": 510.55, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.9460049404998108, "red_1": 0.4858065100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173], "episode_lengths": [437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198], "policy_red_0_reward": [2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173], "policy_red_1_reward": [0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21949823960491632, "mean_inference_ms": 1.6451325775094177, "mean_action_processing_ms": 0.06679788414863654, "mean_env_wait_ms": 0.12096923318824873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01777172088623047, "StateBufferConnector_ms": 0.0014241933822631836, "ViewRequirementAgentConnector_ms": 0.030814528465270996}}, "episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.431811450594239, "episode_len_mean": 510.55, "episodes_this_iter": 13, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.9460049404998108, "red_1": 0.4858065100944259}, "hist_stats": {"episode_reward": [2.621927612816175, 2.627521362816177, 0.9381030335441586, 2.748990112816173, 2.7168877394426056, 2.49606823781618, 2.2999744878161863, 1.9028963628162021, 2.7872088628161737, 2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173], "episode_lengths": [437, 407, 1280, 289, 207, 552, 742, 1055, 251, 270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198], "policy_red_0_reward": [2.144427612816176, 2.151521362816178, 0.49210303354411034, 2.2714901128161737, 2.128736730000014, 2.021568237816181, 1.8269744878161875, 1.4568963628162042, 2.293208862816174, 2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173], "policy_red_1_reward": [0.4775, 0.476, 0.44599999999999995, 0.4775, 0.5881510094425921, 0.4745, 0.473, 0.44599999999999995, 0.494, 0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21949823960491632, "mean_inference_ms": 1.6451325775094177, "mean_action_processing_ms": 0.06679788414863654, "mean_env_wait_ms": 0.12096923318824873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01777172088623047, "StateBufferConnector_ms": 0.0014241933822631836, "ViewRequirementAgentConnector_ms": 0.030814528465270996}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.4163150163537, "num_env_steps_trained_throughput_per_sec": 55.4163150163537, "timesteps_total": 184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 72011.711, "sample_time_ms": 7848.109, "learn_time_ms": 64131.637, "learn_throughput": 62.372, "synch_weights_time_ms": 31.315}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "episodes_total": 241, "training_iteration": 46, "trial_id": "b02c7_00000", "date": "2023-09-27_22-56-25", "timestamp": 1695869785, "time_this_iter_s": 72.18501996994019, "time_total_s": 3390.7278254032135, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42cb760>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42cbaf0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9f370>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3390.7278254032135, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 38.22524271844661, "ram_util_percent": 33.20194174757281}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.89, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3295291950615744, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02238527273827155, "policy_loss": -0.011221140536872554, "vf_loss": 0.0003205210423364709, "vf_explained_var": 0.7649858943497141, "kl": 0.009833505842052502, "entropy": 1.3291094658275446, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.745258397422731, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0010237620704477497, "policy_loss": -0.01123439451669886, "vf_loss": 0.017645489168838444, "vf_explained_var": 0.8029033632948994, "kl": 0.007555627041322249, "entropy": 0.8788007316490014, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "sampler_results": {"episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.4370110741143716, "episode_len_mean": 497.43, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.950796074114369, "red_1": 0.48621499999999995}, "custom_metrics": {"red_0/door_open_done_mean": 0.89, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717], "episode_lengths": [270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180], "policy_red_0_reward": [2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255], "policy_red_1_reward": [0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21928859918593935, "mean_inference_ms": 1.6431142638226495, "mean_action_processing_ms": 0.06668137131598116, "mean_env_wait_ms": 0.12080071969000727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01782989501953125, "StateBufferConnector_ms": 0.0014352798461914062, "ViewRequirementAgentConnector_ms": 0.030858397483825684}}, "episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.4370110741143716, "episode_len_mean": 497.43, "episodes_this_iter": 9, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.950796074114369, "red_1": 0.48621499999999995}, "hist_stats": {"episode_reward": [2.7613494878161737, 2.3270838628161896, 2.8336307378161725, 1.7931932378161837, 2.6501619878161717, 2.818521362816173, 1.7316932378161933, 2.7549276128161737, 1.3061932378162386, 2.354521362816195, 1.7521932378161895, 2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717], "episode_lengths": [270, 643, 212, 1280, 394, 215, 1280, 277, 1280, 567, 1280, 223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180], "policy_red_0_reward": [2.2778494878161744, 1.864583862816191, 2.3366307378161726, 1.3606932378161858, 2.1696619878161716, 2.3245213628161734, 1.2796932378161952, 2.2729276128161744, 0.8646932378162258, 1.8770213628161956, 1.3106932378161917, 2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255], "policy_red_1_reward": [0.4835, 0.46249999999999997, 0.497, 0.43249999999999994, 0.4805, 0.494, 0.45199999999999996, 0.482, 0.44149999999999995, 0.4775, 0.44149999999999995, 0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21928859918593935, "mean_inference_ms": 1.6431142638226495, "mean_action_processing_ms": 0.06668137131598116, "mean_env_wait_ms": 0.12080071969000727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01782989501953125, "StateBufferConnector_ms": 0.0014352798461914062, "ViewRequirementAgentConnector_ms": 0.030858397483825684}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.23749727347181, "num_env_steps_trained_throughput_per_sec": 55.23749727347181, "timesteps_total": 188000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 376000, "timers": {"training_iteration_time_ms": 72058.325, "sample_time_ms": 7859.116, "learn_time_ms": 64167.208, "learn_throughput": 62.337, "synch_weights_time_ms": 31.351}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "done": false, "episodes_total": 250, "training_iteration": 47, "trial_id": "b02c7_00000", "date": "2023-09-27_22-57-38", "timestamp": 1695869858, "time_this_iter_s": 72.41830205917358, "time_total_s": 3463.146127462387, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x3574fc4c0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x3574ff880>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9e290>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3463.146127462387, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 38.97864077669903, "ram_util_percent": 33.373786407767}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.92, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4330774520834286, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.028058566541100543, "policy_loss": -0.01680013429237685, "vf_loss": 0.0003544857612155283, "vf_explained_var": 0.8360263550033172, "kl": 0.010302540687940315, "entropy": 1.34961829247574, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6623631404712795, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0055241487704430865, "policy_loss": -0.01651973907282809, "vf_loss": 0.018781643054777912, "vf_explained_var": 0.7992451723044117, "kl": 0.008287244918014495, "entropy": 0.8814042844499151, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "sampler_results": {"episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.4663797667362095, "episode_len_mean": 463.95, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.9731597667362064, "red_1": 0.49321999999999994}, "custom_metrics": {"red_0/door_open_done_mean": 0.92, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171], "episode_lengths": [223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201], "policy_red_0_reward": [2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712], "policy_red_1_reward": [0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21904851094163927, "mean_inference_ms": 1.6410401525651803, "mean_action_processing_ms": 0.06656189261519396, "mean_env_wait_ms": 0.1206259382196036, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01799154281616211, "StateBufferConnector_ms": 0.001443624496459961, "ViewRequirementAgentConnector_ms": 0.03091442584991455}}, "episode_reward_max": 2.946978033544055, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.4663797667362095, "episode_len_mean": 463.95, "episodes_this_iter": 11, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4514780335440554, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 1.9731597667362064, "red_1": 0.49321999999999994}, "hist_stats": {"episode_reward": [2.8078963628161726, 2.523503125000004, 2.690927612816177, 2.9097557378161714, 2.3160213628161923, 1.3493182378162492, 2.5145369878161787, 2.6340213628161804, 0.8826932378162723, 2.5932557378161807, 2.8797088628161713, 2.336286987816178, 1.2066030335441376, 1.424193237816223, 2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171], "episode_lengths": [223, 143, 341, 108, 631, 1240, 562, 375, 1280, 428, 155, 770, 1280, 1280, 366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201], "policy_red_0_reward": [2.322896362816173, 2.0415031250000046, 2.1999276128161775, 2.4187557378161717, 1.8520213628161935, 0.8988182378162256, 2.0295369878161793, 2.146021362816181, 0.4426932378162254, 2.106755737816181, 2.3857088628161716, 1.8782869878161796, 0.7441030335441106, 1.0006932378162254, 2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712], "policy_red_1_reward": [0.485, 0.482, 0.491, 0.491, 0.46399999999999997, 0.45049999999999996, 0.485, 0.488, 0.43999999999999995, 0.4865, 0.494, 0.45799999999999996, 0.46249999999999997, 0.42349999999999993, 0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21904851094163927, "mean_inference_ms": 1.6410401525651803, "mean_action_processing_ms": 0.06656189261519396, "mean_env_wait_ms": 0.1206259382196036, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01799154281616211, "StateBufferConnector_ms": 0.001443624496459961, "ViewRequirementAgentConnector_ms": 0.03091442584991455}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.25831351315025, "num_env_steps_trained_throughput_per_sec": 55.25831351315025, "timesteps_total": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 72083.252, "sample_time_ms": 7867.264, "learn_time_ms": 64184.044, "learn_throughput": 62.321, "synch_weights_time_ms": 31.293}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "episodes_total": 261, "training_iteration": 48, "trial_id": "b02c7_00000", "date": "2023-09-27_22-58-50", "timestamp": 1695869930, "time_this_iter_s": 72.39114093780518, "time_total_s": 3535.5372684001923, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354ccc190>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354ccceb0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9ce50>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3535.5372684001923, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 39.24519230769231, "ram_util_percent": 33.40865384615385}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5604555466522774, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03071271530946736, "policy_loss": -0.020375404079580526, "vf_loss": 8.814447146884655e-05, "vf_explained_var": 0.8807886994133393, "kl": 0.012699281424899617, "entropy": 1.292124000315865, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7335901886224747, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0032746340994587323, "policy_loss": -0.015319681869004852, "vf_loss": 0.02128532841403891, "vf_explained_var": 0.8241871088122328, "kl": 0.007889440604023627, "entropy": 0.9644487207134564, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "sampler_results": {"episode_reward_max": 2.9501619878161707, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.545991002816598, "episode_len_mean": 405.17, "episode_media": {}, "episodes_this_iter": 14, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0496001077243067, "red_1": 0.49639089509228884}, "custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177], "episode_lengths": [366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244], "policy_red_0_reward": [2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775], "policy_red_1_reward": [0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21876831163787722, "mean_inference_ms": 1.6386302345314916, "mean_action_processing_ms": 0.06641483193402414, "mean_env_wait_ms": 0.12045212143529593, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018122196197509766, "StateBufferConnector_ms": 0.0014532804489135742, "ViewRequirementAgentConnector_ms": 0.03095543384552002}}, "episode_reward_max": 2.9501619878161707, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.545991002816598, "episode_len_mean": 405.17, "episodes_this_iter": 14, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0496001077243067, "red_1": 0.49639089509228884}, "hist_stats": {"episode_reward": [2.6878494878161745, 2.489271362816195, 2.91202136281617, 2.5131463628161756, 1.8023494878162012, 1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177], "episode_lengths": [366, 391, 119, 591, 1230, 1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244], "policy_red_0_reward": [2.204349487816175, 2.0027713628161954, 2.4180213628161704, 2.0341463628161764, 1.3458494878162028, 1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775], "policy_red_1_reward": [0.4835, 0.4865, 0.494, 0.479, 0.45649999999999996, 0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21876831163787722, "mean_inference_ms": 1.6386302345314916, "mean_action_processing_ms": 0.06641483193402414, "mean_env_wait_ms": 0.12045212143529593, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018122196197509766, "StateBufferConnector_ms": 0.0014532804489135742, "ViewRequirementAgentConnector_ms": 0.03095543384552002}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.51964049918758, "num_env_steps_trained_throughput_per_sec": 55.51964049918758, "timesteps_total": 196000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 392000, "timers": {"training_iteration_time_ms": 72107.871, "sample_time_ms": 7871.015, "learn_time_ms": 64204.89, "learn_throughput": 62.301, "synch_weights_time_ms": 31.316}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "done": false, "episodes_total": 275, "training_iteration": 49, "trial_id": "b02c7_00000", "date": "2023-09-27_23-00-03", "timestamp": 1695870003, "time_this_iter_s": 72.05033779144287, "time_total_s": 3607.587606191635, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3e29360>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3e288e0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66ebb50>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3607.587606191635, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 38.04368932038835, "ram_util_percent": 33.49126213592234}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.94, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3401187705186506, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02109901466659115, "policy_loss": -0.010440100655250717, "vf_loss": 0.0005059609888292016, "vf_explained_var": 0.5351508405059576, "kl": 0.01016209131596824, "entropy": 1.2944313048074643, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6890845746422807, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008728343995123093, "policy_loss": -0.017090393308171768, "vf_loss": 0.013398480855297141, "vf_explained_var": 0.7059638686478138, "kl": 0.008303896673434253, "entropy": 0.8283599577844143, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "sampler_results": {"episode_reward_max": 2.9501619878161707, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.5504213507738664, "episode_len_mean": 402.53, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0535504556815756, "red_1": 0.49687089509228877}, "custom_metrics": {"red_0/door_open_done_mean": 0.94, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206], "episode_lengths": [1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258], "policy_red_0_reward": [1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062], "policy_red_1_reward": [0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21867543141583493, "mean_inference_ms": 1.637793679024644, "mean_action_processing_ms": 0.06636758984716988, "mean_env_wait_ms": 0.12040025578300206, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01802659034729004, "StateBufferConnector_ms": 0.001454472541809082, "ViewRequirementAgentConnector_ms": 0.030929088592529297}}, "episode_reward_max": 2.9501619878161707, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.5504213507738664, "episode_len_mean": 402.53, "episodes_this_iter": 5, "policy_reward_min": {"red_0": 0.3516932378162253, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0535504556815756, "red_1": 0.49687089509228877}, "hist_stats": {"episode_reward": [1.6101932378162065, 2.294130042772957, 2.114646362816181, 0.8336932378162785, 1.8509843750000001, 2.2756619878162, 2.2234744878152153, 2.684458862816175, 1.7827401128162164, 2.8194744878161715, 2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206], "episode_lengths": [1280, 788, 1071, 1280, 101, 618, 934, 363, 1105, 230, 182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258], "policy_red_0_reward": [1.1566932378162083, 1.8076300427729581, 1.6446463628161818, 0.3516932378162253, 1.353984375, 1.7951619878162006, 1.742974487815207, 2.1994588628161758, 1.3037401128162172, 2.329974487816172, 2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062], "policy_red_1_reward": [0.45349999999999996, 0.4865, 0.47, 0.482, 0.497, 0.4805, 0.4805, 0.485, 0.479, 0.4895, 0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21867543141583493, "mean_inference_ms": 1.637793679024644, "mean_action_processing_ms": 0.06636758984716988, "mean_env_wait_ms": 0.12040025578300206, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01802659034729004, "StateBufferConnector_ms": 0.001454472541809082, "ViewRequirementAgentConnector_ms": 0.030929088592529297}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.37548915554635, "num_env_steps_trained_throughput_per_sec": 55.37548915554635, "timesteps_total": 200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 72136.758, "sample_time_ms": 7866.642, "learn_time_ms": 64238.064, "learn_throughput": 62.268, "synch_weights_time_ms": 31.403}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 280, "training_iteration": 50, "trial_id": "b02c7_00000", "date": "2023-09-27_23-01-15", "timestamp": 1695870075, "time_this_iter_s": 72.23771715164185, "time_total_s": 3679.825323343277, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354d90790>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354d90850>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3ea3d00>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3679.825323343277, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 37.91844660194175, "ram_util_percent": 33.4621359223301}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.94, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5022839300955335, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03046360170786405, "policy_loss": -0.020320500286228102, "vf_loss": 9.147555598853311e-05, "vf_explained_var": 0.722501733712852, "kl": 0.012712208112060717, "entropy": 1.2731280906746785, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6393516139437756, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01217420144166681, "policy_loss": -0.020856224895639267, "vf_loss": 0.013943254693973966, "vf_explained_var": 0.8110489803676804, "kl": 0.008757957577006436, "entropy": 0.9169912998254101, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "sampler_results": {"episode_reward_max": 2.9501619878161707, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.5835709394641144, "episode_len_mean": 388.72, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.36269323781622487, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0856800443718244, "red_1": 0.4978908950922889}, "custom_metrics": {"red_0/door_open_done_mean": 0.94, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724], "episode_lengths": [182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792], "policy_red_0_reward": [2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732], "policy_red_1_reward": [0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21853767985290148, "mean_inference_ms": 1.6363615431603182, "mean_action_processing_ms": 0.06628272553673681, "mean_env_wait_ms": 0.12027162057122755, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018186450004577637, "StateBufferConnector_ms": 0.0014609098434448242, "ViewRequirementAgentConnector_ms": 0.030926227569580078}}, "episode_reward_max": 2.9501619878161707, "episode_reward_min": 0.7636932378162693, "episode_reward_mean": 2.5835709394641144, "episode_len_mean": 388.72, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.36269323781622487, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0856800443718244, "red_1": 0.4978908950922889}, "hist_stats": {"episode_reward": [2.7378148550000034, 2.8413963628161727, 2.420130737816179, 2.580286292772946, 2.7071776128161713, 0.7636932378162693, 2.918255737816171, 2.6235057378161732, 2.946978033544055, 2.8660994878161707, 2.642802612816177, 2.885146362816172, 2.817302612816173, 2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724], "episode_lengths": [182, 191, 692, 514, 357, 1280, 108, 476, 72, 190, 413, 143, 221, 168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792], "policy_red_0_reward": [2.2423148550000036, 2.347396362816173, 1.9321307378161798, 2.101286292772947, 2.2326776128161723, 0.36269323781622487, 2.4227557378161713, 2.1370057378161738, 2.4514780335440554, 2.369099487816171, 2.1503026128161773, 2.388146362816172, 2.3233026128161733, 2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732], "policy_red_1_reward": [0.4955, 0.494, 0.488, 0.479, 0.4745, 0.4009999999999999, 0.4955, 0.4865, 0.4955, 0.497, 0.4925, 0.497, 0.494, 0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21853767985290148, "mean_inference_ms": 1.6363615431603182, "mean_action_processing_ms": 0.06628272553673681, "mean_env_wait_ms": 0.12027162057122755, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018186450004577637, "StateBufferConnector_ms": 0.0014609098434448242, "ViewRequirementAgentConnector_ms": 0.030926227569580078}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.62322347266495, "num_env_steps_trained_throughput_per_sec": 55.62322347266495, "timesteps_total": 204000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 408000, "timers": {"training_iteration_time_ms": 72116.765, "sample_time_ms": 7866.714, "learn_time_ms": 64217.982, "learn_throughput": 62.288, "synch_weights_time_ms": 31.417}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "done": false, "episodes_total": 290, "training_iteration": 51, "trial_id": "b02c7_00000", "date": "2023-09-27_23-02-28", "timestamp": 1695870148, "time_this_iter_s": 71.91614174842834, "time_total_s": 3751.7414650917053, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a6660a30>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a6660a60>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66e92d0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3751.7414650917053, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 37.03333333333334, "ram_util_percent": 33.380392156862726}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5044113356930515, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.024692066550839324, "policy_loss": -0.014690194760623854, "vf_loss": 0.001443765098588301, "vf_explained_var": 0.7751680808141828, "kl": 0.011492769855262224, "entropy": 1.3022308797885975, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.38684310571601, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.001354328598002515, "policy_loss": -0.011734089628832104, "vf_loss": 0.023180739018910875, "vf_explained_var": 0.7872152344634136, "kl": 0.007541528823407904, "entropy": 0.7644094959522287, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "sampler_results": {"episode_reward_max": 2.9501619878161707, "episode_reward_min": 1.2095057378162717, "episode_reward_mean": 2.586653543657257, "episode_len_mean": 385.03, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"red_0": 0.5634999999999998, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0830776485649674, "red_1": 0.5035758950922888}, "custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784], "episode_lengths": [168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515], "policy_red_0_reward": [2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179], "policy_red_1_reward": [0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21827583077815235, "mean_inference_ms": 1.6344468517667143, "mean_action_processing_ms": 0.06616533856016513, "mean_env_wait_ms": 0.12007519019035447, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017978429794311523, "StateBufferConnector_ms": 0.001455068588256836, "ViewRequirementAgentConnector_ms": 0.030939817428588867}}, "episode_reward_max": 2.9501619878161707, "episode_reward_min": 1.2095057378162717, "episode_reward_mean": 2.586653543657257, "episode_len_mean": 385.03, "episodes_this_iter": 13, "policy_reward_min": {"red_0": 0.5634999999999998, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4516619878161707, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0830776485649674, "red_1": 0.5035758950922888}, "hist_stats": {"episode_reward": [2.831809614442596, 2.6811307378161753, 2.2115057378162115, 2.7444432378161716, 2.6790526128161734, 2.932911987816171, 1.6341932378162087, 2.824411292772946, 2.7006463628161717, 2.8812244878152047, 2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784], "episode_lengths": [168, 372, 572, 336, 397, 90, 1280, 186, 399, 150, 425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515], "policy_red_0_reward": [2.3378096144425964, 2.1931307378161757, 1.723505737816212, 2.253443237816172, 2.192552612816174, 2.437411987816171, 1.1506932378162094, 2.3349112927729463, 2.208146362816172, 2.390224487815205, 1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179], "policy_red_1_reward": [0.494, 0.488, 0.488, 0.491, 0.4865, 0.4955, 0.4835, 0.4895, 0.4925, 0.491, 0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21827583077815235, "mean_inference_ms": 1.6344468517667143, "mean_action_processing_ms": 0.06616533856016513, "mean_env_wait_ms": 0.12007519019035447, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017978429794311523, "StateBufferConnector_ms": 0.001455068588256836, "ViewRequirementAgentConnector_ms": 0.030939817428588867}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.690233063330076, "num_env_steps_trained_throughput_per_sec": 55.690233063330076, "timesteps_total": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 72107.476, "sample_time_ms": 7863.749, "learn_time_ms": 64211.628, "learn_throughput": 62.294, "synch_weights_time_ms": 31.446}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "episodes_total": 303, "training_iteration": 52, "trial_id": "b02c7_00000", "date": "2023-09-27_23-03-40", "timestamp": 1695870220, "time_this_iter_s": 71.82963013648987, "time_total_s": 3823.571095228195, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a66607f0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a6660880>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9f490>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3823.571095228195, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 37.592233009708735, "ram_util_percent": 33.36699029126215}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.96, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.704196366512527, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.023893281937065088, "policy_loss": -0.013149714873118985, "vf_loss": 0.0005831748936846755, "vf_explained_var": 0.7891780281439423, "kl": 0.00910948489944593, "entropy": 1.2857051633298398, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.683255409883956, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.001590828746338957, "policy_loss": -0.01376442831096938, "vf_loss": 0.02217697022279026, "vf_explained_var": 0.7218943597127994, "kl": 0.00610597283463968, "entropy": 0.7466770411158602, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "sampler_results": {"episode_reward_max": 2.95136511281617, "episode_reward_min": 1.0781562499999997, "episode_reward_mean": 2.5783610794632734, "episode_len_mean": 381.55, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0700451843709833, "red_1": 0.5083158950922888}, "custom_metrics": {"red_0/door_open_done_mean": 0.96, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173], "episode_lengths": [425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421], "policy_red_0_reward": [1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173], "policy_red_1_reward": [0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2181396162390843, "mean_inference_ms": 1.6332054076886604, "mean_action_processing_ms": 0.06608625600085387, "mean_env_wait_ms": 0.11998627819471988, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01788961887359619, "StateBufferConnector_ms": 0.0014443397521972656, "ViewRequirementAgentConnector_ms": 0.03083014488220215}}, "episode_reward_max": 2.95136511281617, "episode_reward_min": 1.0781562499999997, "episode_reward_mean": 2.5783610794632734, "episode_len_mean": 381.55, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9425000000000002}, "policy_reward_mean": {"red_0": 2.0700451843709833, "red_1": 0.5083158950922888}, "hist_stats": {"episode_reward": [2.6023644177729524, 2.862458862816171, 2.4929276128161915, 2.8433807378161715, 1.9442812500000057, 2.9066776128161704, 2.5056463628161754, 2.3988338628161867, 2.546630737816187, 2.5699119878161802, 2.5959901128161764, 2.917958862815205, 2.787505737816174, 2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173], "episode_lengths": [425, 171, 437, 196, 486, 133, 623, 627, 404, 474, 449, 107, 252, 250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421], "policy_red_0_reward": [1.659864417772948, 2.3744588628161716, 2.0004276128161917, 2.3538807378161715, 1.45628125, 2.4111776128161706, 2.0206463628161755, 1.9108338628161872, 2.064630737816187, 2.0804119878161806, 2.1199901128161764, 2.4194588628152056, 2.293505737816174, 2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173], "policy_red_1_reward": [0.9425000000000002, 0.488, 0.4925, 0.4895, 0.488, 0.4955, 0.485, 0.488, 0.482, 0.4895, 0.476, 0.4985, 0.494, 0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2181396162390843, "mean_inference_ms": 1.6332054076886604, "mean_action_processing_ms": 0.06608625600085387, "mean_env_wait_ms": 0.11998627819471988, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01788961887359619, "StateBufferConnector_ms": 0.0014443397521972656, "ViewRequirementAgentConnector_ms": 0.03083014488220215}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 56.72828301606964, "num_env_steps_trained_throughput_per_sec": 56.72828301606964, "timesteps_total": 212000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 424000, "timers": {"training_iteration_time_ms": 71945.243, "sample_time_ms": 7859.723, "learn_time_ms": 64053.331, "learn_throughput": 62.448, "synch_weights_time_ms": 31.534}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "done": false, "episodes_total": 313, "training_iteration": 53, "trial_id": "b02c7_00000", "date": "2023-09-27_23-04-51", "timestamp": 1695870291, "time_this_iter_s": 70.51537489891052, "time_total_s": 3894.0864701271057, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a6661090>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a6661150>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428ce50>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3894.0864701271057, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 41.81287128712871, "ram_util_percent": 33.38613861386139}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7453338449199995, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.032927714921728087, "policy_loss": -0.02316502773974207, "vf_loss": 0.00017351157804341711, "vf_explained_var": 0.8846473064273596, "kl": 0.014177986399055582, "entropy": 1.2685040317475795, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6143864466187854, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0020102254671655827, "policy_loss": -0.016646989932633006, "vf_loss": 0.02528356775486221, "vf_explained_var": 0.7019972619290153, "kl": 0.00923093289018915, "entropy": 0.7742996854707599, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "sampler_results": {"episode_reward_max": 2.95136511281617, "episode_reward_min": 1.0781562499999997, "episode_reward_mean": 2.55240578927923, "episode_len_mean": 378.67, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9425}, "policy_reward_mean": {"red_0": 2.0483198941869403, "red_1": 0.5040858950922888}, "custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999], "episode_lengths": [250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182], "policy_red_0_reward": [2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125], "policy_red_1_reward": [0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21808816684287552, "mean_inference_ms": 1.6320726961171692, "mean_action_processing_ms": 0.06603115144086825, "mean_env_wait_ms": 0.11988541228806884, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017788410186767578, "StateBufferConnector_ms": 0.0014450550079345703, "ViewRequirementAgentConnector_ms": 0.030826330184936523}}, "episode_reward_max": 2.95136511281617, "episode_reward_min": 1.0781562499999997, "episode_reward_mean": 2.55240578927923, "episode_len_mean": 378.67, "episodes_this_iter": 13, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9425}, "policy_reward_mean": {"red_0": 2.0483198941869403, "red_1": 0.5040858950922888}, "hist_stats": {"episode_reward": [2.7659119878152105, 2.8879588628161716, 2.0320057378161827, 2.895450239442593, 2.856896362816171, 2.838036987816171, 2.619349487816189, 1.9571619878162227, 2.900755737816171, 2.8557713628161716, 2.87544323781617, 2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999], "episode_lengths": [250, 139, 1180, 123, 191, 210, 302, 778, 140, 199, 176, 307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182], "policy_red_0_reward": [2.265911987815211, 2.393958862816172, 1.5560057378161836, 2.3984502394425933, 2.3613963628161714, 2.344036987816171, 2.122349487816189, 1.4766619878162235, 2.402255737816171, 2.3557713628161716, 2.3799432378161702, 2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125], "policy_red_1_reward": [0.5, 0.494, 0.476, 0.497, 0.4955, 0.494, 0.497, 0.4805, 0.4985, 0.5, 0.4955, 0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21808816684287552, "mean_inference_ms": 1.6320726961171692, "mean_action_processing_ms": 0.06603115144086825, "mean_env_wait_ms": 0.11988541228806884, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017788410186767578, "StateBufferConnector_ms": 0.0014450550079345703, "ViewRequirementAgentConnector_ms": 0.030826330184936523}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.98046690244805, "num_env_steps_trained_throughput_per_sec": 55.98046690244805, "timesteps_total": 216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 71890.339, "sample_time_ms": 7853.182, "learn_time_ms": 64004.976, "learn_throughput": 62.495, "synch_weights_time_ms": 31.523}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "episodes_total": 326, "training_iteration": 54, "trial_id": "b02c7_00000", "date": "2023-09-27_23-06-02", "timestamp": 1695870362, "time_this_iter_s": 71.45727634429932, "time_total_s": 3965.543746471405, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x35780afb0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x357809a80>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428f370>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 3965.543746471405, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 39.30980392156863, "ram_util_percent": 33.54411764705882}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5838715296238661, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.028595704116499594, "policy_loss": -0.01861596732705948, "vf_loss": 0.0009104901890244339, "vf_explained_var": 0.8516540001456936, "kl": 0.012020558850364675, "entropy": 1.283909378076593, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5753722136219344, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.004903104947273581, "policy_loss": -0.01762210240898033, "vf_loss": 0.022208124817310212, "vf_explained_var": 0.7319894153624773, "kl": 0.007823616651144264, "entropy": 0.7321499728908142, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "sampler_results": {"episode_reward_max": 2.95136511281617, "episode_reward_min": 1.0781562499999997, "episode_reward_mean": 2.5367119533784797, "episode_len_mean": 366.71, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 2.0235660582861903, "red_1": 0.5131458950922889}, "custom_metrics": {"red_0/door_open_done_mean": 0.95, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998], "episode_lengths": [307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138], "policy_red_0_reward": [2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999], "policy_red_1_reward": [0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21798751980859268, "mean_inference_ms": 1.6309597459998488, "mean_action_processing_ms": 0.06596127793317516, "mean_env_wait_ms": 0.1198265359706716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018252968788146973, "StateBufferConnector_ms": 0.0014671087265014648, "ViewRequirementAgentConnector_ms": 0.03100442886352539}}, "episode_reward_max": 2.95136511281617, "episode_reward_min": 1.0781562499999997, "episode_reward_mean": 2.5367119533784797, "episode_len_mean": 366.71, "episodes_this_iter": 11, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.3859999999999999}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 2.0235660582861903, "red_1": 0.5131458950922889}, "hist_stats": {"episode_reward": [2.714333862816177, 2.7916463628161754, 1.3245968750000245, 2.833474487816173, 2.4479119878161884, 2.7328807378161732, 2.9031619878161705, 2.895911987816172, 2.264703125000002, 2.836240112816171, 2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998], "episode_lengths": [307, 207, 881, 198, 538, 324, 138, 122, 95, 209, 184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138], "policy_red_0_reward": [2.2248338628161775, 2.308146362816176, 0.9385968749999996, 2.339474487816173, 1.9584119878161887, 2.2448807378161737, 2.4046619878161706, 2.401911987816172, 1.7692031250000002, 2.3467401128161716, 1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999], "policy_red_1_reward": [0.4895, 0.4835, 0.3859999999999999, 0.494, 0.4895, 0.488, 0.4985, 0.494, 0.4955, 0.4895, 0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21798751980859268, "mean_inference_ms": 1.6309597459998488, "mean_action_processing_ms": 0.06596127793317516, "mean_env_wait_ms": 0.1198265359706716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018252968788146973, "StateBufferConnector_ms": 0.0014671087265014648, "ViewRequirementAgentConnector_ms": 0.03100442886352539}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.84340205834459, "num_env_steps_trained_throughput_per_sec": 55.84340205834459, "timesteps_total": 220000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 440000, "timers": {"training_iteration_time_ms": 71859.555, "sample_time_ms": 7861.565, "learn_time_ms": 63965.903, "learn_throughput": 62.533, "synch_weights_time_ms": 31.429}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "done": false, "episodes_total": 337, "training_iteration": 55, "trial_id": "b02c7_00000", "date": "2023-09-27_23-07-14", "timestamp": 1695870434, "time_this_iter_s": 71.63254404067993, "time_total_s": 4037.176290512085, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42646d0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a4267640>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66e9120>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4037.176290512085, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 44.46176470588236, "ram_util_percent": 33.71568627450981}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.94, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.634257921917985, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.023191958962767482, "policy_loss": -0.012458081494454138, "vf_loss": 0.0008533187659774436, "vf_explained_var": 0.8709579865137737, "kl": 0.007915839076683662, "entropy": 1.2743704977134864, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3848407860534886, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00040276002497800317, "policy_loss": -0.010485888581994611, "vf_loss": 0.017924844930045463, "vf_explained_var": 0.8252635911727945, "kl": 0.005544407085942477, "entropy": 0.5426159396146735, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "sampler_results": {"episode_reward_max": 2.95136511281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.508466552250319, "episode_len_mean": 370.86, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.985240657158029, "red_1": 0.5232258950922889}, "custom_metrics": {"red_0/door_open_done_mean": 0.94, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179], "episode_lengths": [184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334], "policy_red_0_reward": [1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793], "policy_red_1_reward": [0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21786985265027023, "mean_inference_ms": 1.6297097012373642, "mean_action_processing_ms": 0.06589651134247386, "mean_env_wait_ms": 0.11972764184629611, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018443703651428223, "StateBufferConnector_ms": 0.0014579296112060547, "ViewRequirementAgentConnector_ms": 0.03101205825805664}}, "episode_reward_max": 2.95136511281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.508466552250319, "episode_len_mean": 370.86, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.985240657158029, "red_1": 0.5232258950922889}, "hist_stats": {"episode_reward": [2.2081250000000012, 2.1610994878161733, 1.2095057378162717, 2.8022869878161734, 2.7942088628161734, 2.2921718750000006, 2.687490112816177, 2.3362557378161997, 1.8086932378161884, 2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179], "episode_lengths": [184, 1118, 1180, 226, 251, 73, 353, 556, 1280, 132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334], "policy_red_0_reward": [1.712625, 1.6835994878161742, 0.7440057378162255, 2.3127869878161738, 2.3002088628161736, 1.7966718750000001, 2.196490112816177, 1.8437557378161997, 1.3326932378161889, 2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793], "policy_red_1_reward": [0.4955, 0.4775, 0.46549999999999997, 0.4895, 0.494, 0.4955, 0.491, 0.4925, 0.476, 0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21786985265027023, "mean_inference_ms": 1.6297097012373642, "mean_action_processing_ms": 0.06589651134247386, "mean_env_wait_ms": 0.11972764184629611, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018443703651428223, "StateBufferConnector_ms": 0.0014579296112060547, "ViewRequirementAgentConnector_ms": 0.03101205825805664}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.37581029194688, "num_env_steps_trained_throughput_per_sec": 55.37581029194688, "timesteps_total": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 71864.835, "sample_time_ms": 7866.743, "learn_time_ms": 63966.211, "learn_throughput": 62.533, "synch_weights_time_ms": 31.232}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "episodes_total": 347, "training_iteration": 56, "trial_id": "b02c7_00000", "date": "2023-09-27_23-08-27", "timestamp": 1695870507, "time_this_iter_s": 72.23748207092285, "time_total_s": 4109.413772583008, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354ccfe20>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354ccdba0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66eb760>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4109.413772583008, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 48.56893203883495, "ram_util_percent": 34.8359223300971}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.93, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5591352072854836, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.026073732528675463, "policy_loss": -0.015725175356783437, "vf_loss": 0.00014156920879599967, "vf_explained_var": 0.8472949722781777, "kl": 0.00835575518603188, "entropy": 1.2090492822229861, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.659232122140626, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007874614956381264, "policy_loss": -0.015317741456965451, "vf_loss": 0.011947033090352003, "vf_explained_var": 0.866083960669736, "kl": 0.006862016239140711, "entropy": 0.5889954867151876, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "sampler_results": {"episode_reward_max": 2.95136511281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.540704785056209, "episode_len_mean": 357.3, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 2.0169988899639195, "red_1": 0.5237058950922888}, "custom_metrics": {"red_0/door_open_done_mean": 0.93, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171], "episode_lengths": [132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110], "policy_red_0_reward": [2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171], "policy_red_1_reward": [0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2177838898971901, "mean_inference_ms": 1.628608868931096, "mean_action_processing_ms": 0.06584086781491184, "mean_env_wait_ms": 0.11965547666252274, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018430352210998535, "StateBufferConnector_ms": 0.0014505386352539062, "ViewRequirementAgentConnector_ms": 0.03109133243560791}}, "episode_reward_max": 2.95136511281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.540704785056209, "episode_len_mean": 357.3, "episodes_this_iter": 9, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 2.0169988899639195, "red_1": 0.5237058950922888}, "hist_stats": {"episode_reward": [2.8988807378161705, 2.7071151128161777, 2.0313494878162155, 2.8135213628161733, 2.848365112816171, 2.7948461050000026, 2.9426463628161703, 2.923958862816171, 2.8834432378161727, 2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171], "episode_lengths": [132, 313, 750, 215, 201, 108, 79, 107, 144, 377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110], "policy_red_0_reward": [2.407880737816171, 2.214615112816178, 1.090349487816173, 2.322521362816172, 2.3573651128161712, 2.299346105000003, 2.4471463628161705, 2.425458862816171, 2.3834432378161727, 2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171], "policy_red_1_reward": [0.491, 0.4925, 0.9410000000000003, 0.491, 0.491, 0.4955, 0.4955, 0.4985, 0.5, 0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2177838898971901, "mean_inference_ms": 1.628608868931096, "mean_action_processing_ms": 0.06584086781491184, "mean_env_wait_ms": 0.11965547666252274, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018430352210998535, "StateBufferConnector_ms": 0.0014505386352539062, "ViewRequirementAgentConnector_ms": 0.03109133243560791}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 54.933556448168424, "num_env_steps_trained_throughput_per_sec": 54.933556448168424, "timesteps_total": 228000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 456000, "timers": {"training_iteration_time_ms": 71904.902, "sample_time_ms": 7861.174, "learn_time_ms": 64011.876, "learn_throughput": 62.488, "synch_weights_time_ms": 31.203}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "done": false, "episodes_total": 356, "training_iteration": 57, "trial_id": "b02c7_00000", "date": "2023-09-27_23-09-40", "timestamp": 1695870580, "time_this_iter_s": 72.81886005401611, "time_total_s": 4182.232632637024, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354d91c00>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354d91cc0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66eb490>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4182.232632637024, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 41.16250000000001, "ram_util_percent": 35.20096153846154}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.91, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.454176318241904, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02540224946666664, "policy_loss": -0.015011521424579162, "vf_loss": 0.0006160344461553298, "vf_explained_var": 0.7776938057194154, "kl": 0.009079743953539396, "entropy": 1.2514694689462582, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6669890135526657, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.005376293041020593, "policy_loss": -0.013909392444475088, "vf_loss": 0.014740275906660827, "vf_explained_var": 0.8184102276340127, "kl": 0.006128712941127408, "entropy": 0.6756525496641795, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "sampler_results": {"episode_reward_max": 2.95136511281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.482608237921726, "episode_len_mean": 382.98, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.963582342829436, "red_1": 0.5190258950922889}, "custom_metrics": {"red_0/door_open_done_mean": 0.91, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279], "episode_lengths": [377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280], "policy_red_0_reward": [2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526], "policy_red_1_reward": [0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21769409214237445, "mean_inference_ms": 1.6273754834876673, "mean_action_processing_ms": 0.0657621890499501, "mean_env_wait_ms": 0.11952676512728445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01856386661529541, "StateBufferConnector_ms": 0.0014522075653076172, "ViewRequirementAgentConnector_ms": 0.031155824661254883}}, "episode_reward_max": 2.95136511281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.482608237921726, "episode_len_mean": 382.98, "episodes_this_iter": 9, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4543651128161703, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.963582342829436, "red_1": 0.5190258950922889}, "hist_stats": {"episode_reward": [2.708615112816171, 2.845973792772942, 1.86795886281622, 2.9501619878161707, 2.825408605000001, 2.903106489442593, 2.92253698781617, 2.8425994878161758, 2.862958862816172, 2.755630737816177, 2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279], "episode_lengths": [377, 230, 939, 74, 88, 105, 114, 158, 171, 244, 240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280], "policy_red_0_reward": [2.2296151128161714, 2.345384283544055, 1.3874588628162208, 2.4516619878161707, 2.3284086050000012, 2.409106489442593, 2.4255369878161703, 2.345599487816176, 2.3674588628161723, 2.2661307378161775, 2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526], "policy_red_1_reward": [0.479, 0.5005895092288869, 0.4805, 0.4985, 0.497, 0.494, 0.497, 0.497, 0.4955, 0.4895, 0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21769409214237445, "mean_inference_ms": 1.6273754834876673, "mean_action_processing_ms": 0.0657621890499501, "mean_env_wait_ms": 0.11952676512728445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01856386661529541, "StateBufferConnector_ms": 0.0014522075653076172, "ViewRequirementAgentConnector_ms": 0.031155824661254883}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.4086340924061, "num_env_steps_trained_throughput_per_sec": 55.4086340924061, "timesteps_total": 232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 71885.264, "sample_time_ms": 7865.718, "learn_time_ms": 63987.739, "learn_throughput": 62.512, "synch_weights_time_ms": 31.162}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "episodes_total": 365, "training_iteration": 58, "trial_id": "b02c7_00000", "date": "2023-09-27_23-10-52", "timestamp": 1695870652, "time_this_iter_s": 72.19454288482666, "time_total_s": 4254.427175521851, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3ac9180>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3ac9810>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9ea70>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4254.427175521851, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 37.491262135922334, "ram_util_percent": 35.60388349514563}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.9, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7530988939727346, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.028568509393153363, "policy_loss": -0.018061079990972454, "vf_loss": 0.00012037302830473588, "vf_explained_var": 0.7265027159204086, "kl": 0.01012041031501579, "entropy": 1.2591698594391345, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.88437280425181, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011483775090406803, "policy_loss": -0.022387700643836675, "vf_loss": 0.015164459239895223, "vf_explained_var": 0.84069254056861, "kl": 0.01355111164136421, "entropy": 0.7436376010999084, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "sampler_results": {"episode_reward_max": 2.958505737815204, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.461283364934037, "episode_len_mean": 400.76, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4615057378152043, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9420383649340351, "red_1": 0.519245}, "custom_metrics": {"red_0/door_open_done_mean": 0.9, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206], "episode_lengths": [240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863], "policy_red_0_reward": [2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061], "policy_red_1_reward": [0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2179149890231113, "mean_inference_ms": 1.6268696686698443, "mean_action_processing_ms": 0.06574806630979634, "mean_env_wait_ms": 0.11952646554909427, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018497228622436523, "StateBufferConnector_ms": 0.0014511346817016602, "ViewRequirementAgentConnector_ms": 0.03118109703063965}}, "episode_reward_max": 2.958505737815204, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.461283364934037, "episode_len_mean": 400.76, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.4615057378152043, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9420383649340351, "red_1": 0.519245}, "hist_stats": {"episode_reward": [2.74544323781618, 2.6917124085440625, 1.8731932378161797, 2.7365369878161747, 2.800786987815206, 2.811161987816172, 1.6066932378162124, 2.7890249085440617, 1.924693237816177, 2.3419744878161928, 2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206], "episode_lengths": [240, 349, 1280, 306, 258, 234, 1280, 217, 1280, 646, 390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863], "policy_red_0_reward": [2.24694323781618, 2.1947124085440626, 1.407693237816181, 2.245536987816175, 2.3052869878152062, 2.3201619878161726, 1.1186932378162129, 2.293524908544062, 1.4396932378161775, 1.846474487816193, 2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061], "policy_red_1_reward": [0.4985, 0.497, 0.46549999999999997, 0.491, 0.4955, 0.491, 0.488, 0.4955, 0.485, 0.4955, 0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2179149890231113, "mean_inference_ms": 1.6268696686698443, "mean_action_processing_ms": 0.06574806630979634, "mean_env_wait_ms": 0.11952646554909427, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018497228622436523, "StateBufferConnector_ms": 0.0014511346817016602, "ViewRequirementAgentConnector_ms": 0.03118109703063965}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.506051138720416, "num_env_steps_trained_throughput_per_sec": 55.506051138720416, "timesteps_total": 236000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 472000, "timers": {"training_iteration_time_ms": 71887.027, "sample_time_ms": 7863.429, "learn_time_ms": 63991.768, "learn_throughput": 62.508, "synch_weights_time_ms": 31.182}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "done": false, "episodes_total": 375, "training_iteration": 59, "trial_id": "b02c7_00000", "date": "2023-09-27_23-12-05", "timestamp": 1695870725, "time_this_iter_s": 72.06791472434998, "time_total_s": 4326.495090246201, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a40d9750>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a40d9cc0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3578dc0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4326.495090246201, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 36.831067961165054, "ram_util_percent": 35.560194174757285}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.92, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6424412617459894, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.030767500561099344, "policy_loss": -0.020872154666722053, "vf_loss": 4.421196949901211e-05, "vf_explained_var": 0.7215722828482588, "kl": 0.010632802392446319, "entropy": 1.2044011981536944, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7514080631236235, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009621509443968534, "policy_loss": -0.017736556566281553, "vf_loss": 0.013114234195866933, "vf_explained_var": 0.870256562034289, "kl": 0.007201409092681408, "entropy": 0.6024927765130996, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.485818736641327, "episode_len_mean": 372.92, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.966258736641325, "red_1": 0.5195599999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.92, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003], "episode_lengths": [390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65], "policy_red_0_reward": [2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003], "policy_red_1_reward": [0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21770962595719445, "mean_inference_ms": 1.6257750137958857, "mean_action_processing_ms": 0.06566890144884972, "mean_env_wait_ms": 0.11940174861333826, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018393993377685547, "StateBufferConnector_ms": 0.0014458894729614258, "ViewRequirementAgentConnector_ms": 0.03109145164489746}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.485818736641327, "episode_len_mean": 372.92, "episodes_this_iter": 10, "policy_reward_min": {"red_0": 0.13565624999999965, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.966258736641325, "red_1": 0.5195599999999999}, "hist_stats": {"episode_reward": [2.6342158644426013, 1.9494119878161915, 2.8038877394425965, 2.536534375000003, 2.4068182378161724, 2.588005737816178, 2.9460369878161705, 2.854802612815205, 2.9073494878161723, 2.5314276128161746, 2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003], "episode_lengths": [390, 1178, 207, 165, 792, 476, 82, 189, 110, 597, 205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65], "policy_red_0_reward": [2.1357158644426013, 1.4734119878161929, 2.3083877394425967, 2.0410343750000033, 1.9218182378161732, 2.097005737816178, 2.4460369878161705, 2.3608026128152053, 2.4103494878161724, 2.041927612816175, 2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003], "policy_red_1_reward": [0.4985, 0.476, 0.4955, 0.4955, 0.485, 0.491, 0.5, 0.494, 0.497, 0.4895, 0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21770962595719445, "mean_inference_ms": 1.6257750137958857, "mean_action_processing_ms": 0.06566890144884972, "mean_env_wait_ms": 0.11940174861333826, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018393993377685547, "StateBufferConnector_ms": 0.0014458894729614258, "ViewRequirementAgentConnector_ms": 0.03109145164489746}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.666059517270426, "num_env_steps_trained_throughput_per_sec": 55.666059517270426, "timesteps_total": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 71849.322, "sample_time_ms": 7864.517, "learn_time_ms": 63952.993, "learn_throughput": 62.546, "synch_weights_time_ms": 31.162}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "episodes_total": 385, "training_iteration": 60, "trial_id": "b02c7_00000", "date": "2023-09-27_23-13-17", "timestamp": 1695870797, "time_this_iter_s": 71.86074113845825, "time_total_s": 4398.355831384659, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42c11e0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a42c1270>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428f1c0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4398.355831384659, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 36.56764705882353, "ram_util_percent": 35.63627450980392}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.9, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.797091513623794, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.025864089276607653, "policy_loss": -0.015177172600427486, "vf_loss": 7.730929601924193e-05, "vf_explained_var": 0.8142568492641051, "kl": 0.008209356157209413, "entropy": 1.2367443117002646, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.631951066541175, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.012245899484211502, "policy_loss": -0.022597276947150628, "vf_loss": 0.016047133095222915, "vf_explained_var": 0.843587466267248, "kl": 0.010116298429401756, "entropy": 0.7070788887639841, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.4679819027242083, "episode_len_mean": 372.89, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9426203926297796, "red_1": 0.5253615100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.9, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942], "episode_lengths": [205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155], "policy_red_0_reward": [2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423], "policy_red_1_reward": [0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21758787177719965, "mean_inference_ms": 1.6248088068868618, "mean_action_processing_ms": 0.0656092583678667, "mean_env_wait_ms": 0.11933999835671409, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0184096097946167, "StateBufferConnector_ms": 0.0014455318450927734, "ViewRequirementAgentConnector_ms": 0.031090378761291504}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.4679819027242083, "episode_len_mean": 372.89, "episodes_this_iter": 10, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9426203926297796, "red_1": 0.5253615100944259}, "hist_stats": {"episode_reward": [2.798552612816177, 2.7912713628161723, 2.8555526128161706, 2.69544323781618, 1.5059999999999998, 2.089615112816179, 2.9367088628161704, 2.5580838628161784, 2.59458386281619, 2.95136511281617, 2.4728026128161806, 1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942], "episode_lengths": [205, 263, 205, 304, 288, 1145, 91, 515, 323, 73, 605, 558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155], "policy_red_0_reward": [2.301552612816177, 2.2987713628161726, 2.3585526128161707, 2.1999432378161803, 0.5634999999999998, 1.6136151128161798, 2.4397088628161705, 2.068583862816179, 2.0975838628161902, 2.4543651128161703, 1.983302612816181, 0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423], "policy_red_1_reward": [0.497, 0.4925, 0.497, 0.4955, 0.9425, 0.476, 0.497, 0.4895, 0.497, 0.497, 0.4895, 0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21758787177719965, "mean_inference_ms": 1.6248088068868618, "mean_action_processing_ms": 0.0656092583678667, "mean_env_wait_ms": 0.11933999835671409, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0184096097946167, "StateBufferConnector_ms": 0.0014455318450927734, "ViewRequirementAgentConnector_ms": 0.031090378761291504}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.54454155022201, "num_env_steps_trained_throughput_per_sec": 55.54454155022201, "timesteps_total": 244000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 488000, "timers": {"training_iteration_time_ms": 71859.509, "sample_time_ms": 7866.408, "learn_time_ms": 63961.352, "learn_throughput": 62.538, "synch_weights_time_ms": 31.1}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "done": false, "episodes_total": 395, "training_iteration": 61, "trial_id": "b02c7_00000", "date": "2023-09-27_23-14-29", "timestamp": 1695870869, "time_this_iter_s": 72.01799297332764, "time_total_s": 4470.373824357986, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3bc79a0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3bc7d00>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a357a050>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4470.373824357986, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 36.15825242718447, "ram_util_percent": 35.599999999999994}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.07453059181571, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02432731175443526, "policy_loss": -0.014532060009029617, "vf_loss": 0.0001406880829070663, "vf_explained_var": 0.7860167756055793, "kl": 0.009689154477964701, "entropy": 1.1803427911053102, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5106106642633677, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0007117537383843834, "policy_loss": -0.011974011876736768, "vf_loss": 0.021266951814565498, "vf_explained_var": 0.7858956273024281, "kl": 0.00883329262101126, "entropy": 0.5976987548793355, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.438673698425165, "episode_len_mean": 381.67, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9129371883307353, "red_1": 0.5257365100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553], "episode_lengths": [558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49], "policy_red_0_reward": [0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553], "policy_red_1_reward": [0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21754624239355722, "mean_inference_ms": 1.6239151548437056, "mean_action_processing_ms": 0.06555677262059996, "mean_env_wait_ms": 0.11926674315299066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018651127815246582, "StateBufferConnector_ms": 0.001447916030883789, "ViewRequirementAgentConnector_ms": 0.031157612800598145}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.438673698425165, "episode_len_mean": 381.67, "episodes_this_iter": 11, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9129371883307353, "red_1": 0.5257365100944259}, "hist_stats": {"episode_reward": [1.0781562499999997, 2.693130737816185, 2.3441463628161863, 2.9008651128161707, 2.6304901128161724, 2.946865112816171, 2.679677612816173, 1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553], "episode_lengths": [558, 244, 719, 137, 449, 73, 421, 1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49], "policy_red_0_reward": [0.13565624999999965, 2.196130737816185, 1.8531463628161864, 2.405365112816171, 2.1589901128161735, 2.448365112816171, 2.185677612816173, 1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553], "policy_red_1_reward": [0.9425, 0.497, 0.491, 0.4955, 0.4715, 0.4985, 0.494, 0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21754624239355722, "mean_inference_ms": 1.6239151548437056, "mean_action_processing_ms": 0.06555677262059996, "mean_env_wait_ms": 0.11926674315299066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018651127815246582, "StateBufferConnector_ms": 0.001447916030883789, "ViewRequirementAgentConnector_ms": 0.031157612800598145}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.43475330933815, "num_env_steps_trained_throughput_per_sec": 55.43475330933815, "timesteps_total": 248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 71892.611, "sample_time_ms": 7869.829, "learn_time_ms": 63991.051, "learn_throughput": 62.509, "synch_weights_time_ms": 31.082}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "episodes_total": 406, "training_iteration": 62, "trial_id": "b02c7_00000", "date": "2023-09-27_23-15-42", "timestamp": 1695870942, "time_this_iter_s": 72.16057705879211, "time_total_s": 4542.534401416779, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a40d97b0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a40da170>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3578af0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4542.534401416779, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 37.94271844660194, "ram_util_percent": 35.709708737864084}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3067688971447449, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.022515220598446226, "policy_loss": -0.01168345456693108, "vf_loss": 0.0004831295153034413, "vf_explained_var": 0.8549783746401469, "kl": 0.007121036501391279, "entropy": 1.249753785505891, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4953476031621298, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00732286410566303, "policy_loss": -0.013310971898317803, "vf_loss": 0.010267850515325942, "vf_explained_var": 0.8603857720270753, "kl": 0.004593121532862924, "entropy": 0.5237538633247216, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.4444037996914196, "episode_len_mean": 384.17, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9227322895969903, "red_1": 0.5216715100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706], "episode_lengths": [1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64], "policy_red_0_reward": [1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706], "policy_red_1_reward": [0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21749768816441314, "mean_inference_ms": 1.6233093893269293, "mean_action_processing_ms": 0.06552648828436856, "mean_env_wait_ms": 0.11921784290443428, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01886904239654541, "StateBufferConnector_ms": 0.001461029052734375, "ViewRequirementAgentConnector_ms": 0.03124535083770752}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.4444037996914196, "episode_len_mean": 384.17, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.46549999999999997}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9227322895969903, "red_1": 0.5216715100944259}, "hist_stats": {"episode_reward": [1.7691932378161912, 2.932802612816171, 2.935427612816171, 2.6190187500000013, 2.791865112816172, 1.8636875000000002, 2.8429276128161707, 2.2220625000000034, 2.317005737816196, 2.712240112816181, 2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706], "episode_lengths": [1280, 93, 85, 74, 265, 100, 213, 140, 604, 273, 362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64], "policy_red_0_reward": [1.3036932378161925, 2.434302612816171, 2.436927612816171, 2.1190187500000013, 2.2993651128161723, 1.3696875, 2.348927612816171, 1.7265625, 1.838005737816197, 2.216740112816181, 2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706], "policy_red_1_reward": [0.46549999999999997, 0.4985, 0.4985, 0.5, 0.4925, 0.494, 0.494, 0.4955, 0.479, 0.4955, 0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21749768816441314, "mean_inference_ms": 1.6233093893269293, "mean_action_processing_ms": 0.06552648828436856, "mean_env_wait_ms": 0.11921784290443428, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01886904239654541, "StateBufferConnector_ms": 0.001461029052734375, "ViewRequirementAgentConnector_ms": 0.03124535083770752}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.34592839841274, "num_env_steps_trained_throughput_per_sec": 55.34592839841274, "timesteps_total": 252000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 504000, "timers": {"training_iteration_time_ms": 72068.725, "sample_time_ms": 7878.91, "learn_time_ms": 64158.142, "learn_throughput": 62.346, "synch_weights_time_ms": 31.026}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "done": false, "episodes_total": 413, "training_iteration": 63, "trial_id": "b02c7_00000", "date": "2023-09-27_23-16-54", "timestamp": 1695871014, "time_this_iter_s": 72.27628207206726, "time_total_s": 4614.810683488846, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x354d91000>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x354d910f0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a428edd0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4614.810683488846, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 38.36893203883495, "ram_util_percent": 35.75631067961165}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7824031429986158, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02414784240912316, "policy_loss": -0.013782325430050453, "vf_loss": 0.00034063390583393506, "vf_explained_var": 0.8919972790405154, "kl": 0.008475755171348404, "entropy": 1.2230984852959712, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5524742287273208, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.035566123792235275, "policy_loss": -0.04872278783295769, "vf_loss": 0.015563053620280699, "vf_explained_var": 0.8535281008730332, "kl": 0.04013184151270736, "entropy": 0.6446392939736446, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.4579956355576837, "episode_len_mean": 391.93, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9358441254632544, "red_1": 0.5221515100944258}, "custom_metrics": {"red_0/door_open_done_mean": 0.88, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618], "episode_lengths": [362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368], "policy_red_0_reward": [2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618], "policy_red_1_reward": [0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2173392941061989, "mean_inference_ms": 1.6221286608838712, "mean_action_processing_ms": 0.06544835036579101, "mean_env_wait_ms": 0.11911345717277486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019006848335266113, "StateBufferConnector_ms": 0.0014655590057373047, "ViewRequirementAgentConnector_ms": 0.03132426738739014}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.7836932378162789, "episode_reward_mean": 2.4579956355576837, "episode_len_mean": 391.93, "episodes_this_iter": 10, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9358441254632544, "red_1": 0.5221515100944258}, "hist_stats": {"episode_reward": [2.5681619878161888, 2.0421151128162105, 1.7625312499999999, 2.8333494878152043, 1.7235468749999998, 2.6588026128161735, 2.1406406250000027, 2.8053182378161723, 2.9107244878161707, 2.8890369878161715, 2.9160369878161707, 2.395724487816195, 2.8897088628161707, 1.7524687499999998, 1.5512031249999998, 2.907521362816171, 2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618], "episode_lengths": [362, 825, 182, 206, 145, 445, 243, 248, 118, 146, 114, 534, 155, 138, 255, 119, 100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368], "policy_red_0_reward": [2.077161987816189, 1.555615112816211, 1.26703125, 2.3498494878152054, 0.7750468749999999, 2.1618026128161736, 1.654140625, 2.3113182378161725, 2.416724487816171, 2.3920369878161716, 2.420536987816171, 1.9032244878161952, 2.392708862816171, 0.8039687499999999, 0.6117031249999998, 2.412021362816171, 2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618], "policy_red_1_reward": [0.491, 0.4865, 0.4955, 0.4835, 0.9485, 0.497, 0.4865, 0.494, 0.494, 0.497, 0.4955, 0.4925, 0.497, 0.9485, 0.9395000000000001, 0.4955, 0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2173392941061989, "mean_inference_ms": 1.6221286608838712, "mean_action_processing_ms": 0.06544835036579101, "mean_env_wait_ms": 0.11911345717277486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019006848335266113, "StateBufferConnector_ms": 0.0014655590057373047, "ViewRequirementAgentConnector_ms": 0.03132426738739014}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.56646608370178, "num_env_steps_trained_throughput_per_sec": 55.56646608370178, "timesteps_total": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 72121.962, "sample_time_ms": 7889.184, "learn_time_ms": 64201.185, "learn_throughput": 62.304, "synch_weights_time_ms": 30.948}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "episodes_total": 423, "training_iteration": 64, "trial_id": "b02c7_00000", "date": "2023-09-27_23-18-06", "timestamp": 1695871086, "time_this_iter_s": 71.98961997032166, "time_total_s": 4686.8003034591675, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a3b11f60>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3b121d0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a66e8280>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4686.8003034591675, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 36.826213592233, "ram_util_percent": 35.85242718446601}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.87, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6868983461832008, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.034465665542908634, "policy_loss": -0.02455545990887913, "vf_loss": 0.00023954053732874552, "vf_explained_var": 0.8942400880157948, "kl": 0.010242146599534584, "entropy": 1.2078405649711688, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5047245984276136, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.004516714505734853, "policy_loss": -0.018545449192364078, "vf_loss": 0.025487127207452432, "vf_explained_var": 0.8253514441351096, "kl": 0.008341849247584032, "entropy": 0.5917448465091487, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.43905000000007455, "episode_reward_mean": 2.440683694564973, "episode_len_mean": 412.85, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9239321844705424, "red_1": 0.5167515100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.87, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618, 1.4258906249999996, 1.5443125, 2.87231823781617, 2.854677612816171, 2.858458862816173, 2.7639119878161704, 2.9283494878161704, 2.8587211050000008, 2.8621342835440564, 2.8977869878161706, 2.9594901128161704, 1.7958906250000002, 0.43905000000007455, 1.9481151128161942, 1.1288338628162775, 2.8777557378161704], "episode_lengths": [100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368, 451, 380, 184, 197, 171, 314, 110, 52, 182, 130, 65, 195, 1280, 1177, 1267, 172], "policy_red_0_reward": [2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618, 0.5808906249999999, 0.6138124999999999, 2.37831823781617, 2.359177612816171, 2.361458862816173, 2.278911987816171, 2.4283494878161704, 2.3587211050000008, 2.3651342835440565, 2.408286987816171, 2.4609901128161704, 1.298890625, -0.05494999999998061, 1.4571151128161945, 0.6378338628162254, 2.3807557378161706], "policy_red_1_reward": [0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985, 0.845, 0.9305000000000001, 0.494, 0.4955, 0.497, 0.485, 0.5, 0.5, 0.497, 0.4895, 0.4985, 0.497, 0.494, 0.491, 0.491, 0.497]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21718489541089422, "mean_inference_ms": 1.6204714792027624, "mean_action_processing_ms": 0.06536271939613303, "mean_env_wait_ms": 0.11897917653739036, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01857459545135498, "StateBufferConnector_ms": 0.0014510154724121094, "ViewRequirementAgentConnector_ms": 0.031148672103881836}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.43905000000007455, "episode_reward_mean": 2.440683694564973, "episode_len_mean": 412.85, "episodes_this_iter": 16, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9485}, "policy_reward_mean": {"red_0": 1.9239321844705424, "red_1": 0.5167515100944259}, "hist_stats": {"episode_reward": [2.9308807378161705, 2.543271362816176, 2.908021362816173, 2.2591406250000015, 1.72321875, 0.7836932378162789, 2.636521362816175, 2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618, 1.4258906249999996, 1.5443125, 2.87231823781617, 2.854677612816171, 2.858458862816173, 2.7639119878161704, 2.9283494878161704, 2.8587211050000008, 2.8621342835440564, 2.8977869878161706, 2.9594901128161704, 1.7958906250000002, 0.43905000000007455, 1.9481151128161942, 1.1288338628162775, 2.8777557378161704], "episode_lengths": [100, 551, 87, 115, 154, 1280, 439, 334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368, 451, 380, 184, 197, 171, 314, 110, 52, 182, 130, 65, 195, 1280, 1177, 1267, 172], "policy_red_0_reward": [2.4323807378161706, 2.0582713628161766, 2.4185213628161732, 1.7591406250000001, 0.7747187499999999, 0.29869323781622525, 2.1500213628161755, 2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618, 0.5808906249999999, 0.6138124999999999, 2.37831823781617, 2.359177612816171, 2.361458862816173, 2.278911987816171, 2.4283494878161704, 2.3587211050000008, 2.3651342835440565, 2.408286987816171, 2.4609901128161704, 1.298890625, -0.05494999999998061, 1.4571151128161945, 0.6378338628162254, 2.3807557378161706], "policy_red_1_reward": [0.4985, 0.485, 0.4895, 0.5, 0.9485, 0.485, 0.4865, 0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985, 0.845, 0.9305000000000001, 0.494, 0.4955, 0.497, 0.485, 0.5, 0.5, 0.497, 0.4895, 0.4985, 0.497, 0.494, 0.491, 0.491, 0.497]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21718489541089422, "mean_inference_ms": 1.6204714792027624, "mean_action_processing_ms": 0.06536271939613303, "mean_env_wait_ms": 0.11897917653739036, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01857459545135498, "StateBufferConnector_ms": 0.0014510154724121094, "ViewRequirementAgentConnector_ms": 0.031148672103881836}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.65396575062486, "num_env_steps_trained_throughput_per_sec": 55.65396575062486, "timesteps_total": 260000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 520000, "timers": {"training_iteration_time_ms": 72146.343, "sample_time_ms": 7883.901, "learn_time_ms": 64230.683, "learn_throughput": 62.276, "synch_weights_time_ms": 31.113}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "done": false, "episodes_total": 439, "training_iteration": 65, "trial_id": "b02c7_00000", "date": "2023-09-27_23-19-19", "timestamp": 1695871159, "time_this_iter_s": 71.87654209136963, "time_total_s": 4758.676845550537, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a42392d0>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a3f19e40>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a7e9dea0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4758.676845550537, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 37.57669902912622, "ram_util_percent": 35.90776699029125}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.87, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8114828879013658, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.026448852760828836, "policy_loss": -0.016046641576879968, "vf_loss": 4.217145936517378e-05, "vf_explained_var": 0.5078184110422929, "kl": 0.008553858392071744, "entropy": 1.2134068763504426, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5829881916443507, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010408370062699153, "policy_loss": -0.017848174891939076, "vf_loss": 0.012055164891353342, "vf_explained_var": 0.8528425416598717, "kl": 0.009076947206723552, "entropy": 0.6300906696977715, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.43905000000007455, "episode_reward_mean": 2.467076908193134, "episode_len_mean": 407.16, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9455000000000001}, "policy_reward_mean": {"red_0": 1.9545403980987042, "red_1": 0.5125365100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.87, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618, 1.4258906249999996, 1.5443125, 2.87231823781617, 2.854677612816171, 2.858458862816173, 2.7639119878161704, 2.9283494878161704, 2.8587211050000008, 2.8621342835440564, 2.8977869878161706, 2.9594901128161704, 1.7958906250000002, 0.43905000000007455, 1.9481151128161942, 1.1288338628162775, 2.8777557378161704, 1.3696932378162399, 2.94344323781617, 2.8621932378161707, 2.6437843750000005, 2.9566776128161703, 2.776333862816171, 2.8719432378161702], "episode_lengths": [334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368, 451, 380, 184, 197, 171, 314, 110, 52, 182, 130, 65, 195, 1280, 1177, 1267, 172, 1280, 80, 192, 53, 69, 307, 176], "policy_red_0_reward": [2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618, 0.5808906249999999, 0.6138124999999999, 2.37831823781617, 2.359177612816171, 2.361458862816173, 2.278911987816171, 2.4283494878161704, 2.3587211050000008, 2.3651342835440565, 2.408286987816171, 2.4609901128161704, 1.298890625, -0.05494999999998061, 1.4571151128161945, 0.6378338628162254, 2.3807557378161706, 0.8726932378162258, 2.4494432378161703, 2.366693237816171, 2.1437843750000005, 2.4581776128161703, 2.2808338628161713, 2.3809432378161706], "policy_red_1_reward": [0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985, 0.845, 0.9305000000000001, 0.494, 0.4955, 0.497, 0.485, 0.5, 0.5, 0.497, 0.4895, 0.4985, 0.497, 0.494, 0.491, 0.491, 0.497, 0.497, 0.494, 0.4955, 0.5, 0.4985, 0.4955, 0.491]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21709484383051592, "mean_inference_ms": 1.6199351038753484, "mean_action_processing_ms": 0.06531966375471124, "mean_env_wait_ms": 0.11893523721422762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018402457237243652, "StateBufferConnector_ms": 0.001456141471862793, "ViewRequirementAgentConnector_ms": 0.031151294708251953}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.43905000000007455, "episode_reward_mean": 2.467076908193134, "episode_len_mean": 407.16, "episodes_this_iter": 7, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9455000000000001}, "policy_reward_mean": {"red_0": 1.9545403980987042, "red_1": 0.5125365100944259}, "hist_stats": {"episode_reward": [2.676849487816179, 2.7980369878161717, 2.8508807378161767, 2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618, 1.4258906249999996, 1.5443125, 2.87231823781617, 2.854677612816171, 2.858458862816173, 2.7639119878161704, 2.9283494878161704, 2.8587211050000008, 2.8621342835440564, 2.8977869878161706, 2.9594901128161704, 1.7958906250000002, 0.43905000000007455, 1.9481151128161942, 1.1288338628162775, 2.8777557378161704, 1.3696932378162399, 2.94344323781617, 2.8621932378161707, 2.6437843750000005, 2.9566776128161703, 2.776333862816171, 2.8719432378161702], "episode_lengths": [334, 274, 132, 136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368, 451, 380, 184, 197, 171, 314, 110, 52, 182, 130, 65, 195, 1280, 1177, 1267, 172, 1280, 80, 192, 53, 69, 307, 176], "policy_red_0_reward": [2.1888494878161793, 2.2980369878161717, 2.353880737816177, 2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618, 0.5808906249999999, 0.6138124999999999, 2.37831823781617, 2.359177612816171, 2.361458862816173, 2.278911987816171, 2.4283494878161704, 2.3587211050000008, 2.3651342835440565, 2.408286987816171, 2.4609901128161704, 1.298890625, -0.05494999999998061, 1.4571151128161945, 0.6378338628162254, 2.3807557378161706, 0.8726932378162258, 2.4494432378161703, 2.366693237816171, 2.1437843750000005, 2.4581776128161703, 2.2808338628161713, 2.3809432378161706], "policy_red_1_reward": [0.488, 0.5, 0.497, 0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985, 0.845, 0.9305000000000001, 0.494, 0.4955, 0.497, 0.485, 0.5, 0.5, 0.497, 0.4895, 0.4985, 0.497, 0.494, 0.491, 0.491, 0.497, 0.497, 0.494, 0.4955, 0.5, 0.4985, 0.4955, 0.491]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21709484383051592, "mean_inference_ms": 1.6199351038753484, "mean_action_processing_ms": 0.06531966375471124, "mean_env_wait_ms": 0.11893523721422762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018402457237243652, "StateBufferConnector_ms": 0.001456141471862793, "ViewRequirementAgentConnector_ms": 0.031151294708251953}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.463121699018544, "num_env_steps_trained_throughput_per_sec": 55.463121699018544, "timesteps_total": 264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 72134.972, "sample_time_ms": 7880.473, "learn_time_ms": 64222.633, "learn_throughput": 62.283, "synch_weights_time_ms": 31.222}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "episodes_total": 446, "training_iteration": 66, "trial_id": "b02c7_00000", "date": "2023-09-27_23-20-31", "timestamp": 1695871231, "time_this_iter_s": 72.12367105484009, "time_total_s": 4830.800516605377, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x3574ffd60>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x3574fd6f0>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a3578160>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4830.800516605377, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 37.78349514563107, "ram_util_percent": 35.86601941747573}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.87, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "episode_media": {}, "info": {"learner": {"red_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7541551059111953, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.030204009187218616, "policy_loss": -0.02054977383474276, "vf_loss": 2.6018411585463733e-05, "vf_explained_var": 0.051469704632957775, "kl": 0.010426207180657891, "entropy": 1.175248576203982, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3983824246873457, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01229179962380537, "policy_loss": -0.0166251749493919, "vf_loss": 0.005142191779304995, "vf_explained_var": 0.7671912459656596, "kl": 0.01078739337837078, "entropy": 0.664883901985983, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "sampler_results": {"episode_reward_max": 2.97605261281617, "episode_reward_min": 0.43905000000007455, "episode_reward_mean": 2.449110501943135, "episode_len_mean": 422.33, "episode_media": {}, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9455000000000001}, "policy_reward_mean": {"red_0": 1.936813991848705, "red_1": 0.5122965100944259}, "custom_metrics": {"red_0/door_open_done_mean": 0.87, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.0, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 0, "red_0/got_eliminated_done_mean": 0.0, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 0, "red_0/eliminated_opponent_num_mean": 0.0, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 0, "red_1/door_open_done_mean": 0.0, "red_1/door_open_done_min": 0, "red_1/door_open_done_max": 0, "red_1/eliminated_opponents_done_mean": 0.0, "red_1/eliminated_opponents_done_min": 0, "red_1/eliminated_opponents_done_max": 0, "red_1/got_eliminated_done_mean": 0.0, "red_1/got_eliminated_done_min": 0, "red_1/got_eliminated_done_max": 0, "red_1/eliminated_opponent_num_mean": 0.0, "red_1/eliminated_opponent_num_min": 0, "red_1/eliminated_opponent_num_max": 0}, "hist_stats": {"episode_reward": [2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618, 1.4258906249999996, 1.5443125, 2.87231823781617, 2.854677612816171, 2.858458862816173, 2.7639119878161704, 2.9283494878161704, 2.8587211050000008, 2.8621342835440564, 2.8977869878161706, 2.9594901128161704, 1.7958906250000002, 0.43905000000007455, 1.9481151128161942, 1.1288338628162775, 2.8777557378161704, 1.3696932378162399, 2.94344323781617, 2.8621932378161707, 2.6437843750000005, 2.9566776128161703, 2.776333862816171, 2.8719432378161702, 1.861786987816223, 2.3955682378161947, 2.2717713628161866], "episode_lengths": [136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368, 451, 380, 184, 197, 171, 314, 110, 52, 182, 130, 65, 195, 1280, 1177, 1267, 172, 1280, 80, 192, 53, 69, 307, 176, 898, 552, 807], "policy_red_0_reward": [2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618, 0.5808906249999999, 0.6138124999999999, 2.37831823781617, 2.359177612816171, 2.361458862816173, 2.278911987816171, 2.4283494878161704, 2.3587211050000008, 2.3651342835440565, 2.408286987816171, 2.4609901128161704, 1.298890625, -0.05494999999998061, 1.4571151128161945, 0.6378338628162254, 2.3807557378161706, 0.8726932378162258, 2.4494432378161703, 2.366693237816171, 2.1437843750000005, 2.4581776128161703, 2.2808338628161713, 2.3809432378161706, 1.387286987816224, 1.8955682378161947, 1.7852713628161871], "policy_red_1_reward": [0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985, 0.845, 0.9305000000000001, 0.494, 0.4955, 0.497, 0.485, 0.5, 0.5, 0.497, 0.4895, 0.4985, 0.497, 0.494, 0.491, 0.491, 0.497, 0.497, 0.494, 0.4955, 0.5, 0.4985, 0.4955, 0.491, 0.4745, 0.5, 0.4865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21698097227549876, "mean_inference_ms": 1.61937380826016, "mean_action_processing_ms": 0.06528505458392356, "mean_env_wait_ms": 0.1188820797894241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018344402313232422, "StateBufferConnector_ms": 0.0014537572860717773, "ViewRequirementAgentConnector_ms": 0.031102657318115234}}, "episode_reward_max": 2.97605261281617, "episode_reward_min": 0.43905000000007455, "episode_reward_mean": 2.449110501943135, "episode_len_mean": 422.33, "episodes_this_iter": 3, "policy_reward_min": {"red_0": -0.1370000000000001, "red_1": 0.4715}, "policy_reward_max": {"red_0": 2.47605261281617, "red_1": 0.9455000000000001}, "policy_reward_mean": {"red_0": 1.936813991848705, "red_1": 0.5122965100944259}, "hist_stats": {"episode_reward": [2.90606823781617, 2.741646362816178, 2.819552612816172, 1.7691925427729638, 1.8276932378161856, 2.892740112816171, 2.917849487816171, 2.843174230000001, 2.7150057378161745, 0.8076932378162782, 2.909224487816171, 1.6453750000000198, 2.3041875000000003, 2.1728468750000145, 2.843771362816171, 0.793193237816279, 2.954286987815204, 2.958505737815204, 2.9403338628161704, 2.908193237816171, 1.15822448781628, 2.8303963628161743, 1.8806932378161827, 2.8647244878161726, 2.7927088628161707, 2.064396362816206, 2.97605261281617, 2.7443026128161714, 1.842193237816185, 2.7439276128161745, 2.3060369878161895, 2.9253807378161705, 2.93809948781617, 2.7723807378161793, 2.892036987816171, 2.6343468750000003, 0.8461932378162791, 0.8085000000000001, 2.7185682378161706, 2.9708338628161703, 2.8211307378161767, 2.8008487927729475, 2.829418989442594, 2.93850573781617, 2.747599487816171, 2.893208167772942, 1.916193237816179, 1.2501932378162515, 2.5943494878161744, 2.9252557378161708, 1.7243125, 2.9087713628161698, 1.75615625, 2.853161987816171, 1.5019062500000362, 2.9172088628161705, 2.9716499085440553, 1.4185031250000457, 2.386802612816203, 2.6884346144425955, 2.83694323781617, 2.7915526128161705, 2.765411987815211, 2.9586932378161706, 2.6473963628161714, 2.6560127394425934, 2.6211619878161736, 2.902521362816172, 2.823064855, 1.9336932378161777, 2.95747448781617, 2.5314711050000014, 2.6371750000000005, 2.65544323781618, 1.4258906249999996, 1.5443125, 2.87231823781617, 2.854677612816171, 2.858458862816173, 2.7639119878161704, 2.9283494878161704, 2.8587211050000008, 2.8621342835440564, 2.8977869878161706, 2.9594901128161704, 1.7958906250000002, 0.43905000000007455, 1.9481151128161942, 1.1288338628162775, 2.8777557378161704, 1.3696932378162399, 2.94344323781617, 2.8621932378161707, 2.6437843750000005, 2.9566776128161703, 2.776333862816171, 2.8719432378161702, 1.861786987816223, 2.3955682378161947, 2.2717713628161866], "episode_lengths": [136, 271, 237, 1280, 1280, 145, 110, 67, 348, 1280, 118, 744, 68, 513, 199, 1280, 66, 60, 83, 128, 1174, 191, 1280, 150, 283, 863, 45, 349, 1280, 309, 722, 100, 94, 196, 146, 65, 1280, 1280, 392, 51, 180, 206, 197, 92, 350, 155, 1280, 1280, 526, 108, 284, 135, 174, 202, 734, 123, 49, 1199, 445, 352, 240, 301, 250, 64, 479, 455, 490, 119, 102, 1280, 70, 484, 56, 368, 451, 380, 184, 197, 171, 314, 110, 52, 182, 130, 65, 195, 1280, 1177, 1267, 172, 1280, 80, 192, 53, 69, 307, 176, 898, 552, 807], "policy_red_0_reward": [2.4090682378161703, 2.246146362816178, 2.324052612816172, 1.297692542772965, 1.354693237816187, 2.395740112816171, 2.419349487816171, 2.343174230000001, 2.2210057378161747, 0.3286932378162253, 2.413724487816171, 1.1498749999999998, 1.8041874999999998, 1.686346875000015, 2.3527713628161715, 0.30669323781622526, 2.4572869878152046, 2.4615057378152043, 2.4433338628161705, 2.409693237816171, 0.6642244878162253, 2.3333963628161745, 1.386693237816183, 2.375224487816173, 2.298708862816171, 1.5718963628162061, 2.47605261281617, 2.2503026128161716, 1.3646932378161853, 2.2484276128161746, 1.81803698781619, 2.4313807378161707, 2.43959948781617, 2.2828807378161797, 2.3950369878161712, 2.1343468750000003, 0.3596932378162253, -0.1370000000000001, 2.223068237816171, 2.4708338628161703, 2.3211307378161767, 2.306848792772948, 2.242767980000002, 2.44000573781617, 2.2505994878161713, 2.3947081677729423, 1.4236932378161793, 0.7636932378162257, 2.0988494878161745, 2.426755737816171, 1.2243125, 2.41177136281617, 0.81065625, 2.354661987816171, 1.0079062499999996, 2.4172088628161705, 2.4716499085440553, 0.92300312500002, 1.8928026128162032, 2.1914346144425956, 2.33694323781617, 2.2930526128161706, 2.2669119878152113, 2.4586932378161706, 2.1548963628161717, 2.1590127394425935, 2.130161987816174, 2.404021362816172, 2.324564855, 1.4366932378161779, 2.45747448781617, 2.041971105000002, 2.1386750000000005, 2.15694323781618, 0.5808906249999999, 0.6138124999999999, 2.37831823781617, 2.359177612816171, 2.361458862816173, 2.278911987816171, 2.4283494878161704, 2.3587211050000008, 2.3651342835440565, 2.408286987816171, 2.4609901128161704, 1.298890625, -0.05494999999998061, 1.4571151128161945, 0.6378338628162254, 2.3807557378161706, 0.8726932378162258, 2.4494432378161703, 2.366693237816171, 2.1437843750000005, 2.4581776128161703, 2.2808338628161713, 2.3809432378161706, 1.387286987816224, 1.8955682378161947, 1.7852713628161871], "policy_red_1_reward": [0.497, 0.4955, 0.4955, 0.4715, 0.473, 0.497, 0.4985, 0.5, 0.494, 0.479, 0.4955, 0.4955, 0.5, 0.4865, 0.491, 0.4865, 0.497, 0.497, 0.497, 0.4985, 0.494, 0.497, 0.494, 0.4895, 0.494, 0.4925, 0.5, 0.494, 0.4775, 0.4955, 0.488, 0.494, 0.4985, 0.4895, 0.497, 0.5, 0.4865, 0.9455000000000001, 0.4955, 0.5, 0.5, 0.494, 0.5866510094425922, 0.4985, 0.497, 0.4985, 0.4925, 0.4865, 0.4955, 0.4985, 0.5, 0.497, 0.9455, 0.4985, 0.494, 0.5, 0.5, 0.4955, 0.494, 0.497, 0.5, 0.4985, 0.4985, 0.5, 0.4925, 0.497, 0.491, 0.4985, 0.4985, 0.497, 0.5, 0.4895, 0.4985, 0.4985, 0.845, 0.9305000000000001, 0.494, 0.4955, 0.497, 0.485, 0.5, 0.5, 0.497, 0.4895, 0.4985, 0.497, 0.494, 0.491, 0.491, 0.497, 0.497, 0.494, 0.4955, 0.5, 0.4985, 0.4955, 0.491, 0.4745, 0.5, 0.4865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21698097227549876, "mean_inference_ms": 1.61937380826016, "mean_action_processing_ms": 0.06528505458392356, "mean_env_wait_ms": 0.1188820797894241, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018344402313232422, "StateBufferConnector_ms": 0.0014537572860717773, "ViewRequirementAgentConnector_ms": 0.031102657318115234}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.28205672753028, "num_env_steps_trained_throughput_per_sec": 55.28205672753028, "timesteps_total": 268000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 536000, "timers": {"training_iteration_time_ms": 72089.069, "sample_time_ms": 7873.719, "learn_time_ms": 64183.373, "learn_throughput": 62.321, "synch_weights_time_ms": 31.33}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "done": false, "episodes_total": 449, "training_iteration": 67, "trial_id": "b02c7_00000", "date": "2023-09-27_23-21-44", "timestamp": 1695871304, "time_this_iter_s": 72.3599910736084, "time_total_s": 4903.160507678986, "pid": 70563, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-CTDE-Red", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": true, "teams": {"red": 2}, "agents": 2, "training_scheme": "CTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "red_1": {"eliminated_opponent_sparse_reward": 0.0, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.0015}}, "randomization": false, "policies_map": {"red_0": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy.YourPolicyName_Policy object at 0x2a4091f30>", "red_1": "<multigrid.agents_pool.YourName_policies.YourPolicyName_policy_v2.YourPolicyNameV2_Policy object at 0x2a4092140>"}, "team_policies_mapping": {"red_0": "your_policy_name", "red_1": "your_policy_name_v2"}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchCentralizedCriticModel'>", "custom_model_config": {"teams": {"red": 2}, "training_scheme": "CTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"red_0": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "sgd_minibatch_size": 128, "num_sgd_iter": 30}], "red_1": [null, null, null, {"lr": 5e-05, "gamma": 0.99, "lambda_": 0.99, "kl_coeff": 0.2, "kl_target": 0.01, "clip_param": 0.3, "grad_clip": null, "vf_clip_param": 10.0, "vf_loss_coeff": 0.5, "entropy_coeff": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30}]}, "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a357b9a0>", "policies_to_train": ["red_0", "red_1"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 4903.160507678986, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 38.21844660194174, "ram_util_percent": 36.15145631067961}}
